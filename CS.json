[
    {
        "title": "Policy Gradient RL Algorithms as Directed Acyclic Graphs",
        "Published: ": "2020-12-14T17:59:26Z",
        "abstract": "Meta Reinforcement Learning (RL) methods focus on automating the design of RL\nalgorithms that generalize to a wide range of environments. The framework\nintroduced in (Anonymous, 2020) addresses the problem by representing different\nRL algorithms as Directed Acyclic Graphs (DAGs), and using an evolutionary meta\nlearner to modify these graphs and find good agent update rules. While the\nsearch language used to generate graphs in the paper serves to represent\nnumerous already-existing RL algorithms (e.g., DQN, DDQN), it has limitations\nwhen it comes to representing Policy Gradient algorithms. In this work we try\nto close this gap by extending the original search language and proposing\ngraphs for five different Policy Gradient algorithms: VPG, PPO, DDPG, TD3, and\nSAC.",
        "author": [
            "Juan Jose Garau Luis"
        ],
        "pdfLink": "http://arxiv.org/pdf/2012.07763v2.pdf",
        "Categories": [
            [
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2012.07763v2",
        "arXiv ID": "2012.07763v2"
    },
    {
        "title": "Interpretable End-to-end Urban Autonomous Driving with Latent Deep\n  Reinforcement Learning",
        "Published: ": "2020-01-23T18:36:35Z",
        "abstract": "Unlike popular modularized framework, end-to-end autonomous driving seeks to\nsolve the perception, decision and control problems in an integrated way, which\ncan be more adapting to new scenarios and easier to generalize at scale.\nHowever, existing end-to-end approaches are often lack of interpretability, and\ncan only deal with simple driving tasks like lane keeping. In this paper, we\npropose an interpretable deep reinforcement learning method for end-to-end\nautonomous driving, which is able to handle complex urban scenarios. A\nsequential latent environment model is introduced and learned jointly with the\nreinforcement learning process. With this latent model, a semantic birdeye mask\ncan be generated, which is enforced to connect with a certain intermediate\nproperty in today's modularized framework for the purpose of explaining the\nbehaviors of learned policy. The latent space also significantly reduces the\nsample complexity of reinforcement learning. Comparison tests with a simulated\nautonomous car in CARLA show that the performance of our method in urban\nscenarios with crowded surrounding vehicles dominates many baselines including\nDQN, DDPG, TD3 and SAC. Moreover, through masked outputs, the learned policy is\nable to provide a better explanation of how the car reasons about the driving\nenvironment. The codes and videos of this work are available at our github repo\nand project website.",
        "author": [
            "Jianyu Chen",
            "Shengbo Eben Li",
            "Masayoshi Tomizuka"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.08726v3.pdf",
        "Categories": [
            [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.08726v3",
        "arXiv ID": "2001.08726v3"
    },
    {
        "title": "Enhancing data efficiency in reinforcement learning: a novel imagination\n  mechanism based on mesh information propagation",
        "Published: ": "2023-09-25T16:03:08Z",
        "abstract": "Reinforcement learning(RL) algorithms face the challenge of limited data\nefficiency, particularly when dealing with high-dimensional state spaces and\nlarge-scale problems. Most of RL methods often rely solely on state transition\ninformation within the same episode when updating the agent's Critic, which can\nlead to low data efficiency and sub-optimal training time consumption. Inspired\nby human-like analogical reasoning abilities, we introduce a novel mesh\ninformation propagation mechanism, termed the 'Imagination Mechanism (IM)',\ndesigned to significantly enhance the data efficiency of RL algorithms.\nSpecifically, IM enables information generated by a single sample to be\neffectively broadcasted to different states across episodes, instead of simply\ntransmitting in the same episode. This capability enhances the model's\ncomprehension of state interdependencies and facilitates more efficient\nlearning of limited sample information. To promote versatility, we extend the\nIM to function as a plug-and-play module that can be seamlessly and fluidly\nintegrated into other widely adopted RL algorithms. Our experiments demonstrate\nthat IM consistently boosts four mainstream SOTA RL algorithms, such as SAC,\nPPO, DDPG, and DQN, by a considerable margin, ultimately leading to superior\nperformance than before across various tasks. For access to our code and data,\nplease visit https://github.com/OuAzusaKou/imagination_mechanism",
        "author": [
            "Zihang Wang",
            "Maowei Jiang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.14243v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.14243v2",
        "arXiv ID": "2309.14243v2"
    },
    {
        "title": "Hybrid Reinforcement Learning for STAR-RISs: A Coupled Phase-Shift Model\n  Based Beamformer",
        "Published: ": "2022-05-10T16:41:54Z",
        "abstract": "A simultaneous transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) assisted multi-user downlink multiple-input single-output (MISO)\ncommunication system is investigated. In contrast to the existing ideal\nSTAR-RIS model assuming an independent transmission and reflection phase-shift\ncontrol, a practical coupled phase-shift model is considered. Then, a joint\nactive and passive beamforming optimization problem is formulated for\nminimizing the long-term transmission power consumption, subject to the coupled\nphase-shift constraint and the minimum data rate constraint. Despite the\ncoupled nature of the phase-shift model, the formulated problem is solved by\ninvoking a hybrid continuous and discrete phase-shift control policy. Inspired\nby this observation, a pair of hybrid reinforcement learning (RL) algorithms,\nnamely the hybrid deep deterministic policy gradient (hybrid DDPG) algorithm\nand the joint DDPG & deep-Q network (DDPG-DQN) based algorithm are proposed.\nThe hybrid DDPG algorithm controls the associated high-dimensional continuous\nand discrete actions by relying on the hybrid action mapping. By contrast, the\njoint DDPG-DQN algorithm constructs two Markov decision processes (MDPs)\nrelying on an inner and an outer environment, thereby amalgamating the two\nagents to accomplish a joint hybrid control. Simulation results demonstrate\nthat the STAR-RIS has superiority over other conventional RISs in terms of its\nenergy consumption. Furthermore, both the proposed algorithms outperform the\nbaseline DDPG algorithm, and the joint DDPG-DQN algorithm achieves a superior\nperformance, albeit at an increased computational complexity.",
        "author": [
            "Ruikang Zhong",
            "Yuanwei Liu",
            "Xidong Mu",
            "Yue Chen",
            "Xianbin Wang",
            "Lajos Hanzo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.05029v1.pdf",
        "Categories": [
            [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.05029v1",
        "arXiv ID": "2205.05029v1"
    },
    {
        "title": "Deep Reinforcement Learning Based Dynamic Power and Beamforming Design\n  for Time-Varying Wireless Downlink Interference Channel",
        "Published: ": "2020-11-07T14:23:44Z",
        "abstract": "With the high development of wireless communication techniques, it is widely\nused in various fields for convenient and efficient data transmission.\nDifferent from commonly used assumption of the time-invariant wireless channel,\nwe focus on the research on the time-varying wireless downlink channel to get\nclose to the practical situation. Our objective is to gain the maximum value of\nsum rate in the time-varying channel under the some constraints about cut-off\nsignal-to-interference and noise ratio (SINR), transmitted power and\nbeamforming. In order to adapt the rapid changing channel, we abandon the\nfrequently used algorithm convex optimization and deep reinforcement learning\nalgorithms are used in this paper. From the view of the ordinary measures such\nas power control, interference incoordination and beamforming, continuous\nchanges of measures should be put into consideration while sparse reward\nproblem due to the abortion of episodes as an important bottleneck should not\nbe ignored. Therefore, with the analysis of relevant algorithms, we proposed\ntwo algorithms, Deep Deterministic Policy Gradient algorithm (DDPG) and\nhierarchical DDPG, in our work. As for these two algorithms, in order to solve\nthe discrete output, DDPG is established by combining the Actor-Critic\nalgorithm with Deep Q-learning (DQN), so that it can output the continuous\nactions without sacrificing the existed advantages brought by DQN and also can\nimprove the performance. Also, to address the challenge of sparse reward, we\ntake advantage of meta policy from the idea of hierarchical theory to divide\none agent in DDPG into one meta-controller and one controller as hierarchical\nDDPG. Our simulation results demonstrate that the proposed DDPG and\nhierarchical DDPG performs well from the views of coverage, convergence and sum\nrate performance.",
        "author": [
            "Mengfan Liu",
            "Rui Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.03780v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.03780v1",
        "arXiv ID": "2011.03780v1"
    },
    {
        "title": "$\\mathrm{SO}(2)$-Equivariant Reinforcement Learning",
        "Published: ": "2022-03-08T23:09:25Z",
        "abstract": "Equivariant neural networks enforce symmetry within the structure of their\nconvolutional layers, resulting in a substantial improvement in sample\nefficiency when learning an equivariant or invariant function. Such models are\napplicable to robotic manipulation learning which can often be formulated as a\nrotationally symmetric problem. This paper studies equivariant model\narchitectures in the context of $Q$-learning and actor-critic reinforcement\nlearning. We identify equivariant and invariant characteristics of the optimal\n$Q$-function and the optimal policy and propose equivariant DQN and SAC\nalgorithms that leverage this structure. We present experiments that\ndemonstrate that our equivariant versions of DQN and SAC can be significantly\nmore sample efficient than competing algorithms on an important class of\nrobotic manipulation problems.",
        "author": [
            "Dian Wang",
            "Robin Walters",
            "Robert Platt"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.04439v1.pdf",
        "Categories": [
            [
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.04439v1",
        "arXiv ID": "2203.04439v1"
    },
    {
        "title": "Deep Reinforcement Learning-based UAV Navigation and Control: A Soft\n  Actor-Critic with Hindsight Experience Replay Approach",
        "Published: ": "2021-06-02T08:30:14Z",
        "abstract": "In this paper, we propose SACHER (soft actor-critic (SAC) with hindsight\nexperience replay (HER)), which constitutes a class of deep reinforcement\nlearning (DRL) algorithms. SAC is known as an off-policy model-free DRL\nalgorithm based on the maximum entropy framework, which outperforms earlier DRL\nalgorithms in terms of exploration, robustness and learning performance.\nHowever, in SAC, maximizing the entropy-augmented objective may degrade the\noptimality of learning outcomes. HER is known as a sample-efficient replay\nmethod that enhances the performance of off-policy DRL algorithms by allowing\nthe agent to learn from both failures and successes. We apply HER to SAC and\npropose SACHER to improve the learning performance of SAC. More precisely,\nSACHER achieves the desired optimal outcomes faster and more accurately than\nSAC, since HER improves the sample efficiency of SAC. We apply SACHER to the\nnavigation and control problem of unmanned aerial vehicles (UAVs), where SACHER\ngenerates the optimal navigation path of the UAV under various obstacles in\noperation. Specifically, we show the effectiveness of SACHER in terms of the\ntracking error and cumulative reward in UAV operation by comparing them with\nthose of state-of-the-art DRL algorithms, SAC and DDPG. Note that SACHER in UAV\nnavigation and control problems can be applied to arbitrary models of UAVs.",
        "author": [
            "Myoung Hoon Lee",
            "Jun Moon"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.01016v2.pdf",
        "Categories": [
            [
                "eess.SY",
                "cs.LG",
                "cs.RO",
                "cs.SY",
                "60J20, 68T05"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.01016v2",
        "arXiv ID": "2106.01016v2"
    },
    {
        "title": "FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading\n  in Quantitative Finance",
        "Published: ": "2020-11-19T01:35:05Z",
        "abstract": "As deep reinforcement learning (DRL) has been recognized as an effective\napproach in quantitative finance, getting hands-on experiences is attractive to\nbeginners. However, to train a practical DRL trading agent that decides where\nto trade, at what price, and what quantity involves error-prone and arduous\ndevelopment and debugging. In this paper, we introduce a DRL library FinRL that\nfacilitates beginners to expose themselves to quantitative finance and to\ndevelop their own stock trading strategies. Along with easily-reproducible\ntutorials, FinRL library allows users to streamline their own developments and\nto compare with existing schemes easily. Within FinRL, virtual environments are\nconfigured with stock market datasets, trading agents are trained with neural\nnetworks, and extensive backtesting is analyzed via trading performance.\nMoreover, it incorporates important trading constraints such as transaction\ncost, market liquidity and the investor's degree of risk-aversion. FinRL is\nfeatured with completeness, hands-on tutorial and reproducibility that favors\nbeginners: (i) at multiple levels of time granularity, FinRL simulates trading\nenvironments across various stock markets, including NASDAQ-100, DJIA, S&P 500,\nHSI, SSE 50, and CSI 300; (ii) organized in a layered architecture with modular\nstructure, FinRL provides fine-tuned state-of-the-art DRL algorithms (DQN,\nDDPG, PPO, SAC, A2C, TD3, etc.), commonly-used reward functions and standard\nevaluation baselines to alleviate the debugging workloads and promote the\nreproducibility, and (iii) being highly extendable, FinRL reserves a complete\nset of user-import interfaces. Furthermore, we incorporated three application\ndemonstrations, namely single stock trading, multiple stock trading, and\nportfolio allocation. The FinRL library will be available on Github at link\nhttps://github.com/AI4Finance-LLC/FinRL-Library.",
        "author": [
            "Xiao-Yang Liu",
            "Hongyang Yang",
            "Qian Chen",
            "Runjia Zhang",
            "Liuqing Yang",
            "Bowen Xiao",
            "Christina Dan Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.09607v2.pdf",
        "Categories": [
            [
                "q-fin.TR",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.09607v2",
        "arXiv ID": "2011.09607v2"
    },
    {
        "title": "SAC-AP: Soft Actor Critic based Deep Reinforcement Learning for Alert\n  Prioritization",
        "Published: ": "2022-07-27T17:33:18Z",
        "abstract": "Intrusion detection systems (IDS) generate a large number of false alerts\nwhich makes it difficult to inspect true positives. Hence, alert prioritization\nplays a crucial role in deciding which alerts to investigate from an enormous\nnumber of alerts that are generated by IDS. Recently, deep reinforcement\nlearning (DRL) based deep deterministic policy gradient (DDPG) off-policy\nmethod has shown to achieve better results for alert prioritization as compared\nto other state-of-the-art methods. However, DDPG is prone to the problem of\noverfitting. Additionally, it also has a poor exploration capability and hence\nit is not suitable for problems with a stochastic environment. To address these\nlimitations, we present a soft actor-critic based DRL algorithm for alert\nprioritization (SAC-AP), an off-policy method, based on the maximum entropy\nreinforcement learning framework that aims to maximize the expected reward\nwhile also maximizing the entropy. Further, the interaction between an\nadversary and a defender is modeled as a zero-sum game and a double oracle\nframework is utilized to obtain the approximate mixed strategy Nash equilibrium\n(MSNE). SAC-AP finds robust alert investigation policies and computes pure\nstrategy best response against opponent's mixed strategy. We present the\noverall design of SAC-AP and evaluate its performance as compared to other\nstate-of-the art alert prioritization methods. We consider defender's loss,\ni.e., the defender's inability to investigate the alerts that are triggered due\nto attacks, as the performance metric. Our results show that SAC-AP achieves up\nto 30% decrease in defender's loss as compared to the DDPG based alert\nprioritization method and hence provides better protection against intrusions.\nMoreover, the benefits are even higher when SAC-AP is compared to other\ntraditional alert prioritization methods including Uniform, GAIN, RIO and\nSuricata.",
        "author": [
            "Lalitha Chavali",
            "Tanay Gupta",
            "Paresh Saxena"
        ],
        "pdfLink": "http://arxiv.org/pdf/2207.13666v3.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2207.13666v3",
        "arXiv ID": "2207.13666v3"
    },
    {
        "title": "Randomized Value Functions via Multiplicative Normalizing Flows",
        "Published: ": "2018-06-06T17:32:24Z",
        "abstract": "Randomized value functions offer a promising approach towards the challenge\nof efficient exploration in complex environments with high dimensional state\nand action spaces. Unlike traditional point estimate methods, randomized value\nfunctions maintain a posterior distribution over action-space values. This\nprevents the agent's behavior policy from prematurely exploiting early\nestimates and falling into local optima. In this work, we leverage recent\nadvances in variational Bayesian neural networks and combine these with\ntraditional Deep Q-Networks (DQN) and Deep Deterministic Policy Gradient (DDPG)\nto achieve randomized value functions for high-dimensional domains. In\nparticular, we augment DQN and DDPG with multiplicative normalizing flows in\norder to track a rich approximate posterior distribution over the parameters of\nthe value function. This allows the agent to perform approximate Thompson\nsampling in a computationally efficient manner via stochastic gradient methods.\nWe demonstrate the benefits of our approach through an empirical comparison in\nhigh dimensional environments.",
        "author": [
            "Ahmed Touati",
            "Harsh Satija",
            "Joshua Romoff",
            "Joelle Pineau",
            "Pascal Vincent"
        ],
        "pdfLink": "http://arxiv.org/pdf/1806.02315v3.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1806.02315v3",
        "arXiv ID": "1806.02315v3"
    },
    {
        "title": "Personalized Cancer Chemotherapy Schedule: a numerical comparison of\n  performance and robustness in model-based and model-free scheduling\n  methodologies",
        "Published: ": "2019-04-02T03:52:08Z",
        "abstract": "Reinforcement learning algorithms are gaining popularity in fields in which\noptimal scheduling is important, and oncology is not an exception. The complex\nand uncertain dynamics of cancer limit the performance of traditional\nmodel-based scheduling strategies like Optimal Control. Motivated by the recent\nsuccess of model-free Deep Reinforcement Learning (DRL) in challenging control\ntasks and in the design of medical treatments, we use Deep Q-Network (DQN) and\nDeep Deterministic Policy Gradient (DDPG) to design a personalized cancer\nchemotherapy schedule. We show that both of them succeed in the task and\noutperform the Optimal Control solution in the presence of uncertainty.\nFurthermore, we show that DDPG can exterminate cancer more efficiently than DQN\npresumably due to its continuous action space. Finally, we provide some insight\nregarding the amount of samples required for the training.",
        "author": [
            "Jesus Tordesillas",
            "Juncal Arbelaiz"
        ],
        "pdfLink": "http://arxiv.org/pdf/1904.01200v3.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1904.01200v3",
        "arXiv ID": "1904.01200v3"
    },
    {
        "title": "Some approaches used to overcome overestimation in Deep Reinforcement\n  Learning algorithms",
        "Published: ": "2020-06-25T04:24:26Z",
        "abstract": "Some phenomena related to statistical noise which have been investigated by\nvarious authors under the framework of deep reinforcement learning (RL)\nalgorithms are discussed. The following algorithms are examined: the deep\nQ-network (DQN), double DQN, deep deterministic policy gradient (DDPG),\ntwin-delayed DDPG (TD3), and hill climbing algorithm. First, we consider\noverestimation, which is a harmful property resulting from noise. Then we deal\nwith noise used for exploration, this is the useful noise. We discuss setting\nthe noise parameter in the TD3 for typical PyBullet environments associated\nwith articulate bodies such as HopperBulletEnv and Walker2DBulletEnv. In the\nappendix, in relation to the hill climbing algorithm, another example related\nto noise is considered - an example of adaptive noise.",
        "author": [
            "Rafael Stekolshchik"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.14167v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML",
                "68T07",
                "I.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.14167v2",
        "arXiv ID": "2006.14167v2"
    },
    {
        "title": "AI-based Robust Resource Allocation in End-to-End Network Slicing under\n  Demand and CSI Uncertainties",
        "Published: ": "2022-02-10T16:35:04Z",
        "abstract": "Network slicing (NwS) is one of the main technologies in the fifth-generation\nof mobile communication and beyond (5G+). One of the important challenges in\nthe NwS is information uncertainty which mainly involves demand and channel\nstate information (CSI). Demand uncertainty is divided into three types: number\nof users requests, amount of bandwidth, and requested virtual network functions\nworkloads. Moreover, the CSI uncertainty is modeled by three methods:\nworst-case, probabilistic, and hybrid. In this paper, our goal is to maximize\nthe utility of the infrastructure provider by exploiting deep reinforcement\nlearning algorithms in end-to-end NwS resource allocation under demand and CSI\nuncertainties. The proposed formulation is a nonconvex mixed-integer non-linear\nprogramming problem. To perform robust resource allocation in problems that\ninvolve uncertainty, we need a history of previous information. To this end, we\nuse a recurrent deterministic policy gradient (RDPG) algorithm, a recurrent and\nmemory-based approach in deep reinforcement learning. Then, we compare the RDPG\nmethod in different scenarios with soft actor-critic (SAC), deep deterministic\npolicy gradient (DDPG), distributed, and greedy algorithms. The simulation\nresults show that the SAC method is better than the DDPG, distributed, and\ngreedy methods, respectively. Moreover, the RDPG method out performs the SAC\napproach on average by 70%.",
        "author": [
            "Amir Gharehgoli",
            "Ali Nouruzi",
            "Nader Mokari",
            "Paeiz Azmi",
            "Mohamad Reza Javan",
            "Eduard A. Jorswieck"
        ],
        "pdfLink": "http://arxiv.org/pdf/2202.05131v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2202.05131v1",
        "arXiv ID": "2202.05131v1"
    },
    {
        "title": "Dynamic Experience Replay",
        "Published: ": "2020-03-04T23:46:45Z",
        "abstract": "We present a novel technique called Dynamic Experience Replay (DER) that\nallows Reinforcement Learning (RL) algorithms to use experience replay samples\nnot only from human demonstrations but also successful transitions generated by\nRL agents during training and therefore improve training efficiency. It can be\ncombined with an arbitrary off-policy RL algorithm, such as DDPG or DQN, and\ntheir distributed versions. We build upon Ape-X DDPG and demonstrate our\napproach on robotic tight-fitting joint assembly tasks, based on force/torque\nand Cartesian pose observations. In particular, we run experiments on two\ndifferent tasks: peg-in-hole and lap-joint. In each case, we compare different\nreplay buffer structures and how DER affects them. Our ablation studies show\nthat Dynamic Experience Replay is a crucial ingredient that either largely\nshortens the training time in these challenging environments or solves the\ntasks that the vanilla Ape-X DDPG cannot solve. We also show that our policies\nlearned purely in simulation can be deployed successfully on the real robot.\nThe video presenting our experiments is available at\nhttps://sites.google.com/site/dynamicexperiencereplay",
        "author": [
            "Jieliang Luo",
            "Hui Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.02372v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.02372v1",
        "arXiv ID": "2003.02372v1"
    },
    {
        "title": "Multi-Agent Path Planning based on MPC and DDPG",
        "Published: ": "2021-02-26T02:57:13Z",
        "abstract": "The problem of mixed static and dynamic obstacle avoidance is essential for\npath planning in highly dynamic environment. However, the paths formed by grid\nedges can be longer than the true shortest paths in the terrain since their\nheadings are artificially constrained. Existing methods can hardly deal with\ndynamic obstacles. To address this problem, we propose a new algorithm\ncombining Model Predictive Control (MPC) with Deep Deterministic Policy\nGradient (DDPG). Firstly, we apply the MPC algorithm to predict the trajectory\nof dynamic obstacles. Secondly, the DDPG with continuous action space is\ndesigned to provide learning and autonomous decision-making capability for\nrobots. Finally, we introduce the idea of the Artificial Potential Field to set\nthe reward function to improve convergence speed and accuracy. We employ Unity\n3D to perform simulation experiments in highly uncertain environment such as\naircraft carrier decks and squares. The results show that our method has made\ngreat improvement on accuracy by 7%-30% compared with the other methods, and on\nthe length of the path and turning angle by reducing 100 units and 400-450\ndegrees compared with DQN (Deep Q Network), respectively.",
        "author": [
            "Junxiao Xue",
            "Xiangyan Kong",
            "Bowei Dong",
            "Mingliang Xu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.13283v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.13283v1",
        "arXiv ID": "2102.13283v1"
    },
    {
        "title": "Decentralized Computation Offloading for Multi-User Mobile Edge\n  Computing: A Deep Reinforcement Learning Approach",
        "Published: ": "2018-12-16T22:40:03Z",
        "abstract": "Mobile edge computing (MEC) emerges recently as a promising solution to\nrelieve resource-limited mobile devices from computation-intensive tasks, which\nenables devices to offload workloads to nearby MEC servers and improve the\nquality of computation experience. Nevertheless, by considering a MEC system\nconsisting of multiple mobile users with stochastic task arrivals and wireless\nchannels in this paper, the design of computation offloading policies is\nchallenging to minimize the long-term average computation cost in terms of\npower consumption and buffering delay. A deep reinforcement learning (DRL)\nbased decentralized dynamic computation offloading strategy is investigated to\nbuild a scalable MEC system with limited feedback. Specifically, a continuous\naction space-based DRL approach named deep deterministic policy gradient (DDPG)\nis adopted to learn efficient computation offloading policies independently at\neach mobile user. Thus, powers of both local execution and task offloading can\nbe adaptively allocated by the learned policies from each user's local\nobservation of the MEC system. Numerical results are illustrated to demonstrate\nthat efficient policies can be learned at each user, and performance of the\nproposed DDPG based decentralized strategy outperforms the conventional deep\nQ-network (DQN) based discrete power control strategy and some other greedy\nstrategies with reduced computation cost. Besides, the power-delay tradeoff is\nalso analyzed for both the DDPG based and DQN based strategies.",
        "author": [
            "Zhao Chen",
            "Xiaodong Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.07394v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "eess.SP",
                "math.OC",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.07394v1",
        "arXiv ID": "1812.07394v1"
    },
    {
        "title": "Online RIS Configuration Learning for Arbitrary Large Numbers of $1$-Bit\n  Phase Resolution Elements",
        "Published: ": "2022-04-18T15:22:33Z",
        "abstract": "Reinforcement Learning (RL) approaches are lately deployed for orchestrating\nwireless communications empowered by Reconfigurable Intelligent Surfaces\n(RISs), leveraging their online optimization capabilities. Most commonly, in\nRL-based formulations for realistic RISs with low resolution phase-tunable\nelements, each configuration is modeled as a distinct reflection action,\nresulting to inefficient exploration due to the exponential nature of the\nsearch space. In this paper, we consider RISs with 1-bit phase resolution\nelements, and model the action of each of them as a binary vector including the\nfeasible reflection coefficients. We then introduce two variations of the\nwell-established Deep Q-Network (DQN) and Deep Deterministic Policy Gradient\n(DDPG) agents, aiming for effective exploration of the binary action spaces.\nFor the case of DQN, we make use of an efficient approximation of the\nQ-function, whereas a discretization post-processing step is applied to the\noutput of DDPG. Our simulation results showcase that the proposed techniques\ngreatly outperform the baseline in terms of the rate maximization objective,\nwhen large-scale RISs are considered. In addition, when dealing with moderate\nscale RIS sizes, where the conventional DQN based on configuration-based action\nspaces is feasible, the performance of the latter technique is similar to the\nproposed learning approach.",
        "author": [
            "Kyriakos Stylianopoulos",
            "George C. Alexandropoulos"
        ],
        "pdfLink": "http://arxiv.org/pdf/2204.08367v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "cs.ET",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2204.08367v1",
        "arXiv ID": "2204.08367v1"
    },
    {
        "title": "A review of motion planning algorithms for intelligent robotics",
        "Published: ": "2021-02-04T02:24:04Z",
        "abstract": "We investigate and analyze principles of typical motion planning algorithms.\nThese include traditional planning algorithms, supervised learning, optimal\nvalue reinforcement learning, policy gradient reinforcement learning.\nTraditional planning algorithms we investigated include graph search\nalgorithms, sampling-based algorithms, and interpolating curve algorithms.\nSupervised learning algorithms include MSVM, LSTM, MCTS and CNN. Optimal value\nreinforcement learning algorithms include Q learning, DQN, double DQN, dueling\nDQN. Policy gradient algorithms include policy gradient method, actor-critic\nalgorithm, A3C, A2C, DPG, DDPG, TRPO and PPO. New general criteria are also\nintroduced to evaluate performance and application of motion planning\nalgorithms by analytical comparisons. Convergence speed and stability of\noptimal value and policy gradient algorithms are specially analyzed. Future\ndirections are presented analytically according to principles and analytical\ncomparisons of motion planning algorithms. This paper provides researchers with\na clear and comprehensive understanding about advantages, disadvantages,\nrelationships, and future of motion planning algorithms in robotics, and paves\nways for better motion planning algorithms.",
        "author": [
            "Chengmin Zhou",
            "Bingding Huang",
            "Pasi Fr\u00e4nti"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.02376v2.pdf",
        "Categories": [
            [
                "cs.RO",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.02376v2",
        "arXiv ID": "2102.02376v2"
    },
    {
        "title": "MicroRacer: a didactic environment for Deep Reinforcement Learning",
        "Published: ": "2022-03-20T08:55:12Z",
        "abstract": "MicroRacer is a simple, open source environment inspired by car racing\nespecially meant for the didactics of Deep Reinforcement Learning. The\ncomplexity of the environment has been explicitly calibrated to allow users to\nexperiment with many different methods, networks and hyperparameters settings\nwithout requiring sophisticated software or the need of exceedingly long\ntraining times. Baseline agents for major learning algorithms such as DDPG,\nPPO, SAC, TD2 and DSAC are provided too, along with a preliminary comparison in\nterms of training time and performance.",
        "author": [
            "Andrea Asperti",
            "Marco Del Brutto"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.10494v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "68T05, 68T07",
                "I.6.7"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.10494v1",
        "arXiv ID": "2203.10494v1"
    },
    {
        "title": "Deterministic and Stochastic Analysis of Deep Reinforcement Learning for\n  Low Dimensional Sensing-based Navigation of Mobile Robots",
        "Published: ": "2022-09-13T22:28:26Z",
        "abstract": "Deterministic and Stochastic techniques in Deep Reinforcement Learning\n(Deep-RL) have become a promising solution to improve motion control and the\ndecision-making tasks for a wide variety of robots. Previous works showed that\nthese Deep-RL algorithms can be applied to perform mapless navigation of mobile\nrobots in general. However, they tend to use simple sensing strategies since it\nhas been shown that they perform poorly with a high dimensional state spaces,\nsuch as the ones yielded from image-based sensing. This paper presents a\ncomparative analysis of two Deep-RL techniques - Deep Deterministic Policy\nGradients (DDPG) and Soft Actor-Critic (SAC) - when performing tasks of mapless\nnavigation for mobile robots. We aim to contribute by showing how the neural\nnetwork architecture influences the learning itself, presenting quantitative\nresults based on the time and distance of navigation of aerial mobile robots\nfor each approach. Overall, our analysis of six distinct architectures\nhighlights that the stochastic approach (SAC) better suits with deeper\narchitectures, while the opposite happens with the deterministic approach\n(DDPG).",
        "author": [
            "Ricardo B. Grando",
            "Junior C. de Jesus",
            "Victor A. Kich",
            "Alisson H. Kolling",
            "Rodrigo S. Guerra",
            "Paulo L. J. Drews-Jr"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.06328v1.pdf",
        "Categories": [
            [
                "cs.RO",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.06328v1",
        "arXiv ID": "2209.06328v1"
    },
    {
        "title": "Advances in Experience Replay",
        "Published: ": "2018-05-15T02:50:35Z",
        "abstract": "This project combines recent advances in experience replay techniques,\nnamely, Combined Experience Replay (CER), Prioritized Experience Replay (PER),\nand Hindsight Experience Replay (HER). We show the results of combinations of\nthese techniques with DDPG and DQN methods. CER always adds the most recent\nexperience to the batch. PER chooses which experiences should be replayed based\non how beneficial they will be towards learning. HER learns from failure by\nsubstituting the desired goal with the achieved goal and recomputing the reward\nfunction. The effectiveness of combinations of these experience replay\ntechniques is tested in a variety of OpenAI gym environments.",
        "author": [
            "Tracy Wan",
            "Neil Xu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1805.05536v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1805.05536v1",
        "arXiv ID": "1805.05536v1"
    },
    {
        "title": "Critic Algorithms using Cooperative Networks",
        "Published: ": "2022-01-19T19:47:18Z",
        "abstract": "An algorithm is proposed for policy evaluation in Markov Decision Processes\nwhich gives good empirical results with respect to convergence rates. The\nalgorithm tracks the Projected Bellman Error and is implemented as a true\ngradient based algorithm. In this respect this algorithm differs from\nTD($\\lambda$) class of algorithms. This algorithm tracks the Projected Bellman\nAlgorithm and is therefore different from the class of residual algorithms.\nFurther the convergence of this algorithm is empirically much faster than GTD2\nclass of algorithms which aim at tracking the Projected Bellman Error. We\nimplemented proposed algorithm in DQN and DDPG framework and found that our\nalgorithm achieves comparable results in both of these experiments",
        "author": [
            "Debangshu Banerjee",
            "Kavita Wagh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.07839v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.07839v1",
        "arXiv ID": "2201.07839v1"
    },
    {
        "title": "Value-Based Reinforcement Learning for Continuous Control Robotic\n  Manipulation in Multi-Task Sparse Reward Settings",
        "Published: ": "2021-07-28T13:40:08Z",
        "abstract": "Learning continuous control in high-dimensional sparse reward settings, such\nas robotic manipulation, is a challenging problem due to the number of samples\noften required to obtain accurate optimal value and policy estimates. While\nmany deep reinforcement learning methods have aimed at improving sample\nefficiency through replay or improved exploration techniques, state of the art\nactor-critic and policy gradient methods still suffer from the hard exploration\nproblem in sparse reward settings. Motivated by recent successes of value-based\nmethods for approximating state-action values, like RBF-DQN, we explore the\npotential of value-based reinforcement learning for learning continuous robotic\nmanipulation tasks in multi-task sparse reward settings. On robotic\nmanipulation tasks, we empirically show RBF-DQN converges faster than current\nstate of the art algorithms such as TD3, SAC, and PPO. We also perform ablation\nstudies with RBF-DQN and have shown that some enhancement techniques for\nvanilla Deep Q learning such as Hindsight Experience Replay (HER) and\nPrioritized Experience Replay (PER) can also be applied to RBF-DQN. Our\nexperimental analysis suggests that value-based approaches may be more\nsensitive to data augmentation and replay buffer sample techniques than\npolicy-gradient methods, and that the benefits of these methods for robot\nmanipulation are heavily dependent on the transition dynamics of generated\nsubgoal states.",
        "author": [
            "Sreehari Rammohan",
            "Shangqun Yu",
            "Bowen He",
            "Eric Hsiung",
            "Eric Rosen",
            "Stefanie Tellex",
            "George Konidaris"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.13356v1.pdf",
        "Categories": [
            [
                "cs.RO",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.13356v1",
        "arXiv ID": "2107.13356v1"
    },
    {
        "title": "Robust Deep Reinforcement Learning against Adversarial Perturbations on\n  State Observations",
        "Published: ": "2020-03-19T17:59:59Z",
        "abstract": "A deep reinforcement learning (DRL) agent observes its states through\nobservations, which may contain natural measurement errors or adversarial\nnoises. Since the observations deviate from the true states, they can mislead\nthe agent into making suboptimal actions. Several works have shown this\nvulnerability via adversarial attacks, but existing approaches on improving the\nrobustness of DRL under this setting have limited success and lack for\ntheoretical principles. We show that naively applying existing techniques on\nimproving robustness for classification tasks, like adversarial training, is\nineffective for many RL tasks. We propose the state-adversarial Markov decision\nprocess (SA-MDP) to study the fundamental properties of this problem, and\ndevelop a theoretically principled policy regularization which can be applied\nto a large family of DRL algorithms, including proximal policy optimization\n(PPO), deep deterministic policy gradient (DDPG) and deep Q networks (DQN), for\nboth discrete and continuous action control problems. We significantly improve\nthe robustness of PPO, DDPG and DQN agents under a suite of strong white box\nadversarial attacks, including new attacks of our own. Additionally, we find\nthat a robust policy noticeably improves DRL performance even without an\nadversary in a number of environments. Our code is available at\nhttps://github.com/chenhongge/StateAdvDRL.",
        "author": [
            "Huan Zhang",
            "Hongge Chen",
            "Chaowei Xiao",
            "Bo Li",
            "Mingyan Liu",
            "Duane Boning",
            "Cho-Jui Hsieh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.08938v7.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.08938v7",
        "arXiv ID": "2003.08938v7"
    },
    {
        "title": "Dynamic Offloading Loading Optimization in distributed Fault Diagnosis\n  system with Deep Reinforcement Learning Approach",
        "Published: ": "2021-03-03T04:44:24Z",
        "abstract": "Artificial intelligence and distributed algorithms have been widely used in\nmechanical fault diagnosis with the explosive growth of diagnostic data. A\nnovel intelligent fault diagnosis system framework that allows intelligent\nterminals to offload computational tasks to Mobile edge computing (MEC) servers\nis provided in this paper, which can effectively address the problems of task\nprocessing delays and enhanced computational complexity. As the resources at\nthe MEC and intelligent terminals are limited, performing reasonable resource\nallocation optimization can improve the performance, especially for a\nmulti-terminals offloading system. In this study, to minimize the task\ncomputation delay, we jointly optimize the local content splitting ratio, the\ntransmission/computation power allocation, and the MEC server selection under a\ndynamic environment with stochastic task arrivals. The challenging dynamic\njoint optimization problem is formulated as a reinforcement learning (RL)\nproblem, which is designed as the computational offloading policies to minimize\nthe long-term average delay cost. Two deep RL strategies, deep Q-learning\nnetwork (DQN) and deep deterministic policy gradient (DDPG), are adopted to\nlearn the computational offloading policies adaptively and efficiently. The\nproposed DQN strategy takes the MEC selection as a unique action while using\nthe convex optimization approach to obtain the local content splitting ratio\nand the transmission/computation power allocation. Simultaneously, the actions\nof the DDPG strategy are selected as all dynamic variables, including the local\ncontent splitting ratio, the transmission/computation power allocation, and the\nMEC server selection. Numerical results demonstrate that both proposed\nstrategies perform better than the traditional non-learning schemes.",
        "author": [
            "Liang Yu",
            "Qixin Guo",
            "Rui Wang",
            "Minyan Shi",
            "Fucheng Yan",
            "Ran Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.02174v3.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.02174v3",
        "arXiv ID": "2103.02174v3"
    },
    {
        "title": "Learning-based Ecological Adaptive Cruise Control of Autonomous Electric\n  Vehicles: A Comparison of ADP, DQN and DDPG Approaches",
        "Published: ": "2023-12-02T02:36:28Z",
        "abstract": "This paper presents model-based and model-free learning methods for economic\nand ecological adaptive cruise control (Eco-ACC) of connected and autonomous\nelectric vehicles. For model-based optimal control of Eco-ACC, we considered\nlongitudinal vehicle dynamics and a quasi-steady-state powertrain model\nincluding the physical limits of a commercial electric vehicle. We used\nadaptive dynamic programming (ADP), in which the value function was trained\nusing data obtained from IPG CarMaker simulations. For real-time\nimplementation, forward multi-step look-ahead prediction and optimization were\nexecuted in a receding horizon scheme to maximize the energy efficiency of the\nelectric machine while avoiding rear-end collisions and satisfying the\npowertrain, speed, and distance-gap constraints. For model-free optimal control\nof Eco-ACC, we applied two reinforcement learning methods, Deep Q-Network (DQN)\nand Deep Deterministic Policy Gradient (DDPG), in which deep neural networks\nwere trained in IPG CarMaker simulations. For performance demonstrations, the\nHWFET, US06, and WLTP Class 3b driving cycles were used to simulate the front\nvehicle, and the energy consumptions of the host vehicle and front vehicle were\ncompared. In high-fidelity IPG CarMaker simulations, the proposed\nlearning-based Eco-ACC methods demonstrated approximately 3-5% and 10-14%\nefficiency improvements in highway and city-highway driving scenarios,\nrespectively, compared with the front vehicle. A video of the CarMaker\nsimulation is available at https://youtu.be/DIXzJxMVig8.",
        "author": [
            "Sunwoo Kim",
            "Kwang-Ki K. Kim"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.01004v1.pdf",
        "Categories": [
            [
                "eess.SY",
                "cs.SY",
                "93E20, 68T20, 49M37, 90-08"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.01004v1",
        "arXiv ID": "2312.01004v1"
    },
    {
        "title": "A Strategy-Oriented Bayesian Soft Actor-Critic Model",
        "Published: ": "2023-03-07T19:31:25Z",
        "abstract": "Adopting reasonable strategies is challenging but crucial for an intelligent\nagent with limited resources working in hazardous, unstructured, and dynamic\nenvironments to improve the system's utility, decrease the overall cost, and\nincrease mission success probability. This paper proposes a novel hierarchical\nstrategy decomposition approach based on the Bayesian chain rule to separate an\nintricate policy into several simple sub-policies and organize their\nrelationships as Bayesian strategy networks (BSN). We integrate this approach\ninto the state-of-the-art DRL method -- soft actor-critic (SAC) and build the\ncorresponding Bayesian soft actor-critic (BSAC) model by organizing several\nsub-policies as a joint policy. We compare the proposed BSAC method with the\nSAC and other state-of-the-art approaches such as TD3, DDPG, and PPO on the\nstandard continuous control benchmarks -- Hopper-v2, Walker2d-v2, and\nHumanoid-v2 -- in MuJoCo with the OpenAI Gym environment. The results\ndemonstrate that the promising potential of the BSAC method significantly\nimproves training efficiency.",
        "author": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.04193v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.04193v1",
        "arXiv ID": "2303.04193v1"
    },
    {
        "title": "Dap-FL: Federated Learning flourishes by adaptive tuning and secure\n  aggregation",
        "Published: ": "2022-06-08T00:25:55Z",
        "abstract": "Federated learning (FL), an attractive and promising distributed machine\nlearning paradigm, has sparked extensive interest in exploiting tremendous data\nstored on ubiquitous mobile devices. However, conventional FL suffers severely\nfrom resource heterogeneity, as clients with weak computational and\ncommunication capability may be unable to complete local training using the\nsame local training hyper-parameters. In this paper, we propose Dap-FL, a deep\ndeterministic policy gradient (DDPG)-assisted adaptive FL system, in which\nlocal learning rates and local training epochs are adaptively adjusted by all\nresource-heterogeneous clients through locally deployed DDPG-assisted adaptive\nhyper-parameter selection schemes. Particularly, the rationality of the\nproposed hyper-parameter selection scheme is confirmed through rigorous\nmathematical proof. Besides, due to the thoughtlessness of security\nconsideration of adaptive FL systems in previous studies, we introduce the\nPaillier cryptosystem to aggregate local models in a secure and\nprivacy-preserving manner. Rigorous analyses show that the proposed Dap-FL\nsystem could guarantee the security of clients' private local models against\nchosen-plaintext attacks and chosen-message attacks in a widely used\nhonest-but-curious participants and active adversaries security model. In\naddition, through ingenious and extensive experiments, the proposed Dap-FL\nachieves higher global model prediction accuracy and faster convergence rates\nthan conventional FL, and the comprehensiveness of the adjusted local training\nhyper-parameters is validated. More importantly, experimental results also show\nthat the proposed Dap-FL achieves higher model prediction accuracy than two\nstate-of-the-art RL-assisted FL methods, i.e., 6.03% higher than DDPG-based FL\nand 7.85% higher than DQN-based FL.",
        "author": [
            "Qian Chen",
            "Zilong Wang",
            "Jiawei Chen",
            "Haonan Yan",
            "Xiaodong Lin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.03623v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.03623v1",
        "arXiv ID": "2206.03623v1"
    },
    {
        "title": "Parametrized Deep Q-Networks Learning: Reinforcement Learning with\n  Discrete-Continuous Hybrid Action Space",
        "Published: ": "2018-10-10T07:38:44Z",
        "abstract": "Most existing deep reinforcement learning (DRL) frameworks consider either\ndiscrete action space or continuous action space solely. Motivated by\napplications in computer games, we consider the scenario with\ndiscrete-continuous hybrid action space. To handle hybrid action space,\nprevious works either approximate the hybrid space by discretization, or relax\nit into a continuous set. In this paper, we propose a parametrized deep\nQ-network (P- DQN) framework for the hybrid action space without approximation\nor relaxation. Our algorithm combines the spirits of both DQN (dealing with\ndiscrete action space) and DDPG (dealing with continuous action space) by\nseamlessly integrating them. Empirical results on a simulation example, scoring\na goal in simulated RoboCup soccer and the solo mode in game King of Glory\n(KOG) validate the efficiency and effectiveness of our method.",
        "author": [
            "Jiechao Xiong",
            "Qing Wang",
            "Zhuoran Yang",
            "Peng Sun",
            "Lei Han",
            "Yang Zheng",
            "Haobo Fu",
            "Tong Zhang",
            "Ji Liu",
            "Han Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.06394v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.06394v1",
        "arXiv ID": "1810.06394v1"
    },
    {
        "title": "Meta-Reinforcement Learning Based Resource Allocation for Dynamic V2X\n  Communications",
        "Published: ": "2021-10-14T21:34:05Z",
        "abstract": "This paper studies the allocation of shared resources between\nvehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) links in\nvehicle-to-everything (V2X) communications. In existing algorithms, dynamic\nvehicular environments and quantization of continuous power become the\nbottlenecks for providing an effective and timely resource allocation policy.\nIn this paper, we develop two algorithms to deal with these difficulties.\nFirst, we propose a deep reinforcement learning (DRL)-based resource allocation\nalgorithm to improve the performance of both V2I and V2V links. Specifically,\nthe algorithm uses deep Q-network (DQN) to solve the sub-band assignment and\ndeep deterministic policy-gradient (DDPG) to solve the continuous power\nallocation problem. Second, we propose a meta-based DRL algorithm to enhance\nthe fast adaptability of the resource allocation policy in the dynamic\nenvironment. Numerical results demonstrate that the proposed DRL-based\nalgorithm can significantly improve the performance compared to the DQN-based\nalgorithm that quantizes continuous power. In addition, the proposed meta-based\nDRL algorithm can achieve the required fast adaptation in the new environment\nwith limited experiences.",
        "author": [
            "Yi Yuan",
            "Gan Zheng",
            "Kai-Kit Wong",
            "Khaled B. Letaief"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.07734v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.07734v1",
        "arXiv ID": "2110.07734v1"
    },
    {
        "title": "Multi-agent deep reinforcement learning (MADRL) meets multi-user MIMO\n  systems",
        "Published: ": "2021-09-10T16:50:45Z",
        "abstract": "A multi-agent deep reinforcement learning (MADRL) is a promising approach to\nchallenging problems in wireless environments involving multiple\ndecision-makers (or actors) with high-dimensional continuous action space. In\nthis paper, we present a MADRL-based approach that can jointly optimize\nprecoders to achieve the outer-boundary, called pareto-boundary, of the\nachievable rate region for a multiple-input single-output (MISO) interference\nchannel (IFC). In order to address two main challenges, namely, multiple actors\n(or agents) with partial observability and multi-dimensional continuous action\nspace in MISO IFC setup, we adopt a multi-agent deep deterministic policy\ngradient (MA-DDPG) framework in which decentralized actors with partial\nobservability can learn a multi-dimensional continuous policy in a centralized\nmanner with the aid of shared critic with global information. Meanwhile, we\nwill also address a phase ambiguity issue with the conventional complex\nbaseband representation of signals widely used in radio communications. In\norder to mitigate the impact of phase ambiguity on training performance, we\npropose a training method, called phase ambiguity elimination (PAE), that leads\nto faster learning and better performance of MA-DDPG in wireless communication\nsystems. The simulation results exhibit that MA-DDPG is capable of learning a\nnear-optimal precoding strategy in a MISO IFC environment. To the best of our\nknowledge, this is the first work to demonstrate that the MA-DDPG framework can\njointly optimize precoders to achieve the pareto-boundary of achievable rate\nregion in a multi-cell multi-user multi-antenna system.",
        "author": [
            "Heunchul Lee",
            "Jaeseong Jeong"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.04986v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.04986v1",
        "arXiv ID": "2109.04986v1"
    },
    {
        "title": "Plug-and-Play Model-Agnostic Counterfactual Policy Synthesis for Deep\n  Reinforcement Learning based Recommendation",
        "Published: ": "2022-08-10T04:39:22Z",
        "abstract": "Recent advances in recommender systems have proved the potential of\nReinforcement Learning (RL) to handle the dynamic evolution processes between\nusers and recommender systems. However, learning to train an optimal RL agent\nis generally impractical with commonly sparse user feedback data in the context\nof recommender systems. To circumvent the lack of interaction of current\nRL-based recommender systems, we propose to learn a general Model-Agnostic\nCounterfactual Synthesis (MACS) Policy for counterfactual user interaction data\naugmentation. The counterfactual synthesis policy aims to synthesise\ncounterfactual states while preserving significant information in the original\nstate relevant to the user's interests, building upon two different training\napproaches we designed: learning with expert demonstrations and joint training.\nAs a result, the synthesis of each counterfactual data is based on the current\nrecommendation agent's interaction with the environment to adapt to users'\ndynamic interests. We integrate the proposed policy Deep Deterministic Policy\nGradient (DDPG), Soft Actor Critic (SAC) and Twin Delayed DDPG in an adaptive\npipeline with a recommendation agent that can generate counterfactual data to\nimprove the performance of recommendation. The empirical results on both online\nsimulation and offline datasets demonstrate the effectiveness and\ngeneralisation of our counterfactual synthesis policy and verify that it\nimproves the performance of RL recommendation agents.",
        "author": [
            "Siyu Wang",
            "Xiaocong Chen",
            "Lina Yao",
            "Sally Cripps",
            "Julian McAuley"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.05142v3.pdf",
        "Categories": [
            [
                "cs.IR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.05142v3",
        "arXiv ID": "2208.05142v3"
    },
    {
        "title": "DDPG based on multi-scale strokes for financial time series trading\n  strategy",
        "Published: ": "2022-06-05T13:10:05Z",
        "abstract": "With the development of artificial intelligence,more and more financial\npractitioners apply deep reinforcement learning to financial trading\nstrategies.However,It is difficult to extract accurate features due to the\ncharacteristics of considerable noise,highly non-stationary,and non-linearity\nof single-scale time series,which makes it hard to obtain high returns.In this\npaper,we extract a multi-scale feature matrix on multiple time scales of\nfinancial time series,according to the classic financial theory-Chan Theory,and\nput forward to an approach of multi-scale stroke deep deterministic policy\ngradient reinforcement learning model(MSSDDPG)to search for the optimal trading\nstrategy.We carried out experiments on the datasets of the Dow Jones,S&P 500 of\nU.S. stocks, and China's CSI 300,SSE Composite,evaluate the performance of our\napproach compared with turtle trading strategy, Deep\nQ-learning(DQN)reinforcement learning strategy,and deep deterministic policy\ngradient (DDPG) reinforcement learning strategy.The result shows that our\napproach gets the best performance in China CSI 300,SSE Composite,and get an\noutstanding result in Dow Jones,S&P 500 of U.S.",
        "author": [
            "Jun-Cheng Chen",
            "Cong-Xiao Chen",
            "Li-Juan Duan",
            "Zhi Cai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2207.10071v1.pdf",
        "Categories": [
            [
                "q-fin.TR",
                "cs.AI",
                "cs.LG",
                "68T20",
                "I.2.8"
            ]
        ],
        "Link": "http://arxiv.org/abs/2207.10071v1",
        "arXiv ID": "2207.10071v1"
    },
    {
        "title": "Deep Reinforcement Learning for Traffic Light Control in Intelligent\n  Transportation Systems",
        "Published: ": "2023-02-04T02:49:12Z",
        "abstract": "Smart traffic lights in intelligent transportation systems (ITSs) are\nenvisioned to greatly increase traffic efficiency and reduce congestion. Deep\nreinforcement learning (DRL) is a promising approach to adaptively control\ntraffic lights based on the real-time traffic situation in a road network.\nHowever, conventional methods may suffer from poor scalability. In this paper,\nwe investigate deep reinforcement learning to control traffic lights, and both\ntheoretical analysis and numerical experiments show that the intelligent\nbehavior ``greenwave\" (i.e., a vehicle will see a progressive cascade of green\nlights, and not have to brake at any intersection) emerges naturally a grid\nroad network, which is proved to be the optimal policy in an avenue with\nmultiple cross streets. As a first step, we use two DRL algorithms for the\ntraffic light control problems in two scenarios. In a single road intersection,\nwe verify that the deep Q-network (DQN) algorithm delivers a thresholding\npolicy; and in a grid road network, we adopt the deep deterministic policy\ngradient (DDPG) algorithm. Secondly, numerical experiments show that the DQN\nalgorithm delivers the optimal control, and the DDPG algorithm with passive\nobservations has the capability to produce on its own a high-level intelligent\nbehavior in a grid road network, namely, the ``greenwave\" policy emerges. We\nalso verify the ``greenwave\" patterns in a $5 \\times 10$ grid road network.\nThirdly, the ``greenwave\" patterns demonstrate that DRL algorithms produce\nfavorable solutions since the ``greenwave\" policy shown in experiment results\nis proved to be optimal in a specified traffic model (an avenue with multiple\ncross streets). The delivered policies both in a single road intersection and a\ngrid road network demonstrate the scalability of DRL algorithms.",
        "author": [
            "Xiao-Yang Liu",
            "Ming Zhu",
            "Sem Borst",
            "Anwar Walid"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.03669v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.03669v2",
        "arXiv ID": "2302.03669v2"
    },
    {
        "title": "Performance Comparison of Deep RL Algorithms for Energy Systems Optimal\n  Scheduling",
        "Published: ": "2022-08-01T10:25:52Z",
        "abstract": "Taking advantage of their data-driven and model-free features, Deep\nReinforcement Learning (DRL) algorithms have the potential to deal with the\nincreasing level of uncertainty due to the introduction of renewable-based\ngeneration. To deal simultaneously with the energy systems' operational cost\nand technical constraints (e.g, generation-demand power balance) DRL algorithms\nmust consider a trade-off when designing the reward function. This trade-off\nintroduces extra hyperparameters that impact the DRL algorithms' performance\nand capability of providing feasible solutions. In this paper, a performance\ncomparison of different DRL algorithms, including DDPG, TD3, SAC, and PPO, are\npresented. We aim to provide a fair comparison of these DRL algorithms for\nenergy systems optimal scheduling problems. Results show DRL algorithms'\ncapability of providing in real-time good-quality solutions, even in unseen\noperational scenarios, when compared with a mathematical programming model of\nthe energy system optimal scheduling problem. Nevertheless, in the case of\nlarge peak consumption, these algorithms failed to provide feasible solutions,\nwhich can impede their practical implementation.",
        "author": [
            "Hou Shengren",
            "Edgar Mauricio Salazar",
            "Pedro P. Vergara",
            "Peter Palensky"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.00728v1.pdf",
        "Categories": [
            [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.00728v1",
        "arXiv ID": "2208.00728v1"
    },
    {
        "title": "STIR$^2$: Reward Relabelling for combined Reinforcement and Imitation\n  Learning on sparse-reward tasks",
        "Published: ": "2022-01-11T08:35:18Z",
        "abstract": "In the search for more sample-efficient reinforcement-learning (RL)\nalgorithms, a promising direction is to leverage as much external off-policy\ndata as possible. For instance, expert demonstrations. In the past, multiple\nideas have been proposed to make good use of the demonstrations added to the\nreplay buffer, such as pretraining on demonstrations only or minimizing\nadditional cost functions. We present a new method, able to leverage both\ndemonstrations and episodes collected online in any sparse-reward environment\nwith any off-policy algorithm. Our method is based on a reward bonus given to\ndemonstrations and successful episodes (via relabeling), encouraging expert\nimitation and self-imitation. Our experiments focus on several\nrobotic-manipulation tasks across two different simulation environments. We\nshow that our method based on reward relabeling improves the performance of the\nbase algorithm (SAC and DDPG) on these tasks. Finally, our best algorithm\nSTIR$^2$ (Self and Teacher Imitation by Reward Relabeling), which integrates\ninto our method multiple improvements from previous works, is more\ndata-efficient than all baselines.",
        "author": [
            "Jesus Bujalance Martin",
            "Fabien Moutarde"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.03834v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.03834v2",
        "arXiv ID": "2201.03834v2"
    },
    {
        "title": "Fulfilling Formal Specifications ASAP by Model-free Reinforcement\n  Learning",
        "Published: ": "2023-04-25T01:16:42Z",
        "abstract": "We propose a model-free reinforcement learning solution, namely the ASAP-Phi\nframework, to encourage an agent to fulfill a formal specification ASAP. The\nframework leverages a piece-wise reward function that assigns quantitative\nsemantic reward to traces not satisfying the specification, and a high constant\nreward to the remaining. Then, it trains an agent with an actor-critic-based\nalgorithm, such as soft actor-critic (SAC), or deep deterministic policy\ngradient (DDPG). Moreover, we prove that ASAP-Phi produces policies that\nprioritize fulfilling a specification ASAP. Extensive experiments are run,\nincluding ablation studies, on state-of-the-art benchmarks. Results show that\nour framework succeeds in finding sufficiently fast trajectories for up to 97\\%\ntest cases and defeats baselines.",
        "author": [
            "Mengyu Liu",
            "Pengyuan Lu",
            "Xin Chen",
            "Fanxin Kong",
            "Oleg Sokolsky",
            "Insup Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.12508v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.FL",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.12508v1",
        "arXiv ID": "2304.12508v1"
    },
    {
        "title": "Contention Window Optimization in IEEE 802.11ax Networks with Deep\n  Reinforcement Learning",
        "Published: ": "2020-03-03T13:04:27Z",
        "abstract": "The proper setting of contention window (CW) values has a significant impact\non the efficiency of Wi-Fi networks. Unfortunately, the standard method used by\n802.11 networks is not scalable enough to maintain stable throughput for an\nincreasing number of stations, yet it remains the default method of channel\naccess for 802.11ax single-user transmissions. Therefore, we propose a new\nmethod of CW control, which leverages deep reinforcement learning (DRL)\nprinciples to learn the correct settings under different network conditions.\nOur method, called centralized contention window optimization with DRL (CCOD),\nsupports two trainable control algorithms: deep Q-network (DQN) and deep\ndeterministic policy gradient (DDPG). We demonstrate through simulations that\nit offers efficiency close to optimal (even in dynamic topologies) while\nkeeping computational cost low.",
        "author": [
            "Witold Wydma\u0144ski",
            "Szymon Szott"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.01492v5.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.LG",
                "eess.SP",
                "91A06, 91A10, 91A80",
                "C.2.0; C.2.5"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.01492v5",
        "arXiv ID": "2003.01492v5"
    },
    {
        "title": "Joint Trajectory and Passive Beamforming Design for Intelligent\n  Reflecting Surface-Aided UAV Communications: A Deep Reinforcement Learning\n  Approach",
        "Published: ": "2020-07-16T14:55:50Z",
        "abstract": "In this paper, the intelligent reflecting surface (IRS)-aided unmanned aerial\nvehicle (UAV) communication system is studied, where the UAV is deployed to\nserve the user equipment (UE) with the assistance of multiple IRSs mounted on\nseveral buildings to enhance the communication quality between UAV and UE. We\naim to maximize the energy efficiency of the system, including the data rate of\nUE and the energy consumption of UAV via jointly optimizing the UAV's\ntrajectory and the phase shifts of reflecting elements of IRS, when the UE\nmoves and the selection of IRSs is considered for the energy saving purpose.\nSince the system is complex and the environment is dynamic, it is challenging\nto derive low-complexity algorithms by using conventional optimization methods.\nTo address this issue, we first propose a deep Q-network (DQN)-based algorithm\nby discretizing the trajectory, which has the advantage of training time.\nFurthermore, we propose a deep deterministic policy gradient (DDPG)-based\nalgorithm to tackle the case with continuous trajectory for achieving better\nperformance. The experimental results show that the proposed algorithms achieve\nconsiderable performance compared to other traditional solutions.",
        "author": [
            "Liang Wang",
            "Kezhi Wang",
            "Cunhua Pan",
            "Nauman Aslam"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.08380v2.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.08380v2",
        "arXiv ID": "2007.08380v2"
    },
    {
        "title": "A Study of Reinforcement Learning Algorithms for Aggregates of\n  Minimalistic Robots",
        "Published: ": "2022-03-28T22:24:47Z",
        "abstract": "The aim of this paper is to study how to apply deep reinforcement learning\nfor the control of aggregates of minimalistic robots. We define aggregates as\ngroups of robots with a physical connection that compels them to form a\nspecified shape. In our case, the robots are pre-attached to an object that\nmust be collectively transported to a known location. Minimalism, in our\nsetting, stems from the barebone capabilities we assume: The robots can sense\nthe target location and the immediate obstacles, but lack the means to\ncommunicate explicitly through, e.g., message-passing. In our setting,\ncommunication is implicit, i.e., mediated by aggregated push-and-pull on the\nobject exerted by each robot. We analyze the ability to reach coordinated\nbehavior of four well-known algorithms for deep reinforcement learning (DQN,\nDDQN, DDPG, and TD3). Our experiments include robot failures and different\ntypes of environmental obstacles. We compare the performance of the best\ncontrol strategies found, highlighting strengths and weaknesses of each of the\nconsidered training algorithms.",
        "author": [
            "Joshua Bloom",
            "Apratim Mukherjee",
            "Carlo Pinciroli"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.15129v1.pdf",
        "Categories": [
            [
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.15129v1",
        "arXiv ID": "2203.15129v1"
    },
    {
        "title": "Multiple Domain Cyberspace Attack and Defense Game Based on Reward\n  Randomization Reinforcement Learning",
        "Published: ": "2022-05-23T01:38:23Z",
        "abstract": "The existing network attack and defense method can be regarded as game, but\nmost of the game only involves network domain, not multiple domain cyberspace.\nTo address this challenge, this paper proposed a multiple domain cyberspace\nattack and defense game model based on reinforcement learning. We define the\nmultiple domain cyberspace include physical domain, network domain and digital\ndomain. By establishing two agents, representing the attacker and the defender\nrespectively, defender will select the multiple domain actions in the multiple\ndomain cyberspace to obtain defender's optimal reward by reinforcement\nlearning. In order to improve the defense ability of defender, a game model\nbased on reward randomization reinforcement learning is proposed. When the\ndefender takes the multiple domain defense action, the reward is randomly given\nand subject to linear distribution, so as to find the better defense policy and\nimprove defense success rate. The experimental results show that the game model\ncan effectively simulate the attack and defense state of multiple domain\ncyberspace, and the proposed method has a higher defense success rate than DDPG\nand DQN.",
        "author": [
            "Lei Zhang",
            "Yu Pan",
            "Yi Liu",
            "Qibin Zheng",
            "Zhisong Pan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.10990v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.10990v1",
        "arXiv ID": "2205.10990v1"
    },
    {
        "title": "Cost-Effective Task Offloading Scheduling for Hybrid Mobile Edge-Quantum\n  Computing",
        "Published: ": "2023-06-26T10:54:52Z",
        "abstract": "In this paper, we aim to address the challenge of hybrid mobile edge-quantum\ncomputing (MEQC) for sustainable task offloading scheduling in mobile networks.\nWe develop cost-effective designs for both task offloading mode selection and\nresource allocation, subject to the individual link latency constraint\nguarantees for mobile devices, while satisfying the required success ratio for\ntheir computation tasks. Specifically, this is a time-coupled offloading\nscheduling optimization problem in need of a computationally affordable and\neffective solution. To this end, we propose a deep reinforcement learning\n(DRL)-based Lyapunov approach. More precisely, we reformulate the original\ntime-coupled challenge into a mixed-integer optimization problem by introducing\na penalty part in terms of virtual queues constructed by time-coupled\nconstraints to the objective function. Subsequently, a Deep Q-Network (DQN) is\nadopted for task offloading mode selection. In addition, we design the Deep\nDeterministic Policy Gradient (DDPG)-based algorithm for partial-task\noffloading decision-making. Finally, tested in a realistic network setting,\nextensive experiment results demonstrate that our proposed approach is\nsignificantly more cost-effective and sustainable compared to existing methods.",
        "author": [
            "Ziqiang Ye",
            "Yulan Gao",
            "Yue Xiao",
            "Minrui Xu",
            "Han Yu",
            "Dusit Niyato"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.14588v1.pdf",
        "Categories": [
            [
                "eess.SY",
                "cs.NI",
                "cs.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.14588v1",
        "arXiv ID": "2306.14588v1"
    },
    {
        "title": "Simple Noisy Environment Augmentation for Reinforcement Learning",
        "Published: ": "2023-05-04T14:45:09Z",
        "abstract": "Data augmentation is a widely used technique for improving model performance\nin machine learning, particularly in computer vision and natural language\nprocessing. Recently, there has been increasing interest in applying\naugmentation techniques to reinforcement learning (RL) problems, with a focus\non image-based augmentation. In this paper, we explore a set of generic\nwrappers designed to augment RL environments with noise and encourage agent\nexploration and improve training data diversity which are applicable to a broad\nspectrum of RL algorithms and environments. Specifically, we concentrate on\naugmentations concerning states, rewards, and transition dynamics and introduce\ntwo novel augmentation techniques. In addition, we introduce a noise rate\nhyperparameter for control over the frequency of noise injection. We present\nexperimental results on the impact of these wrappers on return using three\npopular RL algorithms, Soft Actor-Critic (SAC), Twin Delayed DDPG (TD3), and\nProximal Policy Optimization (PPO), across five MuJoCo environments. To support\nthe choice of augmentation technique in practice, we also present analysis that\nexplores the performance these techniques across environments. Lastly, we\npublish the wrappers in our noisyenv repository for use with gym environments.",
        "author": [
            "Raad Khraishi",
            "Ramin Okhrati"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.02882v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.02882v1",
        "arXiv ID": "2305.02882v1"
    },
    {
        "title": "Invariance to Quantile Selection in Distributional Continuous Control",
        "Published: ": "2022-12-29T11:11:22Z",
        "abstract": "In recent years distributional reinforcement learning has produced many state\nof the art results. Increasingly sample efficient Distributional algorithms for\nthe discrete action domain have been developed over time that vary primarily in\nthe way they parameterize their approximations of value distributions, and how\nthey quantify the differences between those distributions. In this work we\ntransfer three of the most well-known and successful of those algorithms\n(QR-DQN, IQN and FQF) to the continuous action domain by extending two powerful\nactor-critic algorithms (TD3 and SAC) with distributional critics. We\ninvestigate whether the relative performance of the methods for the discrete\naction space translates to the continuous case. To that end we compare them\nempirically on the pybullet implementations of a set of continuous control\ntasks. Our results indicate qualitative invariance regarding the number and\nplacement of distributional atoms in the deterministic, continuous action\nsetting.",
        "author": [
            "Felix Gr\u00fcn",
            "Muhammad Saif-ur-Rehman",
            "Tobias Glasmachers",
            "Ioannis Iossifidis"
        ],
        "pdfLink": "http://arxiv.org/pdf/2212.14262v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "I.2.8; I.2.6"
            ]
        ],
        "Link": "http://arxiv.org/abs/2212.14262v1",
        "arXiv ID": "2212.14262v1"
    },
    {
        "title": "Deep Reinforcement Learning for Autonomous Ground Vehicle Exploration\n  Without A-Priori Maps",
        "Published: ": "2023-01-10T15:38:59Z",
        "abstract": "Autonomous Ground Vehicles (AGVs) are essential tools for a wide range of\napplications stemming from their ability to operate in hazardous environments\nwith minimal human operator input. Effective motion planning is paramount for\nsuccessful operation of AGVs. Conventional motion planning algorithms are\ndependent on prior knowledge of environment characteristics and offer limited\nutility in information poor, dynamically altering environments such as areas\nwhere emergency hazards like fire and earthquake occur, and unexplored\nsubterranean environments such as tunnels and lava tubes on Mars. We propose a\nDeep Reinforcement Learning (DRL) framework for intelligent AGV exploration\nwithout a-priori maps utilizing Actor-Critic DRL algorithms to learn policies\nin continuous and high-dimensional action spaces directly from raw sensor data.\nThe DRL architecture comprises feedforward neural networks for the critic and\nactor representations in which the actor network strategizes linear and angular\nvelocity control actions given current state inputs, that are evaluated by the\ncritic network which learns and estimates Q-values to maximize an accumulated\nreward. Three off-policy DRL algorithms, DDPG, TD3 and SAC, are trained and\ncompared in two environments of varying complexity, and further evaluated in a\nthird with no prior training or knowledge of map characteristics. The agent is\nshown to learn optimal policies at the end of each training period to chart\nquick, collision-free exploration trajectories, and is extensible, capable of\nadapting to an unknown environment without changes to network architecture or\nhyperparameters. The best algorithm is further evaluated in a realistic 3D\nenvironment.",
        "author": [
            "Shathushan Sivashangaran",
            "Azim Eskandarian"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.04036v2.pdf",
        "Categories": [
            [
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.04036v2",
        "arXiv ID": "2301.04036v2"
    },
    {
        "title": "DSAC-T: Distributional Soft Actor-Critic with Three Refinements",
        "Published: ": "2023-10-09T16:52:48Z",
        "abstract": "Reinforcement learning (RL) has proven to be highly effective in tackling\ncomplex decision-making and control tasks. However, prevalent model-free RL\nmethods often face severe performance degradation due to the well-known\noverestimation issue. In response to this problem, we recently introduced an\noff-policy RL algorithm, called distributional soft actor-critic (DSAC or\nDSAC-v1), which can effectively improve the value estimation accuracy by\nlearning a continuous Gaussian value distribution. Nonetheless, standard DSAC\nhas its own shortcomings, including occasionally unstable learning processes\nand needs for task-specific reward scaling, which may hinder its overall\nperformance and adaptability in some special tasks. This paper further\nintroduces three important refinements to standard DSAC in order to address\nthese shortcomings. These refinements consist of critic gradient adjusting,\ntwin value distribution learning, and variance-based target return clipping.\nThe modified RL algorithm is named as DSAC with three refinements (DSAC-T or\nDSAC-v2), and its performances are systematically evaluated on a diverse set of\nbenchmark tasks. Without any task-specific hyperparameter tuning, DSAC-T\nsurpasses a lot of mainstream model-free RL algorithms, including SAC, TD3,\nDDPG, TRPO, and PPO, in all tested environments. Additionally, DSAC-T, unlike\nits standard version, ensures a highly stable learning process and delivers\nsimilar performance across varying reward scales.",
        "author": [
            "Jingliang Duan",
            "Wenxuan Wang",
            "Liming Xiao",
            "Jiaxin Gao",
            "Shengbo Eben Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.05858v3.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.05858v3",
        "arXiv ID": "2310.05858v3"
    },
    {
        "title": "Chemical differentiation in regions of high-mass star formation I. CS,\n  dust and N2H^+ in southern sources",
        "Published: ": "2006-08-01T10:11:49Z",
        "abstract": "Aims. Our goals are to compare the CS, N2H+ and dust distributions in a\nrepresentative sample of high-mass star forming dense cores and to determine\nthe physical and chemical properties of these cores. Methods. We compare the\nresults of CS(5-4) and 1.2 mm continuum mapping of twelve dense cores from the\nsouthern hemisphere presented in this work, in combination with our previous\nN2H+(1-0) and CS(2-1) data. We use numerical modeling of molecular excitation\nto estimate physical parameters of the cores. Results. Most of the maps have\nseveral emission peaks (clumps). We derive basic physical parameters of the\nclumps and estimate CS and N2H+ abundances. Masses calculated from LVG\ndensities are higher than CS virial masses and masses derived from continuum\ndata, implying small-scale clumpiness of the cores. For most of the objects,\nthe CS and continuum peaks are close to the IRAS point source positions. The\nCS(5-4) intensities correlate with continuum fluxes per beam in all cases, but\nonly in five cases with the N2H+(1-0) intensities. The study of spatial\nvariations of molecular integrated intensity ratios to continuum fluxes reveals\nthat I(N2H+)/F{1.2} ratios drop towards the CS peaks for most of the sources,\nwhich can be due to a N2H+ abundance decrease. For CS(5-4), the I(CS)/F{1.2}\nratios show no clear trends with distance from the CS peaks, while for CS(2-1)\nsuch ratios drop towards these peaks. Possible explanations of these results\nare considered. The analysis of normalized velocity differences between CS and\nN2H+ lines has not revealed indications of systematic motions towards CS peaks.",
        "author": [
            "L. Pirogov",
            "I. Zinchenko",
            "P. Caselli",
            "L. E. B. Johansson"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0608015v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0608015v1",
        "arXiv ID": "0608015v1"
    },
    {
        "title": "Comparative chemistry of diffuse clouds III: sulfur-bearing molecules",
        "Published: ": "2002-01-10T19:13:32Z",
        "abstract": "Using data from IRAM's Plateau de Bure Interferometer and 30 m Telescope, we\ndiscuss the mm-wave absorption lines of CS, SO, H2S and HCS+ which arise in\ndiffuse clouds occulting several extragalactic continuum sources. Typical\nrelative abundances are X(CS)/X(HCO+) ~ 2, X(CS)/X(SO) ~ 2, X(CS)/X(H2S) ~ 6\nand X(CS)/X(HCS+) ~ 13.",
        "author": [
            "R. Lucas",
            "H. S. Liszt"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0201163v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0201163v1",
        "arXiv ID": "0201163v1"
    },
    {
        "title": "CS Lines Profiles in Hot Cores",
        "Published: ": "2010-11-05T14:29:12Z",
        "abstract": "We present a theoretical study of CS line profiles in archetypal hot cores.\nWe provide estimates of line fluxes from the CS(1-0) to the CS(15-14)\ntransitions and present the temporal variation of these fluxes. We find that\n\\textit{i)} the CS(1-0) transition is a better tracer of the Envelope of the\nhot core whereas the higher-J CS lines trace the ultra-compact core;\n\\textit{ii)} the peak temperature of the CS transitions is a good indicator of\nthe temperature inside the hot core; \\textit{iii)} in the Envelope, the older\nthe hot core the stronger the self-absorption of CS; \\textit{iv)} the\nfractional abundance of CS is highest in the innermost parts of the\nultra-compact core, confirming the CS molecule as one of the best tracers of\nvery dense gas.",
        "author": [
            "E. Bayet",
            "J. Yates",
            "S. Viti"
        ],
        "pdfLink": "http://arxiv.org/pdf/1011.1406v1.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1011.1406v1",
        "arXiv ID": "1011.1406v1"
    },
    {
        "title": "Coherent states of systems with quadratic Hamiltonians",
        "Published: ": "2015-02-10T17:20:16Z",
        "abstract": "Different families of generalized CS for one-dimensional systems with general\ntime dependent quadratic Hamiltonian are constructed. In principle, all known\nCS of systems with quadratic Hamiltonian are members of these families. Some of\nthe constructed generalized CS are close enough to the well-known due to\nSchr\\\"odinger and Glauber CS of a harmonic oscillator, we call them simply CS.\nHowever, even among these CS there exist different families of complete sets of\nCS. These families differ by values of standard deviations at the initial time\ninstant. According to the values of these initial standard deviations one can\nidentify some of the families with semiclassical CS. We discuss properties of\nthe constructed CS, in particular, completeness relations, minimization of\nuncertainty relations and so on. As a unknown application of the general\nconstruction, we consider different CS of an oscillator with a time dependent\nfrequency.",
        "author": [
            "V. G. Bagrov",
            "D. M. Gitman",
            "A. S. Pereira"
        ],
        "pdfLink": "http://arxiv.org/pdf/1502.02999v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1502.02999v1",
        "arXiv ID": "1502.02999v1"
    },
    {
        "title": "ConceptNet infused DialoGPT for Underlying Commonsense Understanding and\n  Reasoning in Dialogue Response Generation",
        "Published: ": "2022-09-29T21:42:25Z",
        "abstract": "The pre-trained conversational models still fail to capture the implicit\ncommonsense (CS) knowledge hidden in the dialogue interaction, even though they\nwere pre-trained with an enormous dataset. In order to build a dialogue agent\nwith CS capability, we firstly inject external knowledge into a pre-trained\nconversational model to establish basic commonsense through efficient Adapter\ntuning (Section 4). Secondly, we propose the ``two-way learning'' method to\nenable the bidirectional relationship between CS knowledge and sentence pairs\nso that the model can generate a sentence given the CS triplets, also generate\nthe underlying CS knowledge given a sentence (Section 5). Finally, we leverage\nthis integrated CS capability to improve open-domain dialogue response\ngeneration so that the dialogue agent is capable of understanding the CS\nknowledge hidden in dialogue history on top of inferring related other\nknowledge to further guide response generation (Section 6). The experiment\nresults demonstrate that CS\\_Adapter fusion helps DialoGPT to be able to\ngenerate series of CS knowledge. And the DialoGPT+CS\\_Adapter response model\nadapted from CommonGen training can generate underlying CS triplets that fits\nbetter to dialogue context.",
        "author": [
            "Ye Liu",
            "Wolfgang Maier",
            "Wolfgang Minker",
            "Stefan Ultes"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.15109v1.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.15109v1",
        "arXiv ID": "2209.15109v1"
    },
    {
        "title": "Deep Learning Techniques for Compressive Sensing-Based Reconstruction\n  and Inference -- A Ubiquitous Systems Perspective",
        "Published: ": "2021-05-26T14:04:04Z",
        "abstract": "Compressive sensing (CS) is a mathematically elegant tool for reducing the\nsampling rate, potentially bringing context-awareness to a wider range of\ndevices. Nevertheless, practical issues with the sampling and reconstruction\nalgorithms prevent further proliferation of CS in real world domains,\nespecially among heterogeneous ubiquitous devices. Deep learning (DL) naturally\ncomplements CS for adapting the sampling matrix, reconstructing the signal, and\nlearning form the compressed samples. While the CS-DL integration has received\nsubstantial research interest recently, it has not yet been thoroughly\nsurveyed, nor has the light been shed on practical issues towards bringing the\nCS-DL to real world implementations in the ubicomp domain. In this paper we\nidentify main possible ways in which CS and DL can interplay, extract key ideas\nfor making CS-DL efficient, identify major trends in CS-DL research space, and\nderive guidelines for future evolution of CS-DL within the ubicomp domain.",
        "author": [
            "Alina L. Machidon",
            "Veljko Pejovic"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.13191v1.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.13191v1",
        "arXiv ID": "2105.13191v1"
    },
    {
        "title": "Chiral Gravitational Waves in Palatini Chern-Simons",
        "Published: ": "2022-11-16T14:12:30Z",
        "abstract": "We study the parity-breaking higher-curvature gravity theory of Chern-Simons\n(CS), using the Palatini formulation in which the metric and connection are\ntaken to be independent fields. We first show that Palatini CS gravity leads to\nfirst-order derivative equations of motion and thus avoid the typical\ninstabilities of CS gravity in the metric formalism. As an initial application,\nwe analyze the cosmological propagation of gravitational waves (GWs) in\nPalatini CS gravity. We show that, due to parity breaking, the polarizations of\nGWs suffer two effects during propagation: amplitude birefringence (which\nchanges the polarization ellipticity) and velocity birefringence (which rotates\nthe polarization plane). While amplitude birefringence is known to be present\nin CS gravity in the metric formalism, velocity birefringence is not present in\nmetric CS gravity, but now appears in Palatini CS due to the fact that\nleft-handed and right-handed GW polarizations have a different dispersion\nrelation. In the approximation of small deviations from General Relativity\n(GR), we do find however that velocity birefringence appears at least\nquadratically in the CS coupling parameter $\\alpha$, while amplitude\nbirefringence appears linearly in $\\alpha$. This means that amplitude\nbirefringence will be the most relevant effect in Palatini CS and hence this\nmodel will behave similarly to metric CS. We confirm this by applying current\nconstraints on amplitude and velocity birefringence to Palatini CS, and showing\nthat those from amplitude birefringence give the tightest bounds.",
        "author": [
            "Felipe Sulantay",
            "Macarena Lagos",
            "M\u00e1ximo Ba\u00f1ados"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.08925v2.pdf",
        "Categories": [
            [
                "gr-qc",
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.08925v2",
        "arXiv ID": "2211.08925v2"
    },
    {
        "title": "Remarks on the Ideal Structure of Fell Bundle C*-Algebras",
        "Published: ": "2009-12-06T18:47:18Z",
        "abstract": "We show that if $p:\\B\\to G$ is a Fell bundle over a locally compact groupoid\n$G$ and that $A=\\Gamma_{0}(G^{(0)};\\B)$ is the \\cs-algebra sitting over\n$G^{(0)}$, then there is a continuous $G$-action on $\\Prim A$ that reduces to\nthe usual action when $\\B$ comes from a dynamical system. As an application, we\nshow that if $I$ is a $G$-invariant ideal in $A$, then there is a short exact\nsequence of \\cs-algebras \\xymatrix{0\\ar[r]&\\cs(G,\\BI)\\ar[r]\n&\\cs(G,\\B)\\ar[r]&\\cs(G,\\BqI)\\ar[r]&0,} where $\\cs(G,\\B)$ is the Fell bundle\n\\cs-algebra and $\\BI$ and $\\BqI$ are naturally defined Fell bundles\ncorresponding to $I$ and $A/I$, respectively. Of course this exact sequence\nreduces to the usual one for \\cs-dynamical systems.",
        "author": [
            "Marius Ionescu",
            "Dana P. Williams"
        ],
        "pdfLink": "http://arxiv.org/pdf/0912.1124v1.pdf",
        "Categories": [
            [
                "math.OA",
                "math.FA",
                "46L55, 46L05"
            ]
        ],
        "Link": "http://arxiv.org/abs/0912.1124v1",
        "arXiv ID": "0912.1124v1"
    },
    {
        "title": "Applications of Compressed Sensing in Communications Networks",
        "Published: ": "2013-05-14T02:23:47Z",
        "abstract": "This paper presents a tutorial for CS applications in communications\nnetworks. The Shannon's sampling theorem states that to recover a signal, the\nsampling rate must be as least the Nyquist rate. Compressed sensing (CS) is\nbased on the surprising fact that to recover a signal that is sparse in certain\nrepresentations, one can sample at the rate far below the Nyquist rate. Since\nits inception in 2006, CS attracted much interest in the research community and\nfound wide-ranging applications from astronomy, biology, communications, image\nand video processing, medicine, to radar. CS also found successful applications\nin communications networks. CS was applied in the detection and estimation of\nwireless signals, source coding, multi-access channels, data collection in\nsensor networks, and network monitoring, etc. In many cases, CS was shown to\nbring performance gains on the order of 10X. We believe this is just the\nbeginning of CS applications in communications networks, and the future will\nsee even more fruitful applications of CS in our field.",
        "author": [
            "Hong Huang",
            "Satyajayant Misra",
            "Wei Tang",
            "Hajar Barani",
            "Hussein Al-Azzawi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1305.3002v3.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1305.3002v3",
        "arXiv ID": "1305.3002v3"
    },
    {
        "title": "Dynamics of a degenerate Cs-Yb mixture with attractive interspecies\n  interactions",
        "Published: ": "2020-12-20T19:46:45Z",
        "abstract": "We probe the collective dynamics of a quantum degenerate Bose-Bose mixture of\nCs and $^{174}$Yb with attractive interspecies interactions. Specifically, we\nexcite vertical center of mass oscillations of the Cs condensate, and observe\nsignificant damping for the Cs dipole mode, due to the rapid transfer of energy\nto the larger Yb component, and the ensuing acoustic dissipation. Numerical\nsimulations based on coupled Gross-Pitaevskii equations provide excellent\nagreement, and additionally reveal the possibility of late-time revivals\n(beating) which are found to be highly sensitive to the Cs and Yb atom number\ncombinations. By further tuning the interaction strength of Cs using a broad\nFeshbach resonance, we explore the stability of the degenerate mixture, and\nobserve collapse of the Cs condensate mediated by the attractive Cs-Yb\ninteraction when $a_{\\mathrm{Cs}}<50 \\, a_0$, well above the single-species\ncollapse threshold, in good agreement with simulations.",
        "author": [
            "Kali E. Wilson",
            "Alexander Guttridge",
            "I-Kang Liu",
            "Jack Segal",
            "Thomas P. Billam",
            "Nick G. Parker",
            "N. P. Proukakis",
            "Simon L. Cornish"
        ],
        "pdfLink": "http://arxiv.org/pdf/2012.11008v1.pdf",
        "Categories": [
            [
                "cond-mat.quant-gas"
            ]
        ],
        "Link": "http://arxiv.org/abs/2012.11008v1",
        "arXiv ID": "2012.11008v1"
    },
    {
        "title": "Generalized Tensor Summation Compressive Sensing Network (GTSNET): An\n  Easy to Learn Compressive Sensing Operation",
        "Published: ": "2021-08-04T13:13:50Z",
        "abstract": "In CS literature, the efforts can be divided into two groups: finding a\nmeasurement matrix that preserves the compressed information at the maximum\nlevel, and finding a reconstruction algorithm for the compressed information.\nIn the traditional CS setup, the measurement matrices are selected as random\nmatrices, and optimization-based iterative solutions are used to recover the\nsignals. However, when we handle large signals, using random matrices become\ncumbersome especially when it comes to iterative optimization-based solutions.\nEven though recent deep learning-based solutions boost the reconstruction\naccuracy performance while speeding up the recovery, still jointly learning the\nwhole measurement matrix is a difficult process. In this work, we introduce a\nseparable multi-linear learning of the CS matrix by representing it as the\nsummation of arbitrary number of tensors. For a special case where the CS\noperation is set as a single tensor multiplication, the model is reduced to the\nlearning-based separable CS; while a dense CS matrix can be approximated and\nlearned as the summation of multiple tensors. Both cases can be used in CS of\ntwo or multi-dimensional signals e.g., images, multi-spectral images, videos,\netc. Structural CS matrices can also be easily approximated and learned in our\nmulti-linear separable learning setup with structural tensor sum\nrepresentation. Hence, our learnable generalized tensor summation CS operation\nencapsulates most CS setups including separable CS, non-separable CS\n(traditional vector-matrix multiplication), structural CS, and CS of the\nmulti-dimensional signals. For both gray-scale and RGB images, the proposed\nscheme surpasses most state-of-the-art solutions, especially in lower\nmeasurement rates. Although the performance gain remains limited from tensor to\nthe sum of tensor representation for gray-scale images, it becomes significant\nin the RGB case.",
        "author": [
            "Mehmet Yamac",
            "Ugur Akpinar",
            "Erdem Sahin",
            "Serkan Kiranyaz",
            "Moncef Gabbouj"
        ],
        "pdfLink": "http://arxiv.org/pdf/2108.03167v1.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2108.03167v1",
        "arXiv ID": "2108.03167v1"
    },
    {
        "title": "How are Primary School Computer Science Curricular Reforms Contributing\n  to Equity? Impact on Student Learning, Perception of the Discipline, and\n  Gender Gaps",
        "Published: ": "2023-06-01T15:42:26Z",
        "abstract": "Early exposure to Computer Science (CS) for all is critical to broaden\nparticipation and promote equity in the field. But how does introducting CS\ninto primary school curricula impact learning, perception, and gaps between\ngroups of students? We investigate a CS-curricular reform and teacher\nProfessional Development (PD) program from an equity standpoint by applying\nhierarchical regression and structural equation modelling on student learning\nand perception data from three studies with respectively 1384, 2433 & 1644\ngrade 3-6 students (ages 7-11) and their 83, 142 & 95 teachers. Regarding\nlearning, exposure to CS instruction appears to contribute to closing the\nperformance gap between low-achieving and high-achieving students, as well as\npre-existing gender gaps. Despite a lack of direct influence of what was taught\non student learning, there is no impact of teachers' demographics or motivation\non student learning, with teachers' perception of the CS-PD positively\ninfluencing learning. Regarding perception, students perceive CS and its\nteaching tools (robotics, tablets) positively, and even more so when they\nperceive a role model close to them as doing CS. Nonetheless gender differences\nexist all around with boys perceiving CS more positively than girls despite\naccess to CS education. However, access to CS-education affects boys and girls\ndifferently: larger gender gaps are closing (namely those related to robotics),\nwhile smaller gaps are increasing (namely those related to CS and tablets). To\nconclude, our findings highlight how a CS curricular reform impacts learning,\nperception, and equity and supports the importance of i) early introductions to\nCS for all, ii) preparing teachers to teach CS all the while removing the\ninfluence of teacher demographics and motivation on student outcomes, and iii)\nhaving developmentally appropriate activities that signal to all groups of\nstudents.",
        "author": [
            "Laila El-Hamamsy",
            "Barbara Bruno",
            "Catherine Audrin",
            "Morgane Chevalier",
            "Sunny Avry",
            "Jessica Dehler Zufferey",
            "Francesco Mondada"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.00820v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.00820v1",
        "arXiv ID": "2306.00820v1"
    },
    {
        "title": "CS-Rickart and dual CS-Rickart objects in abelian categories",
        "Published: ": "2020-07-21T19:40:54Z",
        "abstract": "We introduce (dual) relative CS-Rickart objects in abelian categories, as\ncommon generalizations of (dual) relative Rickart objects and extending\n(lifting) objects. We study direct summands and (co)products of (dual) relative\nCS-Rickart objects as well as classes all of whose objects are (dual)\nself-CS-Rickart. Applications are given to Grothendieck categories and, in\nparticular, to module and comodule categories.",
        "author": [
            "Septimiu Crivei",
            "Simona Maria Radu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.11059v2.pdf",
        "Categories": [
            [
                "math.CT",
                "math.RA",
                "18E10, 18E15, 16D90, 16T15"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.11059v2",
        "arXiv ID": "2007.11059v2"
    },
    {
        "title": "Barut-Girardello coherent states for u(p,q) and sp(N,R) and their\n  macroscopic superpositions",
        "Published: ": "1997-11-26T10:24:10Z",
        "abstract": "The Barut-Girardello coherent states (BG CS) representation is extended to\nthe noncompact algebras u(p,q) and sp(N,R) in (reducible) quadratic boson\nrealizations. The sp(N,R) BG CS take the form of multimode ordinary\nSchr\\\"odinger cat states. Macroscopic superpositions of 2^{n-1} sp(N,R) CS (2^n\ncanonical CS, n=1,2,...) are pointed out which are overcomplete in the N-mode\nHilbert space and the relation between the canonical CS and the u(p,q) BG-type\nCS representations is established. The sets of u(p,q) and sp(N,R) BG CS and\ntheir discrete superpositions contain many states studied in quantum optics\n(even and odd N-mode CS, pair CS) and provide an approach to quadrature\nsqueezing, alternative to that of intelligent states. New subsets of weakly and\nstrongly nonclassical states are pointed out and their statistical properties\n(first- and second-order squeezing, photon number distributions) are discussed.\nFor specific values of the angle parameters and small amplitude of the\ncanonical CS components these states approaches multimode Fock states with one,\ntwo or three bosons/photons. It is shown that eigenstates of a squared\nnon-Hermitian operator A^2 (generalized cat states) can exhibit squeezing of\nthe quadratures of A.",
        "author": [
            "D. A. Trifonov"
        ],
        "pdfLink": "http://arxiv.org/pdf/quant-ph/9711066v3.pdf",
        "Categories": [
            [
                "quant-ph",
                "nucl-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/quant-ph/9711066v3",
        "arXiv ID": "9711066v3"
    },
    {
        "title": "Denoising-based Turbo Compressed Sensing",
        "Published: ": "2017-03-26T02:26:33Z",
        "abstract": "Turbo compressed sensing (Turbo-CS) is an efficient iterative algorithm for\nsparse signal recovery with partial orthogonal sensing matrices. In this paper,\nwe extend the Turbo-CS algorithm to solve compressed sensing problems involving\nmore general signal structure, including compressive image recovery and\nlow-rank matrix recovery. A main difficulty for such an extension is that the\noriginal Turbo-CS algorithm requires prior knowledge of the signal distribution\nthat is usually unavailable in practice. To overcome this difficulty, we\npropose to redesign the Turbo-CS algorithm by employing a generic denoiser that\ndoes not depend on the prior distribution and hence the name denoising-based\nTurbo-CS (D-Turbo-CS). We then derive the extrinsic information for a generic\ndenoiser by following the Turbo-CS principle. Based on that, we optimize the\nparametric extrinsic denoisers to minimize the output mean-square error (MSE).\nExplicit expressions are derived for the extrinsic SURE-LET denoiser used in\ncompressive image denoising and also for the singular value thresholding (SVT)\ndenoiser used in low-rank matrix denoising. We find that the dynamics of\nD-Turbo-CS can be well described by a scaler recursion called MSE evolution,\nsimilar to the case for Turbo-CS. Numerical results demonstrate that D-Turbo-CS\nconsiderably outperforms the counterpart algorithms in both reconstruction\nquality and running time.",
        "author": [
            "Zhipeng Xue",
            "Junjie Ma",
            "Xiaojun Yuan"
        ],
        "pdfLink": "http://arxiv.org/pdf/1703.08756v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1703.08756v1",
        "arXiv ID": "1703.08756v1"
    },
    {
        "title": "Massive circumstellar envelope around type IIn supernova SN 1995G",
        "Published: ": "2003-06-17T08:57:31Z",
        "abstract": "We model the interaction of the supernova SN 1995G with a dense circumstellar\n(CS) gas in a thin shell approximation. A model fit of the observed bolometric\nlight curve combined with data on the supernova expansion velocity provides an\nestimate of the density of the CS shell, its mass ($\\approx 1 M_{\\odot}$), and\nage ($\\approx 8$ years). It is shown that the derived CS gas density does not\ndepend on the assumed mass of the supernova ejecta. This results from the high\nCS density, which ensures that the forward shock wave is essentially radiative.\nThe derived CS density is consistent with the H$\\alpha$ luminosity and with the\npresence of the apparent effect of Thomson scattering in the red wing of this\nline. The mass of the CS envelope together with its expansion velocity\nindicates that the CS envelope was ejected as a result of violent energy\nrelease ($\\sim 6\\times10^{48}$ erg) eight years before the supernova outburst.",
        "author": [
            "N. N. Chugai",
            "I. J. Danziger"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0306330v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0306330v1",
        "arXiv ID": "0306330v1"
    },
    {
        "title": "Determination of effective microscopic models for the frustrated\n  antiferromagnets Cs$_2$CuCl$_4$ and Cs$_2$CuBr$_4$ by density functional\n  methods",
        "Published: ": "2010-09-03T15:18:18Z",
        "abstract": "We investigate the electronic and magnetic properties of the frustrated\ntriangular-lattice antiferromagnets Cs$_2$CuCl$_4$ and Cs$_2$CuBr$_4$ in the\nframework of density functional theory. Analysis of the exchange couplings J\nand J' using the available X-ray structural data corroborates the values\nobtained from experimental results for Cs$_2$CuBr$_4$ but not for\nCs$_2$CuCl$_4$. In order to understand this discrepancy, we perform a detailed\nstudy of the effect of structural optimization on the exchange couplings of\nCs$_2$CuCl$_4$ employing different exchange-correlation functionals. We find\nthat the exchange couplings depend on rather subtle details of the structural\noptimization and that only when the insulating state (mediated through spin\npolarization) is present in the structural optimization, we do have good\nagreement between the calculated and the experimentally determined exchange\ncouplings. Finally, we discuss the effect of interlayer couplings as well as\nlonger-ranged couplings in both systems.",
        "author": [
            "Kateryna Foyevtsova",
            "Ingo Opahle",
            "Yu-Zhong Zhang",
            "Harald O. Jeschke",
            "Roser Valent\u00ed"
        ],
        "pdfLink": "http://arxiv.org/pdf/1009.0697v2.pdf",
        "Categories": [
            [
                "cond-mat.str-el"
            ]
        ],
        "Link": "http://arxiv.org/abs/1009.0697v2",
        "arXiv ID": "1009.0697v2"
    },
    {
        "title": "Hyperspectral fluorescence microscopy based on Compressive Sampling",
        "Published: ": "2013-07-17T13:17:43Z",
        "abstract": "The mathematical theory of compressed sensing (CS) asserts that one can\nacquire signals from measurements whose rate is much lower than the total\nbandwidth. Whereas the CS theory is now well developed, challenges concerning\nhardware implementations of CS-based acquisition devices-especially in\noptics-have only started being addressed. This paper presents an implementation\nof compressive sensing in fluorescence microscopy and its applications to\nbiomedical imaging. Our CS microscope combines a dynamic structured wide-field\nillumination and a fast and sensitive single-point fluorescence detection to\nenable reconstructions of images of fluorescent beads, cells, and tissues with\nundersampling ratios (between the number of pixels and number of measurements)\nup to 32. We further demonstrate a hyperspectral mode and record images with\n128 spectral channels and undersampling ratios up to 64, illustrating the\npotential benefits of CS acquisition for higher-dimensional signals, which\ntypically exhibits extreme redundancy. Altogether, our results emphasize the\ninterest of CS schemes for acquisition at a significantly reduced rate and\npoint to some remaining challenges for CS fluorescence microscopy.",
        "author": [
            "Makhlad Chahid",
            "Jerome Bobin",
            "Hamed Shams Mousavi",
            "Emmanuel Candes",
            "Maxime Dahan",
            "Vincent Studer"
        ],
        "pdfLink": "http://arxiv.org/pdf/1307.4610v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1307.4610v1",
        "arXiv ID": "1307.4610v1"
    },
    {
        "title": "Sparse Reconstruction-based Detection of Spatial Dimension Holes in\n  Cognitive Radio Networks",
        "Published: ": "2013-07-23T12:14:02Z",
        "abstract": "In this paper, we investigate a spectrum sensing algorithm for detecting\nspatial dimension holes in Multiple Inputs Multiple Outputs (MIMO)\ntransmissions for OFDM systems using Compressive Sensing (CS) tools. This\nextends the energy detector to allow for detecting transmission opportunities\neven if the band is already energy filled. We show that the task described\nabove is not performed efficiently by regular MIMO decoders (such as MMSE\ndecoder) due to possible sparsity in the transmit signal. Since CS\nreconstruction tools take into account the sparsity order of the signal, they\nare more efficient in detecting the activity of the users. Building on\nsuccessful activity detection by the CS detector, we show that the use of a\nCS-aided MMSE decoders yields better performance rather than using either\nCS-based or MMSE decoders separately. Simulations are conducted to verify the\ngains from using CS detector for Primary user activity detection and the\nperformance gain in using CS-aided MMSE decoders for decoding the PU\ninformation for future relaying.",
        "author": [
            "Yahya H. Ezzeldin",
            "Radwa A. Sultan",
            "Karim G. Seddik"
        ],
        "pdfLink": "http://arxiv.org/pdf/1307.6033v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "cs.NI",
                "math.IT",
                "math.OC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1307.6033v1",
        "arXiv ID": "1307.6033v1"
    },
    {
        "title": "Formation of Stoichiometric CsF$_n$ Compounds",
        "Published: ": "2014-08-24T04:39:43Z",
        "abstract": "Alkali halides $MX$, have been viewed as typical ionic compounds,\ncharacterized by 1:1 ratio necessary for charge balance between M$^+$ and\nX$^-$. It was proposed that group I elements like Cs can be oxidized further\nunder high pressure. Here we perform a comprehensive study for the CsF-F system\nat pressures up to 100 GPa, and find extremely versatile chemistry. A series of\nCsF$_n$ ($n$ $\\geq$ 1) compounds are predicted to be stable already at ambient\npressure. Under pressure, 5$p$ electrons in Cs atoms become active, with\ngrowing tendency to form Cs$^{3+}$ and Cs$^{5+}$ valence states at\nfluorine-rich conditions. Although Cs$^{2+}$ and Cs$^{4+}$ are not\nenergetically favoured, the interplay between two mechanisms (polyfluoride\nanions and polyvalent Cs cations) allows CsF$_2$ and CsF$_4$ compounds to be\nstable under pressure. The estimated defluorination temperatures of CsF$_n$\n(n=2,3,5) compounds at atmospheric pressure (218 $^\\circ$C, 150 $^\\circ$C, -15\n$^\\circ$C, respectively), are attractive for fluorine storage applications.",
        "author": [
            "Qiang Zhu",
            "Artem R. Oganov",
            "Qingfeng Zeng"
        ],
        "pdfLink": "http://arxiv.org/pdf/1408.5551v1.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/1408.5551v1",
        "arXiv ID": "1408.5551v1"
    },
    {
        "title": "Performance Limits of Segmented Compressive Sampling: Correlated Samples\n  versus Bits",
        "Published: ": "2014-11-19T11:08:58Z",
        "abstract": "This paper gives performance limits of the segmented compressive sampling\n(CS) which collects correlated samples. It is shown that the effect of\ncorrelation among samples for the segmented CS can be characterized by a\npenalty term in the corresponding bounds on the sampling rate. Moreover, this\npenalty term is vanishing as the signal dimension increases. It means that the\nperformance degradation due to the fixed correlation among samples obtained by\nthe segmented CS (as compared to the standard CS with equivalent size sampling\nmatrix) is negligible for a high-dimensional signal. In combination with the\nfact that the signal reconstruction quality improves with additional samples\nobtained by the segmented CS (as compared to the standard CS with sampling\nmatrix of the size given by the number of original uncorrelated samples), the\nfact that the additional correlated samples also provide new information about\na signal is a strong argument for the segmented CS.",
        "author": [
            "Hao Fang",
            "Sergiy A. Vorobyov",
            "Hai Jiang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1411.5178v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1411.5178v1",
        "arXiv ID": "1411.5178v1"
    },
    {
        "title": "Coherent and semiclassical states of a free particle",
        "Published: ": "2015-02-17T19:32:49Z",
        "abstract": "Coherent states (CS) were first introduced and studied in detail for bound\nmotion and discrete-spectrum systems like harmonic oscillators and similar\nsystems with a quadratic Hamiltonian. However, the problem of constructing CS\nhas still not been investigated in detail for the simplest and physically\nimportant case of a free particle, for which, besides being physically\nimportant, the CS problem is of didactic value in teaching quantum mechanics,\nwith the CS regarded as examples of wave packets representing semiclassical\nmotion. In this paper, we essentially follow the Malkin-Dodonov-Man'ko method\nto construct the CS of a free nonrelativistic particle. We give a detailed\ndiscussion of the properties of the CS obtained, in particular, the\ncompleteness relations, the minimization of uncertainty relations, and the\nevolution of the corresponding probability density. We describe the physical\nconditions under which free-particle CS can be considered semiclassical states.",
        "author": [
            "V. G. Bagrov",
            "D. M. Gitman",
            "A. S. Pereira"
        ],
        "pdfLink": "http://arxiv.org/pdf/1502.05013v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1502.05013v1",
        "arXiv ID": "1502.05013v1"
    },
    {
        "title": "Code-Switching Detection with Data-Augmented Acoustic and Language\n  Models",
        "Published: ": "2018-07-28T15:16:33Z",
        "abstract": "In this paper, we investigate the code-switching detection performance of a\ncode-switching (CS) automatic speech recognition (ASR) system with\ndata-augmented acoustic and language models. We focus on the recognition of\nFrisian-Dutch radio broadcasts where one of the mixed languages, namely\nFrisian, is under-resourced. Recently, we have explored how the acoustic\nmodeling (AM) can benefit from monolingual speech data belonging to the\nhigh-resourced mixed language. For this purpose, we have trained\nstate-of-the-art AMs on a significantly increased amount of CS speech by\napplying automatic transcription and monolingual Dutch speech. Moreover, we\nhave improved the language model (LM) by creating CS text in various ways\nincluding text generation using recurrent LMs trained on existing CS text.\nMotivated by the significantly improved CS ASR performance, we delve into the\nCS detection performance of the same ASR system in this work by reporting CS\ndetection accuracies together with a detailed detection error analysis.",
        "author": [
            "Emre Y\u0131lmaz",
            "Henk van den Heuvel",
            "David A. van Leeuwen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1808.00521v1.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1808.00521v1",
        "arXiv ID": "1808.00521v1"
    },
    {
        "title": "CS-JEDI: Required DEI Education, by CS PhD Students, for CS PhD Students",
        "Published: ": "2023-01-26T21:40:53Z",
        "abstract": "Computer science (CS) has historically struggled with issues related to\ndiversity, equity, and inclusion (DEI). Based on how these issues were\naffecting PhD students in our department, we identified required DEI education\nfor PhD students as a potentially high-impact approach to improving the PhD\nstudent experience in our program. Given that no existing curriculum met the\ndesired criteria, we (PhD students) - along with many others at our school -\ndeveloped and implemented CS-JEDI: Justice, Equity, Diversity, and Inclusion in\nComputer Science. CS-JEDI is a 6-week DEI curriculum that is now taken by all\nfirst-year PhD students in our department. This paper covers CS-JEDI's\nmotivation and goals; describes how its evidence-based curriculum is tailored\nto these goals and to the CS PhD context; and gives a data-driven evaluation of\nthe extent to which CS-JEDI's first offering, in Spring 2022, achieved these\ngoals.",
        "author": [
            "Bailey Flanigan",
            "Ananya A Joshi",
            "Sara McAllister",
            "Catalina Vajiac"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.13045v2.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.13045v2",
        "arXiv ID": "2301.13045v2"
    },
    {
        "title": "Semantic-Aware Image Compressed Sensing",
        "Published: ": "2023-07-06T18:32:50Z",
        "abstract": "Deep learning based image compressed sensing (CS) has achieved great success.\nHowever, existing CS systems mainly adopt a fixed measurement matrix to images,\nignoring the fact the optimal measurement numbers and bases are different for\ndifferent images. To further improve the sensing efficiency, we propose a novel\nsemantic-aware image CS system. In our system, the encoder first uses a fixed\nnumber of base CS measurements to sense different images. According to the base\nCS results, the encoder then employs a policy network to analyze the semantic\ninformation in images and determines the measurement matrix for different image\nareas. At the decoder side, a semantic-aware initial reconstruction network is\ndeveloped to deal with the changes of measurement matrices used at the encoder.\nA rate-distortion training loss is further introduced to dynamically adjust the\naverage compression ratio for the semantic-aware CS system and the policy\nnetwork is trained jointly with the encoder and the decoder in an en-to-end\nmanner by using some proxy functions. Numerical results show that the proposed\nsemantic-aware image CS system is superior to the traditional ones with fixed\nmeasurement matrices.",
        "author": [
            "Bowen Zhang",
            "Zhijin Qin",
            "Geoffrey Ye Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.03246v2.pdf",
        "Categories": [
            [
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.03246v2",
        "arXiv ID": "2307.03246v2"
    },
    {
        "title": "Application of Compressive Sensing Techniques in Distributed Sensor\n  Networks: A Survey",
        "Published: ": "2017-09-28T03:19:33Z",
        "abstract": "In this survey paper, our goal is to discuss recent advances of compressive\nsensing (CS) based solutions in wireless sensor networks (WSNs) including the\nmain ongoing/recent research efforts, challenges and research trends in this\narea. In WSNs, CS based techniques are well motivated by not only the sparsity\nprior observed in different forms but also by the requirement of efficient\nin-network processing in terms of transmit power and communication bandwidth\neven with nonsparse signals. In order to apply CS in a variety of WSN\napplications efficiently, there are several factors to be considered beyond the\nstandard CS framework. We start the discussion with a brief introduction to the\ntheory of CS and then describe the motivational factors behind the potential\nuse of CS in WSN applications. Then, we identify three main areas along which\nthe standard CS framework is extended so that CS can be efficiently applied to\nsolve a variety of problems specific to WSNs. In particular, we emphasize on\nthe significance of extending the CS framework to (i). take communication\nconstraints into account while designing projection matrices and reconstruction\nalgorithms for signal reconstruction in centralized as well in decentralized\nsettings, (ii) solve a variety of inference problems such as detection,\nclassification and parameter estimation, with compressed data without signal\nreconstruction and (iii) take practical communication aspects such as\nmeasurement quantization, physical layer secrecy constraints, and imperfect\nchannel conditions into account. Finally, open research issues and challenges\nare discussed in order to provide perspectives for future research directions.",
        "author": [
            "Thakshila Wimalajeewa",
            "Pramod K. Varshney"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.10401v2.pdf",
        "Categories": [
            [
                "eess.SP",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.10401v2",
        "arXiv ID": "1709.10401v2"
    },
    {
        "title": "Code-Switching Detection Using ASR-Generated Language Posteriors",
        "Published: ": "2019-06-19T09:56:34Z",
        "abstract": "Code-switching (CS) detection refers to the automatic detection of language\nswitches in code-mixed utterances. This task can be achieved by using a CS\nautomatic speech recognition (ASR) system that can handle such language\nswitches. In our previous work, we have investigated the code-switching\ndetection performance of the Frisian-Dutch CS ASR system by using the time\nalignment of the most likely hypothesis and found that this technique suffers\nfrom over-switching due to numerous very short spurious language switches. In\nthis paper, we propose a novel method for CS detection aiming to remedy this\nshortcoming by using the language posteriors which are the sum of the\nframe-level posteriors of phones belonging to the same language. The CS\nASR-generated language posteriors contain more complete language-specific\ninformation on frame level compared to the time alignment of the ASR output.\nHence, it is expected to yield more accurate and robust CS detection. The CS\ndetection experiments demonstrate that the proposed language posterior-based\napproach provides higher detection accuracy than the baseline system in terms\nof equal error rate. Moreover, a detailed CS detection error analysis reveals\nthat using language posteriors reduces the false alarms and results in more\nrobust CS detection.",
        "author": [
            "Qinyi Wang",
            "Emre Y\u0131lmaz",
            "Adem Derinel",
            "Haizhou Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.08003v1.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.08003v1",
        "arXiv ID": "1906.08003v1"
    },
    {
        "title": "Quantum Degenerate Mixtures of Cs and Yb",
        "Published: ": "2020-11-10T22:41:12Z",
        "abstract": "We report the production of quantum degenerate Bose-Bose mixtures of Cs and\nYb with both attractive (Cs + $^{174}$Yb) and repulsive (Cs + $^{170}$Yb)\ninterspecies interactions. Dual-species evaporation is performed in a\nbichromatic optical dipole trap that combines light at 1070 nm and 532 nm to\nenable control of the relative trap depths for Cs and Yb. Maintaining a trap\nwhich is shallower for Yb throughout the evaporation leads to highly efficient\nsympathetic cooling of Cs for both isotopic combinations at magnetic fields\nclose to the Efimov minimum in the Cs three-body recombination rate at around\n22 G. For Cs + $^{174}$Yb, we produce quantum mixtures with typical atom\nnumbers of $N_\\mathrm{Yb} \\sim 5 \\times 10^4$ and $N_\\mathrm{Cs} \\sim 5 \\times\n10^3$. We find that the attractive interspecies interaction (characterised by\nthe scattering length $a_\\mathrm{CsYb} = -75\\,a_0$) is stabilised by the\nrepulsive intraspecies interactions. For Cs + $^{170}$Yb, we produce quantum\nmixtures with typical atom numbers of $N_\\mathrm{Yb} \\sim 4 \\times 10^4$, and\n$N_\\mathrm{Cs} \\sim 1 \\times 10^4$. Here, the repulsive interspecies\ninteraction ($a_\\mathrm{CsYb} = 96\\,a_0$) can overwhelm the intraspecies\ninteractions, such that the mixture sits in a region of partial miscibility.",
        "author": [
            "Kali E. Wilson",
            "Alexander Guttridge",
            "Jack Segal",
            "Simon L. Cornish"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.05436v2.pdf",
        "Categories": [
            [
                "cond-mat.quant-gas",
                "physics.atom-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.05436v2",
        "arXiv ID": "2011.05436v2"
    },
    {
        "title": "CS Education for the Socially-Just Worlds We Need: The Case for\n  Justice-Centered Approaches to CS in Higher Education",
        "Published: ": "2021-09-27T18:08:25Z",
        "abstract": "Justice-centered approaches to equitable computer science (CS) education\nframe CS learning as a means for advancing peace, antiracism, and social\njustice rather than war, empire, and corporations. However, most research in\njustice-centered approaches in CS education focus on K-12 learning\nenvironments. In this position paper, we review justice-centered approaches to\nCS education, problematize the lack of justice-centered approaches to CS in\nhigher education in particular, and describe a justice-centered approach for\nundergraduate Data Structures and Algorithms. Our approach emphasizes three\ncomponents: (1) ethics: critiques the sociopolitical values of data structure\nand algorithm design as well as the underlying logics of dominant computing\nculture; (2) identity: draws on culturally responsive-sustaining pedagogies to\nemphasize student identity as rooted in resistance to the dominant computing\nculture; and (3) political vision: ensures the rightful presence of political\nstruggles by reauthoring rights to frame CS learning as a force for social\njustice. Through a case study of this Critical Comparative Data Structures and\nAlgorithms pedagogy, we argue that justice-centered approaches to higher CS\neducation can help all computing students not only learn about the ethical\nimplications of nominally technical concepts, but also develop greater respect\nfor diverse epistemologies, cultures, and experiences surrounding computing\nthat are essential to creating the socially-just worlds we need.",
        "author": [
            "Kevin Lin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.13283v3.pdf",
        "Categories": [
            [
                "cs.CY",
                "K.3.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.13283v3",
        "arXiv ID": "2109.13283v3"
    },
    {
        "title": "Cofiniteness with respect to extension of Serre subcategories at small\n  dimensions",
        "Published: ": "2022-05-28T22:25:11Z",
        "abstract": "Let $R$ be a commutative noetherian ring, $\\frak a$ be an ideal of $R$, $\\cS$\nbe an arbitrary Serre subcategory of $R$-modules and let $\\cN$ be the\nsubcategory of finitely generated $R$-modules. In this paper, we study\n$\\cN\\cS$-$\\frak a$-cofinite modules with respect to the extension subcategory\n$\\cN\\cS$ when $\\dim R/\\frak a\\leq 2$. We also study $\\frak a$-cofiniteness with\nrespect to a new dimension.",
        "author": [
            "Reza Sazeedeh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.14535v1.pdf",
        "Categories": [
            [
                "math.AC",
                "13D45"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.14535v1",
        "arXiv ID": "2205.14535v1"
    },
    {
        "title": "Influence of Rb, Cs and Ba on Superconductivity of Magnesium Diboride",
        "Published: ": "2007-07-26T14:28:10Z",
        "abstract": "Magnesium diboride has been thermally treated in the presence of Rb, Cs, and\nBa. Magnetic susceptibility shows onsets of superconductivity in the resulting\nsamples at 52K (Rb), 58K (Cs) and 45K (Ba). Room-temperature 11B NMR indicates\nto cubic symmetry of the electric field gradient at boron site for the samples\nreacted with Rb and Cs, in contrast to the axial symmetry in the initial MgB2\nand in the sample treated with Ba.",
        "author": [
            "A. V. Palnichenko",
            "O. M. Vyaselev",
            "N. S. Sidorov"
        ],
        "pdfLink": "http://arxiv.org/pdf/0707.3931v3.pdf",
        "Categories": [
            [
                "cond-mat.supr-con"
            ]
        ],
        "Link": "http://arxiv.org/abs/0707.3931v3",
        "arXiv ID": "0707.3931v3"
    },
    {
        "title": "Complex energy approaches for calculating isobaric analogue states",
        "Published: ": "2008-06-30T12:15:12Z",
        "abstract": "Two methods the complex energy shell model (CXSM) and the complex scaling\n(CS) approach were used for calculating isobaric analog resonances (IAR) in the\nLane model. The IAR parameters calculated by the CXSM and the CS methods were\nchecked against the parameters extracted from the direct numerical solution of\nthe coupled channel Lane equations (CC). The agreement with the CC results was\ngenerally better than 1 keV for both methods and for each partial waves\nconcerned. Similarities and differences of the CXSM and the CS methods are\ndiscussed. CXSM offers a direct way to study the configurations of the IAR wave\nfunction in contrast to the CS method.",
        "author": [
            "R. Id Betan",
            "A. T. Kruppa",
            "T. Vertse"
        ],
        "pdfLink": "http://arxiv.org/pdf/0806.4871v1.pdf",
        "Categories": [
            [
                "nucl-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/0806.4871v1",
        "arXiv ID": "0806.4871v1"
    },
    {
        "title": "Super-resolution ghost imaging via compressive sampling reconstruction",
        "Published: ": "2009-10-26T08:10:10Z",
        "abstract": "For ghost imaging, pursuing high resolution images and short acquisition\ntimes required for reconstructing images are always two main goals. We report\nan image reconstruction algorithm called compressive sampling (CS)\nreconstruction to recover ghost images. By CS reconstruction, ghost imaging\nwith both super-resolution and a good signal-to-noise ratio can be obtained via\nshort acquisition times. Both effect influencing and approaches further\nimproving the resolution of ghost images via CS reconstruction, relationship\nbetween ghost imaging and CS theory are also discussed.",
        "author": [
            "Wenlin Gong",
            "Shensheng Han"
        ],
        "pdfLink": "http://arxiv.org/pdf/0910.4823v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/0910.4823v1",
        "arXiv ID": "0910.4823v1"
    },
    {
        "title": "On Fractional Quantum Hall Solitons in ABJM-like Theory",
        "Published: ": "2011-07-12T13:59:12Z",
        "abstract": "Using D-brane physics, we study fractional quantum Hall solitons (FQHS) in\nABJM-like theory in terms of type IIA dual geometries. In particular, we\ndiscuss a class of Chern-Simons (CS) quivers describing FQHS sytems at low\nenergy. These CS quivers come from R-R gauge fields interacting with D6-branes\nwrapped on 4-cycles, which reside within a blown up CP^3 projective space.\nBased on the CS quiver method and mimicking the construction of del Pezzo\nsurfaces in terms of CP^2, we first give a model which corresponds to a single\nlayer model of FQHS system, then we propose a multi-layer system generalizing\nthe doubled CS field theory, which is used in the study of topological defect\nin graphene.",
        "author": [
            "Adil Belhaj"
        ],
        "pdfLink": "http://arxiv.org/pdf/1107.2295v1.pdf",
        "Categories": [
            [
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/1107.2295v1",
        "arXiv ID": "1107.2295v1"
    },
    {
        "title": "Derived equivalences of functor categories",
        "Published: ": "2015-05-18T06:28:13Z",
        "abstract": "Let $\\Mod \\CS$ denote the category of $\\CS$-modules, where $\\CS$ is a small\ncategory. In the first part of this paper, we provide a version of Rickard's\ntheorem on derived equivalence of rings for $\\Mod \\CS$. This will have several\ninteresting applications. In the second part, we apply our techniques to get\nsome interesting recollements of derived categories in different levels. We\nspecialize our results to path rings as well as graded rings.",
        "author": [
            "Javad Asadollahi",
            "Rasool Hafezi",
            "Razieh Vahed"
        ],
        "pdfLink": "http://arxiv.org/pdf/1505.04522v1.pdf",
        "Categories": [
            [
                "math.RT",
                "18E30, 16E35, 16E65, 16P10, 16G10"
            ]
        ],
        "Link": "http://arxiv.org/abs/1505.04522v1",
        "arXiv ID": "1505.04522v1"
    },
    {
        "title": "Carrier envelope phase dynamics of cavity solitons: soliton stability\n  and scaling law",
        "Published: ": "2015-06-29T11:40:06Z",
        "abstract": "The relationship between carrier envelope phase (CEP) slip of cavity soliton\n(CS) and pump phase detuning is derived analytically and numerically. To\npreserve the stability of CS, CEP slip always equals to the pump phase\ndetuning. When CEP slip fails to follow the pump phase detuning, CS becomes\nunstable. The locking between CEP slip and pump phase detuning results in a\nscaling law for CS.",
        "author": [
            "Chengying Bao",
            "Changxi Yang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1506.08589v1.pdf",
        "Categories": [
            [
                "physics.optics"
            ]
        ],
        "Link": "http://arxiv.org/abs/1506.08589v1",
        "arXiv ID": "1506.08589v1"
    },
    {
        "title": "$Y(4626)$ as a $P$-wave $[cs][\\bar{c}\\bar{s}]$ tetraquark state",
        "Published: ": "2020-04-23T06:03:09Z",
        "abstract": "Motivated by the Belle Collaboration's new observation of $Y(4626)$, we\ninvestigate the possibility of its configuration as a $P$-wave\n$[cs][\\bar{c}\\bar{s}]$ tetraquark state from QCD sum rules. Eventually, the\nextracted mass $4.60^{+0.13}_{-0.19}~\\mbox{GeV}$ for the $P$-wave\n$cs$-scalar-diquark $\\bar{c}\\bar{s}$-scalar-antidiquark state agrees well with\nthe experimental data of $Y(4626)$, which could support its interpretation as a\n$P$-wave scalar-scalar $[cs][\\bar{c}\\bar{s}]$ tetraquark state.",
        "author": [
            "Jian-Rong Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.10985v2.pdf",
        "Categories": [
            [
                "hep-ph",
                "hep-ex"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.10985v2",
        "arXiv ID": "2004.10985v2"
    },
    {
        "title": "Study on Compressed Sensing of Action Potential",
        "Published: ": "2021-01-30T18:28:40Z",
        "abstract": "Compressive sensing (CS) is a signal processing technique that enables\nsub-Nyquist sampling and near lossless reconstruction of a sparse signal. The\ntechnique is particularly appealing for neural signal processing since it\navoids the issues relevant to high sampling rate and large data storage. In\nthis project, different CS reconstruction algorithms were tested on raw action\npotential signals recorded in our lab. Two numerical criteria were set to\nevaluate the performance of different CS algorithms: Compression Ratio (CR) and\nSignal-to-Noise Ratio (SNR). In order to do this, individual CS algorithm\ntesting platforms for the EEG data were constructed within MATLAB scheme. The\nmain considerations for the project were the following. 1) Feasibility of the\ndictionary 2) Tolerance to non-sparsity 3) Applicability of thresholding or\ninterpolation.",
        "author": [
            "Hyunseok Park",
            "Xilin Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.00284v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.00284v1",
        "arXiv ID": "2102.00284v1"
    },
    {
        "title": "Type Ibn supernova SN~2010al: Powerful mass loss half year prior to the\n  explosion",
        "Published: ": "2022-03-05T12:13:28Z",
        "abstract": "Type Ibn supernova SN~2010al is explored to infer parameters of supernova and\na circumstellar (CS) shell. The CS interaction model combined with the spectral\nmodel of 4600\\AA\\ blend suggests the explosion of a WR star with the energy of\n$(1-1.5)\\times10^{51}$ erg inside a dense confined CS shell with the mass of\n$\\sim0.1$\\msun\\ and kinetic energy of $\\sim 10^{48}$ erg. The confined CS shell\nhas been formed during the last 0.4 yr prior to the core collapse.",
        "author": [
            "Nikolai Chugai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.02717v1.pdf",
        "Categories": [
            [
                "astro-ph.HE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.02717v1",
        "arXiv ID": "2203.02717v1"
    },
    {
        "title": "Cutting-Splicing data augmentation: A novel technology for medical image\n  segmentation",
        "Published: ": "2022-10-17T13:52:01Z",
        "abstract": "Background: Medical images are more difficult to acquire and annotate than\nnatural images, which results in data augmentation technologies often being\nused in medical image segmentation tasks. Most data augmentation technologies\nused in medical segmentation were originally developed on natural images and do\nnot take into account the characteristic that the overall layout of medical\nimages is standard and fixed. Methods: Based on the characteristics of medical\nimages, we developed the cutting-splicing data augmentation (CS-DA) method, a\nnovel data augmentation technology for medical image segmentation. CS-DA\naugments the dataset by splicing different position components cut from\ndifferent original medical images into a new image. The characteristics of the\nmedical image result in the new image having the same layout as and similar\nappearance to the original image. Compared with classical data augmentation\ntechnologies, CS-DA is simpler and more robust. Moreover, CS-DA does not\nintroduce any noise or fake information into the newly created image. Results:\nTo explore the properties of CS-DA, many experiments are conducted on eight\ndiverse datasets. On the training dataset with the small sample size, CS-DA can\neffectively increase the performance of the segmentation model. When CS-DA is\nused together with classical data augmentation technologies, the performance of\nthe segmentation model can be further improved and is much better than that of\nCS-DA and classical data augmentation separately. We also explored the\ninfluence of the number of components, the position of the cutting line, and\nthe splicing method on the CS-DA performance. Conclusions: The excellent\nperformance of CS-DA in the experiment has confirmed the effectiveness of\nCS-DA, and provides a new data augmentation idea for the small sample\nsegmentation task.",
        "author": [
            "Lianting Hu",
            "Huiying Liang",
            "Jiajie Tang",
            "Xin Li",
            "Li Huang",
            "Long Lu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.09099v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.09099v1",
        "arXiv ID": "2210.09099v1"
    },
    {
        "title": "A Class of Novel STAP Algorithms Using Sparse Recovery Technique",
        "Published: ": "2009-04-08T11:58:02Z",
        "abstract": "A class of novel STAP algorithms based on sparse recovery technique were\npresented. Intrinsic sparsity of distribution of clutter and target energy on\nspatial-frequency plane was exploited from the viewpoint of compressed sensing.\nThe original sample data and distribution of target and clutter energy was\nconnected by a ill-posed linear algebraic equation and popular $L_1$\noptimization method could be utilized to search for its solution with sparse\ncharacteristic. Several new filtering algorithm acting on this solution were\ndesigned to clean clutter component on spatial-frequency plane effectively for\ndetecting invisible targets buried in clutter. The method above is called\nCS-STAP in general. CS-STAP showed their advantage compared with conventional\nSTAP technique, such as SMI, in two ways: Firstly, the resolution of CS-STAP on\nestimation for distribution of clutter and target energy is ultra-high such\nthat clutter energy might be annihilated almost completely by carefully tuned\nfilter. Output SCR of CS-STAP algorithms is far superior to the requirement of\ndetection; Secondly, a much smaller size of training sample support compared\nwith SMI method is requested for CS-STAP method. Even with only one snapshot\n(from target range cell) could CS-STAP method be able to reveal the existence\nof target clearly. CS-STAP method display its great potential to be used in\nheterogeneous situation. Experimental result on dataset from mountaintop\nprogram has provided the evidence for our assertion on CS-STAP.",
        "author": [
            "Hao Zhang",
            "Gang Li",
            "Huadong Meng"
        ],
        "pdfLink": "http://arxiv.org/pdf/0904.1313v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/0904.1313v1",
        "arXiv ID": "0904.1313v1"
    },
    {
        "title": "Effective Pedestrian Detection Using Center-symmetric Local\n  Binary/Trinary Patterns",
        "Published: ": "2010-09-05T05:16:11Z",
        "abstract": "Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset.",
        "author": [
            "Yongbin Zheng",
            "Chunhua Shen",
            "Richard Hartley",
            "Xinsheng Huang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1009.0892v2.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1009.0892v2",
        "arXiv ID": "1009.0892v2"
    },
    {
        "title": "Sensitivity of the Fe K-alpha Compton shoulder to the geometry and\n  variability of the X-ray illumination of cosmic objects",
        "Published: ": "2016-07-19T02:55:16Z",
        "abstract": "In an X-ray reflection spectrum, a tail-like spectral feature generated via\nCompton down-scattering, known as a Compton shoulder (CS), appears at the\nlow-energy side of the iron K$\\alpha$ line. Despite its great diagnostic\npotential, its use as a spectral probe of the reflector has been seriously\nlimited due to observational difficulties and modelling complexities. We\nrevisit the basic nature of the CS by systematic investigation into its\ndependence on spatial and temporal parameters. The calculations are performed\nby Monte-Carlo simulations for sphere and slab geometries. The dependence is\nobtained in a two-dimensional space of column density and metal abundance,\ndemonstrating that the CS solves parameter degeneration between them which was\nseen in conventional spectral analysis using photoelectric absorption and\nfluorescence lines. Unlike the iron line, the CS does not suffer from any\nobservational dependence on the spectral hardness. The CS profile is highly\ndependent on the inclination angle of the slab geometry unless the slab is\nCompton-thick, and the time evolution of the CS is shown to be useful to\nconstrain temporal information on the source if the intrinsic radiation is\nvariable. We also discuss how atomic binding of the scattering electrons in\ncold matter blurs the CS profile, finding that the effect is practically\nsimilar to thermal broadening in a plasma with a moderate temperature of\n$\\sim$5 eV. Spectral diagnostics using the CS is demonstrated with grating data\nof X-ray binary GX 301$-$2, and will be available in future with\nhigh-resolution spectra of active galactic nuclei obtained by\nmicrocalorimeters.",
        "author": [
            "Hirokazu Odaka",
            "Hiroki Yoneda",
            "Tadayuki Takahashi",
            "Andrew Fabian"
        ],
        "pdfLink": "http://arxiv.org/pdf/1607.05385v1.pdf",
        "Categories": [
            [
                "astro-ph.HE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1607.05385v1",
        "arXiv ID": "1607.05385v1"
    },
    {
        "title": "On the pumping of the CS($v=0$) masers in W51 e2e",
        "Published: ": "2020-11-20T14:16:34Z",
        "abstract": "We present the results of numerically solving the rate equations for the\nfirst 31 rotational states of CS in the ground vibrational state to determine\nthe conditions under which the J=1-0, J=2-1 and J=3-2 transitions are inverted\nto produce maser emission. The essence of our results is that the CS($v=0$)\nmasers are collisionally pumped and that, depending on the spectral energy\ndistribution, dust emission can suppress the masers. Apart from the J=1-0 and\nJ=2-1 masers the calculations also show that the J=3-2 transition can be\ninverted to produce maser emission. It is found that beaming is necessary to\nexplain the observed brightness temperatures of the recently discovered CS\nmasers in W51 e2e. The model calculations suggest that a CS abundance of a few\ntimes $10^{-5}$ and CS($v=0$) column densities of the order\n$10^{16}\\,\\mathrm{cm^{-2}}$ are required for these masers. The rarity of the CS\nmasers in high mass star forming regions might be the result of a required high\nCS abundance as well as due to attenuation of the maser emission inside as well\nas outside of the hot core.",
        "author": [
            "D. J. van der Walt",
            "A. Ginsburg",
            "C. Goddi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.10420v2.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.10420v2",
        "arXiv ID": "2011.10420v2"
    },
    {
        "title": "Black String and G\u00f6del type Solutions of Chern-Simons Modified\n  Gravity",
        "Published: ": "2010-03-31T10:53:59Z",
        "abstract": "Chern-Simons (CS) modified gravity with a prescribed CS scalar field does not\nadmit rotating black hole solutions with spherical topology of the horizon. In\nthis paper, we show that it does admit rotating {\\it black hole/string}\nsolutions with cylindrical topology of the horizon and present two intriguing\nphysical examples of such configurations. First, we show that the\nBanados-Teitelboim-Zanelli (BTZ) stationary black string, that is obtained by\nadding on a spacelike flat dimension to the BTZ black hole metric of\nthree-dimensional gravity, solves the field equations of CS modified gravity\nwith a specific source term and {\\it irrespective of the choice of CS scalar\nfield}. Next, we consider the Lemos solution for a rotating straight black\nstring in general relativity and show that for the CS scalar field being a\nfunction of the radial coordinate alone, this solution persists in CS modified\ngravity. We also discuss two examples of G\\\"{o}del type metrics in CS modified\ngravity by uplifting to four dimensions a general one-parameter family of\nG\\\"{o}del type solutions of three-dimensional gravity. The first example is the\nusual G\\\"{o}del solution of general relativity which also survives in CS\nmodified gravity with the CS scalar field depending on two variables, the\nradial and the azimuthal coordinates. The second example represents a new\nnontrivial (non general relativity) G\\\"{o}del type solution to the vacuum field\nequations of CS modified gravity. This solution originates from the respective\nvacuum solution of topologically massive gravity when extending it to four\ndimensions by adding on an extra spatial coordinate and choosing the CS scalar\nfield as a linear function of this coordinate.",
        "author": [
            "Haji Ahmedov",
            "Alikram N. Aliev"
        ],
        "pdfLink": "http://arxiv.org/pdf/1003.6017v2.pdf",
        "Categories": [
            [
                "hep-th",
                "astro-ph.HE",
                "gr-qc"
            ]
        ],
        "Link": "http://arxiv.org/abs/1003.6017v2",
        "arXiv ID": "1003.6017v2"
    },
    {
        "title": "Free energy sources in current sheets formed in collisionless plasma\n  turbulence",
        "Published: ": "2020-08-30T15:58:37Z",
        "abstract": "Collisionless dissipation of macroscopic energy into heat is an unsolved\nproblem of space and astrophysical plasmas, e.g., solar wind and Earth's\nmagnetosheath. The most viable process under consideration is the\nturbulent-cascade of macroscopic energy to kinetic-scales where\ncollisionless-plasma-processes dissipate the energy. Space observations and\nnumerical simulations show the formation of kinetic scale current sheets in\nturbulent plasmas. Instabilities in these CS can provide collisionless\ndissipation and influence the turbulence. Spatial gradients of physical\nquantities and non-Maxwellian velocity distribution functions provide the\nfree-energy-sources for CS plasma instabilities. To determine the\nfree-energy-sources provided by the spatial gradients of plasma density and\nelectron/ion bulk velocities in CS formed in collisionless turbulent plasmas\nwith an external magnetic field $\\mathbf{B}_0$, we carried out two-dimensional\nPIC-hybrid simulations and interpret the results within the limitations of the\nsimulation model.\n  We found that ion-scale CS in a collisionless turbulent plasma are formed\nprimarily by electron shear flows, i.e., electron bulk velocity inside CS is\nmuch larger than ion bulk velocity while the density variations through the CS\nare relatively small ($<$ 10\\%). The electron-bulk-velocity and, thus, the\ncurrent density inside the sheets are directed mainly parallel to\n$\\mathbf{B}_0$. The shear in the perpendicular electron- and\nion-bulk-velocities generates parallel electron- and ion-flow-vorticities.\nInside CS, parallel electron-flow-vorticity exceeds the parallel\nion-flow-vorticity, changes sign around the CS centers and peaks near the CS\nedges. An ion temperature anisotropy develops near CS during the CS formation.\nIt has positive correlation with the parallel ion- and\nelectron-flow-vorticities. Theoretical estimates support the simulation\nresults.",
        "author": [
            "Neeraj Jain",
            "J\u00f6rg B\u00fcchner",
            "Horia Comi\u015fel",
            "Uwe Motschmann"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.13206v2.pdf",
        "Categories": [
            [
                "physics.plasm-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.13206v2",
        "arXiv ID": "2008.13206v2"
    },
    {
        "title": "Stability of adsorption of Mg and Na on sulfur-functionalized MXenes",
        "Published: ": "2021-10-20T22:31:23Z",
        "abstract": "Two-dimensional materials composed of transition metal carbides and nitrides\n(MXenes) are poised to revolutionize energy conversion and storage. In this\nwork, we used density functional theory (DFT) to investigate adsorption of Mg\nand Na adatoms on five M$_{2}$CS$_{2}$ monolayers (where M= Mo, Nb, Ti, V, Zr)\nfor battery applications. We assessed the stability of the adatom (i.e. Na and\nMg)-monolayer systems by calculating adsorption and formation energies, as well\nas voltages as a function of surface coverage. For instance, we found that\nMo$_{2}$CS$_{2}$ cannot support a full layer of Na nor even a single Mg atom.\nNa and Mg exhibit the strongest binding on Zr$_{2}$CS$_{2}$, followed by\nTi$_{2}$CS$_{2}$, Nb$_{2}$CS$_{2}$ and V$_{2}$CS$_{2}$. Using the nudged\nelastic band method (NEB) we computed promising diffusion barriers for both\ndilute and nearly-full ion surface coverage cases. In the dilute ion adsorption\ncase, a single Mg and Na atom on Ti$_{2}$CS$_{2}$ experience $\\sim$0.47 eV and\n$\\sim$0.10 eV diffusion barriers between the lowest energy sites, respectively.\nFor a nearly full surface coverage, a Na ion moving on Ti$_{2}$CS$_{2}$\nexperiences a $\\sim$0.33 eV energy barrier, implying a concentration dependent\ndiffusion barrier. Our molecular dynamics results indicate that three (one)\nlayers (layer) of Mg (Na) ion on both surfaces of Ti$_{2}$CS$_{2}$ remain\nstable at T=300 K. While, according to voltage calculations, Zr$_{2}$CS$_{2}$\ncan store Na up to three atomic layers, our MD simulations predict that the\noutermost layers detach from Zr$_{2}$CS$_{2}$ monolayer due to weak interaction\nbetween Na ions and the monolayer. This suggests that MD simulations are\nessential to confirming the stability of an ion-electrode system - an insight\nthat is mostly absence in previous studies.",
        "author": [
            "G. Chaney",
            "D. \u00c7ak\u0131r",
            "F. M. Peeters",
            "C. Ataca"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.10810v1.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.10810v1",
        "arXiv ID": "2110.10810v1"
    },
    {
        "title": "Worst Configurations (Instantons) for Compressed Sensing over Reals: a\n  Channel Coding Approach",
        "Published: ": "2010-01-28T07:08:33Z",
        "abstract": "We consider the Linear Programming (LP) solution of the Compressed Sensing\n(CS) problem over reals, also known as the Basis Pursuit (BasP) algorithm. The\nBasP allows interpretation as a channel-coding problem, and it guarantees\nerror-free reconstruction with a properly chosen measurement matrix and\nsufficiently sparse error vectors. In this manuscript, we examine how the BasP\nperforms on a given measurement matrix and develop an algorithm to discover the\nsparsest vectors for which the BasP fails. The resulting algorithm is a\ngeneralization of our previous results on finding the most probable\nerror-patterns degrading performance of a finite size Low-Density Parity-Check\n(LDPC) code in the error-floor regime. The BasP fails when its output is\ndifferent from the actual error-pattern. We design a CS-Instanton Search\nAlgorithm (ISA) generating a sparse vector, called a CS-instanton, such that\nthe BasP fails on the CS-instanton, while the BasP recovery is successful for\nany modification of the CS-instanton replacing a nonzero element by zero. We\nalso prove that, given a sufficiently dense random input for the error-vector,\nthe CS-ISA converges to an instanton in a small finite number of steps. The\nperformance of the CS-ISA is illustrated on a randomly generated $120\\times\n512$ matrix. For this example, the CS-ISA outputs the shortest instanton (error\nvector) pattern of length 11.",
        "author": [
            "Shashi Kiran Chilappagari",
            "Michael Chertkov",
            "Bane Vasic"
        ],
        "pdfLink": "http://arxiv.org/pdf/1001.5113v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1001.5113v2",
        "arXiv ID": "1001.5113v2"
    },
    {
        "title": "Coherent and semiclassical states in magnetic field in the presence of\n  the Aharonov-Bohm solenoid",
        "Published: ": "2010-08-10T18:36:45Z",
        "abstract": "A new approach to constructing coherent states (CS) and semiclassical states\n(SS) in magnetic-solenoid field is proposed. The main idea is based on the fact\nthat the AB solenoid breaks the translational symmetry in the xy-plane, this\nhas a topological effect such that there appear two types of trajectories which\nembrace and do not embrace the solenoid. Due to this fact, one has to construct\ntwo different kinds of CS/SS, which correspond to such trajectories in the\nsemiclassical limit. Following this idea, we construct CS in two steps, first\nthe instantaneous CS (ICS) and the time dependent CS/SS as an evolution of the\nICS. The construction is realized for nonrelativistic and relativistic spinning\nparticles both in (2+1)- and (3+1)- dimensions and gives a non-trivial example\nof SS/CS for systems with a nonquadratic Hamiltonian. It is stressed that CS\ndepending on their parameters (quantum numbers) describe both pure quantum and\nsemiclassical states. An analysis is represented that classifies parameters of\nthe CS in such respect. Such a classification is used for the semiclassical\ndecompositions of various physical quantities.",
        "author": [
            "V. G. Bagrov",
            "S. P. Gavrilov",
            "D. M. Gitman",
            "D. P. Meira Filho"
        ],
        "pdfLink": "http://arxiv.org/pdf/1008.1768v3.pdf",
        "Categories": [
            [
                "quant-ph",
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/1008.1768v3",
        "arXiv ID": "1008.1768v3"
    },
    {
        "title": "Cost Minimization of Charging Stations with Photovoltaics: An Approach\n  with EV Classification",
        "Published: ": "2015-07-29T00:26:31Z",
        "abstract": "This paper proposes a novel electric vehicle (EV) classification scheme for a\nphotovoltaic (PV) powered EV charging station (CS) that reduces the effect of\nintermittency of electricity supply as well as reducing the cost of energy\ntrading of the CS. Since not all EV drivers would like to be environmentally\nfriendly, all vehicles in the CS are divided into three categories: 1) premium,\n2) conservative, and 3) green, according to their charging behavior. Premium\nand conservative EVs are considered to be interested only in charging their\nbatteries, with noticeably higher rate of charging for premium EVs. Green\nvehicles are more environmentally friendly, and thus assist the CS to reduce\nits cost of energy trading by allowing the CS to use their batteries as\ndistributed storage. A different charging scheme is proposed for each type of\nEV, which is adopted by the CS to encourage more EVs to be green. A basic mixed\ninteger programming (MIP) technique is used to facilitate the proposed\nclassification scheme. It is shown that the uncertainty in PV generation can be\neffectively compensated, along with minimization of total cost of energy\ntrading to the CS, by consolidating more green EVs. Real solar and pricing data\nare used for performance analysis of the system. It is demonstrated that the\ntotal cost to the CS reduces considerably as the percentage of green vehicles\nincreases, and also that the contributions of green EVs in winter are greater\nthan those in summer.",
        "author": [
            "Wayes Tushar",
            "Chau Yuen",
            "Shisheng Huang",
            "David Smith",
            "H. Vincent Poor"
        ],
        "pdfLink": "http://arxiv.org/pdf/1507.07994v1.pdf",
        "Categories": [
            [
                "cs.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1507.07994v1",
        "arXiv ID": "1507.07994v1"
    },
    {
        "title": "Could multiple voids explain the Cosmic Microwave Background Cold Spot\n  anomaly?",
        "Published: ": "2015-12-08T23:12:59Z",
        "abstract": "Understanding the observed Cold Spot (CS) (temperature of ~ -150 mu K at its\ncentre) on the Cosmic Microwave Background (CMB) is an outstanding problem.\nExplanations vary from assuming it is just a > 3 sigma primordial Gaussian\nfluctuation to the imprint of a supervoid via the Integrated Sachs-Wolfe and\nRees-Sciama (ISW+RS) effects. Since single spherical supervoids cannot account\nfor the full profile, the ISW+RS of multiple line-of-sight voids is studied\nhere to mimic the structure of the cosmic web. Two structure configurations are\nconsidered. The first, through simulations of 20 voids, produces a central mean\ntemperature of ~-50 mu K. In this model the central CS temperature lies at ~ 2\nsigma but fails to explain the CS hot ring. An alternative multi-void model\n(using more pronounced compensated voids) produces much smaller temperature\nprofiles, but contains a prominent hot ring. Arrangements containing closely\nplaced voids at low redshift are found to be particularly well suited to\nproduce CS-like profiles. We then measure the significance of the CS if CS-like\nprofiles (which are fitted to the ISW+RS of multi-void scenarios) are removed.\nThe CS tension with the LCDM model can be reduced dramatically for an array of\ntemperature profiles smaller than the CS itself.",
        "author": [
            "Krishna Naidoo",
            "Aur\u00e9lien Benoit-L\u00e9vy",
            "Ofer Lahav"
        ],
        "pdfLink": "http://arxiv.org/pdf/1512.02694v2.pdf",
        "Categories": [
            [
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1512.02694v2",
        "arXiv ID": "1512.02694v2"
    },
    {
        "title": "Effects of Quantum and Dielectric Confinement on the Emission of\n  Cs-Pb-Br Composites",
        "Published: ": "2023-06-14T14:48:19Z",
        "abstract": "The halide perovskite CsPbBr$_3$ belongs to the Cs-Pb-Br material system,\nwhich features two additional thermodynamically stable ternary phases,\nCs$_4$PbBr$_6$ and CsPb$_2$Br$_5$. The coexistence of these phases and their\nreportedly similar photoluminescence have resulted in a debate on the nature of\nthe emission in these systems. Here, we combine optical and microscopic\ncharacterization with an effective mass, correlated electron-hole model of\nexcitons in confined systems, to investigate the emission properties of the\nternary phases in the Cs-Pb-Br system. We find that all Cs-Pb-Br phases exhibit\ngreen emission and the non-perovskite phases exhibit photoluminescence quantum\nyields orders of magnitude larger than CsPbBr$_3$. In particular, we measure\nblue- and red-shifted emission for the Cs- and Pb-rich phases, respectively,\nstemming from embedded CsPbBr$_3$ nanocrystals. Our model reveals that the\ndifference in emission shift is caused by the combined effects of nanocrystal\nsize and different band mismatch. Furthermore, we demonstrate the importance of\nincluding the dielectric mismatch in the calculation of the emission energy for\nCs-Pb-Br composites. Our results explain the reportedly limited blue shift in\nCsPbBr$_3$@Cs$_4$PbBr$_6$ composites and rationalize some of its differences\nwith CsPb$_2$Br$_5$.",
        "author": [
            "Sebasti\u00e1n Caicedo-D\u00e1vila",
            "Pietro Caprioglio",
            "Frederike Lehmann",
            "Sergiu Levcenco",
            "Martin Stolterfoht",
            "Dieter Neher",
            "Leeor Kronik",
            "Daniel Abou-Ras"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.08548v2.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.08548v2",
        "arXiv ID": "2306.08548v2"
    },
    {
        "title": "A fundamental mechanism of solar eruption initiation in multipolar\n  magnetic field",
        "Published: ": "2023-08-09T12:46:41Z",
        "abstract": "Recently we established a fundamental mechanism of solar eruption initiation,\nin which an eruption can be initiated from a bipolar field through magnetic\nreconnection in the current sheet (CS) that is formed slowly in the core field\nas driven by photospheric shearing motion. Here using a series of fully 3D MHD\nsimulations with a range of different photospheric magnetic flux distributions,\nwe extended this fundamental mechanism to the quadrupolar magnetic field\ncontaining a null point above the core field, which is the basic configuration\nof the classical breakout model. As is commonly believed, in such multipolar\nconfiguration, the reconnection triggered in the CS originated at the null\npoint (namely, the breakout reconnection) plays the key role in eruption\ninitiation by establishing a positive feedback-loop between the breakout\nreconnection and the expansion of the core field. However, our simulation\nshowed that the key of eruption initiation in such multipolar configuration\nremains to be the slow formation of the CS in the sheared core rather than the\nonset of fast breakout reconnection. The breakout reconnection only helps the\nformation of the core CS by letting the core field expand faster, but the\neruption cannot occur when the bottom surface driving is stopped well before\nthe core CS is formed, even though the fast reconnection has already been\ntriggered in the breakout CS. This study clarified the role of breakout\nreconnection and confirmed formation of the core CS as the key to the eruption\ninitiation in a multipolar magnetic field.",
        "author": [
            "Xinkai Bian",
            "Chaowei Jiang",
            "Xueshang Feng",
            "Pingbing Zuo",
            "Yi Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.04924v1.pdf",
        "Categories": [
            [
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.04924v1",
        "arXiv ID": "2308.04924v1"
    },
    {
        "title": "Chemical abundances of the metal-poor horizontal-branch stars CS\n  22186-005 and CS 30344-033",
        "Published: ": "2014-10-08T16:39:33Z",
        "abstract": "We report on a chemical-abundance analysis of two very metal-poor\nhorizontal-branch stars in the Milky Way halo: CS 22186-005 ([Fe/H]=-2.70) and\nCS 30344-033 ([Fe/H]=-2.90). The analysis is based on high-resolution spectra\nobtained at ESO, with the spectrographs HARPS at the 3.6 m telescope, and UVES\nat the VLT. We adopted one-dimensional, plane-parallel model atmospheres\nassuming local thermodynamic equilibrium. We derived elemental abundances for\n13 elements for CS 22186-005 and 14 elements for CS 30344-033. This study is\nthe first abundance analysis of CS 30344-033. CS 22186-005 has been analyzed\npreviously, but we report here the first measurement of nickel (Ni; Z = 28) for\nthis star, based on twenty-two NiI lines ([Ni/Fe]=-0.21$\\pm$0.02); the\nmeasurement is significantly below the mean found for most metal-poor stars.\nDifferences of up to 0.5 dex in [Ni/Fe] ratios were determined by different\nauthors for the same type of stars in the literature, which means that it is\nnot yet possible to conclude that there is a real intrinsic scatter in the\n[Ni/Fe] ratios. For the other elements for which we obtained estimates, the\nabundance patterns in these two stars match the Galactic trends defined by\ngiant and turnoff stars well. This confirms the value of horizontal-branch\nstars as tracers of the chemical properties of stellar populations in the\nGalaxy. Our radial velocities measurements for CS 22186-005 differ from\npreviously published measurements by more than the expected statistical errors.\nMore measurements of the radial velocity of this star are encouraged to confirm\nor refute its radial velocity variability.",
        "author": [
            "S. Caliskan",
            "E. Caffau",
            "P. Bonifacio",
            "N. Christlieb",
            "L. Monaco",
            "T. C. Beers",
            "B. Albayrak",
            "L. Sbordone"
        ],
        "pdfLink": "http://arxiv.org/pdf/1410.2189v1.pdf",
        "Categories": [
            [
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1410.2189v1",
        "arXiv ID": "1410.2189v1"
    },
    {
        "title": "Mapping CS in Starburst Galaxies: Disentangling and Characterising Dense\n  Gas",
        "Published: ": "2015-02-16T16:24:02Z",
        "abstract": "Aims. We observe the dense gas tracer CS in two nearby starburst galaxies to\ndetermine how the conditions of the dense gas varies across the circumnuclear\nregions in starburst galaxies. Methods. Using the IRAM-30m telescope, we mapped\nthe distribution of the CS(2-1) and CS(3-2) lines in the circumnuclear regions\nof the nearby starburst galaxies NGC 3079 and NGC 6946. We also detected the\nformaldehyde (H2CO) and methanol (CH3OH) in both galaxies. We marginally detect\nthe isotopologue C34S. Results. We calculate column densities under LTE\nconditions for CS and CH3OH. Using the detections accumulated here to guide our\ninputs, we link a time and depth dependent chemical model with a molecular line\nradiative transfer model; we reproduce the observations, showing how conditions\nwhere CS is present are likely to vary away from the galactic centres.\nConclusions. Using the rotational diagram method for CH3OH, we obtain a lower\nlimit temperature of 14 K. In addition to this, by comparing the chemical and\nradiative transfer models to observations, we determine the properties of the\ndense gas as traced by CS (and CH3OH). We also estimate the quantity of the\ndense gas. We find that, provided that there are a between 10^5 and 10^6 dense\ncores in our beam, for both target galaxies, emission of CS from warm (T = 100\n- 400 K), dense (n(H2) = 10^5-6 cm-3) cores, possibly with a high cosmic ray\nionisation rate (zeta = 100 zeta0) best describes conditions for our central\npointing. In NGC 6946, conditions are generally cooler and/or less dense\nfurther from the centre, whereas in NGC 3079, conditions are more uniform. The\ninclusion of shocks allows for more efficient CS formation, leading to an order\nof magnitude less dense gas being required to replicate observations in some\ncases.",
        "author": [
            "G. Kelly",
            "S. Viti",
            "E. Bayet",
            "R. Aladro",
            "J. Yates"
        ],
        "pdfLink": "http://arxiv.org/pdf/1502.04601v2.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1502.04601v2",
        "arXiv ID": "1502.04601v2"
    },
    {
        "title": "Infrared Detection of Abundant CS in the Hot Core AFGL 2591 at High\n  Spectral Resolution with SOFIA/EXES",
        "Published: ": "2018-10-25T11:17:09Z",
        "abstract": "We have performed a 5-8 $\\mu$m spectral line survey of the hot molecular core\nassociated with the massive protostar AFGL 2591, using the\nEchelon-Cross-Echelle Spectrograph (EXES) on the Stratospheric Observatory for\nInfrared Astronomy (SOFIA). We have supplemented these data with a ground based\nstudy in the atmospheric M band around 4.5 $\\mu$m using the iSHELL instrument\non the Infrared Telescope Facility (IRTF), and the full N band window from 8-13\n$\\mu$m using the Texas Echelon Cross Echelle Spectrograph (TEXES) on the IRTF.\n  Here we present the first detection of ro-vibrational transitions of CS in\nthis source. The absorption lines are centred on average around -10 kms$^{-1}$\nand the line widths of CS compare well with the hot component of $^{13}$CO\n(around 10 kms$^{-1}$). Temperatures for CS, hot $^{13}$CO and $^{12}$CO v=1-2\nagree well and are around 700 K. We derive a CS abundance of 8$\\times$10$^{-3}$\nand 2$\\times$10$^{-6}$ with respect to CO and H$_2$ respectively. This enhanced\nCS abundance with respect to the surrounding cloud (1$\\times$10$^{-8}$) may\nreflect sublimation of H$_2$S ice followed by gas-phase reactions to form CS.\n  Transitions are in LTE and we derive a density of $>$10$^7$ cm$^{-3}$, which\ncorresponds to an absorbing region of $<$0.04$''$. EXES observations of CS are\nlikely to probe deeply into the hot core, to the base of the outflow.\nSubmillimeter and infrared observations trace different components of the hot\ncore as revealed by the difference in systemic velocities, line widths and\ntemperatures, as well as the CS abundance.",
        "author": [
            "Andrew G. Barr",
            "Adwin Boogert",
            "Curtis N. DeWitt",
            "Edward Montiel",
            "Matthew J. Richter",
            "Nick Indriolo",
            "David A. Neufeld",
            "Yvonne Pendleton",
            "Jean Chiar",
            "Ryan Dungee",
            "Alexander G. G. M. Tielens"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.10833v1.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.10833v1",
        "arXiv ID": "1810.10833v1"
    },
    {
        "title": "Chemical Compositions of Four Metal-poor Giants",
        "Published: ": "2001-02-18T14:52:22Z",
        "abstract": "We present the chemical compositions of four K giants CS 22877-1, CS\n22166-16, CS22169-35 and BS 16085 - 0050 that have [Fe/H] in the range -2.4 to\n-3.1. Metal-poor stars with [Fe/H] < -2.5 are known to exhibit considerable\nstar - to - star variations of many elements. This quartet confirms this\nconclusion. CS 22877-1 and CS 22166-16 are carbon-rich. There is significant\nspread for [$\\alpha$/Fe] within our sample where [$\\alpha$/Fe] is computed from\nthe mean of the [Mg/Fe], and [Ca/Fe] ratios. BS 16085 - 0050 is remarkably\n$\\alpha$ enriched with a mean [$\\alpha$/Fe] of $+$0.7 but CS 22169-35 is\n$\\alpha$-poor. The aluminium abundance also shows a significant variation over\nthe sample. A parallel and unsuccessful search among high-velocity late-type\nstars for metal-poor stars is described.",
        "author": [
            "Sunetra Giridhar",
            "David L. Lambert",
            "Guillermo Gonzalez",
            "Gajendra Pandey"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0102307v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0102307v1",
        "arXiv ID": "0102307v1"
    },
    {
        "title": "Origin of the giant magnetic moments of Fe impurities on and in Cs films",
        "Published: ": "1999-12-03T12:16:17Z",
        "abstract": "To explore the origin of the observed giant magnetic moments ($\\sim 7 \\mu_B$)\nof Fe impurities on the surface and in the bulk of Cs films, we have performed\nthe relativistic LSDA + U calculations using the linearized muffin-tin orbital\n(LMTO) band method. We have found that Fe impurities in Cs behave differently\nfrom those in noble metals or in Pd. Whereas the induced spin polarization of\nCs atoms is negligible, the Fe ion itself is found to be the source of the\ngiant magnetic moment. The 3d electrons of Fe in Cs are localized as the 4f\nelectrons in rare-earth ions so that the orbital magnetic moment becomes as\nlarge as the spin magnetic moment. The calculated total magnetic moment of $M =\n6.43 \\mu_B$, which comes mainly from Fe ion, is close to the experimentally\nobserved value.",
        "author": [
            "S. K. Kwon",
            "B. I. Min"
        ],
        "pdfLink": "http://arxiv.org/pdf/cond-mat/9912047v1.pdf",
        "Categories": [
            [
                "cond-mat.str-el",
                "cond-mat.dis-nn"
            ]
        ],
        "Link": "http://arxiv.org/abs/cond-mat/9912047v1",
        "arXiv ID": "9912047v1"
    },
    {
        "title": "$^{133}$Cs NMR investigation of 2D frustrated Heisenberg\n  antiferromagnet, Cs$_2$CuCl$_4$",
        "Published: ": "2006-09-11T17:36:03Z",
        "abstract": "We report $^{133}$Cs nuclear magnetic resonance (NMR) measurements on the 2D\nfrustrated Heisenberg antiferromagnet Cs$_2$CuCl$_4$ down to 2 K and up to 15\nT. We show that $^{133}$Cs NMR is a good probe of the magnetic degrees of\nfreedom in this material. Cu spin degrees of freedom are sensed through a\nstrong anisotropic hyperfine coupling. The spin excitation gap opens above the\ncritical saturation field. The gap value was determined from the activation\nenergy of the nuclear spin-lattice relaxation rate in a magnetic field applied\nparallel to the Cu chains (b axis). The values of the g-factor and the\nsaturation field are consistent with the neutron-scattering and magnetization\nresults. The measurements of the spin-spin relaxation time are exploited to\nshow that no structural changes occur down to the lowest temperatures\ninvestigated.",
        "author": [
            "M. -A. Vachon",
            "W. Kundhikanjana",
            "A. Straub",
            "V. F. Mitrovi\u0107",
            "A. P. Reyes",
            "P. Kuhns",
            "R. Coldea",
            "Z. Tylczynski"
        ],
        "pdfLink": "http://arxiv.org/pdf/cond-mat/0609256v1.pdf",
        "Categories": [
            [
                "cond-mat.str-el"
            ]
        ],
        "Link": "http://arxiv.org/abs/cond-mat/0609256v1",
        "arXiv ID": "0609256v1"
    },
    {
        "title": "Coherent States of $SU(l,1)$ groups",
        "Published: ": "1993-08-31T17:33:29Z",
        "abstract": "This work can be considered as a continuation of our previous one (J.Phys.,\n26 (1993) 313), in which an explicit form of coherent states (CS) for all SU(N)\ngroups was constructed by means of representations on polynomials. Here we\nextend that approach to any SU(l,1) group and construct explicitly\ncorresponding CS. The CS are parametrized by dots of a coset space, which is,\nin that particular case, the open complex ball $CD^{l}$. This space together\nwith the projective space $CP^{l}$, which parametrizes CS of the SU(l+1) group,\nexhausts all complex spaces of constant curvature. Thus, both sets of CS\nprovide a possibility for an explicit analysis of the quantization problem on\nall the spaces of constant curvature.",
        "author": [
            "D. M. Gitman",
            "A. L. Shelepin"
        ],
        "pdfLink": "http://arxiv.org/pdf/hep-th/9308157v1.pdf",
        "Categories": [
            [
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/hep-th/9308157v1",
        "arXiv ID": "9308157v1"
    },
    {
        "title": "Bayesian Compressive Sensing via Belief Propagation",
        "Published: ": "2008-12-25T21:00:28Z",
        "abstract": "Compressive sensing (CS) is an emerging field based on the revelation that a\nsmall collection of linear projections of a sparse signal contains enough\ninformation for stable, sub-Nyquist signal acquisition. When a statistical\ncharacterization of the signal is available, Bayesian inference can complement\nconventional CS methods based on linear programming or greedy algorithms. We\nperform approximate Bayesian inference using belief propagation (BP) decoding,\nwhich represents the CS encoding matrix as a graphical model. Fast computation\nis obtained by reducing the size of the graphical model with sparse encoding\nmatrices. To decode a length-N signal containing K large coefficients, our\nCS-BP decoding algorithm uses O(Klog(N)) measurements and O(Nlog^2(N))\ncomputation. Finally, although we focus on a two-state mixture Gaussian model,\nCS-BP is easily adapted to other signal models.",
        "author": [
            "Dror Baron",
            "Shriram Sarvotham",
            "Richard G. Baraniuk"
        ],
        "pdfLink": "http://arxiv.org/pdf/0812.4627v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/0812.4627v2",
        "arXiv ID": "0812.4627v2"
    },
    {
        "title": "Generalized Chern-Simons Modified Gravity in First-Order Formalism",
        "Published: ": "2009-12-08T08:47:40Z",
        "abstract": "We propose a generalization of Chern-Simons (CS) modified gravity in\nfirst-order formalism. CS modified gravity action has a term that comes from\nthe chiral anomaly which is Pontryagin invariant. First-order CS modified\ngravity is a torsional theory and in a space-time with torsion the chiral\nanomaly includes a torsional topological term called Nieh-Yan invariant. We\ngeneralize the CS modified gravity by adding the Nieh-Yan term to the action\nand find the effective theory. We compare the generalized theory with the\nfirst-order CS modified gravity and comment on the similarities and\ndifferences.",
        "author": [
            "\u00dcmit Ertem",
            "\u00d6zg\u00fcr A\u00e7\u0131k"
        ],
        "pdfLink": "http://arxiv.org/pdf/0912.1433v2.pdf",
        "Categories": [
            [
                "gr-qc",
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/0912.1433v2",
        "arXiv ID": "0912.1433v2"
    },
    {
        "title": "Hamming Compressed Sensing",
        "Published: ": "2011-10-01T05:25:51Z",
        "abstract": "Compressed sensing (CS) and 1-bit CS cannot directly recover quantized\nsignals and require time consuming recovery. In this paper, we introduce\n\\textit{Hamming compressed sensing} (HCS) that directly recovers a k-bit\nquantized signal of dimensional $n$ from its 1-bit measurements via invoking\n$n$ times of Kullback-Leibler divergence based nearest neighbor search.\nCompared with CS and 1-bit CS, HCS allows the signal to be dense, takes\nconsiderably less (linear) recovery time and requires substantially less\nmeasurements ($\\mathcal O(\\log n)$). Moreover, HCS recovery can accelerate the\nsubsequent 1-bit CS dequantizer. We study a quantized recovery error bound of\nHCS for general signals and \"HCS+dequantizer\" recovery error bound for sparse\nsignals. Extensive numerical simulations verify the appealing accuracy,\nrobustness, efficiency and consistency of HCS.",
        "author": [
            "Tianyi Zhou",
            "Dacheng Tao"
        ],
        "pdfLink": "http://arxiv.org/pdf/1110.0073v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1110.0073v2",
        "arXiv ID": "1110.0073v2"
    },
    {
        "title": "Improve the Practice of Software Development in India by Having a\n  Software Development Career Track in Indian CS & IT Academia",
        "Published: ": "2012-02-08T14:43:54Z",
        "abstract": "Many, but not all, Indian CS & IT academics tend to have a focus on theory\nand research. They do not give much importance to the practice of software\ndevelopment. This paper proposes an additional software development career\ntrack for Indian CS & IT academics different from the existing research\noriented career track. A measure of software contribution record is suggested.\nIt opines that adoption of such changes to academic regulations will result in\nsignificant improvement of software development skill set in Indian CS & IT\nacademia which, in turn, will result in better software development skill set\nin Indian CS & IT graduates.",
        "author": [
            "Ravi S. Iyer"
        ],
        "pdfLink": "http://arxiv.org/pdf/1202.1715v4.pdf",
        "Categories": [
            [
                "cs.CY",
                "K.3.2; D.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/1202.1715v4",
        "arXiv ID": "1202.1715v4"
    },
    {
        "title": "Recoverability Analysis for Modified Compressive Sensing with Partially\n  Known Support",
        "Published: ": "2012-07-08T08:58:40Z",
        "abstract": "The recently proposed modified-compressive sensing (modified-CS), which\nutilizes the partially known support as prior knowledge, significantly improves\nthe performance of recovering sparse signals. However, modified-CS depends\nheavily on the reliability of the known support. An important problem, which\nmust be studied further, is the recoverability of modified-CS when the known\nsupport contains a number of errors. In this letter, we analyze the\nrecoverability of modified-CS in a stochastic framework. A sufficient and\nnecessary condition is established for exact recovery of a sparse signal.\nUtilizing this condition, the recovery probability that reflects the\nrecoverability of modified-CS can be computed explicitly for a sparse signal\nwith \\ell nonzero entries, even though the known support exists some errors.\nSimulation experiments have been carried out to validate our theoretical\nresults.",
        "author": [
            "Jun Zhang",
            "Yuanqing Li",
            "Zhu Liang Yu",
            "Zhenghui Gu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1207.1855v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1207.1855v1",
        "arXiv ID": "1207.1855v1"
    },
    {
        "title": "Chern-Simons Forms in Gravitation Theories",
        "Published: ": "2012-08-16T12:28:35Z",
        "abstract": "The Chern-Simons (CS) form evolved from an obstruction in mathematics into an\nimportant object in theoretical physics. In fact, the presence of CS terms in\nphysics is more common than one may think: they seem to play an important role\nin high Tc superconductivity and in recently discovered topological insulators.\nIn classical physics, the minimal coupling in electromagnetism and to the\naction for a mechanical system in Hamiltonian form are examples of CS\nfunctionals. CS forms are also the natural generalization of the minimal\ncoupling between the electromagnetic field and a point charge when the source\nis not point-like but an extended fundamental object, a membrane. They are\nfound in relation with anomalies in quantum field theories, and as Lagrangians\nfor gauge fields, including gravity and supergravity. A cursory review of the\nrole of CS forms in gravitation theories is presented at an introductory level.",
        "author": [
            "Jorge Zanelli"
        ],
        "pdfLink": "http://arxiv.org/pdf/1208.3353v1.pdf",
        "Categories": [
            [
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/1208.3353v1",
        "arXiv ID": "1208.3353v1"
    },
    {
        "title": "Local properties of WMAP Cold Spot",
        "Published: ": "2012-09-06T04:37:41Z",
        "abstract": "We investigate the local properties of WMAP Cold Spot (CS) by defining the\nlocal statistics: mean temperature, variance, skewness and kurtosis. We find\nthat, compared with the \\emph{coldest spots} in random Gaussian simulations,\nWMAP CS deviates from Gaussianity at $\\sim 99%$ significant level. In the\nmeanwhile, when compared with the spots at the same position in the simulated\nmaps, the values of local variance and skewness around CS are all\nsystematically larger in the scale of $R>5^{\\circ}$, which implies that WMAP CS\nis a large-scale non-Gaussian structure, rather than a combination of some\nsmall structures. This is consistent with the finding that the non-Gaussianity\nof CS is totally encoded in the WMAP low multipoles. Furthermore, we find that\nthe cosmic texture can excellently explain all the anomalies in these\nstatistics.",
        "author": [
            "Wen Zhao"
        ],
        "pdfLink": "http://arxiv.org/pdf/1209.1174v2.pdf",
        "Categories": [
            [
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1209.1174v2",
        "arXiv ID": "1209.1174v2"
    },
    {
        "title": "Reconstruction of Complex-Valued Fractional Brownian Motion Fields Based\n  on Compressive Sampling and Its Application to PSF Interpolation in Weak\n  Lensing Survey",
        "Published: ": "2013-11-01T09:11:55Z",
        "abstract": "A new reconstruction method of complex-valued fractional Brownian motion\n(CV-fBm) field based on Compressive Sampling (CS) is proposed. The decay\nproperty of Fourier coefficients magnitude of the fBm signals/ fields indicates\nthat fBms are compressible. Therefore, a few numbers of samples will be\nsufficient for a CS based method to reconstruct the full field. The\neffectiveness of the proposed method is showed by simulating, random sampling,\nand reconstructing CV-fBm fields. Performance evaluation shows advantages of\nthe proposed method over boxcar filtering and thin plate methods. It is also\nfound that the reconstruction performance depends on both of the fBm's Hurst\nparameter and the number of samples, which in fact is consistent with the CS\nreconstruction theory. In contrast to other fBm or fractal interpolation\nmethods, the proposed CS based method does not require the knowledge of fractal\nparameters in the reconstruction process; the inherent sparsity is just\nsufficient for the CS to do the reconstruction. Potential applicability of the\nproposed method in weak gravitational lensing survey, particularly for\ninterpolating non-smooth PSF (Point Spread Function) distribution representing\ndistortion by a turbulent field is also discussed.",
        "author": [
            "Andriyan B. Suksmono"
        ],
        "pdfLink": "http://arxiv.org/pdf/1311.0124v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1311.0124v1",
        "arXiv ID": "1311.0124v1"
    },
    {
        "title": "CS reconstruction of the speech and musical signals",
        "Published: ": "2015-02-05T20:40:41Z",
        "abstract": "The application of Compressive sensing approach to the speech and musical\nsignals is considered in this paper. Compressive sensing (CS) is a new approach\nto the signal sampling that allows signal reconstruction from a small set of\nrandomly acquired samples. This method is developed for the signals that\nexhibit the sparsity in a certain domain. Here we have observed two sparsity\ndomains: discrete Fourier and discrete cosine transform domain. Furthermore,\ntwo different types of audio signals are analyzed in terms of sparsity and CS\nperformance - musical and speech signals. Comparative analysis of the CS\nreconstruction using different number of signal samples is performed in the two\ndomains of sparsity. It is shown that the CS can be successfully applied to\nboth, musical and speech signals, but the speech signals are more demanding in\nterms of the number of observations. Also, our results show that discrete\ncosine transform domain allows better reconstruction using lower number of\nobservations, compared to the Fourier transform domain, for both types of\nsignals.",
        "author": [
            "Trifun Savic",
            "Radoje Albijanic"
        ],
        "pdfLink": "http://arxiv.org/pdf/1502.01707v1.pdf",
        "Categories": [
            [
                "cs.SD",
                "cs.MM"
            ]
        ],
        "Link": "http://arxiv.org/abs/1502.01707v1",
        "arXiv ID": "1502.01707v1"
    },
    {
        "title": "Investigation of two-color magneto-optical trap with cesium\n  6S1/2-6P3/2-7S1/2 ladder-type system",
        "Published: ": "2016-01-12T06:45:24Z",
        "abstract": "A novel cesium (Cs) two-color magneto-optical trap (TC-MOT), which partially\nemploys the optical radiation forces due to photon scattering of the 6P3/2\n(F'=5) - 7S1/2 (F\"=4) excited-state transition in the Cs 6S1/2 - 6P3/2 - 7S1/2\n(852 + 1470 nm) ladder-type system, has been proposed and experimentally\ninvestigated. One of the three pairs of 852 nm cooling/trapping beams (CTBs) in\na conventional Cs MOT is replaced with a pair of the 1470 nm CTBs (type-I) or\nwith one 852 nm CTB plus another counter-propagating 1470 nm CTB (type-II).\nBoth the type-I and type-II Cs TC-MOTs can cool and trap atoms on both the red-\nand blue-detuning sides of the two-photon resonance. The Cs TC-MOT demonstrated\nin this work may have applications in the background-free detection of cooled\nand trapped atoms, and the photon-pair sources compatible with the\nensemble-based quantum memory and the long-distance quantum communication via\noptical fiber.",
        "author": [
            "Jie Wang",
            "Guang Yang",
            "Baodong Yang",
            "Jun He",
            "Junmin Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1601.02746v1.pdf",
        "Categories": [
            [
                "physics.atom-ph",
                "physics.optics",
                "J.2; G.1.8"
            ]
        ],
        "Link": "http://arxiv.org/abs/1601.02746v1",
        "arXiv ID": "1601.02746v1"
    },
    {
        "title": "Network Clustering via Maximizing Modularity: Approximation Algorithms\n  and Theoretical Limits",
        "Published: ": "2016-02-02T17:23:59Z",
        "abstract": "Many social networks and complex systems are found to be naturally divided\ninto clusters of densely connected nodes, known as community structure (CS).\nFinding CS is one of fundamental yet challenging topics in network science. One\nof the most popular classes of methods for this problem is to maximize Newman's\nmodularity. However, there is a little understood on how well we can\napproximate the maximum modularity as well as the implications of finding\ncommunity structure with provable guarantees. In this paper, we settle\ndefinitely the approximability of modularity clustering, proving that\napproximating the problem within any (multiplicative) positive factor is\nintractable, unless P = NP. Yet we propose the first additive approximation\nalgorithm for modularity clustering with a constant factor. Moreover, we\nprovide a rigorous proof that a CS with modularity arbitrary close to maximum\nmodularity QOPT might bear no similarity to the optimal CS of maximum\nmodularity. Thus even when CS with near-optimal modularity are found, other\nverification methods are needed to confirm the significance of the structure.",
        "author": [
            "Thang N. Dinh",
            "Xiang Li",
            "My T. Thai"
        ],
        "pdfLink": "http://arxiv.org/pdf/1602.01016v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.DS",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1602.01016v1",
        "arXiv ID": "1602.01016v1"
    },
    {
        "title": "Mott transition in the A15 phase of Cs$_{3} $C$_{60}$: absence of\n  pseudogap and charge order",
        "Published: ": "2016-10-03T12:24:54Z",
        "abstract": "We present a detailed NMR study of the insulator to metal transition induced\nby an applied pressure $p$ in the A15 phase of Cs$_{3}$C$_{60}$. We evidence\nthat the insulating antiferromagnetic (AF) and superconducting (SC) phases only\ncoexist in a narrow $p$ range. At fixed $p$, in the metallic state above the SC\ntransition $T_c$, the $^{133}$Cs and $^{13}$C NMR spin lattice relaxation data\nare seemingly governed by a pseudogap like feature. We prove that this feature,\nalso seen in the $^{133}$Cs NMR shift data is rather a signature of the Mott\ntransition, which broadens and smears out progressively for increasing $(p,T)$.\nThe analysis of the variation of the quadrupole splitting $\\nu _{Q}$ of the\n$^{133}$Cs NMR spectrum precludes any cell symmetry change at the Mott\ntransition and only monitors a weak variation of lattice parameter. These\nresults open an opportunity to consider theoretically the Mott transition in a\nmultiorbital three dimensional system well beyond its critical point.",
        "author": [
            "H. Alloul",
            "P. Wzietek",
            "T. Mito",
            "D. Pontiroli",
            "M. Aramini",
            "M. Ricc\u00f2",
            "J. P. Iti\u00e9",
            "E. Elkaim"
        ],
        "pdfLink": "http://arxiv.org/pdf/1610.00513v2.pdf",
        "Categories": [
            [
                "cond-mat.str-el"
            ]
        ],
        "Link": "http://arxiv.org/abs/1610.00513v2",
        "arXiv ID": "1610.00513v2"
    },
    {
        "title": "Interspecies thermalization in an ultracold mixture of Cs and Yb in an\n  optical trap",
        "Published: ": "2017-04-11T12:51:44Z",
        "abstract": "We present measurements of interspecies thermalization between ultracold\nsamples of $^{133}$Cs and either $^{174}$Yb or $^{170}$Yb. The two species are\ntrapped in a far-off-resonance optical dipole trap and $^{133}$Cs is\nsympathetically cooled by Yb. We extract effective interspecies thermalization\ncross sections by fitting the thermalization measurements to a rate equation\nmodel, giving $\\sigma_{\\mathrm{Cs^{174}Yb}} = \\left(5 \\pm 2\\right) \\times\n10^{-13} \\, \\mathrm{cm^{2}}$ and $\\sigma_{\\mathrm{Cs^{170}Yb}} = \\left(18 \\pm\n8\\right) \\times 10^{-13} \\, \\mathrm{cm^{2}}$. We perform quantum scattering\ncalculations of the thermalization cross sections and optimize the CsYb\ninteraction potential to reproduce the measurements. We predict scattering\nlengths for all isotopic combinations of Cs and Yb. We also demonstrate the\nindependent production of $^{174}$Yb and $^{133}$Cs Bose-Einstein condensates\nusing the same optical dipole trap, an important step towards the realization\nof a quantum-degenerate mixture of the two species.",
        "author": [
            "A. Guttridge",
            "S. A. Hopkins",
            "S. L. Kemp",
            "Matthew D. Frye",
            "Jeremy M. Hutson",
            "Simon L. Cornish"
        ],
        "pdfLink": "http://arxiv.org/pdf/1704.03270v2.pdf",
        "Categories": [
            [
                "physics.atom-ph",
                "cond-mat.quant-gas"
            ]
        ],
        "Link": "http://arxiv.org/abs/1704.03270v2",
        "arXiv ID": "1704.03270v2"
    },
    {
        "title": "Dynamic Principal Projection for Cost-Sensitive Online Multi-Label\n  Classification",
        "Published: ": "2017-11-14T11:20:29Z",
        "abstract": "We study multi-label classification (MLC) with three important real-world\nissues: online updating, label space dimensional reduction (LSDR), and\ncost-sensitivity. Current MLC algorithms have not been designed to address\nthese three issues simultaneously. In this paper, we propose a novel algorithm,\ncost-sensitive dynamic principal projection (CS-DPP) that resolves all three\nissues. The foundation of CS-DPP is an online LSDR framework derived from a\nleading LSDR algorithm. In particular, CS-DPP is equipped with an efficient\nonline dimension reducer motivated by matrix stochastic gradient, and\nestablishes its theoretical backbone when coupled with a carefully-designed\nonline regression learner. In addition, CS-DPP embeds the cost information into\nlabel weights to achieve cost-sensitivity along with theoretical guarantees.\nExperimental results verify that CS-DPP achieves better practical performance\nthan current MLC algorithms across different evaluation criteria, and\ndemonstrate the importance of resolving the three issues simultaneously.",
        "author": [
            "Hong-Min Chu",
            "Kuan-Hao Huang",
            "Hsuan-Tien Lin"
        ],
        "pdfLink": "http://arxiv.org/pdf/1711.05060v2.pdf",
        "Categories": [
            [
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1711.05060v2",
        "arXiv ID": "1711.05060v2"
    },
    {
        "title": "Parity-violating gravity and GW170817",
        "Published: ": "2018-09-04T07:11:33Z",
        "abstract": "We consider gravitational waves (GWs) in generic parity-violating gravity\nincluding recently proposed ghost-free theories with parity violation as well\nas Chern-Simons (CS) modified gravity, and study the implications of\nobservational constraints from GW170817/GRB 170817A. Whereas GWs propagate at\nthe speed of light, c, in CS gravity, we point out that this is specific to CS\ngravity and the GW propagation speed deviates from c, in general, in\nparity-violating gravity. Therefore, contrary to the previous literature in\nwhich only CS gravity is studied as a concrete example, we show that\nGW170817/GRB 170817A can, in fact, be used to limit gravitational parity\nviolation. Our argument implies that the constraint on the propagation speed of\nGWs can pin down the parity-violating sector, if any, to CS gravity.",
        "author": [
            "Atsushi Nishizawa",
            "Tsutomu Kobayashi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1809.00815v2.pdf",
        "Categories": [
            [
                "gr-qc"
            ]
        ],
        "Link": "http://arxiv.org/abs/1809.00815v2",
        "arXiv ID": "1809.00815v2"
    },
    {
        "title": "Compressively Sensed Image Recognition",
        "Published: ": "2018-10-15T12:55:10Z",
        "abstract": "Compressive Sensing (CS) theory asserts that sparse signal reconstruction is\npossible from a small number of linear measurements. Although CS enables\nlow-cost linear sampling, it requires non-linear and costly reconstruction.\nRecent literature works show that compressive image classification is possible\nin CS domain without reconstruction of the signal. In this work, we introduce a\nDCT base method that extracts binary discriminative features directly from CS\nmeasurements. These CS measurements can be obtained by using (i) a random or a\npseudo-random measurement matrix, or (ii) a measurement matrix whose elements\nare learned from the training data to optimize the given classification task.\nWe further introduce feature fusion by concatenating Bag of Words (BoW)\nrepresentation of our binary features with one of the two state-of-the-art\nCNN-based feature vectors. We show that our fused feature outperforms the\nstate-of-the-art in both cases.",
        "author": [
            "Aysen Degerli",
            "Sinem Aslan",
            "Mehmet Yamac",
            "Bulent Sankur",
            "Moncef Gabbouj"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.06323v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.06323v1",
        "arXiv ID": "1810.06323v1"
    },
    {
        "title": "Joint group and residual sparse coding for image compressive sensing",
        "Published: ": "2019-01-23T04:36:02Z",
        "abstract": "Nonlocal self-similarity and group sparsity have been widely utilized in\nimage compressive sensing (CS). However, when the sampling rate is low, the\ninternal prior information of degraded images may be not enough for accurate\nrestoration, resulting in loss of image edges and details. In this paper, we\npropose a joint group and residual sparse coding method for CS image recovery\n(JGRSC-CS). In the proposed JGRSC-CS, patch group is treated as the basic unit\nof sparse coding and two dictionaries (namely internal and external\ndictionaries) are applied to exploit the sparse representation of each group\nsimultaneously. The internal self-adaptive dictionary is used to remove\nartifacts, and an external Gaussian Mixture Model (GMM) dictionary, learned\nfrom clean training images, is used to enhance details and texture. To make the\nproposed method effective and robust, the split Bregman method is adopted to\nreconstruct the whole image. Experimental results manifest the proposed\nJGRSC-CS algorithm outperforms existing state-of-the-art methods in both peak\nsignal to noise ratio (PSNR) and visual quality.",
        "author": [
            "Lizhao Li",
            "Song Xiao"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.07720v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.07720v1",
        "arXiv ID": "1901.07720v1"
    },
    {
        "title": "The ASRU 2019 Mandarin-English Code-Switching Speech Recognition\n  Challenge: Open Datasets, Tracks, Methods and Results",
        "Published: ": "2020-07-12T05:38:57Z",
        "abstract": "Code-switching (CS) is a common phenomenon and recognizing CS speech is\nchallenging. But CS speech data is scarce and there' s no common testbed in\nrelevant research. This paper describes the design and main outcomes of the\nASRU 2019 Mandarin-English code-switching speech recognition challenge, which\naims to improve the ASR performance in Mandarin-English code-switching\nsituation. 500 hours Mandarin speech data and 240 hours Mandarin-English\nintra-sentencial CS data are released to the participants. Three tracks were\nset for advancing the AM and LM part in traditional DNN-HMM ASR system, as well\nas exploring the E2E models' performance. The paper then presents an overview\nof the results and system performance in the three tracks. It turns out that\ntraditional ASR system benefits from pronunciation lexicon, CS text generating\nand data augmentation. In E2E track, however, the results highlight the\nimportance of using language identification, building-up a rational set of\nmodeling units and spec-augment. The other details in model training and method\ncomparsion are discussed.",
        "author": [
            "Xian Shi",
            "Qiangze Feng",
            "Lei Xie"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.05916v1.pdf",
        "Categories": [
            [
                "eess.AS",
                "cs.CL",
                "cs.SD"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.05916v1",
        "arXiv ID": "2007.05916v1"
    },
    {
        "title": "Training a code-switching language model with monolingual data",
        "Published: ": "2019-11-14T09:09:10Z",
        "abstract": "A lack of code-switching data complicates the training of code-switching (CS)\nlanguage models. We propose an approach to train such CS language models on\nmonolingual data only. By constraining and normalizing the output projection\nmatrix in RNN-based language models, we bring embeddings of different languages\ncloser to each other. Numerical and visualization results show that the\nproposed approaches remarkably improve the performance of CS language models\ntrained on monolingual data. The proposed approaches are comparable or even\nbetter than training CS language models with artificially generated CS data. We\nadditionally use unsupervised bilingual word translation to analyze whether\nsemantically equivalent words in different languages are mapped together.",
        "author": [
            "Shun-Po Chuang",
            "Tzu-Wei Sung",
            "Hung-Yi Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/1911.06003v2.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1911.06003v2",
        "arXiv ID": "1911.06003v2"
    },
    {
        "title": "Getting coherent state superpositions to stay put in phase space: $Q$\n  functions and one dimensional integral representations of generator\n  eigenstates",
        "Published: ": "2019-11-22T10:50:11Z",
        "abstract": "We study quantum mechanics in the phase space associated with the coherent\nstate (CS) manifold of Lie groups. Eigenstates of generators of the group are\nconstructed as one dimensional integral superpositions of CS along their\norbits. We distinguish certain privileged orbits where the superposition is in\nphase. Interestingly, for closed in phase orbits, the geometric phase must be\nquantized to $2\\pi\\mathbb{Z}$, else the superposition vanishes. This\ncorresponds to exact Bohr-Sommerfeld quantization. The maximum of the\nHusimi-Kano $Q$ quasiprobability distribution is used to diagnose where in\nphase space the eigenstates of the generators lie. The $Q$ function of a\ngenerator eigenstate is constant along each orbit. We conjecture that the\nmaximum of the $Q$ function corresponds to these privileged in phase orbits. We\nprovide some intuition for this proposition using interference in phase space,\nand then demonstrate it for canonical CS ($H_4$ oscillator group), spin CS\n($SU(2)$) and $SU(1,1)$ CS, relevant to squeezing.",
        "author": [
            "Mayukh Nilay Khan"
        ],
        "pdfLink": "http://arxiv.org/pdf/1911.09966v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1911.09966v1",
        "arXiv ID": "1911.09966v1"
    },
    {
        "title": "Critically Evaluated Energy Levels, Wavelengths, Transition\n  Probabilities, and Intensities of Six-Times Ionized Cesium: Cs VII",
        "Published: ": "2020-03-16T11:25:12Z",
        "abstract": "Previously reported works on the spectrum of Cs VII are critically studied\nusing supplementary spectrograms recorded on a 3 m normal incidence vacuum\nspectrograph in the wavelength region 300-1240 A at the Antigonish laboratory\n(Canada). We confirmed the results of the earlier work of Gayasov and Joshi on\nthis spectrum. Our analysis is supported by extended calculations with the\npseudo-relativistic Hartree-Fock (HFR) method with superposition of\nconfiguration interactions implemented in Cowan's suite of codes. In this\ncritical evaluation, in addition to the accurate energy levels of Cs VII with\ntheir uncertainties, observed and Ritz wavelengths with uncertainties and\ntransition probabilities, the uniformly-scaled intensities of Cs VII lines are\nalso presented. A total of 196 lines attributed to 197 transitions enabled us\nto optimize the energy values of 72 levels in Cs VII spectrum. Furthermore,\nRitz wavelengths of 141 possibly observable lines are provided along with their\ntransition probabilities.",
        "author": [
            "Abid Husain",
            "K. Haris",
            "S. Jabeen",
            "A. Tauheed"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.07123v1.pdf",
        "Categories": [
            [
                "physics.atom-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.07123v1",
        "arXiv ID": "2003.07123v1"
    },
    {
        "title": "CORE-Deblur: Parallel MRI Reconstruction by Deblurring Using Compressed\n  Sensing",
        "Published: ": "2020-04-02T17:17:46Z",
        "abstract": "In this work we introduce a new method that combines Parallel MRI and\nCompressed Sensing (CS) for accelerated image reconstruction from subsampled\nk-space data. The method first computes a convolved image, which gives the\nconvolution between a user-defined kernel and the unknown MR image, and then\nreconstructs the image by CS-based image deblurring, in which CS is applied for\nremoving the inherent blur stemming from the convolution process. This method\nis hence termed CORE-Deblur. Retrospective subsampling experiments with data\nfrom a numerical brain phantom and in-vivo 7T brain scans showed that\nCORE-Deblur produced high-quality reconstructions, comparable to those of a\nconventional CS method, while reducing the number of iterations by a factor of\n10 or more. The average Normalized Root Mean Square Error (NRMSE) obtained by\nCORE-Deblur for the in-vivo datasets was 0.016. CORE-Deblur also exhibited\nrobustness regarding the chosen kernel and compatibility with various k-space\nsubsampling schemes, ranging from regular to random. In summary, CORE-Deblur\nenables high quality reconstructions and reduction of the CS iterations number\nby 10-fold.",
        "author": [
            "Efrat Shimron",
            "Andrew G. Webb",
            "Haim Azhari"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.01147v1.pdf",
        "Categories": [
            [
                "physics.med-ph",
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.01147v1",
        "arXiv ID": "2004.01147v1"
    },
    {
        "title": "Sublattice mixing in Cs$_2$AgInCl$_6$ for enhanced optical properties\n  from first-principles",
        "Published: ": "2020-04-16T23:24:51Z",
        "abstract": "Lead-free double perovskite materials (viz. Cs$_2$AgInCl$_6$) are being\nexplored as stable and non-toxic alternatives of lead halide perovskites. In\norder to expand the optical response of Cs$_2$AgInCl$_6$ in visible region, we\nreport here the stability, electronic structure and optical properties of\nCs$_2$AgInCl$_6$ by sublattice mixing of various elements. Here, we have\nemployed %high-throughput screening using a hierarchical first-principles based\napproach starting from density functional theory (DFT) with appropriate\nexchange-correlation functionals to beyond DFT methods under the framework of\nmany body perturbation theory (viz. G$_0$W$_0$@HSE06). We have started with 32\nprimary set of combinations of metals M(I), M(II), M(III) and halogen X at\nAg/In and Cl site, respectively, where concentration of each set is varied to\nbuild a database of nearly 140 combinations. The most suitable mixed\nsublattices are identified to engineer the band gap of Cs$_2$AgInCl$_6$ to have\nits application in optoelectronic devices under visible light.",
        "author": [
            "Manish Kumar",
            "Manjari Jain",
            "Arunima Singh",
            "Saswata Bhattacharya"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.07991v2.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.07991v2",
        "arXiv ID": "2004.07991v2"
    },
    {
        "title": "New families of highly neighborly centrally symmetric spheres",
        "Published: ": "2020-05-03T17:51:35Z",
        "abstract": "In 1995, Josckusch constructed an infinite family of centrally symmetric (cs,\nfor short) triangulations of $3$-spheres that are cs-$2$-neighborly. Recently,\nNovik and Zheng extended Jockusch's construction: for all $d$ and $n>d$, they\nconstructed a cs triangulation of a $d$-sphere with $2n$ vertices,\n$\\Delta^d_n$, that is cs-$\\lceil d/2\\rceil$-neighborly. Here, several new cs\nconstructions, related to $\\Delta^d_n$, are provided. It is shown that for all\n$k>2$ and a sufficiently large $n$, there is another cs triangulation of a\n$(2k-1)$-sphere with $2n$ vertices that is cs-$k$-neighborly, while for $k=2$\nthere are $\\Omega(2^n)$ such pairwise non-isomorphic triangulations. It is also\nshown that for all $k>2$ and a sufficiently large $n$, there are $\\Omega(2^n)$\npairwise non-isomorphic cs triangulations of a $(2k-1)$-sphere with $2n$\nvertices that are cs-$(k-1)$-neighborly. The constructions are based on\nstudying facets of $\\Delta^d_n$, and, in particular, on some necessary and some\nsufficient conditions similar in spirit to Gale's evenness condition. Along the\nway, it is proved that Jockusch's spheres $\\Delta^3_n$ are shellable and an\naffirmative answer to Murai--Nevo's question about $2$-stacked shellable balls\nis given.",
        "author": [
            "Isabella Novik",
            "Hailun Zheng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.01155v2.pdf",
        "Categories": [
            [
                "math.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.01155v2",
        "arXiv ID": "2005.01155v2"
    },
    {
        "title": "Novel depletion mode JFET based low static power complementary circuit\n  technology",
        "Published: ": "2021-01-30T12:40:31Z",
        "abstract": "The lack of an easily realizable complementary circuit technology offering\nlow static power consumption has been limiting the utilization of other\nsemiconductor materials than silicon. In this publication, a novel depletion\nmode JFET based complementary circuit technology is presented and herein after\nreferred to as Complementary Semiconductor (CS) circuit technology. The fact\nthat JFETs are pure semiconductor devices, i.e. a carefully optimized Metal\nOxide Semiconductor (MOS) gate stack is not required, facilitates the\nimplementation of CS circuit technology to many semiconductor materials, like\ne.g. germanium and silicon carbide. Furthermore, when the CS circuit technology\nis idle there are neither conductive paths between nodes that are biased at\ndifferent potentials nor forward biased p-n junctions and thus it enables low\nstatic power consumption. Moreover, the fact that the operation of depletion\nmode JFETs does not necessitate the incorporation of forward biased p-n\njunctions means that CS circuit technology is not limited to wide band-gap\nsemiconductor materials, low temperatures, and/or low voltage spans. In this\npaper the operation of the CS logic is described and proven via simulations.",
        "author": [
            "Artto Aurola",
            "Vladislav Marochkin",
            "Mika Laiho"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.00219v1.pdf",
        "Categories": [
            [
                "physics.app-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.00219v1",
        "arXiv ID": "2102.00219v1"
    },
    {
        "title": "Image Segmentation Methods for Non-destructive testing Applications",
        "Published: ": "2021-03-13T17:13:33Z",
        "abstract": "In this paper, we present new image segmentation methods based on hidden\nMarkov random fields (HMRFs) and cuckoo search (CS) variants. HMRFs model the\nsegmentation problem as a minimization of an energy function. CS algorithm is\none of the recent powerful optimization techniques. Therefore, five variants of\nthe CS algorithm are used to compute a solution. Through tests, we conduct a\nstudy to choose the CS variant with parameters that give good results\n(execution time and quality of segmentation). CS variants are evaluated and\ncompared with non-destructive testing (NDT) images using a misclassification\nerror (ME) criterion.",
        "author": [
            "EL-Hachemi Guerrout",
            "Ramdane Mahiou",
            "Randa Boukabene",
            "Assia Ouali"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.07754v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.07754v1",
        "arXiv ID": "2103.07754v1"
    },
    {
        "title": "A Conceptual Framework for Implicit Evaluation of Conversational Search\n  Interfaces",
        "Published: ": "2021-04-08T17:33:18Z",
        "abstract": "Conversational search (CS) has recently become a significant focus of the\ninformation retrieval (IR) research community. Multiple studies have been\nconducted which explore the concept of conversational search. Understanding and\nadvancing research in CS requires careful and detailed evaluation. Existing CS\nstudies have been limited to evaluation based on simple user feedback on task\ncompletion. We propose a CS evaluation framework which includes multiple\ndimensions: search experience, knowledge gain, software usability, cognitive\nload and user experience, based on studies of conversational systems and IR. We\nintroduce these evaluation criteria and propose their use in a framework for\nthe evaluation of CS systems.",
        "author": [
            "Abhishek Kaushik",
            "Gareth J. F. Jones"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.03940v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.IR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.03940v1",
        "arXiv ID": "2104.03940v1"
    },
    {
        "title": "Deep Geometric Distillation Network for Compressive Sensing MRI",
        "Published: ": "2021-07-11T02:24:55Z",
        "abstract": "Compressed sensing (CS) is an efficient method to reconstruct MR image from\nsmall sampled data in $k$-space and accelerate the acquisition of MRI. In this\nwork, we propose a novel deep geometric distillation network which combines the\nmerits of model-based and deep learning-based CS-MRI methods, it can be\ntheoretically guaranteed to improve geometric texture details of a linear\nreconstruction. Firstly, we unfold the model-based CS-MRI optimization problem\ninto two sub-problems that consist of image linear approximation and image\ngeometric compensation. Secondly, geometric compensation sub-problem for\ndistilling lost texture details in approximation stage can be expanded by\nTaylor expansion to design a geometric distillation module fusing features of\ndifferent geometric characteristic domains. Additionally, we use a learnable\nversion with adaptive initialization of the step-length parameter, which allows\nmodel more flexibility that can lead to convergent smoothly. Numerical\nexperiments verify its superiority over other state-of-the-art CS-MRI\nreconstruction approaches. The source code will be available at\n\\url{https://github.com/fanxiaohong/Deep-Geometric-Distillation-Network-for-CS-MRI}",
        "author": [
            "Xiaohong Fan",
            "Yin Yang",
            "Jianping Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.04943v2.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV",
                "68T05, 68T20, 68T09, 68W25",
                "F.2.2; I.2.7"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.04943v2",
        "arXiv ID": "2107.04943v2"
    },
    {
        "title": "A Typed Slicing Compilation of the Polymorphic RPC Calculus",
        "Published: ": "2021-07-22T16:48:28Z",
        "abstract": "The polymorphic RPC calculus allows programmers to write succinct multitier\nprograms using polymorphic location constructs. However, until now it lacked an\nimplementation. We develop an experimental programming language based on the\npolymorphic RPC calculus. We introduce a polymorphic Client-Server (CS)\ncalculus with the client and server parts separated. In contrast to existing\nuntyped CS calculi, our calculus is not only able to resolve polymorphic\nlocations statically, but it is also able to do so dynamically. We design a\ntype-based slicing compilation of the polymorphic RPC calculus into this CS\ncalculus, proving type and semantic correctness. We propose a method to erase\ntypes unnecessary for execution but retaining locations at runtime by\ntranslating the polymorphic CS calculus into an untyped CS calculus, proving\nsemantic correctness.",
        "author": [
            "Kwanghoon Choi",
            "James Cheney",
            "Sam Lindley",
            "Bob Reynders"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.10793v2.pdf",
        "Categories": [
            [
                "cs.PL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.10793v2",
        "arXiv ID": "2107.10793v2"
    },
    {
        "title": "Mandarin-English Code-switching Speech Recognition with Self-supervised\n  Speech Representation Models",
        "Published: ": "2021-10-07T14:43:35Z",
        "abstract": "Code-switching (CS) is common in daily conversations where more than one\nlanguage is used within a sentence. The difficulties of CS speech recognition\nlie in alternating languages and the lack of transcribed data. Therefore, this\npaper uses the recently successful self-supervised learning (SSL) methods to\nleverage many unlabeled speech data without CS. We show that hidden\nrepresentations of SSL models offer frame-level language identity even if the\nmodels are trained with English speech only. Jointly training CTC and language\nidentification modules with self-supervised speech representations improves CS\nspeech recognition performance. Furthermore, using multilingual speech data for\npre-training obtains the best CS speech recognition.",
        "author": [
            "Liang-Hsuan Tseng",
            "Yu-Kuan Fu",
            "Heng-Jui Chang",
            "Hung-yi Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.03504v1.pdf",
        "Categories": [
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.03504v1",
        "arXiv ID": "2110.03504v1"
    },
    {
        "title": "First-Order Context-Specific Likelihood Weighting in Hybrid\n  Probabilistic Logic Programs",
        "Published: ": "2022-01-26T20:06:02Z",
        "abstract": "Statistical relational AI and probabilistic logic programming have so far\nmostly focused on discrete probabilistic models. The reasons for this is that\none needs to provide constructs to succinctly model the independencies in such\nmodels, and also provide efficient inference.\n  Three types of independencies are important to represent and exploit for\nscalable inference in hybrid models: conditional independencies elegantly\nmodeled in Bayesian networks, context-specific independencies naturally\nrepresented by logical rules, and independencies amongst attributes of related\nobjects in relational models succinctly expressed by combining rules.\n  This paper introduces a hybrid probabilistic logic programming language, DC#,\nwhich integrates distributional clauses' syntax and semantics principles of\nBayesian logic programs. It represents the three types of independencies\nqualitatively. More importantly, we also introduce the scalable inference\nalgorithm FO-CS-LW for DC#. FO-CS-LW is a first-order extension of the\ncontext-specific likelihood weighting algorithm (CS-LW), a novel sampling\nmethod that exploits conditional independencies and context-specific\nindependencies in ground models. The FO-CS-LW algorithm upgrades CS-LW with\nunification and combining rules to the first-order case.",
        "author": [
            "Nitesh Kumar",
            "Ondrej Kuzelka",
            "Luc De Raedt"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.11165v2.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.LO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.11165v2",
        "arXiv ID": "2201.11165v2"
    },
    {
        "title": "Current-sheet Oscillations Caused by Kelvin-Helmholtz Instability at the\n  Loop Top of Solar Flares",
        "Published: ": "2022-05-20T02:38:25Z",
        "abstract": "Current sheets (CSs), long stretching structures of magnetic reconnection\nabove solar flare loops, are usually observed to oscillate, their origins,\nhowever, are still puzzled at present. Based on a high-resolution\n2.5-dimensional MHD simulation of magnetic reconnection, we explore the\nformation mechanism of the CS oscillations. We find that large-amplitude\ntransverse waves are excited by the Kelvin-Helmholtz instability (KHI) at the\nhighly turbulent cusp-shaped region. The perturbations propagate upward along\nthe CS with a phase speed close to local Alfv\\'{e}n speed thus resulting in the\nCS oscillations we observe. Though the perturbations damp after propagating for\na long distance, the CS oscillations are still detectable. In terms of detected\nCS oscillations, with a combination of differential emission measure technique,\nwe propose a new method for measuring the magnetic field strength of the CSs\nand its distribution in height.",
        "author": [
            "Yulei Wang",
            "Xin Cheng",
            "Zining Ren",
            "Mingde Ding"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.10361v1.pdf",
        "Categories": [
            [
                "astro-ph.SR",
                "physics.plasm-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.10361v1",
        "arXiv ID": "2205.10361v1"
    },
    {
        "title": "LR-CSNet: Low-Rank Deep Unfolding Network for Image Compressive Sensing",
        "Published: ": "2022-12-18T13:54:11Z",
        "abstract": "Deep unfolding networks (DUNs) have proven to be a viable approach to\ncompressive sensing (CS). In this work, we propose a DUN called low-rank CS\nnetwork (LR-CSNet) for natural image CS. Real-world image patches are often\nwell-represented by low-rank approximations. LR-CSNet exploits this property by\nadding a low-rank prior to the CS optimization task. We derive a corresponding\niterative optimization procedure using variable splitting, which is then\ntranslated to a new DUN architecture. The architecture uses low-rank generation\nmodules (LRGMs), which learn low-rank matrix factorizations, as well as\ngradient descent and proximal mappings (GDPMs), which are proposed to extract\nhigh-frequency features to refine image details. In addition, the deep features\ngenerated at each reconstruction stage in the DUN are transferred between\nstages to boost the performance. Our extensive experiments on three widely\nconsidered datasets demonstrate the promising performance of LR-CSNet compared\nto state-of-the-art methods in natural image CS.",
        "author": [
            "Tianfang Zhang",
            "Lei Li",
            "Christian Igel",
            "Stefan Oehmcke",
            "Fabian Gieseke",
            "Zhenming Peng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2212.09088v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2212.09088v1",
        "arXiv ID": "2212.09088v1"
    },
    {
        "title": "The Conditional Cauchy-Schwarz Divergence with Applications to\n  Time-Series Data and Sequential Decision Making",
        "Published: ": "2023-01-21T16:32:22Z",
        "abstract": "The Cauchy-Schwarz (CS) divergence was developed by Pr\\'{i}ncipe et al. in\n2000. In this paper, we extend the classic CS divergence to quantify the\ncloseness between two conditional distributions and show that the developed\nconditional CS divergence can be simply estimated by a kernel density estimator\nfrom given samples. We illustrate the advantages (e.g., the rigorous\nfaithfulness guarantee, the lower computational complexity, the higher\nstatistical power, and the much more flexibility in a wide range of\napplications) of our conditional CS divergence over previous proposals, such as\nthe conditional KL divergence and the conditional maximum mean discrepancy. We\nalso demonstrate the compelling performance of conditional CS divergence in two\nmachine learning tasks related to time series data and sequential inference,\nnamely the time series clustering and the uncertainty-guided exploration for\nsequential decision making.",
        "author": [
            "Shujian Yu",
            "Hongming Li",
            "Sigurd L\u00f8kse",
            "Robert Jenssen",
            "Jos\u00e9 C. Pr\u00edncipe"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.08970v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.08970v1",
        "arXiv ID": "2301.08970v1"
    },
    {
        "title": "A Transparency Index Framework for AI in Education",
        "Published: ": "2022-05-09T10:10:47Z",
        "abstract": "Numerous AI ethics checklists and frameworks have been proposed focusing on\ndifferent dimensions of ethical AI such as fairness, explainability, and\nsafety. Yet, no such work has been done on developing transparent AI systems\nfor real-world educational scenarios. This paper presents a Transparency Index\nframework that has been iteratively co-designed with different stakeholders of\nAI in education, including educators, ed-tech experts, and AI practitioners. We\nmap the requirements of transparency for different categories of stakeholders\nof AI in education and demonstrate that transparency considerations are\nembedded in the entire AI development process from the data collection stage\nuntil the AI system is deployed in the real world and iteratively improved. We\nalso demonstrate how transparency enables the implementation of other ethical\nAI dimensions in Education like interpretability, accountability, and safety.\nIn conclusion, we discuss the directions for future research in this newly\nemerging field. The main contribution of this study is that it highlights the\nimportance of transparency in developing AI-powered educational technologies\nand proposes an index framework for its conceptualization for AI in education.",
        "author": [
            "Muhammad Ali Chaudhry",
            "Mutlu Cukurova",
            "Rose Luckin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.03220v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.03220v1",
        "arXiv ID": "2206.03220v1"
    },
    {
        "title": "Improving Human-AI Collaboration With Descriptions of AI Behavior",
        "Published: ": "2023-01-06T00:33:08Z",
        "abstract": "People work with AI systems to improve their decision making, but often\nunder- or over-rely on AI predictions and perform worse than they would have\nunassisted. To help people appropriately rely on AI aids, we propose showing\nthem behavior descriptions, details of how AI systems perform on subgroups of\ninstances. We tested the efficacy of behavior descriptions through user studies\nwith 225 participants in three distinct domains: fake review detection,\nsatellite image classification, and bird classification. We found that behavior\ndescriptions can increase human-AI accuracy through two mechanisms: helping\npeople identify AI failures and increasing people's reliance on the AI when it\nis more accurate. These findings highlight the importance of people's mental\nmodels in human-AI collaboration and show that informing people of high-level\nAI behaviors can significantly improve AI-assisted decision making.",
        "author": [
            "\u00c1ngel Alexander Cabrera",
            "Adam Perer",
            "Jason I. Hong"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.06937v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.06937v1",
        "arXiv ID": "2301.06937v1"
    },
    {
        "title": "Everyone Can Be Picasso? A Computational Framework into the Myth of\n  Human versus AI Painting",
        "Published: ": "2023-04-17T05:48:59Z",
        "abstract": "The recent advances of AI technology, particularly in AI-Generated Content\n(AIGC), have enabled everyone to easily generate beautiful paintings with\nsimple text description. With the stunning quality of AI paintings, it is\nwidely questioned whether there still exists difference between human and AI\npaintings and whether human artists will be replaced by AI. To answer these\nquestions, we develop a computational framework combining neural latent space\nand aesthetics features with visual analytics to investigate the difference\nbetween human and AI paintings. First, with categorical comparison of human and\nAI painting collections, we find that AI artworks show distributional\ndifference from human artworks in both latent space and some aesthetic features\nlike strokes and sharpness, while in other aesthetic features like color and\ncomposition there is less difference. Second, with individual artist analysis\nof Picasso, we show human artists' strength in evolving new styles compared to\nAI. Our findings provide concrete evidence for the existing discrepancies\nbetween human and AI paintings and further suggest improvements of AI art with\nmore consideration of aesthetics and human artists' involvement.",
        "author": [
            "Yilin Ye",
            "Rong Huang",
            "Kang Zhang",
            "Wei Zeng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.07999v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.AI",
                "cs.CV",
                "I.2.0; J.5; H.5.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.07999v1",
        "arXiv ID": "2304.07999v1"
    },
    {
        "title": "How Do UX Practitioners Communicate AI as a Design Material? Artifacts,\n  Conceptions, and Propositions",
        "Published: ": "2023-05-27T06:57:40Z",
        "abstract": "UX practitioners (UXPs) face novel challenges when working with and\ncommunicating artificial intelligence (AI) as a design material. We explore how\nUXPs communicate AI concepts when given hands-on experience training and\nexperimenting with AI models. To do so, we conducted a task-based design study\nwith 27 UXPs in which they prototyped and created a design presentation for a\nAI-enabled interface while having access to a simple AI model training tool.\nThrough analyzing UXPs' design presentations and post-activity interviews, we\nfound that although UXPs struggled to clearly communicate some AI concepts,\ntinkering with AI broadened common ground when communicating with technical\nstakeholders. UXPs also identified key risks and benefits of AI in their\ndesigns, and proposed concrete next steps for both UX and AI work. We conclude\nwith a sensitizing concept and recommendations for design and AI tools to\nenhance multi-stakeholder communication and collaboration when crafting\nhuman-centered AI experiences.",
        "author": [
            "K. J. Kevin Feng",
            "Maxwell James Coppock",
            "David W. McDonald"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.17389v1.pdf",
        "Categories": [
            [
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.17389v1",
        "arXiv ID": "2305.17389v1"
    },
    {
        "title": "Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for\n  AI-Native Services",
        "Published: ": "2023-06-04T01:47:42Z",
        "abstract": "Foundation models, such as GPT-4, DALL-E have brought unprecedented AI\n\"operating system\" effect and new forms of human-AI interaction, sparking a\nwave of innovation in AI-native services, where natural language prompts serve\nas executable \"code\" directly (prompt as executable code), eliminating the need\nfor programming language as an intermediary and opening up the door to personal\nAI. Prompt Sapper has emerged in response, committed to support the development\nof AI-native services by AI chain engineering. It creates a large language\nmodel (LLM) empowered software engineering infrastructure for authoring AI\nchains through human-AI collaborative intelligence, unleashing the AI\ninnovation potential of every individual, and forging a future where everyone\ncan be a master of AI innovation. This article will introduce the R\\&D\nmotivation behind Prompt Sapper, along with its corresponding AI chain\nengineering methodology and technical practices.",
        "author": [
            "Zhenchang Xing",
            "Qing Huang",
            "Yu Cheng",
            "Liming Zhu",
            "Qinghua Lu",
            "Xiwei Xu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.02230v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.02230v1",
        "arXiv ID": "2306.02230v1"
    },
    {
        "title": "AI Deception: A Survey of Examples, Risks, and Potential Solutions",
        "Published: ": "2023-08-28T17:59:35Z",
        "abstract": "This paper argues that a range of current AI systems have learned how to\ndeceive humans. We define deception as the systematic inducement of false\nbeliefs in the pursuit of some outcome other than the truth. We first survey\nempirical examples of AI deception, discussing both special-use AI systems\n(including Meta's CICERO) built for specific competitive situations, and\ngeneral-purpose AI systems (such as large language models). Next, we detail\nseveral risks from AI deception, such as fraud, election tampering, and losing\ncontrol of AI systems. Finally, we outline several potential solutions to the\nproblems posed by AI deception: first, regulatory frameworks should subject AI\nsystems that are capable of deception to robust risk-assessment requirements;\nsecond, policymakers should implement bot-or-not laws; and finally,\npolicymakers should prioritize the funding of relevant research, including\ntools to detect AI deception and to make AI systems less deceptive.\nPolicymakers, researchers, and the broader public should work proactively to\nprevent AI deception from destabilizing the shared foundations of our society.",
        "author": [
            "Peter S. Park",
            "Simon Goldstein",
            "Aidan O'Gara",
            "Michael Chen",
            "Dan Hendrycks"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.14752v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.14752v1",
        "arXiv ID": "2308.14752v1"
    },
    {
        "title": "A study of the magnetic field in the photospheric and circumstellar\n  components of Herbig Ae stars",
        "Published: ": "2006-10-14T17:33:05Z",
        "abstract": "We intend to investigate separately the photospheric and circumstellar (CS)\nmagnetic field components in seven Herbig Ae stars. The study is based on\nlow-resolution (R ~ 2000 and 4000) spectropolarimetric data collected from 2003\nto 2005 at the Very Large Telescope (ESO, Chile) with the multi-mode instrument\nFORS1. We show that the spectropolarimetric results strongly depend on the\nlevel of CS contribution to the stellar spectra. We have improved the\ndetermination accuracy of magnetic fields up to the 7 sigma level in the two\nHerbig Ae stars HD139614 and HD144432, observed in 2005 when these objects were\nat a low level state of their CS activity. We have established that at a higher\nlevel state of CS activity the polarisation signatures are related mainly to\nthe CS matter. The presence of CS polarisation signatures formed in the stellar\nwind supports the assumption that the magnetic centrifuge is a principal\nmechanism of wind acceleration. We conclude that the most effective way to\ninvestigate the magnetism of Herbig Ae stars is to monitor their\nspectropolarimetric behaviour at different states of CS activity. Obviously,\nhigher resolution spectropolarimetric observations would extend the sample of\nspectral lines to be used for the measurements of magnetic fields at different\nlevels in the stellar atmosphere and CS envelope. Such observations will give a\nmore complete insight into the magnetic topology in Herbig Ae stars.",
        "author": [
            "S. Hubrig",
            "M. A. Pogodin",
            "R. V. Yudin",
            "M. Schoeller",
            "R. S. Schnerr"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0610439v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0610439v1",
        "arXiv ID": "0610439v1"
    },
    {
        "title": "Reconstruction of a Large-scale Pre-flare Coronal Current Sheet\n  Associated with an Homologous X-shaped Flare",
        "Published: ": "2017-10-08T03:39:55Z",
        "abstract": "As a fundamental magnetic structure in the solar corona, electric current\nsheets (CSs) can form either prior to or during solar flare, and they are\nessential for magnetic energy dissipation in the solar corona by enabling\nmagnetic reconnection. However static reconstruction of CS is rare, possibly\ndue to limitation inherent in available coronal field extrapolation codes. Here\nwe present the reconstruction of a large-scale pre-flare CS in solar active\nregion 11967 using an MHD-relaxation model constrained by SDO/HMI vector\nmagnetogram. The CS is found to be associated with a set of peculiar homologous\nflares that exhibit unique X-shaped ribbons and loops occurring in a\nquadrupolar magnetic configuration. This is evidenced by that the field lines\ntraced from the CS to the photosphere form an X shape which nearly precisely\nreproduces the shape of the observed flare ribbons, suggesting that the flare\nis a product of the dissipation of the CS through reconnection. The CS forms in\na hyperbolic flux tube, which is an intersection of two quasi-separatrix\nlayers. The recurrence of the X-shaped flares might be attributed to the\nrepetitive formation and dissipation of the CS, as driven by the photospheric\nfootpoint motions. These results demonstrate the power of data-constrained MHD\nmodel in reproducing CS in the corona as well as providing insight into the\nmagnetic mechanism of solar flares.",
        "author": [
            "Chaowei Jiang",
            "Xiaoli Yan",
            "Xueshang Feng",
            "Aiying Duan",
            "Qiang Hu",
            "Pingbing Zuo",
            "Yi Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1710.02775v1.pdf",
        "Categories": [
            [
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1710.02775v1",
        "arXiv ID": "1710.02775v1"
    },
    {
        "title": "Multi-Channel Deep Networks for Block-Based Image Compressive Sensing",
        "Published: ": "2019-08-28T13:49:28Z",
        "abstract": "Incorporating deep neural networks in image compressive sensing (CS) receives\nintensive attentions in multimedia technology and applications recently. As\ndeep network approaches learn the inverse mapping directly from the CS\nmeasurements, the reconstruction speed is significantly faster than the\nconventional CS algorithms. However, for existing network based approaches, a\nCS sampling procedure has to map a separate network model. This may potentially\ndegrade the performance of image CS with block-wise sampling because of\nblocking artifacts, especially when multiple sampling rates are assigned to\ndifferent blocks within an image. In this paper, we develop a multichannel deep\nnetwork for block-based image CS by exploiting inter-block correlation with\nperformance significantly exceeding the current state-of-the-art methods. The\nsignificant performance improvement is attributed to block-wise approximation\nbut full image removal of blocking artifacts. Specifically, with our\nmultichannel structure, the image blocks with a variety of sampling rates can\nbe reconstructed in a single model. The initially reconstructed blocks are then\ncapable of being reassembled into a full image to improve the recovered images\nby unrolling a hand-designed block based CS recovery algorithm. Experimental\nresults demonstrate that the proposed method outperforms the state-of-the-art\nCS methods by a large margin in terms of objective metrics and subjective\nvisual image quality. Our source codes are available at\nhttps://github.com/siwangzhou/DeepBCS.",
        "author": [
            "Siwang Zhou",
            "Yan He",
            "Yonghe Liu",
            "Chengqing Li",
            "Jianming Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1908.11221v2.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.ML",
                "68Q30"
            ]
        ],
        "Link": "http://arxiv.org/abs/1908.11221v2",
        "arXiv ID": "1908.11221v2"
    },
    {
        "title": "Weak CS Emission in an Extremely Metal-poor Galaxy DDO 70",
        "Published: ": "2020-05-08T08:44:56Z",
        "abstract": "In most galaxies like the Milky Way, stars form in clouds of molecular gas.\nUnlike the CO emission that traces the bulk of molecular gas, the rotational\ntransitions of HCN and CS molecules mainly probe the dense phase of molecular\ngas, which has a tight and almost linear relation with the far-infrared\nluminosity and star formation rate. However, it is unclear if dense molecular\ngas exists at very low metallicity, and if exists, how it is related to star\nformation. In this work, we report ALMA observations of the CS\n$J$=5$\\rightarrow$4 emission line of DDO~70, a nearby gas-rich dwarf galaxy\nwith $\\sim7\\%$ solar metallicity. We did not detect CS emission from all\nregions with strong CO emission. After stacking all CS spectra from CO-bright\nclumps, we find no more than a marginal detection of CS $J$=5$\\rightarrow$4\ntransition, at a signal-to-noise ratio of $\\sim 3.3$. This 3-$\\sigma$ upper\nlimit deviates from the $L^\\prime_{\\rm CS}$-$L_{\\rm IR}$ and $L^\\prime_{\\rm\nCS}$-SFR relationships found in local star forming galaxies and dense clumps in\nthe Milky Way, implying weaker CS emission at given IR luminosity and SFR. We\ndiscuss the possible mechanisms that suppress CS emission at low metallicity.",
        "author": [
            "Kaiyi Du",
            "Yong Shi",
            "Zhi-Yu Zhang",
            "Junzhi Wang",
            "Yu Gao"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.03907v1.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.03907v1",
        "arXiv ID": "2005.03907v1"
    },
    {
        "title": "Site-specific online compressive beam codebook learning in mmWave\n  vehicular communication",
        "Published: ": "2020-05-11T23:32:27Z",
        "abstract": "Millimeter wave (mmWave) communication is one viable solution to support Gbps\nsensor data sharing in vehicular networks. The use of large antenna arrays at\nmmWave and high mobility in vehicular communication make it challenging to\ndesign fast beam alignment solutions. In this paper, we propose a novel\nframework that learns the channel angle-of-departure (AoD) statistics at a base\nstation (BS) and uses this information to efficiently acquire channel\nmeasurements. Our framework integrates online learning for compressive sensing\n(CS) codebook learning and the optimized codebook is used for CS-based beam\nalignment. We formulate a CS matrix optimization problem based on the AoD\nstatistics available at the BS. Furthermore, based on the CS channel\nmeasurements, we develop techniques to update and learn such channel AoD\nstatistics at the BS. We use the upper confidence bound (UCB) algorithm to\nlearn the AoD statistics and the CS matrix. Numerical results show that the CS\nmatrix in the proposed framework provides faster beam alignment than standard\nCS matrix designs. Simulation results indicate that the proposed beam training\ntechnique can reduce overhead by 80% compared to exhaustive beam search, and\n70% compared to standard CS solutions that do not exploit any AoD statistics.",
        "author": [
            "Yuyang Wang",
            "Nitin Jonathan Myers",
            "Nuria Gonz\u00e1lez-Prelcic",
            "Robert W. Heath Jr"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.05485v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.05485v1",
        "arXiv ID": "2005.05485v1"
    },
    {
        "title": "Uncoordinated Spectrum Sharing in Millimeter Wave Networks Using Carrier\n  Sensing",
        "Published: ": "2021-02-24T08:58:23Z",
        "abstract": "We propose using Carrier Sensing (CS) for distributed interference management\nin millimeter-wave (mmWave) cellular networks where spectrum is shared by\nmultiple operators that do not coordinate among themselves. In addition, even\nthe base station sites can be shared by the operators. We describe important\nchallenges in using traditional CS in this setting and propose enhanced CS\nprotocols to address these challenges. Using stochastic geometry, we develop a\ngeneral framework for downlink coverage probability analysis of our shared\nmmWave network in the presence of CS and derive the downlink coverage\nprobability expressions for several CS protocols. To the best of our knowledge,\nour work is the first to investigate and analyze (using stochastic geometry) CS\nfor mmWave networks with spectrum and BS sites shared among non-coordinating\noperators. We evaluate the downlink coverage probability of our shared mmWave\nnetwork using simulations as well as numerical examples based on our analysis.\nOur evaluations show that our proposed enhancements lead to an improvement in\ndownlink coverage probability, compared to the downlink coverage probability\nwith no CS, for higher values of signal-to-interference and noise ratio (SINR).\nInterestingly, our evaluations also reveal that for lower values of SINR, not\nusing any CS is the best strategy in terms of the downlink coverage\nprobability.",
        "author": [
            "Shamik Sarkar",
            "Xiang Zhang",
            "Arupjyoti Bhuyan",
            "Mingyue Ji",
            "Sneha Kumar Kasera"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.12138v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "cs.NI",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.12138v1",
        "arXiv ID": "2102.12138v1"
    },
    {
        "title": "Preparation of one $^{87}$Rb and one $^{133}$Cs atom in a single optical\n  tweezer",
        "Published: ": "2021-04-12T18:48:17Z",
        "abstract": "We report the preparation of exactly one $^{87}$Rb atom and one $^{133}$Cs\natom in the same optical tweezer as the essential first step towards the\nconstruction of a tweezer array of individually trapped $^{87}$Rb$^{133}$Cs\nmolecules. Through careful selection of the tweezer wavelengths, we show how to\nengineer species-selective trapping potentials suitable for high-fidelity\npreparation of Rb $+$ Cs atom pairs. Using a wavelength of 814~nm to trap Rb\nand 938~nm to trap Cs, we achieve loading probabilities of $0.508(6)$ for Rb\nand $0.547(6)$ for Cs using standard red-detuned molasses cooling. Loading the\ntraps sequentially yields exactly one Rb and one Cs atom in $28.4(6)\\,\\%$ of\nexperimental runs. Using a combination of an acousto-optic deflector and a\npiezo-controlled mirror to control the relative position of the tweezers, we\nmerge the two tweezers, retaining the atom pair with a probability of\n$0.99^{(+0.01)}_{(-0.02)}$. We use this capability to study\nhyperfine-state-dependent collisions of Rb and Cs in the combined tweezer and\ncompare the measured two-body loss rates with coupled-channel quantum\nscattering calculations.",
        "author": [
            "R V Brooks",
            "S Spence",
            "A Guttridge",
            "A Alampounti",
            "A Rakonjac",
            "L A McArd",
            "Jeremy M Hutson",
            "Simon L Cornish"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.05760v1.pdf",
        "Categories": [
            [
                "physics.atom-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.05760v1",
        "arXiv ID": "2104.05760v1"
    },
    {
        "title": "Cross-Modal Knowledge Distillation Method for Automatic Cued Speech\n  Recognition",
        "Published: ": "2021-06-25T15:12:45Z",
        "abstract": "Cued Speech (CS) is a visual communication system for the deaf or hearing\nimpaired people. It combines lip movements with hand cues to obtain a complete\nphonetic repertoire. Current deep learning based methods on automatic CS\nrecognition suffer from a common problem, which is the data scarcity. Until\nnow, there are only two public single speaker datasets for French (238\nsentences) and British English (97 sentences). In this work, we propose a\ncross-modal knowledge distillation method with teacher-student structure, which\ntransfers audio speech information to CS to overcome the limited data problem.\nFirstly, we pretrain a teacher model for CS recognition with a large amount of\nopen source audio speech data, and simultaneously pretrain the feature\nextractors for lips and hands using CS data. Then, we distill the knowledge\nfrom teacher model to the student model with frame-level and sequence-level\ndistillation strategies. Importantly, for frame-level, we exploit multi-task\nlearning to weigh losses automatically, to obtain the balance coefficient.\nBesides, we establish a five-speaker British English CS dataset for the first\ntime. The proposed method is evaluated on French and British English CS\ndatasets, showing superior CS recognition performance to the state-of-the-art\n(SOTA) by a large margin.",
        "author": [
            "Jianrong Wang",
            "Ziyue Tang",
            "Xuewei Li",
            "Mei Yu",
            "Qiang Fang",
            "Li Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.13686v1.pdf",
        "Categories": [
            [
                "cs.MM",
                "cs.SD",
                "eess.AS",
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.13686v1",
        "arXiv ID": "2106.13686v1"
    },
    {
        "title": "An Attention Self-supervised Contrastive Learning based Three-stage\n  Model for Hand Shape Feature Representation in Cued Speech",
        "Published: ": "2021-06-26T13:20:33Z",
        "abstract": "Cued Speech (CS) is a communication system for deaf people or hearing\nimpaired people, in which a speaker uses it to aid a lipreader in phonetic\nlevel by clarifying potentially ambiguous mouth movements with hand shape and\npositions. Feature extraction of multi-modal CS is a key step in CS\nrecognition. Recent supervised deep learning based methods suffer from noisy CS\ndata annotations especially for hand shape modality. In this work, we first\npropose a self-supervised contrastive learning method to learn the feature\nrepresentation of image without using labels. Secondly, a small amount of\nmanually annotated CS data are used to fine-tune the first module. Thirdly, we\npresent a module, which combines Bi-LSTM and self-attention networks to further\nlearn sequential features with temporal and contextual information. Besides, to\nenlarge the volume and the diversity of the current limited CS datasets, we\nbuild a new British English dataset containing 5 native CS speakers. Evaluation\nresults on both French and British English datasets show that our model\nachieves over 90% accuracy in hand shape recognition. Significant improvements\nof 8.75% (for French) and 10.09% (for British English) are achieved in CS\nphoneme recognition correctness compared with the state-of-the-art.",
        "author": [
            "Jianrong Wang",
            "Nan Gu",
            "Mei Yu",
            "Xuewei Li",
            "Qiang Fang",
            "Li Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.14016v1.pdf",
        "Categories": [
            [
                "cs.MM"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.14016v1",
        "arXiv ID": "2106.14016v1"
    },
    {
        "title": "Localization for CS manifolds and volume of homogeneous superspaces",
        "Published: ": "2022-12-14T21:04:06Z",
        "abstract": "We prove the Schwarz-Zaboronsky localization theorem for CS manifolds and use\nthis to give a volume calculation for homogeneous superspaces for super-Lie\ngroups that lack a real form.",
        "author": [
            "Vera Serganova",
            "Dmitry Vaintrob"
        ],
        "pdfLink": "http://arxiv.org/pdf/2212.07503v1.pdf",
        "Categories": [
            [
                "math.DG",
                "math.RT",
                "14M30, 17B81, 17B22, 81Q60, 17B10, 17B15, 17B81"
            ]
        ],
        "Link": "http://arxiv.org/abs/2212.07503v1",
        "arXiv ID": "2212.07503v1"
    },
    {
        "title": "Connecting Beliefs, Mindsets, Anxiety, and Self-Efficacy in Computer\n  Science Learning: An Instrument for Capturing Secondary School Students'\n  Self-Beliefs",
        "Published: ": "2023-07-19T14:47:08Z",
        "abstract": "Background and Context: Few instruments exist to measure students' CS\nengagement and learning especially in areas where coding happens with creative,\nproject-based learning and in regard to students' self-beliefs about computing.\nObjective: We introduce the CS Interests and Beliefs Inventory (CSIBI), an\ninstrument designed for novice secondary students learning by designing\nprojects (particularly with physical computing). The inventory contains\nsubscales on beliefs on problem solving competency, fascination in design,\nvalue of CS, creative expression, and beliefs about context-specific CS\nabilities alongside programming mindsets and outcomes. We explain the creation\nof the instrument and attend to the role of mindsets as mediators of\nself-beliefs and how CSIBI may be adapted to other K-12 project-based learning\nsettings. Method: We administered the instrument to 303 novice CS secondary\nstudents who largely came from historically marginalized backgrounds (gender,\nethnicity, and socioeconomic status). We assessed the nine-factor structure for\nthe 32-item instrument using confirmatory factor analysis and tested the\nhypothesized model of mindsets as mediators with structural equation modeling.\nFindings: We confirmed the nine factor structure of CSIBI and found significant\npositive correlations across factors. The structural model results showed that\nproblem solving competency beliefs and CS creative expression promoted\nprogramming growth mindset, which subsequently fostered students' programming\nself-concept. Implications: We validated an instrument to measure secondary\nstudents' self-beliefs in CS that fills several gaps in K-12 CS measurement\ntools by focusing on contexts of learning by designing. CSIBI can be easily\nadapted to other learning by designing computing education contexts.",
        "author": [
            "Luis Morales-Navarro",
            "Michael T. Giang",
            "Deborah A. Fields",
            "Yasmin B. Kafai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.10010v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "K.3.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.10010v1",
        "arXiv ID": "2307.10010v1"
    },
    {
        "title": "Cs evaporation in a negative ion source and Cs cleaning tests by plasma\n  sputtering",
        "Published: ": "2023-08-29T14:25:34Z",
        "abstract": "The compact radio frequency negative ion source NIO1 (Negative Ion\nOptimization phase 1) has been designed, built and operated by Consorzio RFX\nand INFN-LNL in order to study and optimize the production and acceleration of\nH- ions in continuous operation. In 2020 Cs was evaporated in the source to\nincrease the total extracted ion current. After an initial reduction of\nextracted electron to ion ratio and subsequently an increase of extracted\nnegative ion current, the source performances progressively worsened, because\nof the excessive amount of Cs evaporated in the source; the extracted electron\nto ion ratio increased from below 1 to more than 10, while ion current density\nreduced from max. 67 A/m2 ion current to not more than 30 A/m2). The paper\npresents the experimental observations collected during Cs evaporation\n(reduction of plasma light, Cs emission and H$\\beta$/H$\\gamma$ ratio, etc.)\nthat can help stopping the process before an excessive amount of Cs is\nintroduced in the source. The paper also reports the cleaning techniques tested\nto remove the Cs excess by the action of hydrogen or argon plasmas; while argon\nwas predictably more effective in surface sputtering, a 3 h Ar plasma treatment\nwas not sufficient to recover from overcesiation.",
        "author": [
            "M. Barbisan",
            "R. S. Delogu",
            "A. Pimazzoni",
            "C. Poggi",
            "M. Ugoletti",
            "M. Cavenago"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.15328v1.pdf",
        "Categories": [
            [
                "physics.plasm-ph",
                "physics.acc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.15328v1",
        "arXiv ID": "2308.15328v1"
    },
    {
        "title": "Patterns of Lorentz symmetry breaking in QED by CPT-odd interaction",
        "Published: ": "1998-04-29T18:16:20Z",
        "abstract": "A tiny Lorentz symmetry breaking can be mediated in Electrodynamics by means\nof the Chern-Simons (CS) interaction polarized along a constant CS vector. Its\npresence makes the vacuum optically active that has been recently estimated\nfrom astrophysical data. We examine two possibilities for the CS vector to be\ntime-like or space-like, under the assumption that it originates from v.e.v. of\nsome pseudoscalar matter. It is shown that: a) a time-like CS vector makes the\nvacuum unstable under pairs creation of tachyonic photon modes with the finite\nvacuum decay rate, i.e. it is unlikely realized at macroscopic time scales; b)\non the contrary, the space-like CS vector does not yield any tachyonic modes\nand, moreover, if its dynamical counterpart is substantially described by a\nscale invariant interaction, then the QED radiation effects induce the\ndynamical breaking of Lorentz symmetry, i.e. the occurrence of space-like CS\nvector appears to be rather natural.",
        "author": [
            "A. A. Andrianov",
            "R. Soldati"
        ],
        "pdfLink": "http://arxiv.org/pdf/hep-ph/9804448v3.pdf",
        "Categories": [
            [
                "hep-ph",
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/hep-ph/9804448v3",
        "arXiv ID": "9804448v3"
    },
    {
        "title": "Coherent States of the SU(N) groups",
        "Published: ": "1992-08-05T16:17:28Z",
        "abstract": "Coherent states $(CS)$ of the $SU(N)$ groups are constructed explicitly and\ntheir properties are investigated. They represent a nontrivial generalization\nof the spining $CS$ of the $SU(2)$ group. The $CS$ are parametrized by the\npoints of the coset space, which is, in that particular case, the projective\nspace $CP^{N-1}$ and plays the role of the phase space of a corresponding\nclassical mechanics. The $CS$ possess of a minimum uncertainty, they minimize\nan invariant dispersion of the quadratic Casimir operator. The classical limit\nis ivestigated in terms of symbols of operators. The role of the Planck\nconstant playes $h=P^{-1}$, where $P$ is the signature of the representation.\nThe classical limit of the so called star commutator generates the Poisson\nbracket in the $CP^{N-1}$ phase space. The logarithm of the modulus of the $CS$\noverlapping, being interpreted as a symmetric in the space, gives the\nFubini-Study metric in $CP^{N-1}$. The $CS$ constructed are useful for the\nquasi-classical analysis of the quantum equations of the $SU(N)$ gauge\nsymmetric theories.",
        "author": [
            "D. M. Gitman",
            "A. L. Shelepin"
        ],
        "pdfLink": "http://arxiv.org/pdf/hep-th/9208017v1.pdf",
        "Categories": [
            [
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/hep-th/9208017v1",
        "arXiv ID": "9208017v1"
    },
    {
        "title": "D=4 Einstein gravity from higher D CS and BI gravity and an alternative\n  to dimensional reduction",
        "Published: ": "2007-03-05T08:56:06Z",
        "abstract": "An alternative to usual dimensional reduction for gravity is analyzed, in the\nvielbein-spin connection formulation. Usual 4d Einstein gravity plus a\ntopological term (the \"Born-Infeld\" Lagrangian for gravity), is shown to be\nobtained by a generalized dimensional reduction from 5d Chern-Simons gravity.\nChern-Simons gravity in d=2n+1 is dimensionally reduced to CS gravity in d=2n-1\nvia a mechanism similar to descent equations. The consistency of the\ndimensional reduction in both cases is analyzed. The dimensional reduction of\nd=2n+2 Born-Infeld gravity to d=2n BI gravity, as well as d=2n BI gravity to\nd=2n-1 CS gravity is hard to achieve. Thus 4d gravity (plus a topological term)\ncan be embedded into d=2n+1 CS gravity, including 11d CS, whose supersymmetric\nversion could possibly be related to usual 11d supergravity. This raises the\nhope that maybe 4d quantum Einstein gravity could be embedded in a well defined\nquantum theory, similar to Witten's treatment of 3d quantum Einstein gravity as\na CS theory.",
        "author": [
            "Horatiu Nastase"
        ],
        "pdfLink": "http://arxiv.org/pdf/hep-th/0703034v2.pdf",
        "Categories": [
            [
                "hep-th",
                "gr-qc"
            ]
        ],
        "Link": "http://arxiv.org/abs/hep-th/0703034v2",
        "arXiv ID": "0703034v2"
    },
    {
        "title": "Extraction of Cs-137 by alcohol-water solvents from plants containing\n  cardiac glycosides",
        "Published: ": "2001-02-11T22:21:17Z",
        "abstract": "As a result of nuclear power plant accidents, large areas receive radioactive\ninputs of Cs-137. This cesium accumulates in herbs growing in such territories.\nThe problem is whether the herbs contaminated by radiocesium may be used as a\nraw material for medicine. The answer depends on the amount of Cs-137\ntransfered from the contaminated raw material to the medicine. We have\npresented new results of the transfer of Cs-137 from contaminated Digitalis\ngrandiflora Mill. and Convallaria majalis L. to medicine. We found that the\nextraction of Cs-137 depends strongly on the hydrophilicity of the solvent. For\nexample 96.5%(vol.) ethyl alcohol extracts less Cs-137 (11.6%) than 40%(vol.)\nethyl alcohol or pure water (66.2%). The solubility of the cardiac glycosides\nis inverse to the solubility of cesium, which may be of use in the\ntechnological processes for manufacturing ecologically pure herbal medicine.",
        "author": [
            "S. N. Dzyubak",
            "Yu. I. Gubin",
            "O. P. Dzyubak",
            "P. V. Sorokin",
            "V. F. Popov",
            "A. A. Orlov",
            "V. P. Krasnov"
        ],
        "pdfLink": "http://arxiv.org/pdf/physics/0102029v1.pdf",
        "Categories": [
            [
                "physics.med-ph",
                "physics.bio-ph",
                "physics.chem-ph",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/physics/0102029v1",
        "arXiv ID": "0102029v1"
    },
    {
        "title": "Fuzzy spheres from inequivalent coherent states quantizations",
        "Published: ": "2006-10-10T18:59:16Z",
        "abstract": "We present a new procedure which allows a coherent state (CS) quantization of\nany set with a measure. It is manifest through the replacement of classical\nobservables by CS quantum observables, which acts on a Hilbert space of\nprescribed dimension $N$. The algebra of CS quantum observables has the finite\ndimension $N^2$. The application to the 2-sphere provides a family of\ninequivalent CS quantizations, based on the spin spherical harmonics (the CS\nquantization from usual spherical harmonics appears to give a trivial issue for\nthe cartesian coordinates). We compare these CS quantizations to the usual\n(Madore) construction of the fuzzy sphere. The difference allows us to consider\nour procedures as the constructions of new type of fuzzy spheres. The very\ngeneral character of our method suggests applications to construct fuzzy\nversions of a variety of sets.",
        "author": [
            "Jean-Pierre Gazeau",
            "Eric Huguet",
            "Marc Lachi\u00e8ze-Rey",
            "Jacques Renaud"
        ],
        "pdfLink": "http://arxiv.org/pdf/quant-ph/0610080v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/quant-ph/0610080v1",
        "arXiv ID": "0610080v1"
    },
    {
        "title": "Baryons and the Chern-Simons term in holographic QCD with three flavors",
        "Published: ": "2007-10-13T03:36:25Z",
        "abstract": "We study dynamical baryons in the holographic QCD model of Sakai and Sugimoto\nin the case of three flavors and with special interest in the construction of\nthe Chern-Simons (CS) term. The baryon classical solution in this model is\ngiven by the BPST instanton, and we carry out the collective coordinate\nquantization of the solution. The CS term should give rise to a first class\nconstraint which selects baryon states with right spins. However, the original\nCS term written in terms of the CS 5-form does not work. We instead propose a\nnew CS term which is gauge invariant and is given as an integral over a six\ndimensional space having as its boundary the original five dimensional\nspacetime of the holographic model. Collective coordinate quantization using\nour new CS term leads to correct baryon states and their mass formula.",
        "author": [
            "Hiroyuki Hata",
            "Masaki Murata"
        ],
        "pdfLink": "http://arxiv.org/pdf/0710.2579v2.pdf",
        "Categories": [
            [
                "hep-th",
                "hep-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/0710.2579v2",
        "arXiv ID": "0710.2579v2"
    },
    {
        "title": "New example of CP violation from search for the permanent electric\n  dipole moment of Cs atoms",
        "Published: ": "2008-09-27T12:57:42Z",
        "abstract": "Using special capacitors three experiments to search for a permanent electric\ndipole moment (EDM) of Cesium atom were completed. The electric susceptibility\nxe of Cs vapor varies in direct proportion to the density N, where xe =70 when\nN=7.37*1022 m-3! The relationship between xe of Cs vapor and the absolute\ntemperatures T is xe =B/T, where the slope B=320(k) as polar molecules\nH2O(B=1.50(k)). Its capacitance C at different voltage V was measured. The C-V\ncurve shows that the saturation polarization of Cs vapor has be observed when\nthe field E=7.4*104V/m. Our measurements give the EDM of an Cs atom :\ndCs=2.97*10-29 C.m=1.86*10-8 e.cm. New example of CP (charge conjugation and\nparity) violation occurred in Cs atoms. Our results are easy to be repeated\nbecause the details of the experiment are described in the article.",
        "author": [
            "Pei-Lin You",
            "Xiang-You Huang"
        ],
        "pdfLink": "http://arxiv.org/pdf/0809.4767v1.pdf",
        "Categories": [
            [
                "physics.atom-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/0809.4767v1",
        "arXiv ID": "0809.4767v1"
    },
    {
        "title": "Analyzing Least Squares and Kalman Filtered Compressed Sensing",
        "Published: ": "2009-03-29T17:24:45Z",
        "abstract": "In recent work, we studied the problem of causally reconstructing time\nsequences of spatially sparse signals, with unknown and slow time-varying\nsparsity patterns, from a limited number of linear \"incoherent\" measurements.\nWe proposed a solution called Kalman Filtered Compressed Sensing (KF-CS). The\nkey idea is to run a reduced order KF only for the current signal's estimated\nnonzero coefficients' set, while performing CS on the Kalman filtering error to\nestimate new additions, if any, to the set. KF may be replaced by Least Squares\n(LS) estimation and we call the resulting algorithm LS-CS. In this work, (a) we\nbound the error in performing CS on the LS error and (b) we obtain the\nconditions under which the KF-CS (or LS-CS) estimate converges to that of a\ngenie-aided KF (or LS), i.e. the KF (or LS) which knows the true nonzero sets.",
        "author": [
            "Namrata Vaswani"
        ],
        "pdfLink": "http://arxiv.org/pdf/0903.5074v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/0903.5074v1",
        "arXiv ID": "0903.5074v1"
    },
    {
        "title": "A Classic Morita Equivalence Result for Fell Bundle C*-algebras",
        "Published: ": "2009-12-06T18:40:39Z",
        "abstract": "We show how to extend a classic Morita Equivalence Result of Green's to the\n\\cs-algebras of Fell bundles over transitive groupoids. Specifically, we show\nthat if $p:\\B\\to G$ is a saturated Fell bundle over a transitive groupoid $G$\nwith stability group $H=G(u)$ at $u\\in \\go$, then $\\cs(G,\\B)$ is Morita\nequivalent to $\\cs(H,\\CC)$, where $\\CC=\\B\\restr H$. As an application, we show\nthat if $p:\\B\\to G$ is a Fell bundle over a group $G$ and if there is a\ncontinuous $G$-equivariant map $\\sigma:\\Prim A\\to G/H$, where $A=B(e)$ is the\n\\cs-algebra of $\\B$ and $H$ is a closed subgroup, then $\\cs(G,\\B)$ is Morita\nequivalent to $\\cs(H,\\CC^{I})$ where $\\CC^{I}$ is a Fell bundle over $H$ whose\nfibres are $A/I\\sme A/I$-\\ib s and $I=\\bigcap\\set{P:\\sigma(P)=eH}$. Green's\nresult is a special case of our application to bundles over groups.",
        "author": [
            "Marius Ionescu",
            "Dana P. Williams"
        ],
        "pdfLink": "http://arxiv.org/pdf/0912.1125v2.pdf",
        "Categories": [
            [
                "math.OA",
                "math.FA",
                "46L55"
            ]
        ],
        "Link": "http://arxiv.org/abs/0912.1125v2",
        "arXiv ID": "0912.1125v2"
    },
    {
        "title": "CS 5-4 survey toward nearby IR bright galaxies",
        "Published: ": "2011-06-15T04:48:21Z",
        "abstract": "With the observations of the CS 5-4 line toward a sample of 24 infrared\nbright galaxies using HHSMT, we detected CS 5-4 emission in 14 galaxies,\nincluding 12 ULIRGs/LIRGs and 2 nearby normal galaxies. As a good dense gas\ntracer, which has been well used for studying star formation in the Milky Way,\nCS 5-4 can trace the active star forming gas in galaxies. The correlation\nbetween CS 5-4 luminosity, which is estimated with detected CS 5-4 line\nemission, and infrared luminosity in these 14 galaxies is fitted with\ncorrelation coefficient of 0.939 and the slope close to unity. This correlation\nconfirmed that dense gas, which is closely linked to star formation, is very\nimportant for understanding star formation in galaxies.",
        "author": [
            "Junzhi Wang",
            "Zhiyu Zhang",
            "Yong Shi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1106.2873v1.pdf",
        "Categories": [
            [
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1106.2873v1",
        "arXiv ID": "1106.2873v1"
    },
    {
        "title": "Variational Bayesian algorithm for quantized compressed sensing",
        "Published: ": "2012-03-22T02:22:58Z",
        "abstract": "Compressed sensing (CS) is on recovery of high dimensional signals from their\nlow dimensional linear measurements under a sparsity prior and digital\nquantization of the measurement data is inevitable in practical implementation\nof CS algorithms. In the existing literature, the quantization error is modeled\ntypically as additive noise and the multi-bit and 1-bit quantized CS problems\nare dealt with separately using different treatments and procedures. In this\npaper, a novel variational Bayesian inference based CS algorithm is presented,\nwhich unifies the multi- and 1-bit CS processing and is applicable to various\ncases of noiseless/noisy environment and unsaturated/saturated quantizer. By\ndecoupling the quantization error from the measurement noise, the quantization\nerror is modeled as a random variable and estimated jointly with the signal\nbeing recovered. Such a novel characterization of the quantization error\nresults in superior performance of the algorithm which is demonstrated by\nextensive simulations in comparison with state-of-the-art methods for both\nmulti-bit and 1-bit CS problems.",
        "author": [
            "Zai Yang",
            "Lihua Xie",
            "Cishen Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1203.4870v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1203.4870v2",
        "arXiv ID": "1203.4870v2"
    },
    {
        "title": "Observation of Efimov Resonances in a Mixture with Extreme Mass\n  Imbalance",
        "Published: ": "2014-03-27T23:24:51Z",
        "abstract": "We observe two consecutive heteronuclear Efimov resonances in an ultracold\nLi-Cs mixture by measuring three-body loss coefficients as a function of\nmagnetic field near a Feshbach resonance. The first resonance is detected at a\nscattering length of $a_-^{(1)}=-320(10)~a_0$ corresponding to $\\sim 7 $ ($\\sim\n3$) times the Li-Cs (Cs-Cs) van der Waals range. The second resonance appears\nat $5.8(1.0) a_-^{(1)}$ close to the unitarity-limited regime at the sample\ntemperature of 450 nK. Indication of a third resonance is found in the atom\nloss spectra. The scaling of the resonance positions is close to the universal\nscaling value of 4.9 predicted for zero temperature. Deviations from\nuniversality might be caused by finite-range and temperature effects, as well\nas magnetic field dependent Cs-Cs interactions.",
        "author": [
            "R. Pires",
            "J. Ulmanis",
            "S. H\u00e4fner",
            "M. Repp",
            "A. Arias",
            "E. D. Kuhnle",
            "M. Weidem\u00fcller"
        ],
        "pdfLink": "http://arxiv.org/pdf/1403.7246v2.pdf",
        "Categories": [
            [
                "cond-mat.quant-gas",
                "nucl-th",
                "physics.atom-ph",
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1403.7246v2",
        "arXiv ID": "1403.7246v2"
    },
    {
        "title": "Bi-level Protected Compressive Sampling",
        "Published: ": "2014-05-29T14:50:41Z",
        "abstract": "Some pioneering works have investigated embedding cryptographic properties in\ncompressive sampling (CS) in a way similar to one-time pad symmetric cipher.\nThis paper tackles the problem of constructing a CS-based symmetric cipher\nunder the key reuse circumstance, i.e., the cipher is resistant to common\nattacks even a fixed measurement matrix is used multiple times. To this end, we\nsuggest a bi-level protected CS (BLP-CS) model which makes use of the advantage\nof the non-RIP measurement matrix construction. Specifically, two kinds of\nartificial basis mismatch techniques are investigated to construct key-related\nsparsifying bases. It is demonstrated that the encoding process of BLP-CS is\nsimply a random linear projection, which is the same as the basic CS model.\nHowever, decoding the linear measurements requires knowledge of both the\nkey-dependent sensing matrix and its sparsifying basis. The proposed model is\nexemplified by sampling images as a joint data acquisition and protection layer\nfor resource-limited wireless sensors. Simulation results and numerical\nanalyses have justified that the new model can be applied in circumstances\nwhere the measurement matrix can be re-used.",
        "author": [
            "Leo Yu Zhang",
            "Kwok-Wo Wong",
            "Yushu Zhang",
            "Jiantao Zhou"
        ],
        "pdfLink": "http://arxiv.org/pdf/1406.1725v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1406.1725v2",
        "arXiv ID": "1406.1725v2"
    },
    {
        "title": "IR-Improved DGLAP-CS QCD Parton Showers in Pythia8",
        "Published: ": "2015-04-03T17:09:26Z",
        "abstract": "We introduce the recently developed IR-improved DGLAP-CS theory into the\nshowers in Pythia8, as this Monte Carlo event generator is in wide use at LHC.\nWe show that, just as it was true in the IR-improved shower Monte Carlo\nHerwiri, which realizes the IR-improved DGLAP-CS theory in the Herwig6.5\nenvironment, the soft limit in processes such as single heavy gauge boson\nproduction is now more physical in the IR-improved DGLAP-CS theory version of\nPythia8. This opens the way to one's getting a comparison between the actual\ndetector simulations for some of the LHC experiments between IR-improved and\nunimproved showers as Pythia8 is used in detector simulations at LHC whereas\nHerwig6.5, the environment of the only other IR-improved DGLAP-CS QCD MC in the\nliterature, Herwiri1.031, is not any longer so used. Our achieving the\navailability of the IR-improved DGLAP-CS Pythia8 then is an important step in\nthe further development of the LHC precision theory program under development\nby the author and his collaborators.",
        "author": [
            "B. F. L. Ward"
        ],
        "pdfLink": "http://arxiv.org/pdf/1504.00892v1.pdf",
        "Categories": [
            [
                "hep-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1504.00892v1",
        "arXiv ID": "1504.00892v1"
    },
    {
        "title": "EXIT Chart Analysis of Turbo Compressed Sensing Using Message Passing\n  De-Quantization",
        "Published: ": "2015-05-03T23:42:27Z",
        "abstract": "We propose an iterative decoding method, which we call turbo-CS, for the\nreception of concatenated source-channel encoded sparse signals transmitted\nover an AWGN channel. The turbo-CS encoder applies 1-bit compressed sensing as\na source encoder concatenated serially with a convolutional channel encoder. At\nthe turbo-CS decoder, an iterative joint source-channel decoding method is\nproposed for signal reconstruction. We analyze, for the first time, the\nconvergence of turbo-CS decoder by determining an EXIT chart of the constituent\ndecoders. We modify the soft-outputs of the decoder to improve the signal\nreconstruction performance of turbo-CS decoder. For a fixed signal\nreconstruction performance RSNR of 10 dB, we achieve more than 5 dB of\nimprovement in the channel SNR after 6 iterations of the turbo-CS.\nAlternatively, for a fixed SNR of -1 dB, we achieve a 10 dB improvement in\nRSNR.",
        "author": [
            "Amin Movahed",
            "Mark C. Reed",
            "Shahriar Etemadi Tajbakhsh"
        ],
        "pdfLink": "http://arxiv.org/pdf/1505.00494v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1505.00494v1",
        "arXiv ID": "1505.00494v1"
    },
    {
        "title": "A model bridging chimera state and explosive synchronization",
        "Published: ": "2017-02-25T14:41:49Z",
        "abstract": "Global and partial synchronization are the two distinctive forms of\nsynchronization in coupled oscillators and have been well studied in the past\ndecades. Recent attention on synchronization is focused on the chimera state\n(CS) and explosive synchronization (ES), but little attention has been paid to\ntheir relationship. We here study this topic by presenting a model to bridge\nthese two phenomena, which consists of two groups of coupled oscillators and\nits coupling strength is adaptively controlled by a local order parameter. We\nfind that this model displays either CS or ES in two limits. In between the two\nlimits, this model exhibits both CS and ES, where CS can be observed for a\nfixed coupling strength and ES appears when the coupling is increased\nadiabatically. Moreover, we show both theoretically and numerically that there\nare a variety of CS basin patterns for the case of identical oscillators,\ndepending on the distributions of both the initial order parameters and the\ninitial average phases. This model suggests a way to easily observe CS, in\ncontrast to others models having some (weak or strong) dependence on initial\nconditions.",
        "author": [
            "Xiyun Zhang",
            "Hongjie Bi",
            "Shuguang Guan",
            "Jinming Liu",
            "Zonghua Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1702.07897v1.pdf",
        "Categories": [
            [
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1702.07897v1",
        "arXiv ID": "1702.07897v1"
    },
    {
        "title": "Indistinguishability and Energy Sensitivity of Asymptotically Gaussian\n  Compressed Encryption",
        "Published: ": "2017-09-18T02:13:15Z",
        "abstract": "The principle of compressed sensing (CS) can be applied in a cryptosystem by\nproviding the notion of security. In information-theoretic sense, it is known\nthat a CS-based cryptosystem can be perfectly secure if it employs a random\nGaussian sensing matrix updated at each encryption and its plaintext has\nconstant energy. In this paper, we propose a new CS-based cryptosystem that\nemploys a secret bipolar keystream and a public unitary matrix, which can be\nsuitable for practical implementation by generating and renewing the keystream\nin a fast and efficient manner. We demonstrate that the sensing matrix is\nasymptotically Gaussian for a sufficiently large plaintext length, which\nguarantees a reliable CS decryption for a legitimate recipient. By means of\nprobability metrics, we also show that the new CS-based cryptosystem can have\nthe indistinguishability against an adversary, as long as the keystream is\nupdated at each encryption and each plaintext has constant energy. Finally, we\ninvestigate how much the security of the new CS-based cryptosystem is sensitive\nto energy variation of plaintexts.",
        "author": [
            "Nam Yul Yu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.05744v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.05744v1",
        "arXiv ID": "1709.05744v1"
    },
    {
        "title": "On Collaborative Compressive Sensing Systems: The Framework, Design and\n  Algorithm",
        "Published: ": "2017-09-19T19:13:15Z",
        "abstract": "Based on the maximum likelihood estimation principle, we derive a\ncollaborative estimation framework that fuses several different estimators and\nyields a better estimate. Applying it to compressive sensing (CS), we propose a\ncollaborative CS (CCS) scheme consisting of a bank of $K$ CS systems that share\nthe same sensing matrix but have different sparsifying dictionaries. This CCS\nsystem is expected to yield better performance than each individual CS system,\nwhile requiring the same time as that needed for each individual CS system when\na parallel computing strategy is used. We then provide an approach to designing\noptimal CCS systems by utilizing a measure that involves both the sensing\nmatrix and dictionaries and hence allows us to simultaneously optimize the\nsensing matrix and all the $K$ dictionaries. An alternating minimization-based\nalgorithm is derived for solving the corresponding optimal design problem. With\na rigorous convergence analysis, we show that the proposed algorithm is\nconvergent. Experiments are carried out to confirm the theoretical results and\nshow that the proposed CCS system yields significant improvements over the\nexisting CS systems in terms of the signal recovery accuracy.",
        "author": [
            "Zhihui Zhu",
            "Gang Li",
            "Jiajun Ding",
            "Qiuwei Li",
            "Xiongxiong He"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.06616v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.06616v2",
        "arXiv ID": "1709.06616v2"
    },
    {
        "title": "Deep neural network based sparse measurement matrix for image compressed\n  sensing",
        "Published: ": "2018-06-19T02:53:12Z",
        "abstract": "Gaussian random matrix (GRM) has been widely used to generate linear\nmeasurements in compressed sensing (CS) of natural images. However, there\nactually exist two disadvantages with GRM in practice. One is that GRM has\nlarge memory requirement and high computational complexity, which restrict the\napplications of CS. Another is that the CS measurements randomly obtained by\nGRM cannot provide sufficient reconstruction performances. In this paper, a\nDeep neural network based Sparse Measurement Matrix (DSMM) is learned by the\nproposed convolutional network to reduce the sampling computational complexity\nand improve the CS reconstruction performance. Two sub networks are included in\nthe proposed network, which are the sampling sub-network and the reconstruction\nsub-network. In the sampling sub-network, the sparsity and the normalization\nare both considered by the limitation of the storage and the computational\ncomplexity. In order to improve the CS reconstruction performance, a\nreconstruction sub-network are introduced to help enhance the sampling\nsub-network. So by the offline iterative training of the proposed end-to-end\nnetwork, the DSMM is generated for accurate measurement and excellent\nreconstruction. Experimental results demonstrate that the proposed DSMM\noutperforms GRM greatly on representative CS reconstruction methods",
        "author": [
            "Wenxue Cui",
            "Feng Jiang",
            "Xinwei Gao",
            "Wen Tao",
            "Debin Zhao"
        ],
        "pdfLink": "http://arxiv.org/pdf/1806.07026v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1806.07026v1",
        "arXiv ID": "1806.07026v1"
    },
    {
        "title": "From English to Code-Switching: Transfer Learning with Strong\n  Morphological Clues",
        "Published: ": "2019-09-11T15:53:21Z",
        "abstract": "Linguistic Code-switching (CS) is still an understudied phenomenon in natural\nlanguage processing. The NLP community has mostly focused on monolingual and\nmulti-lingual scenarios, but little attention has been given to CS in\nparticular. This is partly because of the lack of resources and annotated data,\ndespite its increasing occurrence in social media platforms. In this paper, we\naim at adapting monolingual models to code-switched text in various tasks.\nSpecifically, we transfer English knowledge from a pre-trained ELMo model to\ndifferent code-switched language pairs (i.e., Nepali-English, Spanish-English,\nand Hindi-English) using the task of language identification. Our method,\nCS-ELMo, is an extension of ELMo with a simple yet effective position-aware\nattention mechanism inside its character convolutions. We show the\neffectiveness of this transfer learning step by outperforming multilingual BERT\nand homologous CS-unaware ELMo models and establishing a new state of the art\nin CS tasks, such as NER and POS tagging. Our technique can be expanded to more\nEnglish-paired code-switched languages, providing more resources to the CS\ncommunity.",
        "author": [
            "Gustavo Aguilar",
            "Thamar Solorio"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.05158v3.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.05158v3",
        "arXiv ID": "1909.05158v3"
    },
    {
        "title": "New SU(1, 1) Position-Dependent Effective Mass Coherent States for the\n  Generalized Shifted Harmonic Oscillator",
        "Published: ": "2013-06-02T11:35:08Z",
        "abstract": "A new SU(1, 1) position-dependent effective mass coherent states (PDEM CS)\nrelated to the shifted harmonic oscillator (SHO) are deduced. This is\naccomplished by applying a similarity transformation to the generally deformed\noscillator algebra (GDOA) generators for PDEM system and construct a new set of\noperators which close the su(1, 1) Lie algebra, being the PDEM CS of the basis\nfor its unitary irreducible representation. The residual potential is\nassociated to the SHO. From the Lie algebra generators, we evaluate the\nuncertainty relationship for a position and momentum-like operators in the PDEM\nCS and show that it is minimized in the sense of Barut-Girardello CS. We prove\nthat the deduced PDEM CS preserve the same analytical form than those of\nGlauber states. We show that the probability density of dynamical evolution in\nthe PDEM CS oscillates back and forth as time goes by and behaves as classical\nwave packet.",
        "author": [
            "Sid-Ahmed Yahiaoui",
            "Mustapha Bentaiba"
        ],
        "pdfLink": "http://arxiv.org/pdf/1306.0197v1.pdf",
        "Categories": [
            [
                "math-ph",
                "math.MP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1306.0197v1",
        "arXiv ID": "1306.0197v1"
    },
    {
        "title": "Coherent States, Superpositions of Coherent States and Uncertainty\n  Relations on a M\u00f6bius Strip",
        "Published: ": "2013-06-16T21:26:14Z",
        "abstract": "Since symmetry properties of coherent states (CS) on M\\\"obius strip (MS) and\nfermions are closely related, CS on MS are naturally associated to the\ntopological properties of fermionic fields. Here we consider CS and\nsuperpositions of coherent states (SCS) on MS. We extend a recent propose of CS\non MS (Cirilo-Lombardo, 2012 [25]), including the analysis of periodic\nbehaviors of CS and SCS on MS and the uncertainty relations associated to\nangular momentum and the phase angle. The advantage of CS and SCS on MS with\nrespect to the standard ones and potential applications in continuous variable\nquantum computation are also addressed.",
        "author": [
            "Thiago Prud\u00eancio",
            "Diego Julio Cirilo-Lombardo"
        ],
        "pdfLink": "http://arxiv.org/pdf/1306.3499v1.pdf",
        "Categories": [
            [
                "quant-ph",
                "cond-mat.str-el",
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1306.3499v1",
        "arXiv ID": "1306.3499v1"
    },
    {
        "title": "High-Throughput Screening for Band gap Engineering by Sublattice Mixing\n  of Cs$_2$AgBiCl$_6$ from First-Principles",
        "Published: ": "2020-05-30T05:23:47Z",
        "abstract": "The lead-free double perovskite material (viz. Cs$_2$AgBiCl$_6$) has emerged\nas an efficient and environmentally friendly alternative to lead halide\nperovskites. To make Cs$_2$AgBiCl$_6$ optically active in the visible region of\nsolar spectrum, band gap engineering approach has been undertaken. Using\nCs$_2$AgBiCl$_6$ as a host, band gap and optical properties of Cs$_2$AgBiCl$_6$\nhave been modulated by alloying with M(I), M(II), and M(III) cations at\nAg-/Bi-sites. Here, we have employed density functional theory (DFT) with\nsuitable exchange-correlation functionals in light of spin-orbit coupling (SOC)\nto determine the stability, band gap and optical properties of different\ncompositions, that are obtained on Ag-Cl and Bi-Cl sublattices mixing. On\nanalyzing the 64 combinations within Cs$_2$AgBiCl$_6$, we have identified 19\npromising configurations having band gap sensitive to solar cell applications.\nThe most suitable configurations with Ge(II) and Sn(II) substitutions have\nspectroscopic limited maximum efficiency (SLME) of 32.08% and 30.91%,\nrespectively, which are apt for solar cell absorber.",
        "author": [
            "Deepika Gill",
            "Preeti Bhumla",
            "Manish Kumar",
            "Saswata Bhattacharya"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.00183v1.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci",
                "cond-mat.other"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.00183v1",
        "arXiv ID": "2006.00183v1"
    },
    {
        "title": "Commonsense Knowledge in Wikidata",
        "Published: ": "2020-08-18T18:23:06Z",
        "abstract": "Wikidata and Wikipedia have been proven useful for reason-ing in natural\nlanguage applications, like question answering or entitylinking. Yet, no\nexisting work has studied the potential of Wikidata for commonsense reasoning.\nThis paper investigates whether Wikidata con-tains commonsense knowledge which\nis complementary to existing commonsense sources. Starting from a definition of\ncommon sense, we devise three guiding principles, and apply them to generate a\ncommonsense subgraph of Wikidata (Wikidata-CS). Within our approach, we map the\nrelations of Wikidata to ConceptNet, which we also leverage to integrate\nWikidata-CS into an existing consolidated commonsense graph. Our experiments\nreveal that: 1) albeit Wikidata-CS represents a small portion of Wikidata, it\nis an indicator that Wikidata contains relevant commonsense knowledge, which\ncan be mapped to 15 ConceptNet relations; 2) the overlap between Wikidata-CS\nand other commonsense sources is low, motivating the value of knowledge\nintegration; 3) Wikidata-CS has been evolving over time at a slightly slower\nrate compared to the overall Wikidata, indicating a possible lack of focus on\ncommonsense knowledge. Based on these findings, we propose three recommended\nactions to improve the coverage and quality of Wikidata-CS further.",
        "author": [
            "Filip Ilievski",
            "Pedro Szekely",
            "Daniel Schwabe"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.08114v2.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.08114v2",
        "arXiv ID": "2008.08114v2"
    },
    {
        "title": "Belief Space Planning: A Covariance Steering Approach",
        "Published: ": "2021-05-24T04:44:39Z",
        "abstract": "A new belief space planning algorithm, called covariance steering Belief\nRoadMap (CS-BRM), is introduced, which is a multi-query algorithm for motion\nplanning of dynamical systems under simultaneous motion and observation\nuncertainties. CS-BRM extends the probabilistic roadmap (PRM) approach to\nbelief spaces and is based on the recently developed theory of covariance\nsteering (CS) that enables guaranteed satisfaction of terminal belief\nconstraints in finite-time. The nodes in the CS-BRM are sampled in belief space\nand represent distributions of the system states. A covariance steering\ncontroller steers the system from one BRM node to another, thus acting as an\nedge controller of the corresponding belief graph that ensures belief\nconstraint satisfaction. After the edge controller is computed, a specific edge\ncost is assigned to that edge. The CS-BRM algorithm allows the sampling of\nnon-stationary belief nodes, and thus is able to explore the velocity space and\nfind efficient motion plans. The performance of CS-BRM is evaluated and\ncompared to a previous belief space planning method, demonstrating the benefits\nof the proposed approach.",
        "author": [
            "Dongliang Zheng",
            "Jack Ridderhof",
            "Panagiotis Tsiotras",
            "Ali-akbar Agha-mohammadi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.11092v1.pdf",
        "Categories": [
            [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.11092v1",
        "arXiv ID": "2105.11092v1"
    },
    {
        "title": "Overlapping Bose-Einstein Condensates of $^{23}$Na and $^{133}$Cs",
        "Published: ": "2021-06-02T17:45:00Z",
        "abstract": "We report on the creation of dual-species Bose-Einstein condensates (BECs) of\n$^{23}$Na atoms and $^{133}$Cs atoms. We demonstrate sympathetic cooling of Cs\nwith Na in a magnetic quadrupole trap and a crossed optical dipole trap,\nleading to Na BECs with $8 \\times 10^5$ atoms and Cs BECs with $3.5 \\times\n10^4$ atoms. Investigating cross-thermalization and lifetimes of the mixture,\nwe find that the Na and Cs BECs are miscible and overlapping, interacting with\na moderate interspecies scattering length of $18(4)\\,a_0$ at $23\\,$G and\n$29(4)\\,a_0$ at $894\\,$G and coexisting for tens of seconds. Overlapping\ncondensates of Na and Cs offer new possibilities for many-body physics with\nultracold bosonic mixtures and constitute an ideal starting point for the\ncreation of ultracold ensembles of NaCs ground state molecules.",
        "author": [
            "Claire Warner",
            "Aden Z. Lam",
            "Niccol\u00f2 Bigagli",
            "Henry C. Liu",
            "Ian Stevenson",
            "Sebastian Will"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.01334v2.pdf",
        "Categories": [
            [
                "cond-mat.quant-gas",
                "physics.atom-ph",
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.01334v2",
        "arXiv ID": "2106.01334v2"
    },
    {
        "title": "Chance constrained conic-segmentation support vector machine with\n  uncertain data",
        "Published: ": "2021-07-28T12:29:47Z",
        "abstract": "Support vector machines (SVM) is one of the well known supervised classes of\nlearning algorithms. Furthermore, the conic-segmentation SVM (CS-SVM) is a\nnatural multiclass analogue of the standard binary SVM, as CS-SVM models are\ndealing with the situation where the exact values of the data points are known.\nThis paper studies CS-SVM when the data points are uncertain or mislabelled.\nWith some properties known for the distributions, a chance-constrained CS-SVM\napproach is used to ensure the small probability of misclassification for the\nuncertain data. The geometric interpretation is presented to show how CS-SVM\nworks. Finally, we present experimental results to investigate the chance\nconstrained CS-SVM's performance.",
        "author": [
            "Shen Peng",
            "Gianpiero Canessa",
            "Zhihua Allen-Zhao"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.13319v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "math.OC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.13319v2",
        "arXiv ID": "2107.13319v2"
    },
    {
        "title": "Efficient experimental characterization of quantum processes via\n  compressed sensing on an NMR quantum processor",
        "Published: ": "2021-09-27T17:05:13Z",
        "abstract": "We employ the compressed sensing (CS) algorithm and a heavily reduced data\nset to experimentally perform true quantum process tomography (QPT) on an NMR\nquantum processor. We obtain the estimate of the process matrix $\\chi$\ncorresponding to various two- and three-qubit quantum gates with a high\nfidelity. The CS algorithm is implemented using two different operator bases,\nnamely, the standard Pauli basis and the Pauli-error basis. We experimentally\ndemonstrate that the performance of the CS algorithm is significantly better in\nthe Pauli-error basis, where the constructed $\\chi$ matrix is maximally sparse.\nWe compare the standard least square (LS) optimization QPT method with the\nCS-QPT method and observe that, provided an appropriate basis is chosen, the\nCS-QPT method performs significantly better as compared to the LS-QPT method.\nIn all the cases considered, we obtained experimental fidelities greater than\n0.9 from a reduced data set, which was approximately five to six times smaller\nin size than a full data set. We also experimentally characterized the reduced\ndynamics of a two-qubit subsystem embedded in a three-qubit system, and used\nthe CS-QPT method to characterize processes corresponding to the evolution of\ntwo-qubit states under various $J$-coupling interactions.",
        "author": [
            "Akshay Gaikwad",
            "Arvind",
            "Kavita Dorai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.13189v1.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.13189v1",
        "arXiv ID": "2109.13189v1"
    },
    {
        "title": "Predicting User Code-Switching Level from Sociological and Psychological\n  Profiles",
        "Published: ": "2021-12-13T07:36:02Z",
        "abstract": "Multilingual speakers tend to alternate between languages within a\nconversation, a phenomenon referred to as \"code-switching\" (CS). CS is a\ncomplex phenomenon that not only encompasses linguistic challenges, but also\ncontains a great deal of complexity in terms of its dynamic behaviour across\nspeakers. This dynamic behaviour has been studied by sociologists and\npsychologists, identifying factors affecting CS. In this paper, we provide an\nempirical user study on Arabic-English CS, where we show the correlation\nbetween users' CS frequency and character traits. We use machine learning (ML)\nto validate the findings, informing and confirming existing theories. The\npredictive models were able to predict users' CS frequency with an accuracy\nhigher than 55%, where travel experiences and personality traits played the\nbiggest role in the modeling process.",
        "author": [
            "Injy Hamed",
            "Alia El Bolock",
            "Nader Rizk",
            "Cornelia Herbert",
            "Slim Abdennadher",
            "Ngoc Thang Vu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.06462v1.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.06462v1",
        "arXiv ID": "2112.06462v1"
    },
    {
        "title": "Covariance Steering of Discrete-Time Linear Systems with Mixed\n  Multiplicative and Additive Noise",
        "Published: ": "2022-10-04T17:03:12Z",
        "abstract": "In this paper, we study the covariance steering (CS) problem for\ndiscrete-time linear systems subject to multiplicative and additive noise.\nSpecifically, we consider two variants of the so-called CS problem. The goal of\nthe first problem, which is called the exact CS problem, is to steer the mean\nand the covariance of the state process to their desired values in finite time.\nIn the second one, which is called the ``relaxed'' CS problem, the covariance\nassignment constraint is relaxed into a positive semi-definite constraint. We\nshow that the relaxed CS problem can be cast as an equivalent convex\nsemi-definite program (SDP) after applying suitable variable transformations\nand constraint relaxations. Furthermore, we propose a two-step solution\nprocedure for the exact CS problem based on the relaxed problem formulation\nwhich returns a feasible solution, if there exists one. Finally, results from\nnumerical experiments are provided to show the efficacy of the proposed\nsolution methods.",
        "author": [
            "Isin M. Balci",
            "Efstathios Bakolas"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.01743v1.pdf",
        "Categories": [
            [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.01743v1",
        "arXiv ID": "2210.01743v1"
    },
    {
        "title": "Better Balance in Informatics: An Honest Discussion with Students",
        "Published: ": "2023-01-06T14:44:32Z",
        "abstract": "In recent years, there has been considerable effort to promote gender balance\nin the academic environment of Computer Science (CS). However, there is still a\ngender gap at all CS academic levels: from students, to PhD candidates, to\nfaculty members. This general trend is followed by the Department of Computer\nScience at UiT The Arctic University of Norway. To combat this trend within the\nCS environment at UiT, we embarked on structured discussions with students of\nour department. After analyzing the data collected from these discussions, we\nwere able to identify action items that could mitigate the existing gender gap\nat our department. In particular, these discussions elucidated ways to achieve\n(i) a balanced flow of students into CS undergraduate program, (ii) a balanced\nCS study environment, and (iii) a balanced flow of graduates into higher levels\nof the CS academia (e.g., PhD program). This paper presents the results of the\ndiscussions and the subsequent recommendations that we made to the\nadministration of the department. We also provide a road-map that other\ninstitutions could follow to organize similar events as part of their\ngender-balance action plan.",
        "author": [
            "Elisavet Kozyri",
            "Mariel Evelyn Markussen Ellingsen",
            "Ragnhild Abel Grape",
            "Letizia Jaccheri"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.02532v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.02532v1",
        "arXiv ID": "2301.02532v1"
    },
    {
        "title": "Speech collage: code-switched audio generation by collaging monolingual\n  corpora",
        "Published: ": "2023-09-27T14:17:53Z",
        "abstract": "Designing effective automatic speech recognition (ASR) systems for\nCode-Switching (CS) often depends on the availability of the transcribed CS\nresources. To address data scarcity, this paper introduces Speech Collage, a\nmethod that synthesizes CS data from monolingual corpora by splicing audio\nsegments. We further improve the smoothness quality of audio generation using\nan overlap-add approach. We investigate the impact of generated data on speech\nrecognition in two scenarios: using in-domain CS text and a zero-shot approach\nwith synthesized CS text. Empirical results highlight up to 34.4% and 16.2%\nrelative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and\nzero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation\nbolsters the model's code-switching inclination and reduces its monolingual\nbias.",
        "author": [
            "Amir Hussein",
            "Dorsa Zeinali",
            "Ond\u0159ej Klejch",
            "Matthew Wiesner",
            "Brian Yan",
            "Shammur Chowdhury",
            "Ahmed Ali",
            "Shinji Watanabe",
            "Sanjeev Khudanpur"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.15674v1.pdf",
        "Categories": [
            [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.15674v1",
        "arXiv ID": "2309.15674v1"
    },
    {
        "title": "AI in Human-computer Gaming: Techniques, Challenges and Opportunities",
        "Published: ": "2021-11-15T09:35:53Z",
        "abstract": "With breakthrough of the AlphaGo, human-computer gaming AI has ushered in a\nbig explosion, attracting more and more researchers all around the world. As a\nrecognized standard for testing artificial intelligence, various human-computer\ngaming AI systems (AIs) have been developed such as the Libratus, OpenAI Five\nand AlphaStar, beating professional human players. The rapid development of\nhuman-computer gaming AIs indicate a big step of decision making intelligence,\nand it seems that current techniques can handle very complex human-computer\ngames. So, one natural question raises: what are the possible challenges of\ncurrent techniques in human-computer gaming, and what are the future trends? To\nanswer the above question, in this paper, we survey recent successful game AIs,\ncovering board game AIs, card game AIs, first-person shooting game AIs and real\ntime strategy game AIs. Through this survey, we 1) compare the main\ndifficulties among different kinds of games and the corresponding techniques\nutilized for achieving professional human level AIs; 2) summarize the\nmainstream frameworks and techniques that can be properly relied on for\ndeveloping AIs for complex human-computer gaming; 3) raise the challenges or\ndrawbacks of current techniques in the successful AIs; and 4) try to point out\nfuture trends in human-computer gaming AIs. Finally, we hope this brief review\ncan provide an introduction for beginners, and inspire insights for researchers\nin the field of AI in human-computer gaming.",
        "author": [
            "Qiyue Yin",
            "Jun Yang",
            "Kaiqi Huang",
            "Meijing Zhao",
            "Wancheng Ni",
            "Bin Liang",
            "Yan Huang",
            "Shu Wu",
            "Liang Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2111.07631v2.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2111.07631v2",
        "arXiv ID": "2111.07631v2"
    },
    {
        "title": "Uncalibrated Models Can Improve Human-AI Collaboration",
        "Published: ": "2022-02-12T04:51:00Z",
        "abstract": "In many practical applications of AI, an AI model is used as a decision aid\nfor human users. The AI provides advice that a human (sometimes) incorporates\ninto their decision-making process. The AI advice is often presented with some\nmeasure of \"confidence\" that the human can use to calibrate how much they\ndepend on or trust the advice. In this paper, we present an initial exploration\nthat suggests showing AI models as more confident than they actually are, even\nwhen the original AI is well-calibrated, can improve human-AI performance\n(measured as the accuracy and confidence of the human's final prediction after\nseeing the AI advice). We first train a model to predict human incorporation of\nAI advice using data from thousands of human-AI interactions. This enables us\nto explicitly estimate how to transform the AI's prediction confidence, making\nthe AI uncalibrated, in order to improve the final human prediction. We\nempirically validate our results across four different tasks--dealing with\nimages, text and tabular data--involving hundreds of human participants. We\nfurther support our findings with simulation analysis. Our findings suggest the\nimportance of jointly optimizing the human-AI system as opposed to the standard\nparadigm of optimizing the AI model alone.",
        "author": [
            "Kailas Vodrahalli",
            "Tobias Gerstenberg",
            "James Zou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2202.05983v3.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2202.05983v3",
        "arXiv ID": "2202.05983v3"
    },
    {
        "title": "Never trust, always verify : a roadmap for Trustworthy AI?",
        "Published: ": "2022-06-23T21:13:10Z",
        "abstract": "Artificial Intelligence (AI) is becoming the corner stone of many systems\nused in our daily lives such as autonomous vehicles, healthcare systems, and\nunmanned aircraft systems. Machine Learning is a field of AI that enables\nsystems to learn from data and make decisions on new data based on models to\nachieve a given goal. The stochastic nature of AI models makes verification and\nvalidation tasks challenging. Moreover, there are intrinsic biaises in AI\nmodels such as reproductibility bias, selection bias (e.g., races, genders,\ncolor), and reporting bias (i.e., results that do not reflect the reality).\nIncreasingly, there is also a particular attention to the ethical, legal, and\nsocietal impacts of AI. AI systems are difficult to audit and certify because\nof their black-box nature. They also appear to be vulnerable to threats; AI\nsystems can misbehave when untrusted data are given, making them insecure and\nunsafe. Governments, national and international organizations have proposed\nseveral principles to overcome these challenges but their applications in\npractice are limited and there are different interpretations in the principles\nthat can bias implementations. In this paper, we examine trust in the context\nof AI-based systems to understand what it means for an AI system to be\ntrustworthy and identify actions that need to be undertaken to ensure that AI\nsystems are trustworthy. To achieve this goal, we first review existing\napproaches proposed for ensuring the trustworthiness of AI systems, in order to\nidentify potential conceptual gaps in understanding what trustworthy AI is.\nThen, we suggest a trust (resp. zero-trust) model for AI and suggest a set of\nproperties that should be satisfied to ensure the trustworthiness of AI\nsystems.",
        "author": [
            "Lionel Nganyewou Tidjon",
            "Foutse Khomh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.11981v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.11981v1",
        "arXiv ID": "2206.11981v1"
    },
    {
        "title": "A Systematic Review of Green AI",
        "Published: ": "2023-01-26T11:41:46Z",
        "abstract": "With the ever-growing adoption of AI-based systems, the carbon footprint of\nAI is no longer negligible. AI researchers and practitioners are therefore\nurged to hold themselves accountable for the carbon emissions of the AI models\nthey design and use. This led in recent years to the appearance of researches\ntackling AI environmental sustainability, a field referred to as Green AI.\nDespite the rapid growth of interest in the topic, a comprehensive overview of\nGreen AI research is to date still missing. To address this gap, in this paper,\nwe present a systematic review of the Green AI literature. From the analysis of\n98 primary studies, different patterns emerge. The topic experienced a\nconsiderable growth from 2020 onward. Most studies consider monitoring AI model\nfootprint, tuning hyperparameters to improve model sustainability, or\nbenchmarking models. A mix of position papers, observational studies, and\nsolution papers are present. Most papers focus on the training phase, are\nalgorithm-agnostic or study neural networks, and use image data. Laboratory\nexperiments are the most common research strategy. Reported Green AI energy\nsavings go up to 115%, with savings over 50% being rather common. Industrial\nparties are involved in Green AI studies, albeit most target academic readers.\nGreen AI tool provisioning is scarce. As a conclusion, the Green AI research\nfield results to have reached a considerable level of maturity. Therefore, from\nthis review emerges that the time is suitable to adopt other Green AI research\nstrategies, and port the numerous promising academic results to industrial\npractice.",
        "author": [
            "Roberto Verdecchia",
            "June Sallou",
            "Lu\u00eds Cruz"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.11047v3.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.11047v3",
        "arXiv ID": "2301.11047v3"
    },
    {
        "title": "Bridging the Global Divide in AI Regulation: A Proposal for a\n  Contextual, Coherent, and Commensurable Framework",
        "Published: ": "2023-03-20T15:23:40Z",
        "abstract": "This paper examines the current landscape of AI regulations, highlighting the\ndivergent approaches being taken, and proposes an alternative contextual,\ncoherent, and commensurable (3C) framework. The EU, Canada, South Korea, and\nBrazil follow a horizontal or lateral approach that postulates the homogeneity\nof AI systems, seeks to identify common causes of harm, and demands uniform\nhuman interventions. In contrast, the U.K., Israel, Switzerland, Japan, and\nChina have pursued a context-specific or modular approach, tailoring\nregulations to the specific use cases of AI systems. The U.S. is reevaluating\nits strategy, with growing support for controlling existential risks associated\nwith AI. Addressing such fragmentation of AI regulations is crucial to ensure\nthe interoperability of AI. The present degree of proportionality, granularity,\nand foreseeability of the EU AI Act is not sufficient to garner consensus. The\ncontext-specific approach holds greater promises but requires further\ndevelopment in terms of details, coherency, and commensurability. To strike a\nbalance, this paper proposes a hybrid 3C framework. To ensure contextuality,\nthe framework categorizes AI into distinct types based on their usage and\ninteraction with humans: autonomous, allocative, punitive, cognitive, and\ngenerative AI. To ensure coherency, each category is assigned specific\nregulatory objectives: safety for autonomous AI; fairness and explainability\nfor allocative AI; accuracy and explainability for punitive AI; accuracy,\nrobustness, and privacy for cognitive AI; and the mitigation of infringement\nand misuse for generative AI. To ensure commensurability, the framework\npromotes the adoption of international industry standards that convert\nprinciples into quantifiable metrics. In doing so, the framework is expected to\nfoster international collaboration and standardization without imposing\nexcessive compliance costs.",
        "author": [
            "Sangchul Park"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.11196v3.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.11196v3",
        "arXiv ID": "2303.11196v3"
    },
    {
        "title": "Human Indignity: From Legal AI Personhood to Selfish Memes",
        "Published: ": "2018-10-02T20:01:43Z",
        "abstract": "It is possible to rely on current corporate law to grant legal personhood to\nArtificially Intelligent (AI) agents. In this paper, after introducing pathways\nto AI personhood, we analyze consequences of such AI empowerment on human\ndignity, human safety and AI rights. We emphasize possibility of creating\nselfish memes and legal system hacking in the context of artificial entities.\nFinally, we consider some potential solutions for addressing described\nproblems.",
        "author": [
            "Roman V. Yampolskiy"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.02724v1.pdf",
        "Categories": [
            [
                "cs.GL",
                "cs.AI",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.02724v1",
        "arXiv ID": "1810.02724v1"
    },
    {
        "title": "Towards Goldilocks Zone in Child-centered AI",
        "Published: ": "2023-03-20T15:52:33Z",
        "abstract": "Using YouTube Kids as an example, in this work, we argue the need to\nunderstand a child's interaction process with AI and its broader implication on\na child's emotional, social, and creative development. We present several\ndesign recommendations to create value-driven interaction in child-centric AI\nthat can guide designing compelling, age-appropriate, beneficial AI experiences\nfor children.",
        "author": [
            "Tahiya Chowdhury"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.11221v2.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.11221v2",
        "arXiv ID": "2303.11221v2"
    },
    {
        "title": "Strategies to architect AI Safety: Defense to guard AI from Adversaries",
        "Published: ": "2019-06-08T14:34:47Z",
        "abstract": "The impact of designing for security of AI is critical for humanity in the AI\nera. With humans increasingly becoming dependent upon AI, there is a need for\nneural networks that work reliably, inspite of Adversarial attacks. The vision\nfor Safe and secure AI for popular use is achievable. To achieve safety of AI,\nthis paper explores strategies and a novel deep learning architecture. To guard\nAI from adversaries, paper explores combination of 3 strategies:\n  1. Introduce randomness at inference time to hide the representation learning\nfrom adversaries.\n  2. Detect presence of adversaries by analyzing the sequence of inferences.\n  3. Exploit visual similarity.\n  To realize these strategies, this paper designs a novel architecture, Dynamic\nNeural Defense, DND. This defense has 3 deep learning architectural features:\n  1. By hiding the way a neural network learns from exploratory attacks using a\nrandom computation graph, DND evades attack.\n  2. By analyzing input sequence to cloud AI inference engine with LSTM, DND\ndetects attack sequence.\n  3. By inferring with visual similar inputs generated by VAE, any AI defended\nby DND approach does not succumb to hackers.\n  Thus, a roadmap to develop reliable, safe and secure AI is presented.",
        "author": [
            "Rajagopal. A",
            "Nirmala. V"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.03466v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CR",
                "cs.CV",
                "I.2.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.03466v1",
        "arXiv ID": "1906.03466v1"
    },
    {
        "title": "\"Brilliant AI Doctor\" in Rural China: Tensions and Challenges in\n  AI-Powered CDSS Deployment",
        "Published: ": "2021-01-04T05:32:48Z",
        "abstract": "Artificial intelligence (AI) technology has been increasingly used in the\nimplementation of advanced Clinical Decision Support Systems (CDSS). Research\ndemonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical\ndecision making scenarios. However, post-adoption user perception and\nexperience remain understudied, especially in developing countries. Through\nobservations and interviews with 22 clinicians from 6 rural clinics in China,\nthis paper reports the various tensions between the design of an AI-CDSS system\n(\"Brilliant Doctor\") and the rural clinical context, such as the misalignment\nwith local context and workflow, the technical limitations and usability\nbarriers, as well as issues related to transparency and trustworthiness of\nAI-CDSS. Despite these tensions, all participants expressed positive attitudes\ntoward the future of AI-CDSS, especially acting as \"a doctor's AI assistant\" to\nrealize a Human-AI Collaboration future in clinical settings. Finally we draw\non our findings to discuss implications for designing AI-CDSS interventions for\nrural clinical contexts in developing countries.",
        "author": [
            "Dakuo Wang",
            "Liuping Wang",
            "Zhan Zhang",
            "Ding Wang",
            "Haiyi Zhu",
            "Yvonne Gao",
            "Xiangmin Fan",
            "Feng Tian"
        ],
        "pdfLink": "http://arxiv.org/pdf/2101.01524v2.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2101.01524v2",
        "arXiv ID": "2101.01524v2"
    },
    {
        "title": "Montreal AI Ethics Institute's (MAIEI) Submission to the World\n  Intellectual Property Organization (WIPO) Conversation on Intellectual\n  Property (IP) and Artificial Intelligence (AI) Second Session",
        "Published: ": "2020-08-11T05:31:10Z",
        "abstract": "This document posits that, at best, a tenuous case can be made for providing\nAI exclusive IP over their \"inventions\". Furthermore, IP protections for AI are\nunlikely to confer the benefit of ensuring regulatory compliance. Rather, IP\nprotections for AI \"inventors\" present a host of negative externalities and\nobscures the fact that the genuine inventor, deserving of IP, is the human\nagent. This document will conclude by recommending strategies for WIPO to bring\nIP law into the 21st century, enabling it to productively account for AI\n\"inventions\".\n  Theme: IP Protection for AI-Generated and AI-Assisted Works Based on insights\nfrom the Montreal AI Ethics Institute (MAIEI) staff and supplemented by\nworkshop contributions from the AI Ethics community convened by MAIEI on July\n5, 2020.",
        "author": [
            "Allison Cohen",
            "Abhishek Gupta"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.04520v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.04520v1",
        "arXiv ID": "2008.04520v1"
    },
    {
        "title": "Measuring Human Adaptation to AI in Decision Making: Application to\n  Evaluate Changes after AlphaGo",
        "Published: ": "2020-12-30T04:34:46Z",
        "abstract": "Across a growing number of domains, human experts are expected to learn from\nand adapt to AI with superior decision making abilities. But how can we\nquantify such human adaptation to AI? We develop a simple measure of human\nadaptation to AI and test its usefulness in two case studies. In Study 1, we\nanalyze 1.3 million move decisions made by professional Go players and find\nthat a positive form of adaptation to AI (learning) occurred after the players\ncould observe the reasoning processes of AI, rather than mere actions of AI.\nThese findings based on our measure highlight the importance of explainability\nfor human learning from AI. In Study 2, we test whether our measure is\nsufficiently sensitive to capture a negative form of adaptation to AI (cheating\naided by AI), which occurred in a match between professional Go players. We\ndiscuss our measure's applications in domains other than Go, especially in\ndomains in which AI's decision making ability will likely surpass that of human\nexperts.",
        "author": [
            "Minkyu Shin",
            "Jin Kim",
            "Minkyung Kim"
        ],
        "pdfLink": "http://arxiv.org/pdf/2012.15035v3.pdf",
        "Categories": [
            [
                "cs.HC",
                "econ.GN",
                "q-fin.EC",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2012.15035v3",
        "arXiv ID": "2012.15035v3"
    },
    {
        "title": "AI in Finance: Challenges, Techniques and Opportunities",
        "Published: ": "2021-07-20T01:39:10Z",
        "abstract": "AI in finance broadly refers to the applications of AI techniques in\nfinancial businesses. This area has been lasting for decades with both classic\nand modern AI techniques applied to increasingly broader areas of finance,\neconomy and society. In contrast to either discussing the problems, aspects and\nopportunities of finance that have benefited from specific AI techniques and in\nparticular some new-generation AI and data science (AIDS) areas or reviewing\nthe progress of applying specific techniques to resolving certain financial\nproblems, this review offers a comprehensive and dense roadmap of the\noverwhelming challenges, techniques and opportunities of AI research in finance\nover the past decades. The landscapes and challenges of financial businesses\nand data are firstly outlined, followed by a comprehensive categorization and a\ndense overview of the decades of AI research in finance. We then structure and\nillustrate the data-driven analytics and learning of financial businesses and\ndata. The comparison, criticism and discussion of classic vs. modern AI\ntechniques for finance are followed. Lastly, open issues and opportunities\naddress future AI-empowered finance and finance-motivated AI research.",
        "author": [
            "Longbing Cao"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.09051v1.pdf",
        "Categories": [
            [
                "q-fin.CP",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.09051v1",
        "arXiv ID": "2107.09051v1"
    },
    {
        "title": "The AI Triplet: Computational, Conceptual, and Mathematical Knowledge in\n  AI Education",
        "Published: ": "2021-10-14T14:19:30Z",
        "abstract": "Efforts to enhance education and broaden participation in AI will benefit\nfrom a systematic understanding of the competencies underlying AI expertise. In\nthis paper, we observe that AI expertise requires integrating computational,\nconceptual, and mathematical knowledge and representations. We call this the\n``AI triplet,'' similar in spirit to the ``chemistry triplet'' that has heavily\ninfluenced the past four decades of chemistry education research. We describe a\ntheoretical foundation for this triplet and show how it maps onto two sample AI\ntopics: tree search and gradient descent. Finally, just as the chemistry\ntriplet has impacted chemistry education in concrete ways, we suggest two\ninitial hypotheses for how the AI triplet might impact AI education: 1) how we\ncan help AI students gain proficiency in moving between the corners of the\ntriplet; and 2) how all corners of the AI triplet highlight the need for\nsupporting students' spatial cognitive skills.",
        "author": [
            "Maithilee Kunda"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.09290v2.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.09290v2",
        "arXiv ID": "2110.09290v2"
    },
    {
        "title": "Understanding Older Adults' Perceptions and Challenges in Using\n  AI-enabled Everyday Technologies",
        "Published: ": "2022-10-04T04:19:21Z",
        "abstract": "Artificial intelligence (AI)-enabled everyday technologies could help address\nage-related challenges like physical impairments and cognitive decline. While\nrecent research studied older adults' experiences with specific AI-enabled\nproducts (e.g., conversational agents and assistive robots), it remains unknown\nhow older adults perceive and experience current AI-enabled everyday\ntechnologies in general, which could impact their adoption of future AI-enabled\nproducts. We conducted a survey study (N=41) and semi-structured interviews\n(N=15) with older adults to understand their experiences and perceptions of AI.\nWe found that older adults were enthusiastic about learning and using\nAI-enabled products, but they lacked learning avenues. Additionally, they\nworried when AI-enabled products outwitted their expectations, intruded on\ntheir privacy, or impacted their decision-making skills. Therefore, they held\nmixed views towards AI-enabled products such as AI, an aid, or an adversary. We\nconclude with design recommendations that make older adults feel inclusive,\nsecure, and in control of their interactions with AI-enabled products.",
        "author": [
            "Esha Shandilya",
            "Mingming Fan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.01369v1.pdf",
        "Categories": [
            [
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.01369v1",
        "arXiv ID": "2210.01369v1"
    },
    {
        "title": "AI Maintenance: A Robustness Perspective",
        "Published: ": "2023-01-08T15:02:38Z",
        "abstract": "With the advancements in machine learning (ML) methods and compute resources,\nartificial intelligence (AI) empowered systems are becoming a prevailing\ntechnology. However, current AI technology such as deep learning is not\nflawless. The significantly increased model complexity and data scale incur\nintensified challenges when lacking trustworthiness and transparency, which\ncould create new risks and negative impacts. In this paper, we carve out AI\nmaintenance from the robustness perspective. We start by introducing some\nhighlighted robustness challenges in the AI lifecycle and motivating AI\nmaintenance by making analogies to car maintenance. We then propose an AI model\ninspection framework to detect and mitigate robustness risks. We also draw\ninspiration from vehicle autonomy to define the levels of AI robustness\nautomation. Our proposal for AI maintenance facilitates robustness assessment,\nstatus tracking, risk scanning, model hardening, and regulation throughout the\nAI lifecycle, which is an essential milestone toward building sustainable and\ntrustworthy AI ecosystems.",
        "author": [
            "Pin-Yu Chen",
            "Payel Das"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.03052v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.03052v1",
        "arXiv ID": "2301.03052v1"
    },
    {
        "title": "Competent but Rigid: Identifying the Gap in Empowering AI to Participate\n  Equally in Group Decision-Making",
        "Published: ": "2023-02-17T11:07:17Z",
        "abstract": "Existing research on human-AI collaborative decision-making focuses mainly on\nthe interaction between AI and individual decision-makers. There is a limited\nunderstanding of how AI may perform in group decision-making. This paper\npresents a wizard-of-oz study in which two participants and an AI form a\ncommittee to rank three English essays. One novelty of our study is that we\nadopt a speculative design by endowing AI equal power to humans in group\ndecision-making.We enable the AI to discuss and vote equally with other human\nmembers. We find that although the voice of AI is considered valuable, AI still\nplays a secondary role in the group because it cannot fully follow the dynamics\nof the discussion and make progressive contributions. Moreover, the divergent\nopinions of our participants regarding an \"equal AI\" shed light on the possible\nfuture of human-AI relations.",
        "author": [
            "Chengbo Zheng",
            "Yuheng Wu",
            "Chuhan Shi",
            "Shuai Ma",
            "Jiehui Luo",
            "Xiaojuan Ma"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.08807v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.08807v1",
        "arXiv ID": "2302.08807v1"
    },
    {
        "title": "Democratising AI: Multiple Meanings, Goals, and Methods",
        "Published: ": "2023-03-22T15:23:22Z",
        "abstract": "Numerous parties are calling for the democratisation of AI, but the phrase is\nused to refer to a variety of goals, the pursuit of which sometimes conflict.\nThis paper identifies four kinds of AI democratisation that are commonly\ndiscussed: (1) the democratisation of AI use, (2) the democratisation of AI\ndevelopment, (3) the democratisation of AI profits, and (4) the democratisation\nof AI governance. Numerous goals and methods of achieving each form of\ndemocratisation are discussed. The main takeaway from this paper is that AI\ndemocratisation is a multifarious and sometimes conflicting concept that should\nnot be conflated with improving AI accessibility. If we want to move beyond\nambiguous commitments to democratising AI, to productive discussions of\nconcrete policies and trade-offs, then we need to recognise the principal role\nof the democratisation of AI governance in navigating tradeoffs and risks\nacross decisions around use, development, and profits.",
        "author": [
            "Elizabeth Seger",
            "Aviv Ovadya",
            "Ben Garfinkel",
            "Divya Siddarth",
            "Allan Dafoe"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.12642v3.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.12642v3",
        "arXiv ID": "2303.12642v3"
    },
    {
        "title": "The Chai Platform's AI Safety Framework",
        "Published: ": "2023-06-05T15:51:38Z",
        "abstract": "Chai empowers users to create and interact with customized chatbots, offering\nunique and engaging experiences. Despite the exciting prospects, the work\nrecognizes the inherent challenges of a commitment to modern safety standards.\nTherefore, this paper presents the integrated AI safety principles into Chai to\nprioritize user safety, data protection, and ethical technology use. The paper\nspecifically explores the multidimensional domain of AI safety research,\ndemonstrating its application in Chai's conversational chatbot platform. It\npresents Chai's AI safety principles, informed by well-established AI research\ncentres and adapted for chat AI. This work proposes the following safety\nframework: Content Safeguarding; Stability and Robustness; and Operational\nTransparency and Traceability. The subsequent implementation of these\nprinciples is outlined, followed by an experimental analysis of Chai's AI\nsafety framework's real-world impact. We emphasise the significance of\nconscientious application of AI safety principles and robust safety measures.\nThe successful implementation of the safe AI framework in Chai indicates the\npracticality of mitigating potential risks for responsible and ethical use of\nAI technologies. The ultimate vision is a transformative AI tool fostering\nprogress and innovation while prioritizing user safety and ethical standards.",
        "author": [
            "Xiaoding Lu",
            "Aleksey Korshuk",
            "Zongyi Liu",
            "William Beauchamp"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.02979v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.02979v1",
        "arXiv ID": "2306.02979v1"
    },
    {
        "title": "VerifAI: Verified Generative AI",
        "Published: ": "2023-07-06T06:11:51Z",
        "abstract": "Generative AI has made significant strides, yet concerns about the accuracy\nand reliability of its outputs continue to grow. Such inaccuracies can have\nserious consequences such as inaccurate decision-making, the spread of false\ninformation, privacy violations, legal liabilities, and more. Although efforts\nto address these risks are underway, including explainable AI and responsible\nAI practices such as transparency, privacy protection, bias mitigation, and\nsocial and environmental responsibility, misinformation caused by generative AI\nwill remain a significant challenge. We propose that verifying the outputs of\ngenerative AI from a data management perspective is an emerging issue for\ngenerative AI. This involves analyzing the underlying data from multi-modal\ndata lakes, including text files, tables, and knowledge graphs, and assessing\nits quality and consistency. By doing so, we can establish a stronger\nfoundation for evaluating the outputs of generative AI models. Such an approach\ncan ensure the correctness of generative AI, promote transparency, and enable\ndecision-making with greater confidence. Our vision is to promote the\ndevelopment of verifiable generative AI and contribute to a more trustworthy\nand responsible use of AI.",
        "author": [
            "Nan Tang",
            "Chenyu Yang",
            "Ju Fan",
            "Lei Cao",
            "Yuyu Luo",
            "Alon Halevy"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.02796v2.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.CL",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.02796v2",
        "arXiv ID": "2307.02796v2"
    },
    {
        "title": "Artificial Intelligence in the Knowledge Economy",
        "Published: ": "2023-12-09T06:59:55Z",
        "abstract": "How does Artificial Intelligence (AI) affect the organization of work and the\nstructure of wages? We study this question in a model where heterogeneous\nagents in terms of knowledge--humans and machines--endogenously sort into\nhierarchical teams: Less knowledgeable agents become \"workers\" (i.e., execute\nroutine tasks), while more knowledgeable agents become \"managers\" (i.e.,\nspecialize in problem solving). When AI's knowledge is equivalent to that of a\npre-AI worker, AI displaces humans from routine work into managerial work\ncompared to the pre-AI outcome. In contrast, when AI's knowledge is that of a\npre-AI manager, it shifts humans from managerial work to routine work. AI\nincreases total human labor income, but it necessarily creates winners and\nlosers: When AI's knowledge is low, only the most knowledgeable humans\nexperience income gains. In contrast, when AI's knowledge is high, both\nextremes of the knowledge distribution benefit. In any case, the introduction\nof AI harms the middle class.",
        "author": [
            "Enrique Ide",
            "Eduard Talamas"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.05481v1.pdf",
        "Categories": [
            [
                "econ.TH"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.05481v1",
        "arXiv ID": "2312.05481v1"
    },
    {
        "title": "Human AI Collaboration in Software Engineering: Lessons Learned from a\n  Hands On Workshop",
        "Published: ": "2023-12-17T06:31:05Z",
        "abstract": "This paper investigates the dynamics of human AI collaboration in software\nengineering, focusing on the use of ChatGPT. Through a thematic analysis of a\nhands on workshop in which 22 professional software engineers collaborated for\nthree hours with ChatGPT, we explore the transition of AI from a mere tool to a\ncollaborative partner. The study identifies key themes such as the evolving\nnature of human AI interaction, the capabilities of AI in software engineering\ntasks, and the challenges and limitations of integrating AI in this domain. The\nfindings show that while AI, particularly ChatGPT, improves the efficiency of\ncode generation and optimization, human oversight remains crucial, especially\nin areas requiring complex problem solving and security considerations. This\nresearch contributes to the theoretical understanding of human AI collaboration\nin software engineering and provides practical insights for effectively\nintegrating AI tools into development processes. It highlights the need for\nclear role allocation, effective communication, and balanced AI human\ncollaboration to realize the full potential of AI in software engineering.",
        "author": [
            "Muhammad Hamza",
            "Dominik Siemon",
            "Muhammad Azeem Akbar",
            "Tahsinur Rahman"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.10620v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.10620v1",
        "arXiv ID": "2312.10620v1"
    },
    {
        "title": "Modeling the submillimeter emission from the Cepheus A young stellar\n  cluster: Evidence for large scale collapse",
        "Published: ": "2004-04-10T01:07:57Z",
        "abstract": "Evidence for a large scale flow of low density gas onto the Cepheus A young\nstellar cluster is presented. Observations of K-band near-infrared and\nmulti-transition CS and N2H+ millimeter line emission are shown in relation to\na sub-millimeter map of the cool dust around the most embedded stars. The\nnear-infrared emission is offset from the dust peak suggesting a shift in the\nlocation of star formation over the history of the core. The CS emission is\nconcentrated toward the core center but N2H+ peaks in two main cores offset\nfrom the center, opposite to the chemistry observed in low mass cores. A\nstarless core with strong CS but weak N2H+ emission is found toward the western\nedge of the region. The average CS(2-1) spectrum over the cluster forming core\nis asymmetrically self-absorbed suggesting infall. We analyze the large scale\ndynamics by applying a one-dimensional radiative transfer code to a model\nspherical core with constant temperature and linewidth, and a density profile\nmeasured from an archival 850 micron map of the region. The best fit model that\nmatches the three CS profiles requires a low CS abundance in the core and an\nouter, infalling envelope with a low density and undepleted CS abundance. The\nintegrated intensities of the two N2H+ lines is well matched with a constant\nN2H+ abundance. The envelope infall velocity is tightly constrained by the\nCS(2-1) asymmetry and is sub-sonic but the size of the infalling region is\npoorly determined. The picture of a high density center with depleted CS slowly\naccreting a low density outer envelope with normal CS abundance suggests that\ncore growth occurs at least partially by the dissipation of turbulent support\non large scales.",
        "author": [
            "Sandrine Bottinelli",
            "Jonathan P. Williams"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0404215v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0404215v1",
        "arXiv ID": "0404215v1"
    },
    {
        "title": "Chemistry in disks. XI. Sulfur-bearing species as tracers of\n  protoplanetary disk physics and chemistry: the DM Tau case",
        "Published: ": "2018-06-20T13:11:00Z",
        "abstract": "Context. Several sulfur-bearing molecules are observed in the interstellar\nmedium and in comets, in strong contrast to protoplanetary disks where only CS,\nH$_2$CS and SO have been detected so far. Aims. We combine observations and\nchemical models to constrain the sulfur abundances and their sensitivity to\nphysical and chemical conditions in the DM Tau protoplanetary disk. Methods. We\nobtained $0.5^{\"}$ ALMA observations of DM Tau in Bands 4 and 6 in lines of CS,\nSO, SO$_2$, OCS, CCS, H$_2$CS and H$_2$S, achieving a $\\sim 5$ mJy sensitivity.\nUsing the non-LTE radiative transfer code RADEX and the forward-modeling tool\nDiskFit, disk-averaged CS column densities and upper limits for the other\nspecies were derived. Results. Only CS was detected with a derived column\ndensity of $\\sim 2-6 \\times 10^{12}$ cm$^{-2}$. We report a first tentative\ndetection of SO$_2$ in DM Tau. The upper limits range between $\\sim 10^{11}$\nand $10^{14}$ cm$^{-2}$ for the other S-bearing species. The best-fit chemical\nmodel matching these values requires a gas-phase C/O ratio of > 1 at $r \\sim\n50-100$ au. With chemical modeling we demonstrate that sulfur-bearing species\ncould be robust tracers of the gas-phase C/O ratio, surface reaction rates,\ngrain size and UV intensities. Conclusions. The lack of detections of a variety\nof sulfur-bearing molecules in DM Tau other than CS implies a dearth of\nreactive sulfur in the gas phase, either through efficient freeze-out or\nbecause most of the elemental sulfur is in other large species, as found in\ncomets. The inferred high CS/SO and CS/SO$_2$ ratios require a non-solar C/O\ngas-phase ratio of > 1, consistent with the recent observations of hydrocarbon\nrings in DM Tau. The stronger depletion of oxygen-bearing S-species compared to\nCS is likely linked to the low observed abundances of gaseous water in DM Tau\nand points to a removal mechanism of oxygen from the gas.",
        "author": [
            "D. Semenov",
            "C. Favre",
            "D. Fedele",
            "S. Guilloteau",
            "R. Teague",
            "Th. Henning",
            "A. Dutrey",
            "E. Chapillon",
            "F. Hersant",
            "V. Pi\u00e9tu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1806.07707v2.pdf",
        "Categories": [
            [
                "astro-ph.GA",
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1806.07707v2",
        "arXiv ID": "1806.07707v2"
    },
    {
        "title": "Study of CS, SiO, and SiS abundances in carbon star envelopes: Assessing\n  their role as gas-phase precursors of dust",
        "Published: ": "2019-06-22T15:34:54Z",
        "abstract": "Aim: We aim to determine the abundances of CS, SiO, and SiS in a large sample\nof carbon star envelopes covering a wide range of mass loss rates to\ninvestigate the potential role that these molecules could play in the formation\nof dust in the surroundings of the central AGB star. Methods: We surveyed a\nsample of 25 carbon-rich AGB stars in the $\\lambda$ 2 mm band, using the IRAM\n30 m telescope. We performed excitation and radiative transfer calculations\nbased on the LVG method to model the observed lines of the molecules and to\nderive their fractional abundances in the observed CSEs. Results: We detected\nCS in all 25 CSEs, SiO in 24 of them, and SiS in 17 sources. We found that CS\nand SiS have similar abundances in carbon star envelopes, while SiO is present\nwith a lower abundance. We also found a strong correlation in which the denser\nthe envelope, the less abundant are CS and SiO. The trend is however only\ntentatively seen for SiS in the range of high mass loss rates. Furthermore, we\nfound a relation in which the integrated flux of the MgS dust feature at 30 um\nincreases as the fractional abundance of CS decreases. Conclusions: The decline\nin the fractional abundance of CS with increasing density could be due to\ngas-phase chemistry in the inner envelope or to adsorption onto dust grains.\nThe latter possibility is favored by a correlation between the CS fractional\nabundance and the 30 um feature, which suggests that CS is efficiently\nincorporated onto MgS dust around C-rich AGB stars. In the case of SiO, the\nobserved abundance depletion with increasing density is most likely caused by\nan efficient incorporation onto dust grains. We conclude that CS, SiO (very\nlikely), and SiS (tentatively) are good candidates to act as gas-phase\nprecursors of dust in C-rich AGB envelopes.",
        "author": [
            "S. Massalkhi",
            "M. Ag\u00fandez",
            "J. Cernicharo"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.09461v2.pdf",
        "Categories": [
            [
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.09461v2",
        "arXiv ID": "1906.09461v2"
    },
    {
        "title": "The 6-Ds of Creating AI-Enabled Systems",
        "Published: ": "2022-02-04T15:51:59Z",
        "abstract": "We are entering our tenth year of the current Artificial Intelligence (AI)\nspring, and, as with previous AI hype cycles, the threat of an AI winter looms.\nAI winters occurred because of ineffective approaches towards navigating the\ntechnology valley of death. The 6-D framework provides an end-to-end framework\nto successfully navigate this challenge. The 6-D framework starts with problem\ndecomposition to identify potential AI solutions, and ends with considerations\nfor deployment of AI-enabled systems. Each component of the 6-D framework and a\nprecision medicine use case is described in this paper.",
        "author": [
            "John Piorkowski"
        ],
        "pdfLink": "http://arxiv.org/pdf/2202.03172v1.pdf",
        "Categories": [
            [
                "cs.SE",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2202.03172v1",
        "arXiv ID": "2202.03172v1"
    },
    {
        "title": "Framework for disruptive AI/ML Innovation",
        "Published: ": "2022-04-27T00:22:13Z",
        "abstract": "This framework enables C suite executive leaders to define a business plan\nand manage technological dependencies for building AI/ML Solutions. The\nbusiness plan of this framework provides components and background information\nto define strategy and analyze cost. Furthermore, the business plan represents\nthe fundamentals of AI/ML Innovation and AI/ML Solutions. Therefore, the\nframework provides a menu for managing and investing in AI/ML. Finally, this\nframework is constructed with an interdisciplinary and holistic view of AI/ML\nInnovation and builds on advances in business strategy in harmony with\ntechnological progress for AI/ML. This framework incorporates value chain,\nsupply chain, and ecosystem strategies.",
        "author": [
            "Wim Verleyen",
            "William McGinnis"
        ],
        "pdfLink": "http://arxiv.org/pdf/2204.12641v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2204.12641v1",
        "arXiv ID": "2204.12641v1"
    },
    {
        "title": "Can Artificial Intelligence Transform DevOps?",
        "Published: ": "2022-06-01T04:21:39Z",
        "abstract": "DevOps and Artificial Intelligence (AI) are interconnected with each other.\nDevOps is a business-driven approach to providing quickly delivered quality\nsoftware, and AI is the technology that can be used in the system to enhance\nits functionality. So, DevOps teams can use AI to test, code, release, monitor,\nand improve the system. Through AI, the automation process delivered by DevOps\ncould be improved efficiently. This study aims to explore how AI can transform\nDevOps. The research is useful in terms of facilitating software developers and\nbusinesses to assess the importance of AI in DevOps. The study has practical\nimplications as it elaborates on how AI transforms DevOps and in what way it\ncan support businesses in their business.",
        "author": [
            "Mamdouh Alenezi",
            "Mohammad Zarour",
            "Mohammad Akour"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.00225v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.00225v1",
        "arXiv ID": "2206.00225v1"
    },
    {
        "title": "Mapping the Design Space of Interactions in Human-AI Text Co-creation\n  Tasks",
        "Published: ": "2023-03-11T15:45:47Z",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive text generation\ncapabilities, prompting us to reconsider the future of human-AI co-creation and\nhow humans interact with LLMs. In this paper, we present a spectrum of content\ngeneration tasks and their corresponding human-AI interaction patterns. These\ntasks include: 1) fixed-scope content curation tasks with minimal human-AI\ninteractions, 2) independent creative tasks with precise human-AI interactions,\nand 3) complex and interdependent creative tasks with iterative human-AI\ninteractions. We encourage the generative AI and HCI research communities to\nfocus on the more complex and interdependent tasks, which require greater\nlevels of human involvement.",
        "author": [
            "Zijian Ding",
            "Joel Chan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.06430v2.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.06430v2",
        "arXiv ID": "2303.06430v2"
    },
    {
        "title": "Effect of Confidence and Explanation on Accuracy and Trust Calibration\n  in AI-Assisted Decision Making",
        "Published: ": "2020-01-07T15:33:48Z",
        "abstract": "Today, AI is being increasingly used to help human experts make decisions in\nhigh-stakes scenarios. In these scenarios, full automation is often\nundesirable, not only due to the significance of the outcome, but also because\nhuman experts can draw on their domain knowledge complementary to the model's\nto ensure task success. We refer to these scenarios as AI-assisted decision\nmaking, where the individual strengths of the human and the AI come together to\noptimize the joint decision outcome. A key to their success is to appropriately\n\\textit{calibrate} human trust in the AI on a case-by-case basis; knowing when\nto trust or distrust the AI allows the human expert to appropriately apply\ntheir knowledge, improving decision outcomes in cases where the model is likely\nto perform poorly. This research conducts a case study of AI-assisted decision\nmaking in which humans and AI have comparable performance alone, and explores\nwhether features that reveal case-specific model information can calibrate\ntrust and improve the joint performance of the human and AI. Specifically, we\nstudy the effect of showing confidence score and local explanation for a\nparticular prediction. Through two human experiments, we show that confidence\nscore can help calibrate people's trust in an AI model, but trust calibration\nalone is not sufficient to improve AI-assisted decision making, which may also\ndepend on whether the human can bring in enough unique knowledge to complement\nthe AI's errors. We also highlight the problems in using local explanation for\nAI-assisted decision making scenarios and invite the research community to\nexplore new approaches to explainability for calibrating human trust in AI.",
        "author": [
            "Yunfeng Zhang",
            "Q. Vera Liao",
            "Rachel K. E. Bellamy"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.02114v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.02114v1",
        "arXiv ID": "2001.02114v1"
    },
    {
        "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork",
        "Published: ": "2020-04-27T19:06:28Z",
        "abstract": "AI practitioners typically strive to develop the most accurate systems,\nmaking an implicit assumption that the AI system will function autonomously.\nHowever, in practice, AI systems often are used to provide advice to people in\ndomains ranging from criminal justice and finance to healthcare. In such\nAI-advised decision making, humans and machines form a team, where the human is\nresponsible for making final decisions. But is the most accurate AI the best\nteammate? We argue \"No\" -- predictable performance may be worth a slight\nsacrifice in AI accuracy. Instead, we argue that AI systems should be trained\nin a human-centered manner, directly optimized for team performance. We study\nthis proposal for a specific type of human-AI teaming, where the human overseer\nchooses to either accept the AI recommendation or solve the task themselves. To\noptimize the team performance for this setting we maximize the team's expected\nutility, expressed in terms of the quality of the final decision, cost of\nverifying, and individual accuracies of people and machines. Our experiments\nwith linear and non-linear models on real-world, high-stakes datasets show that\nthe most accuracy AI may not lead to highest team performance and show the\nbenefit of modeling teamwork during training through improvements in expected\nteam utility across datasets, considering parameters such as human skill and\nthe cost of mistakes. We discuss the shortcoming of current optimization\napproaches beyond well-studied loss functions such as log-loss, and encourage\nfuture work on AI optimization problems motivated by human-AI collaboration.",
        "author": [
            "Gagan Bansal",
            "Besmira Nushi",
            "Ece Kamar",
            "Eric Horvitz",
            "Daniel S. Weld"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.13102v3.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.13102v3",
        "arXiv ID": "2004.13102v3"
    },
    {
        "title": "Trustworthy AI: A Computational Perspective",
        "Published: ": "2021-07-12T14:21:46Z",
        "abstract": "In the past few decades, artificial intelligence (AI) technology has\nexperienced swift developments, changing everyone's daily life and profoundly\naltering the course of human society. The intention of developing AI is to\nbenefit humans, by reducing human labor, bringing everyday convenience to human\nlives, and promoting social good. However, recent research and AI applications\nshow that AI can cause unintentional harm to humans, such as making unreliable\ndecisions in safety-critical scenarios or undermining fairness by inadvertently\ndiscriminating against one group. Thus, trustworthy AI has attracted immense\nattention recently, which requires careful consideration to avoid the adverse\neffects that AI may bring to humans, so that humans can fully trust and live in\nharmony with AI technologies.\n  Recent years have witnessed a tremendous amount of research on trustworthy\nAI. In this survey, we present a comprehensive survey of trustworthy AI from a\ncomputational perspective, to help readers understand the latest technologies\nfor achieving trustworthy AI. Trustworthy AI is a large and complex area,\ninvolving various dimensions. In this work, we focus on six of the most crucial\ndimensions in achieving trustworthy AI: (i) Safety & Robustness, (ii)\nNon-discrimination & Fairness, (iii) Explainability, (iv) Privacy, (v)\nAccountability & Auditability, and (vi) Environmental Well-Being. For each\ndimension, we review the recent related technologies according to a taxonomy\nand summarize their applications in real-world systems. We also discuss the\naccordant and conflicting interactions among different dimensions and discuss\npotential aspects for trustworthy AI to investigate in the future.",
        "author": [
            "Haochen Liu",
            "Yiqi Wang",
            "Wenqi Fan",
            "Xiaorui Liu",
            "Yaxin Li",
            "Shaili Jain",
            "Yunhao Liu",
            "Anil K. Jain",
            "Jiliang Tang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.06641v3.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.06641v3",
        "arXiv ID": "2107.06641v3"
    },
    {
        "title": "State of AI Ethics Report (Volume 6, February 2022)",
        "Published: ": "2022-02-12T14:14:32Z",
        "abstract": "This report from the Montreal AI Ethics Institute (MAIEI) covers the most\nsalient progress in research and reporting over the second half of 2021 in the\nfield of AI ethics. Particular emphasis is placed on an \"Analysis of the AI\nEcosystem\", \"Privacy\", \"Bias\", \"Social Media and Problematic Information\", \"AI\nDesign and Governance\", \"Laws and Regulations\", \"Trends\", and other areas\ncovered in the \"Outside the Boxes\" section. The two AI spotlights feature\napplication pieces on \"Constructing and Deconstructing Gender with AI-Generated\nArt\" as well as \"Will an Artificial Intellichef be Cooking Your Next Meal at a\nMichelin Star Restaurant?\". Given MAIEI's mission to democratize AI,\nsubmissions from external collaborators have featured, such as pieces on the\n\"Challenges of AI Development in Vietnam: Funding, Talent and Ethics\" and using\n\"Representation and Imagination for Preventing AI Harms\". The report is a\ncomprehensive overview of what the key issues in the field of AI ethics were in\n2021, what trends are emergent, what gaps exist, and a peek into what to expect\nfrom the field of AI ethics in 2022. It is a resource for researchers and\npractitioners alike in the field to set their research and development agendas\nto make contributions to the field of AI ethics.",
        "author": [
            "Abhishek Gupta",
            "Connor Wright",
            "Marianna Bergamaschi Ganapini",
            "Masa Sweidan",
            "Renjie Butalid"
        ],
        "pdfLink": "http://arxiv.org/pdf/2202.07435v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI",
                "K.4; I.2; A.1"
            ]
        ],
        "Link": "http://arxiv.org/abs/2202.07435v1",
        "arXiv ID": "2202.07435v1"
    },
    {
        "title": "What drives the acceptance of AI technology?: the role of expectations\n  and experiences",
        "Published: ": "2023-06-17T02:47:48Z",
        "abstract": "In recent years, Artificial intelligence products and services have been\noffered potential users as pilots. The acceptance intention towards artificial\nintelligence is greatly influenced by the experience with current AI products\nand services, expectations for AI, and past experiences with ICT technology.\nThis study aims to explore the factors that impact AI acceptance intention and\nunderstand the process of its formation. The analysis results of this study\nreveal that AI experience and past ICT experience affect AI acceptance\nintention in two ways. Through the direct path, higher AI experience and ICT\nexperience are associated with a greater intention to accept AI. Additionally,\nthere is an indirect path where AI experience and ICT experience contribute to\nincreased expectations for AI, and these expectations, in turn, elevate\nacceptance intention. Based on the findings, several recommendations are\nsuggested for companies and public organizations planning to implement\nartificial intelligence in the future. It is crucial to manage the user\nexperience of ICT services and pilot AI products and services to deliver\npositive experiences. It is essential to provide potential AI users with\nspecific information about the features and benefits of AI products and\nservices. This will enable them to develop realistic expectations regarding AI\ntechnology.",
        "author": [
            "Minsang Yi",
            "Hanbyul Choi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.13670v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.13670v1",
        "arXiv ID": "2306.13670v1"
    },
    {
        "title": "The Pace of Artificial Intelligence Innovations: Speed, Talent, and\n  Trial-and-Error",
        "Published: ": "2020-09-03T17:26:04Z",
        "abstract": "Innovations in artificial intelligence (AI) are occurring at speeds faster\nthan ever witnessed before. However, few studies have managed to measure or\ndepict this increasing velocity of innovations in the field of AI. In this\npaper, we combine data on AI from arXiv and Semantic Scholar to explore the\npace of AI innovations from three perspectives: AI publications, AI players,\nand AI updates (trial and error). A research framework and three novel\nindicators, Average Time Interval (ATI), Innovation Speed (IS) and Update Speed\n(US), are proposed to measure the pace of innovations in the field of AI. The\nresults show that: (1) in 2019, more than 3 AI preprints were submitted to\narXiv per hour, over 148 times faster than in 1994. Furthermore, there was one\ndeep learning-related preprint submitted to arXiv every 0.87 hours in 2019,\nover 1,064 times faster than in 1994. (2) For AI players, 5.26 new researchers\nentered into the field of AI each hour in 2019, more than 175 times faster than\nin the 1990s. (3) As for AI updates (trial and error), one updated AI preprint\nwas submitted to arXiv every 41 days, with around 33% of AI preprints having\nbeen updated at least twice in 2019. In addition, as reported in 2019, it took,\non average, only around 0.2 year for AI preprints to receive their first\ncitations, which is 5 times faster than 2000-2007. This swift pace in AI\nillustrates the increase in popularity of AI innovation. The systematic and\nfine-grained analysis of the AI field enabled to portrait the pace of AI\ninnovation and demonstrated that the proposed approach can be adopted to\nunderstand other fast-growing fields such as cancer research and nano science.",
        "author": [
            "Xuli Tang",
            "Xin Li",
            "Ying Ding",
            "Min Song",
            "Yi Bu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2009.01812v1.pdf",
        "Categories": [
            [
                "cs.DL",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2009.01812v1",
        "arXiv ID": "2009.01812v1"
    },
    {
        "title": "Thin accretion disk signatures in dynamical Chern-Simons modified\n  gravity",
        "Published: ": "2009-09-07T15:00:32Z",
        "abstract": "A promising extension of general relativity is Chern-Simons (CS) modified\ngravity, in which the Einstein-Hilbert action is modified by adding a\nparity-violating CS term, which couples to gravity via a scalar field. In this\nwork, we consider the interesting, yet relatively unexplored, dynamical\nformulation of CS modified gravity, where the CS coupling field is treated as a\ndynamical field, endowed with its own stress-energy tensor and evolution\nequation. We consider the possibility of observationally testing dynamical CS\nmodified gravity by using the accretion disk properties around slowly-rotating\nblack holes. The energy flux, temperature distribution, the emission spectrum\nas well as the energy conversion efficiency are obtained, and compared to the\nstandard general relativistic Kerr solution. It is shown that the Kerr black\nhole provide a more efficient engine for the transformation of the energy of\nthe accreting mass into radiation than their slowly-rotating counterparts in CS\nmodified gravity. Specific signatures appear in the electromagnetic spectrum,\nthus leading to the possibility of directly testing CS modified gravity by\nusing astrophysical observations of the emission spectra from accretion disks.",
        "author": [
            "Tiberiu Harko",
            "Zolt\u00e1n Kov\u00e1cs",
            "Francisco S. N. Lobo"
        ],
        "pdfLink": "http://arxiv.org/pdf/0909.1267v2.pdf",
        "Categories": [
            [
                "gr-qc",
                "astro-ph.HE",
                "hep-th"
            ]
        ],
        "Link": "http://arxiv.org/abs/0909.1267v2",
        "arXiv ID": "0909.1267v2"
    },
    {
        "title": "The Pros and Cons of Compressive Sensing for Wideband Signal\n  Acquisition: Noise Folding vs. Dynamic Range",
        "Published: ": "2011-04-26T05:05:29Z",
        "abstract": "Compressive sensing (CS) exploits the sparsity present in many signals to\nreduce the number of measurements needed for digital acquisition. With this\nreduction would come, in theory, commensurate reductions in the size, weight,\npower consumption, and/or monetary cost of both signal sensors and any\nassociated communication links. This paper examines the use of CS in the design\nof a wideband radio receiver in a noisy environment. We formulate the problem\nstatement for such a receiver and establish a reasonable set of requirements\nthat a receiver should meet to be practically useful. We then evaluate the\nperformance of a CS-based receiver in two ways: via a theoretical analysis of\nits expected performance, with a particular emphasis on noise and dynamic\nrange, and via simulations that compare the CS receiver against the performance\nexpected from a conventional implementation. On the one hand, we show that\nCS-based systems that aim to reduce the number of acquired measurements are\nsomewhat sensitive to signal noise, exhibiting a 3dB SNR loss per octave of\nsubsampling, which parallels the classic noise-folding phenomenon. On the other\nhand, we demonstrate that since they sample at a lower rate, CS-based systems\ncan potentially attain a significantly larger dynamic range. Hence, we conclude\nthat while a CS-based system has inherent limitations that do impose some\nrestrictions on its potential applications, it also has attributes that make it\nhighly desirable in a number of important practical settings.",
        "author": [
            "Mark A. Davenport",
            "Jason N. Laska",
            "John R. Treichler",
            "Richard G. Baraniuk"
        ],
        "pdfLink": "http://arxiv.org/pdf/1104.4842v4.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1104.4842v4",
        "arXiv ID": "1104.4842v4"
    },
    {
        "title": "Scan-based Compressed Terahertz Imaging and Real-Time Reconstruction via\n  the Complex-valued Fast Block Sparse Bayesian Learning Algorithm",
        "Published: ": "2013-09-20T23:08:27Z",
        "abstract": "Compressed Sensing based Terahertz imaging (CS-THz) is a computational\nimaging technique. It uses only one THz receiver to accumulate the random\nmodulated image measurements where the original THz image is reconstruct from\nthese measurements using compressed sensing solvers. The advantage of the\nCS-THz is its reduced acquisition time compared with the raster scan mode.\nHowever, when it applied to large-scale two-dimensional (2D) imaging, the\nincreased dimension resulted in both high computational complexity and\nexcessive memory usage. In this paper, we introduced a novel CS-based THz\nimaging system that progressively compressed the THz image column by column.\nTherefore, the CS-THz system could be simplified with a much smaller sized\nmodulator and reduced dimension. In order to utilize the block structure and\nthe correlation of adjacent columns of the THz image, a complex-valued block\nsparse Bayesian learning algorithm was proposed. We conducted systematic\nevaluation of state-of-the-art CS algorithms under the scan based CS-THz\narchitecture. The compression ratios and the choices of the sensing matrices\nwere analyzed in detail using both synthetic and real-life THz images.\nSimulation results showed that both the scan based architecture and the\nproposed recovery algorithm were superior and efficient for large scale CS-THz\napplications.",
        "author": [
            "Benyuan Liu",
            "Hongqi Fan",
            "Zaiqi Lu",
            "Qiang Fu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1309.6195v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1309.6195v1",
        "arXiv ID": "1309.6195v1"
    },
    {
        "title": "Noncommutative Chern-Simons gauge and gravity theories and their\n  geometric Seiberg-Witten map",
        "Published: ": "2014-06-18T21:35:14Z",
        "abstract": "We use a geometric generalization of the Seiberg-Witten map between\nnoncommutative and commutative gauge theories to find the expansion of\nnoncommutative Chern-Simons (CS) theory in any odd dimension $D$ and at first\norder in the noncommutativity parameter $\\theta$. This expansion extends the\nclassical CS theory with higher powers of the curvatures and their derivatives.\n  A simple explanation of the equality between noncommutative and commutative\nCS actions in $D=1$ and $D=3$ is obtained. The $\\theta$ dependent terms are\npresent for $D\\geq 5$ and give a higher derivative theory on commutative space\nreducing to classical CS theory for $\\theta\\to 0$. These terms depend on the\nfield strength and not on the bare gauge potential.\n  In particular, as for the Dirac-Born-Infeld action, these terms vanish in the\nslowly varying field strength approximation: in this case noncommutative and\ncommutative CS actions coincide in any dimension.\n  The Seiberg-Witten map on the $D=5$ noncommutative CS theory is explored in\nmore detail, and we give its second order $\\theta$-expansion for any gauge\ngroup. The example of extended $D=5$ CS gravity, where the gauge group is\n$SU(2,2)$, is treated explicitly.",
        "author": [
            "Paolo Aschieri",
            "Leonardo Castellani"
        ],
        "pdfLink": "http://arxiv.org/pdf/1406.4896v2.pdf",
        "Categories": [
            [
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1406.4896v2",
        "arXiv ID": "1406.4896v2"
    },
    {
        "title": "Characterization of Cs vapor cell coated with octadecyltrichlorosilane\n  using coherent population trapping spectroscopy",
        "Published: ": "2015-05-09T11:49:11Z",
        "abstract": "We report the realization and characterization using coherent population\ntrapping (CPT) spectroscopy of an octadecyltrichlorosilane (OTS)-coated\ncentimeter-scale Cs vapor cell. The dual-structure of the resonance lineshape,\nwith presence of a narrow structure line at the top of a Doppler-broadened\nstructure, is clearly observed. The linewidth of the narrow resonance is\ncompared to the linewidth of an evacuated Cs cell and of a buffer gas Cs cell\nof similar size. The Cs-OTS adsorption energy is measured to be (0.42 $\\pm$\n0.03) eV, leading to a clock frequency shift rate of $2.7\\times10^{-9}/$K in\nfractional unit. A hyperfine population lifetime, $T_1$, and a microwave\ncoherence lifetime, $T_2$, of 1.6 and 0.5 ms are reported, corresponding to\nabout 37 and 12 useful bounces, respectively. Atomic-motion induced Ramsey\nnarrowing of dark resonances is observed in Cs-OTS cells by reducing the\noptical beam diameter. Ramsey CPT fringes are detected using a pulsed CPT\ninterrogation scheme. Potential applications of the Cs-OTS cell to the\ndevelopment of a vapor cell atomic clock are discussed.",
        "author": [
            "Moustafa Abdel Hafiz",
            "Vincent Maurice",
            "Ravinder Chutani",
            "Nicolas Passilly",
            "Christophe Gorecki",
            "St\u00e9phane Gu\u00e9randel",
            "Emeric de Clercq",
            "Rodolphe Boudot"
        ],
        "pdfLink": "http://arxiv.org/pdf/1505.02264v1.pdf",
        "Categories": [
            [
                "physics.atom-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1505.02264v1",
        "arXiv ID": "1505.02264v1"
    },
    {
        "title": "Optimal Arrays for Compressed Sensing in Snapshot-Mode Radio\n  Interferometry",
        "Published: ": "2015-12-19T04:38:34Z",
        "abstract": "Radio interferometry has always faced the problem of incomplete sampling of\nthe Fourier plane. A possible remedy can be found in the promising new theory\nof compressed sensing (CS), which allows for the accurate recovery of sparse\nsignals from sub-Nyquist sampling given certain measurement conditions. We\nprovide an introductory assessment of optimal arrays for CS in snapshot-mode\nradio interferometry, using orthogonal matching pursuit (OMP), a widely used CS\nrecovery algorithm similar in some respects to CLEAN. We focus on centrally\ncondensed (specifically, Gaussian) arrays versus uniform arrays, and the\nprinciple of randomization versus deterministic arrays such as the VLA. The\ntheory of CS is grounded in $a)$ sparse representation of signals and $b)$\nmeasurement matrices of low coherence. We calculate a related quantity, mutual\ncoherence (MC), as a theoretical indicator of arrays' suitability for OMP based\non the recovery error bounds in (Donoho et al. 2006). OMP reconstructions of\nboth point and extended objects are also run from simulated incomplete data.\nOptimal arrays are considered for object recovery through 1) the natural pixel\nrepresentation and 2) the representation by the block discrete cosine transform\n(BDCT). We find that reconstructions of the pixel representation perform best\nwith the uniform random array, while reconstructions of the BDCT representation\nperform best with normal random arrays. Slight randomization to the VLA also\nimproves it hugely for CS with the pixel basis. In the pixel basis, array\ndesign for CS reflects known principles of array design for small numbers of\nantennas, namely of randomness and uniform distribution. Differing results with\nthe BDCT, however, emphasize the importance of studying how sparsifying bases\naffect array design before CS can be optimized.",
        "author": [
            "Clara Fannjiang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1512.06185v1.pdf",
        "Categories": [
            [
                "astro-ph.IM"
            ]
        ],
        "Link": "http://arxiv.org/abs/1512.06185v1",
        "arXiv ID": "1512.06185v1"
    },
    {
        "title": "Role of the intraspecies scattering length in the Efimov scenario with\n  large mass difference",
        "Published: ": "2017-01-27T10:47:13Z",
        "abstract": "We experimentally and theoretically study the effect of the intraspecies\nscattering length onto the heteronuclear Efimov scenario, following up on our\nearlier observation of Efimov resonances in an ultracold Cs-Li mixture for\nnegative [Pires et al., Phys. Rev. Lett. 112, 250404 (2014)] and positive Cs-Cs\nscattering length [Ulmanis et al., Phys. Rev. Lett. 117, 153201 (2016)]. Three\ntheoretical models of increasing complexity are employed to quantify its\ninfluence on the scaling factor and the three-body parameter: a simple\nBorn-Oppenheimer picture, a zero-range theory, and a spinless van der Waals\nmodel. These models are compared to Efimov resonances observed in an ultracold\nmixture of bosonic $^{133}$Cs and fermionic $^6$Li atoms close to two Cs-Li\nFeshbach resonances located at 843 G and 889 G, characterized by different sign\nand magnitude of the Cs-Cs interaction. By changing the sign and magnitude of\nthe intraspecies scattering length different scaling behaviors of the\nthree-body loss rate are identified, in qualitative agreement with theoretical\npredictions. The three-body loss rate is strongly influenced by the\nintraspecies scattering length.",
        "author": [
            "Stephan H\u00e4fner",
            "Juris Ulmanis",
            "Eva D. Kuhnle",
            "Yujun Wang",
            "Chris H. Greene",
            "Matthias Weidem\u00fcller"
        ],
        "pdfLink": "http://arxiv.org/pdf/1701.08007v2.pdf",
        "Categories": [
            [
                "cond-mat.quant-gas"
            ]
        ],
        "Link": "http://arxiv.org/abs/1701.08007v2",
        "arXiv ID": "1701.08007v2"
    },
    {
        "title": "The cosmic microwave background Cold Spot anomaly: the impact of sky\n  masking and the expected contribution from the Integrated Sachs-Wolfe effect",
        "Published: ": "2017-03-23T00:18:09Z",
        "abstract": "We re-analyse the cosmic microwave background (CMB) Cold Spot (CS) anomaly\nwith particular focus on understanding the bias a mask (contaminated by\nGalactic and point sources) may introduce. We measure the coldest spot, found\nby applying the Spherical Mexican Hat Wavelet transform on 100 000 cut-sky\n(masked) and full-sky CMB simulated maps. The CS itself is barely affected by\nthe mask; we estimate a 94 per cent probability that the CS is the full-sky\ntemperature minimum. However, approximately 48 per cent (masked fraction of the\nmask) of full-sky minima are obscured by the mask. Since the observed minima\nare slightly hotter than the full-sky ensemble of minima, a cut-sky analysis\nwould have found the CS to be significant at approximately 2.2 sigma with a\nwavelet angular scale of R = 5 degrees. None the less, comparisons to full-sky\nminima show the CS significance to be only approximately 1.9 sigma and less\nthan 2 sigma for all R. The CS on the last scattering surface may be hotter due\nto the integrated Sachs-Wolfe effect in the line of sight. However, our\nsimulations show that this on average only approximately 10 per cent (about 10\nmicro K but consistent with zero) of the CS temperature profile. This is\nconsistent with Lambda and cold dark matter reconstructions of this effect\nbased on observed line-of-sight voids.",
        "author": [
            "Krishna Naidoo",
            "Aur\u00e9lien Benoit-L\u00e9vy",
            "Ofer Lahav"
        ],
        "pdfLink": "http://arxiv.org/pdf/1703.07894v2.pdf",
        "Categories": [
            [
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1703.07894v2",
        "arXiv ID": "1703.07894v2"
    },
    {
        "title": "Maximum Correntropy Adaptive Filtering Approach for Robust Compressive\n  Sensing Reconstruction",
        "Published: ": "2017-06-10T12:25:29Z",
        "abstract": "Robust compressive sensing(CS) reconstruction has become an attractive\nresearch topic in recent years. Robust CS aims to reconstruct the sparse\nsignals under non-Gaussian(i.e. heavy tailed) noises where traditional CS\nreconstruction algorithms may perform very poorly due to utilizing $l_2$ norm\nof the residual vector in optimization. Most of existing robust CS\nreconstruction algorithms are based on greedy pursuit method or convex\nrelaxation approach. Recently, the adaptive filtering framework has been\nintroduced to deal with the CS reconstruction, which shows desirable\nperformance in both efficiency and reconstruction performance under Gaussian\nnoise. In this paper, we propose an adaptive filtering based robust CS\nreconstruction algorithm, called $l_0$ regularized maximum correntropy\ncriterion($l_0$-MCC) algorithm, which combines the adaptive filtering framework\nand maximum correntropy criterion(MCC). MCC has recently been successfully used\nin adaptive filtering due to its robustness to impulsive non-Gaussian noises\nand low computational complexity. We analyze theoretically the stability of the\nproposed $l_0$-MCC algorithm. A mini-batch based $l_0$-MCC(MB-$l_0$-MCC)\nalgorithm is further developed to speed up the convergence. Comparison with\nexisting robust CS reconstruction algorithms is conducted via simulations,\nshowing that the proposed $l_0$-MCC and MB-$l_0$-MCC can achieve significantly\nbetter performance than other algorithms.",
        "author": [
            "Yicong He",
            "Fei Wang",
            "Shiyuan Wang",
            "Jiuwen Cao",
            "Badong Chen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.03226v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.03226v1",
        "arXiv ID": "1706.03226v1"
    },
    {
        "title": "Faculty citation measures are highly correlated with peer assessment of\n  computer science doctoral programs",
        "Published: ": "2017-08-17T20:46:28Z",
        "abstract": "We study relationship between peer assessment of quality of U.S. Computer\nScience (CS) doctoral programs and objective measures of research strength of\nthose programs. In Fall 2016 we collected Google Scholar citation data for\n4,352 tenure-track CS faculty from 173 U.S. universities. The citations are\nmeasured by the t10 index, which represents the number of citations received by\nthe 10th highest cited paper of a faculty. To measure the research strength of\na CS doctoral program we use 2 groups of citation measures. The first group of\nmeasures averages t10 of faculty in a program. Pearson correlation of those\nmeasures with the peer assessment of U.S. CS doctoral programs published by the\nU.S. News in 2014 is as high as 0.890. The second group of measures counts the\nnumber of well cited faculty in a program. Pearson correlation of those\nmeasures with the peer assessment is as high as 0.909. By combining those two\ngroups of measures using linear regression, we create the Scholar score whose\nPearson correlation with the peer assessment is 0.933 and which explains 87.2%\nof the variance in the peer assessment. Our evaluation shows that the highest\n62 ranked CS doctoral programs by the U.S. News peer assessment are much higher\ncorrelated with the Scholar score than the next 57 ranked programs, indicating\nthe deficiencies of peer assessment of less-known CS programs. Our results also\nindicate that university reputation might have a sizeable impact on peer\nassessment of CS doctoral programs. To promote transparency, the raw data and\nthe codes used in this study are made available to research community at\nhttp://www.dabi.temple.edu/~vucetic/CSranking/.",
        "author": [
            "Slobodan Vucetic",
            "Ashis Kumar Chanda",
            "Shanshan Zhang",
            "Tian Bai",
            "Aniruddha Maiti"
        ],
        "pdfLink": "http://arxiv.org/pdf/1708.05435v1.pdf",
        "Categories": [
            [
                "cs.DL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1708.05435v1",
        "arXiv ID": "1708.05435v1"
    },
    {
        "title": "Circumstellar Light Echo as a Possible Origin of the Polarization of\n  Type IIP Supernovae",
        "Published: ": "2017-09-07T05:44:27Z",
        "abstract": "Type IIP supernovae (SNe IIP) are the most common class of core-collapse SNe.\nThey often show rapid increase of polarization degree in the late phase. This\ntime evolution is generally believed to originate from the emergence of an\ninner aspherical core, while an effect of polarized-scattered echoes by\ncircumstellar (CS) dust around the SN may also substantially contribute to this\npolarization feature. In this study, we examine the effects of the scatted\nechoes on the SN polarization through radiative transfer simulations for\nvarious geometry and amount of CS dust. It has been found that\nasymmetrically-distributed CS dust, which is generally inferred for red\nsupergiants, could reproduce the observed polarization features. We have\napplied our results to SNe 2004dj and 2006ov, deriving the geometry and amount\nof CS dust to explain their observed polarization features in this scenario.\nFor both SNe, the blob-like or bipolar distribution of CS dust rather than the\ndisk-like distribution is favored. The derived dust mass $M_{\\mathrm{dust}}$ in\nthe blob model (the bipolar CS dust model) for SNe 2004dj and 2006ov are $\\sim\n7.5 \\times 10^{-4}$ M$_{\\odot}$ ($\\sim 8.5 \\times10^{-4}$ M$_{\\odot}$) and\n$\\sim 5.2 \\times 10^{-4}$ M$_{\\odot}$ ($\\sim 1.3 \\times10^{-3}$ M$_{\\odot}$),\nrespectively. Even in the case where this process would not play a dominant\nrole in the observed polarization signals, this effect should in principle\ncontribute to it, the strength of which depends on the nature of CS dust.\nTherefore, this effect must be taken into account in discussing\nmulti-dimensional structure of an SN explosion through polarimetric\nobservations.",
        "author": [
            "Takashi Nagao",
            "Keiichi Maeda",
            "Masaomi Tanaka"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.02077v1.pdf",
        "Categories": [
            [
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.02077v1",
        "arXiv ID": "1709.02077v1"
    },
    {
        "title": "A Theoretically Guaranteed Deep Optimization Framework for Robust\n  Compressive Sensing MRI",
        "Published: ": "2018-11-09T05:35:50Z",
        "abstract": "Magnetic Resonance Imaging (MRI) is one of the most dynamic and safe imaging\ntechniques available for clinical applications. However, the rather slow speed\nof MRI acquisitions limits the patient throughput and potential indi cations.\nCompressive Sensing (CS) has proven to be an efficient technique for\naccelerating MRI acquisition. The most widely used CS-MRI model, founded on the\npremise of reconstructing an image from an incompletely filled k-space, leads\nto an ill-posed inverse problem. In the past years, lots of efforts have been\nmade to efficiently optimize the CS-MRI model. Inspired by deep learning\ntechniques, some preliminary works have tried to incorporate deep architectures\ninto CS-MRI process. Unfortunately, the convergence issues (due to the\nexperience-based networks) and the robustness (i.e., lack real-world noise\nmodeling) of these deeply trained optimization methods are still missing. In\nthis work, we develop a new paradigm to integrate designed numerical solvers\nand the data-driven architectures for CS-MRI. By introducing an optimal\ncondition checking mechanism, we can successfully prove the convergence of our\nestablished deep CS-MRI optimization scheme. Furthermore, we explicitly\nformulate the Rician noise distributions within our framework and obtain an\nextended CS-MRI network to handle the real-world nosies in the MRI process.\nExtensive experimental results verify that the proposed paradigm outperforms\nthe existing state-of-the-art techniques both in reconstruction accuracy and\nefficiency as well as robustness to noises in real scene.",
        "author": [
            "Risheng Liu",
            "Yuxi Zhang",
            "Shichao Cheng",
            "Xin Fan",
            "Zhongxuan Luo"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.03782v3.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.03782v3",
        "arXiv ID": "1811.03782v3"
    },
    {
        "title": "Two-Point Statistics of Coherent Structure in Turbulent Flow",
        "Published: ": "2019-08-15T05:19:47Z",
        "abstract": "This review summarizes the coherent structures (CS) based on two-point\ncorrelations and their applications, with a focus on the interpretation of\nstatistic CS and their characteristics. We review studies on this topic, which\nhave attracted attention in recent years, highlighting improvements,\nexpansions, and promising future directions for two-point statistics of CS in\nturbulent flow. The CS is one of typical structures of turbulent flow,\ntransporting energy from large-scale to small-scale structures. To investigate\nthe CS in turbulent flow, a large amount of two-point correlation techniques\nfor CS identification and visualization have been, and are currently being,\nintensively studied by researchers. Two-point correlations with examples and\ncomparisons between different methods are briefly reviewed at first. Some of\nthe uses of correlations in both Eulerian and Lagrangian frames of reference to\nobtain their properties at consecutive spatial locations and time events are\nsurveyed. Two-point correlations, involving space-time correlations, two-point\nspatial correlations, and cross correlations, as essential to theories and\nmodels of turbulence and for the analyses of experimental and numerical\nturbulence data are then discussed. The velocity-vorticity correlation\nstructure (VVCS) as one of the statistical CS based on two-point correlations\nis reiterated in detail. Finally, we summarize the current understanding of\ntwo-point correlations of turbulence and conclude with future issues for this\nfield.",
        "author": [
            "Jun Chen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1908.05422v3.pdf",
        "Categories": [
            [
                "physics.flu-dyn"
            ]
        ],
        "Link": "http://arxiv.org/abs/1908.05422v3",
        "arXiv ID": "1908.05422v3"
    },
    {
        "title": "Multi-Armed Bandit Based Client Scheduling for Federated Learning",
        "Published: ": "2020-07-05T12:32:32Z",
        "abstract": "By exploiting the computing power and local data of distributed clients,\nfederated learning (FL) features ubiquitous properties such as reduction of\ncommunication overhead and preserving data privacy. In each communication round\nof FL, the clients update local models based on their own data and upload their\nlocal updates via wireless channels. However, latency caused by hundreds to\nthousands of communication rounds remains a bottleneck in FL. To minimize the\ntraining latency, this work provides a multi-armed bandit-based framework for\nonline client scheduling (CS) in FL without knowing wireless channel state\ninformation and statistical characteristics of clients. Firstly, we propose a\nCS algorithm based on the upper confidence bound policy (CS-UCB) for ideal\nscenarios where local datasets of clients are independent and identically\ndistributed (i.i.d.) and balanced. An upper bound of the expected performance\nregret of the proposed CS-UCB algorithm is provided, which indicates that the\nregret grows logarithmically over communication rounds. Then, to address\nnon-ideal scenarios with non-i.i.d. and unbalanced properties of local datasets\nand varying availability of clients, we further propose a CS algorithm based on\nthe UCB policy and virtual queue technique (CS-UCB-Q). An upper bound is also\nderived, which shows that the expected performance regret of the proposed\nCS-UCB-Q algorithm can have a sub-linear growth over communication rounds under\ncertain conditions. Besides, the convergence performance of FL training is also\nanalyzed. Finally, simulation results validate the efficiency of the proposed\nalgorithms.",
        "author": [
            "Wenchao Xia",
            "Tony Q. S. Quek",
            "Kun Guo",
            "Wanli Wen",
            "Howard H. Yang",
            "Hongbo Zhu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.02315v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.02315v1",
        "arXiv ID": "2007.02315v1"
    },
    {
        "title": "Carbon stars as standard candles: II. The median J magnitude as a\n  distance indicator",
        "Published: ": "2020-11-23T19:19:39Z",
        "abstract": "We introduce a new distance determination method using carbon-rich asymptotic\ngiant branch stars (CS) as standard candles and the Large and Small Magellanic\nClouds (LMC and SMC) as the fundamental calibrators. We select the samples of\nCS from the ($(J-K_{s})_0$, $J_0$) colour-magnitude diagrams, as, in this\ncombination of filters, CS are bright and easy to identify. We fit the CS\n$J$-band luminosity functions using a Lorentzian distribution modified to allow\nthe distribution to be asymmetric. We use the parameters of the best-fit\ndistribution to determine if the CS luminosity function of a given galaxy\nresembles that of the LMC or SMC. Based on this resemblance, we use either the\nLMC or SMC as the calibrator and estimate the distance to the given galaxy\nusing the median $J$ magnitude ($\\overline{J}$) of the CS samples. We apply\nthis new method to the two Local Group galaxies NGC 6822 and IC 1613. We find\nthat NGC 6822 has an \"LMC-like\" CS luminosity function while IC 1613 is more\n\"SMC-like\". Using the values for the median absolute $J$ magnitude for the LMC\nand SMC found in Paper I we find a distance modulus of $\\mu_{0}=23.54\\pm0.03$\n(stat) for NGC 6822 and $\\mu_{0}=24.34\\pm0.05$ (stat) for IC 1613.",
        "author": [
            "Javiera Parada",
            "Jeremy Heyl",
            "Harvey Richer",
            "Paul Ripoche",
            "Laurie Rousseau-Nepton"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.11681v2.pdf",
        "Categories": [
            [
                "astro-ph.GA",
                "astro-ph.CO",
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.11681v2",
        "arXiv ID": "2011.11681v2"
    },
    {
        "title": "Gender Diversity in Computer Science at a Large Research University",
        "Published: ": "2020-04-28T18:11:44Z",
        "abstract": "With the number of Computer Science (CS) jobs on the rise, there is a greater\nneed for Computer Science graduates than ever. At the same time, most CS\ndepartments across the country are only seeing 25 to 30 percent of female\nstudents in their classes, meaning that we are failing to draw interest from a\nlarge portion of the population. In this work, we explore the gender gap in CS\nat a large public research university, using three data sets that span\nthousands of students across 5 and a half academic years. By combining these\ndata sets, we can explore many issues such as retention as students progress\nthrough the CS major. For example, we find that a large percentage of women\ntaking the Introductory CS1 course for majors do not intend to major in CS,\nwhich contributes to a large increase in the gender gap immediately after CS1.\nThis finding implies that a large part of the retention task is attracting\nthese women to further explore the major. We report findings in three areas of\nresearch in the context of the CS department at our university: the CS\nenvironment, the computing background of our students, and the students'\ngrades. These findings may also be applicable to computing programs at other\nlarge public research universities.",
        "author": [
            "Monica Babes-Vroman",
            "Thu D. Nguyen"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.13760v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "K.3.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.13760v1",
        "arXiv ID": "2004.13760v1"
    },
    {
        "title": "Triggering tearing in a forming current sheet with the mirror\n  instability",
        "Published: ": "2021-12-07T22:05:31Z",
        "abstract": "We study the time-dependent formation and evolution of a current sheet (CS)\nin a magnetized, collisionless, high-beta plasma using hybrid-kinetic\nparticle-in-cell simulations. An initially tearing-stable Harris sheet is\nfrozen into a persistently driven incompressible flow so that its\ncharacteristic thickness gradually decreases in time. As the CS thins, the\nstrength of the reconnecting field increases, and adiabatic invariance in the\ninflowing fluid elements produces a field-biased pressure anisotropy with\nexcess perpendicular pressure. At large plasma beta, this anisotropy excites\nthe mirror instability, which deforms the reconnecting field on ion-Larmor\nscales and dramatically reduces the effective thickness of the CS. Tearing\nmodes whose wavelengths are comparable to that of the mirrors then become\nunstable, triggering reconnection on smaller scales and at earlier times than\nwould have occurred if the thinning CS were to have retained its Harris\nprofile. A novel method for identifying and tracking X-points is introduced,\nyielding X-point separations that are initially intermediate between the\nperpendicular and parallel mirror wavelengths in the upstream plasma. These\nmirror-stimulated tearing modes ultimately grow and merge to produce island\nwidths comparable to the CS thickness, an outcome we verify across a range of\nCS formation timescales and initial CS widths. Our results may find their most\nimmediate application in the tearing disruption of magnetic folds generated by\nturbulent dynamo in weakly collisional, high-beta, astrophysical plasmas.",
        "author": [
            "Himawan W. Winarto",
            "Matthew W. Kunz"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.04018v2.pdf",
        "Categories": [
            [
                "astro-ph.HE",
                "physics.plasm-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.04018v2",
        "arXiv ID": "2112.04018v2"
    },
    {
        "title": "Off-Shell Color-Kinematics Duality for Chern-Simons",
        "Published: ": "2021-12-21T18:57:14Z",
        "abstract": "Many gauge theories possess a hidden duality between color and kinematics in\ntheir on-shell scattering amplitudes. An open problem is to formulate an\noff-shell realization of the duality, thus manifesting a kinematic algebra. We\nshow that 3D Chern-Simons (CS) theory in Lorenz gauge obeys off-shell\ncolor-kinematics duality. This holds both for the gauge field and the BRST\nghosts, and the duality is manifest in the Feynman rules. A kinematic algebra\ncan be formulated through a second-order differential operator (Poisson\nbracket) acting on the off-shell fields, and it corresponds to 3D\nvolume-preserving diffeomorphisms, generated by functions in Lorenz gauge. We\nconsider several admissible double-copy constructions of CS theory with\nYang-Mills theory, a higher-derivative (DF)^2 gauge theory, or CS theory\nitself. To obtain non-vanishing amplitudes, we deform pure CS theory by\nincluding the maximum amount of adjoint matter that respects the on-shell\nduality. This gives a new formulation of an N=4 CS-matter theory, with fields\nof unusual statistics. We argue that the color-stripped tree amplitudes of this\ntheory are equivalent to those of the Gaiotto-Witten N=4 CS theory with\nbi-fundamental matter. We further show that the double copy of the N=4 CS\ntheory with itself corresponds to maximally supersymmetric N=8\nDirac-Born-Infeld theory.",
        "author": [
            "Maor Ben-Shahar",
            "Henrik Johansson"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.11452v3.pdf",
        "Categories": [
            [
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.11452v3",
        "arXiv ID": "2112.11452v3"
    },
    {
        "title": "Uformer-ICS: A Specialized U-Shaped Transformer for Image Compressive\n  Sensing",
        "Published: ": "2022-09-05T04:52:12Z",
        "abstract": "Recently, several studies have applied deep convolutional neural networks\n(CNNs) in image compressive sensing (CS) tasks to improve reconstruction\nquality. However, convolutional layers generally have a small receptive field;\ntherefore, capturing long-range pixel correlations using CNNs is challenging,\nwhich limits their reconstruction performance in image CS tasks. Considering\nthis limitation, we propose a U-shaped transformer for image CS tasks, called\nthe Uformer-ICS. We develop a projection-based transformer block by integrating\nthe prior projection knowledge of CS into the original transformer blocks, and\nthen build a symmetrical reconstruction model using the projection-based\ntransformer blocks and residual convolutional blocks. Compared with previous\nCNN-based CS methods that can only exploit local image features, the proposed\nreconstruction model can simultaneously utilize the local features and\nlong-range dependencies of an image, and the prior projection knowledge of the\nCS theory. Additionally, we design an adaptive sampling model that can\nadaptively sample image blocks based on block sparsity, which can ensure that\nthe compressed results retain the maximum possible information of the original\nimage under a fixed sampling ratio. The proposed Uformer-ICS is an end-to-end\nframework that simultaneously learns the sampling and reconstruction processes.\nExperimental results demonstrate that it achieves significantly better\nreconstruction performance than existing state-of-the-art deep learning-based\nCS methods.",
        "author": [
            "Kuiyuan Zhang",
            "Zhongyun Hua",
            "Yuanman Li",
            "Yushu Zhang",
            "Yicong Zhou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.01763v1.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CR",
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.01763v1",
        "arXiv ID": "2209.01763v1"
    },
    {
        "title": "Complement Sparsification: Low-Overhead Model Pruning for Federated\n  Learning",
        "Published: ": "2023-03-10T23:07:02Z",
        "abstract": "Federated Learning (FL) is a privacy-preserving distributed deep learning\nparadigm that involves substantial communication and computation effort, which\nis a problem for resource-constrained mobile and IoT devices. Model\npruning/sparsification develops sparse models that could solve this problem,\nbut existing sparsification solutions cannot satisfy at the same time the\nrequirements for low bidirectional communication overhead between the server\nand the clients, low computation overhead at the clients, and good model\naccuracy, under the FL assumption that the server does not have access to raw\ndata to fine-tune the pruned models. We propose Complement Sparsification (CS),\na pruning mechanism that satisfies all these requirements through a\ncomplementary and collaborative pruning done at the server and the clients. At\neach round, CS creates a global sparse model that contains the weights that\ncapture the general data distribution of all clients, while the clients create\nlocal sparse models with the weights pruned from the global model to capture\nthe local trends. For improved model performance, these two types of\ncomplementary sparse models are aggregated into a dense model in each round,\nwhich is subsequently pruned in an iterative process. CS requires little\ncomputation overhead on the top of vanilla FL for both the server and the\nclients. We demonstrate that CS is an approximation of vanilla FL and, thus,\nits models perform well. We evaluate CS experimentally with two popular FL\nbenchmark datasets. CS achieves substantial reduction in bidirectional\ncommunication, while achieving performance comparable with vanilla FL. In\naddition, CS outperforms baseline pruning mechanisms for FL.",
        "author": [
            "Xiaopeng Jiang",
            "Cristian Borcea"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.06237v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.06237v1",
        "arXiv ID": "2303.06237v1"
    },
    {
        "title": "Cuing Without Sharing: A Federated Cued Speech Recognition Framework via\n  Mutual Knowledge Distillation",
        "Published: ": "2023-08-07T09:26:36Z",
        "abstract": "Cued Speech (CS) is a visual coding tool to encode spoken languages at the\nphonetic level, which combines lip-reading and hand gestures to effectively\nassist communication among people with hearing impairments. The Automatic CS\nRecognition (ACSR) task aims to recognize CS videos into linguistic texts,\nwhich involves both lips and hands as two distinct modalities conveying\ncomplementary information. However, the traditional centralized training\napproach poses potential privacy risks due to the use of facial and gesture\nvideos in CS data. To address this issue, we propose a new Federated Cued\nSpeech Recognition (FedCSR) framework to train an ACSR model over the\ndecentralized CS data without sharing private information. In particular, a\nmutual knowledge distillation method is proposed to maintain cross-modal\nsemantic consistency of the Non-IID CS data, which ensures learning a unified\nfeature space for both linguistic and visual information. On the server side, a\nglobally shared linguistic model is trained to capture the long-term\ndependencies in the text sentences, which is aligned with the visual\ninformation from the local clients via visual-to-linguistic distillation. On\nthe client side, the visual model of each client is trained with its own local\ndata, assisted by linguistic-to-visual distillation treating the linguistic\nmodel as the teacher. To the best of our knowledge, this is the first approach\nto consider the federated ACSR task for privacy protection. Experimental\nresults on the Chinese CS dataset with multiple cuers demonstrate that our\napproach outperforms both mainstream federated learning baselines and existing\ncentralized state-of-the-art ACSR methods, achieving 9.7% performance\nimprovement for character error rate (CER) and 15.0% for word error rate (WER).",
        "author": [
            "Yuxuan Zhang",
            "Lei Liu",
            "Li Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.03432v1.pdf",
        "Categories": [
            [
                "cs.MM"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.03432v1",
        "arXiv ID": "2308.03432v1"
    },
    {
        "title": "Three-dimensional simulation of thermodynamics on confined turbulence in\n  a large-scale CME-flare current sheet",
        "Published: ": "2023-08-18T12:12:57Z",
        "abstract": "Turbulence plays a key role for forming the complex geometry of the\nlarge-scale current sheet (CS) and fast energy release in a solar eruption. In\nthis paper, we present full 3D high-resolution simulations for the process of a\nmoderate Coronal Mass Ejection (CME) and the thermodynamical evolution of the\nhighly confined CS. Copious elongated blobs are generated due to tearing and\nplasmoid instabilities giving rise to a higher reconnection rate and undergo\nthe splitting, merging and kinking processes in a more complex way in 3D. A\ndetailed thermodynamical analysis shows that the CS is mainly heated by\nadiabatic and numerical viscous terms, and thermal conduction is the dominant\nfactor that balances the energy inside the CS. Accordingly, the temperature of\nthe CS reaches to a maximum of about 20 MK and the range of temperatures is\nrelatively narrow. From the face-on view in the synthetic Atmospheric Imaging\nAssembly 131 $\\mathring{A}$, the downflowing structures with similar morphology\nto supra-arcade downflows are mainly located between the post-flare loops and\nloop-top, while moving blobs can extend spikes higher above the loop-top. The\ndownward-moving plasmoids can keep the twisted magnetic field configuration\nuntil the annihilation at the flare loop-top, indicating that plasmoid\nreconnection dominates in the lower CS. Meanwhile, the upward-moving ones turn\ninto turbulent structures before arriving at the bottom of the CME, implying\nthat turbulent reconnection dominates in the upper CS. The spatial\ndistributions of the turbulent energy and anisotropy are addressed, which show\na significant variation in the spectra with height.",
        "author": [
            "Jing Ye",
            "John C. Raymond",
            "Zhixing Mei",
            "Qiangwei Cai",
            "Yuhao Chen",
            "Yan Li",
            "Jun Lin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.09496v1.pdf",
        "Categories": [
            [
                "astro-ph.SR",
                "physics.space-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.09496v1",
        "arXiv ID": "2308.09496v1"
    },
    {
        "title": "Who Goes First? Influences of Human-AI Workflow on Decision Making in\n  Clinical Imaging",
        "Published: ": "2022-05-19T16:59:25Z",
        "abstract": "Details of the designs and mechanisms in support of human-AI collaboration\nmust be considered in the real-world fielding of AI technologies. A critical\naspect of interaction design for AI-assisted human decision making are policies\nabout the display and sequencing of AI inferences within larger decision-making\nworkflows. We have a poor understanding of the influences of making AI\ninferences available before versus after human review of a diagnostic task at\nhand. We explore the effects of providing AI assistance at the start of a\ndiagnostic session in radiology versus after the radiologist has made a\nprovisional decision. We conducted a user study where 19 veterinary\nradiologists identified radiographic findings present in patients' X-ray\nimages, with the aid of an AI tool. We employed two workflow configurations to\nanalyze (i) anchoring effects, (ii) human-AI team diagnostic performance and\nagreement, (iii) time spent and confidence in decision making, and (iv)\nperceived usefulness of the AI. We found that participants who are asked to\nregister provisional responses in advance of reviewing AI inferences are less\nlikely to agree with the AI regardless of whether the advice is accurate and,\nin instances of disagreement with the AI, are less likely to seek the second\nopinion of a colleague. These participants also reported the AI advice to be\nless useful. Surprisingly, requiring provisional decisions on cases in advance\nof the display of AI inferences did not lengthen the time participants spent on\nthe task. The study provides generalizable and actionable insights for the\ndeployment of clinical AI tools in human-in-the-loop systems and introduces a\nmethodology for studying alternative designs for human-AI collaboration. We\nmake our experimental platform available as open source to facilitate future\nresearch on the influence of alternate designs on human-AI workflows.",
        "author": [
            "Riccardo Fogliato",
            "Shreya Chappidi",
            "Matthew Lungren",
            "Michael Fitzke",
            "Mark Parkinson",
            "Diane Wilson",
            "Paul Fisher",
            "Eric Horvitz",
            "Kori Inkpen",
            "Besmira Nushi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.09696v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.09696v1",
        "arXiv ID": "2205.09696v1"
    },
    {
        "title": "Actionable Guidance for High-Consequence AI Risk Management: Towards\n  Standards Addressing AI Catastrophic Risks",
        "Published: ": "2022-06-17T18:40:41Z",
        "abstract": "Artificial intelligence (AI) systems can provide many beneficial capabilities\nbut also risks of adverse events. Some AI systems could present risks of events\nwith very high or catastrophic consequences at societal scale. The US National\nInstitute of Standards and Technology (NIST) has been developing the NIST\nArtificial Intelligence Risk Management Framework (AI RMF) as voluntary\nguidance on AI risk assessment and management for AI developers and others. For\naddressing risks of events with catastrophic consequences, NIST indicated a\nneed to translate from high level principles to actionable risk management\nguidance.\n  In this document, we provide detailed actionable-guidance recommendations\nfocused on identifying and managing risks of events with very high or\ncatastrophic consequences, intended as a risk management practices resource for\nNIST for AI RMF version 1.0 (released in January 2023), or for AI RMF users, or\nfor other AI risk management guidance and standards as appropriate. We also\nprovide our methodology for our recommendations.\n  We provide actionable-guidance recommendations for AI RMF 1.0 on: identifying\nrisks from potential unintended uses and misuses of AI systems; including\ncatastrophic-risk factors within the scope of risk assessments and impact\nassessments; identifying and mitigating human rights harms; and reporting\ninformation on AI risk factors including catastrophic-risk factors.\n  In addition, we provide recommendations on additional issues for a roadmap\nfor later versions of the AI RMF or supplementary publications. These include:\nproviding an AI RMF Profile with supplementary guidance for cutting-edge\nincreasingly multi-purpose or general-purpose AI.\n  We aim for this work to be a concrete risk-management practices contribution,\nand to stimulate constructive dialogue on how to address catastrophic risks and\nassociated issues in AI standards.",
        "author": [
            "Anthony M. Barrett",
            "Dan Hendrycks",
            "Jessica Newman",
            "Brandie Nonnecke"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.08966v3.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.08966v3",
        "arXiv ID": "2206.08966v3"
    },
    {
        "title": "Should ChatGPT and Bard Share Revenue with Their Data Providers? A New\n  Business Model for the AI Era",
        "Published: ": "2023-05-04T05:21:09Z",
        "abstract": "With various AI tools such as ChatGPT becoming increasingly popular, we are\nentering a true AI era. We can foresee that exceptional AI tools will soon reap\nconsiderable profits. A crucial question arise: should AI tools share revenue\nwith their training data providers in additional to traditional stakeholders\nand shareholders? The answer is Yes. Large AI tools, such as large language\nmodels, always require more and better quality data to continuously improve,\nbut current copyright laws limit their access to various types of data. Sharing\nrevenue between AI tools and their data providers could transform the current\nhostile zero-sum game relationship between AI tools and a majority of\ncopyrighted data owners into a collaborative and mutually beneficial one, which\nis necessary to facilitate the development of a virtuous cycle among AI tools,\ntheir users and data providers that drives forward AI technology and builds a\nhealthy AI ecosystem. However, current revenue-sharing business models do not\nwork for AI tools in the forthcoming AI era, since the most widely used metrics\nfor website-based traffic and action, such as clicks, will be replaced by new\nmetrics such as prompts and cost per prompt for generative AI tools. A\ncompletely new revenue-sharing business model, which must be almost independent\nof AI tools and be easily explained to data providers, needs to establish a\nprompt-based scoring system to measure data engagement of each data provider.\nThis paper systematically discusses how to build such a scoring system for all\ndata providers for AI tools based on classification and content similarity\nmodels, and outlines the requirements for AI tools or third parties to build\nit. Sharing revenue with data providers using such a scoring system would\nencourage more data owners to participate in the revenue-sharing program. This\nwill be a utilitarian AI era where all parties benefit.",
        "author": [
            "Dong Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.02555v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.02555v2",
        "arXiv ID": "2305.02555v2"
    },
    {
        "title": "Bootstrapping Developmental AIs: From Simple Competences to Intelligent\n  Human-Compatible AIs",
        "Published: ": "2023-08-08T21:14:21Z",
        "abstract": "Mainstream approaches for creating AIs include deep learning and generative\napproaches (e.g., large language models) and manually constructed symbolic\napproaches. These approaches have led to valuable AI systems and impressive\nfeats, but they can create risks when their operations affect people. Manually\nconstructed AIs are brittle even in circumscribed domains. Generative AIs make\nstrange mistakes and do not notice them. These AIs cannot be instructed easily,\nfail to use common sense, and lack curiosity. They lack social alignment.\nDevelopmental AI is a bootstrapping approach that uses embodied AIs. The AIs\nstart with innate competences and learn by interacting with their environment.\nThe AIs develop abilities in small steps along a bio-inspired trajectory.\nDevelopmental AIs have shown capabilities for multimodal perception, object\nrecognition, and manipulation. Powerful computational models for hierarchical\nplanning, abstraction discovery, curiosity, and language acquisition exist but\nneed to be adapted to an embodied approach. This research aims to produce AIs\nthat learn to communicate, establish common ground, read critically, consider\nthe provenance of information, test hypotheses, and collaborate. However,\ndevelopmental AI systems have not yet passed the abilities of young children.\nThey need to bridge competence gaps involving nonverbal communication, speech,\nreading, and writing. Scaling to practical applications also requires reducing\nhardware costs. This position paper lays out prospects, gaps, and challenges\nfor this approach. The ambition is to create data-rich experientially based\nfoundation models for human-compatible, resilient, and trustworthy AIs. The AIs\nwould learn, share what they learn, and collaborate to achieve high standards.\nThe approach would make AI technology more democratic and enable more people to\ntrain, test, build on, and replicate AIs.",
        "author": [
            "Mark Stefik",
            "Robert Price"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.04586v13.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.04586v13",
        "arXiv ID": "2308.04586v13"
    },
    {
        "title": "Modeling Progress in AI",
        "Published: ": "2015-12-18T04:17:39Z",
        "abstract": "Participants in recent discussions of AI-related issues ranging from\nintelligence explosion to technological unemployment have made diverse claims\nabout the nature, pace, and drivers of progress in AI. However, these theories\nare rarely specified in enough detail to enable systematic evaluation of their\nassumptions or to extrapolate progress quantitatively, as is often done with\nsome success in other technological domains. After reviewing relevant\nliteratures and justifying the need for more rigorous modeling of AI progress,\nthis paper contributes to that research program by suggesting ways to account\nfor the relationship between hardware speed increases and algorithmic\nimprovements in AI, the role of human inputs in enabling AI capabilities, and\nthe relationships between different sub-fields of AI. It then outlines ways of\ntailoring AI progress models to generate insights on the specific issue of\ntechnological unemployment, and outlines future directions for research on AI\nprogress.",
        "author": [
            "Miles Brundage"
        ],
        "pdfLink": "http://arxiv.org/pdf/1512.05849v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1512.05849v1",
        "arXiv ID": "1512.05849v1"
    },
    {
        "title": "Perspectives for Evaluating Conversational AI",
        "Published: ": "2017-09-14T12:37:08Z",
        "abstract": "Conversational AI systems are becoming famous in day to day lives. In this\npaper, we are trying to address the following key question: To identify whether\ndesign, as well as development efforts for search oriented conversational AI\nare successful or not.It is tricky to define 'success' in the case of\nconversational AI and equally tricky part is to use appropriate metrics for the\nevaluation of conversational AI. We propose four different perspectives namely\nuser experience, information retrieval, linguistic and artificial intelligence\nfor the evaluation of conversational AI systems. Additionally, background\ndetails of conversational AI systems are provided including desirable\ncharacteristics of personal assistants, differences between chatbot and an AI\nbased personal assistant. An importance of personalization and how it can be\nachieved is explained in detail. Current challenges in the development of an\nideal conversational AI (personal assistant) are also highlighted along with\nguidelines for achieving personalized experience for users.",
        "author": [
            "Mahipal Jadeja",
            "Neelanshi Varia"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.04734v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.04734v1",
        "arXiv ID": "1709.04734v1"
    },
    {
        "title": "Distinguished Capabilities of Artificial Intelligence Wireless\n  Communication Systems",
        "Published: ": "2018-09-15T08:30:39Z",
        "abstract": "With the great success of artificial intelligence (AI) technologies in\npattern recognitions and signal processing, it is interesting to introduce AI\ntechnologies into wireless communication systems. Currently, most of studies\nare focused on applying AI technologies for solving old problems, e.g.,\nwireless location accuracy and resource allocation optimization in wireless\ncommunication systems. However, It is important to distinguish new capabilities\ncreated by AI technologies and rethink wireless communication systems based on\nAI running schemes. Compared with conventional capabilities of wireless\ncommunication systems, three distinguished capabilities, i.e., the cognitive,\nlearning and proactive capabilities are proposed for future AI wireless\ncommunication systems. Moreover, an intelligent vehicular communication system\nis configured to validate the cognitive capability based on AI clustering\nalgorithm. Considering the revolutionary impact of AI technologies on the data,\ntransmission and protocol architecture of wireless communication systems, the\nfuture challenges of AI wireless communication systems are analyzed. Driven by\nnew distinguished capabilities of AI wireless communication systems, the new\nwireless communication theory and functions would indeed emerge in the next\nround of the wireless communications revolution.",
        "author": [
            "Xiaohu Ge"
        ],
        "pdfLink": "http://arxiv.org/pdf/1809.05673v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1809.05673v1",
        "arXiv ID": "1809.05673v1"
    },
    {
        "title": "Federated AI lets a team imagine together: Federated Learning of GANs",
        "Published: ": "2019-06-09T08:44:23Z",
        "abstract": "Envisioning a new imaginative idea together is a popular human need.\nImagining together as a team can often lead to breakthrough ideas, but the\ncollaboration effort can also be challenging, especially when the team members\nare separated by time and space. What if there is a AI that can assist the team\nto collaboratively envision new ideas?. Is it possible to develop a working\nmodel of such an AI? This paper aims to design such an intelligence. This paper\nproposes a approach to design a creative and collaborative intelligence by\nemploying a form of distributed machine learning approach called Federated\nLearning along with fusion on Generative Adversarial Networks, GAN. This\ncollaborative creative AI presents a new paradigm in AI, one that lets a team\nof two or more to come together to imagine and envision ideas that synergies\nwell with interests of all members of the team. In short, this paper explores\nthe design of a novel type of AI paradigm, called Federated AI Imagination, one\nthat lets geographically distributed teams to collaboratively imagine.",
        "author": [
            "Rajagopal. A",
            "Nirmala. V"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.03595v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.DC",
                "cs.MA",
                "I.2.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.03595v1",
        "arXiv ID": "1906.03595v1"
    },
    {
        "title": "Challenges of Human-Aware AI Systems",
        "Published: ": "2019-10-15T22:34:50Z",
        "abstract": "From its inception, AI has had a rather ambivalent relationship to\nhumans---swinging between their augmentation and replacement. Now, as AI\ntechnologies enter our everyday lives at an ever increasing pace, there is a\ngreater need for AI systems to work synergistically with humans. To do this\neffectively, AI systems must pay more attention to aspects of intelligence that\nhelped humans work with each other---including social intelligence. I will\ndiscuss the research challenges in designing such human-aware AI systems,\nincluding modeling the mental states of humans in the loop, recognizing their\ndesires and intentions, providing proactive support, exhibiting explicable\nbehavior, giving cogent explanations on demand, and engendering trust. I will\nsurvey the progress made so far on these challenges, and highlight some\npromising directions. I will also touch on the additional ethical quandaries\nthat such systems pose. I will end by arguing that the quest for human-aware AI\nsystems broadens the scope of AI enterprise, necessitates and facilitates true\ninter-disciplinary collaborations, and can go a long way towards increasing\npublic acceptance of AI technologies.",
        "author": [
            "Subbarao Kambhampati"
        ],
        "pdfLink": "http://arxiv.org/pdf/1910.07089v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1910.07089v1",
        "arXiv ID": "1910.07089v1"
    },
    {
        "title": "Ten AI Stepping Stones for Cybersecurity",
        "Published: ": "2019-12-14T09:54:36Z",
        "abstract": "With the turmoil in cybersecurity and the mind-blowing advances in AI, it is\nonly natural that cybersecurity practitioners consider further employing\nlearning techniques to help secure their organizations and improve the\nefficiency of their security operation centers. But with great fears come great\nopportunities for both the good and the evil, and a myriad of bad deals. This\npaper discusses ten issues in cybersecurity that hopefully will make it easier\nfor practitioners to ask detailed questions about what they want from an AI\nsystem in their cybersecurity operations. We draw on the state of the art to\nprovide factual arguments for a discussion on well-established AI in\ncybersecurity issues, including the current scope of AI and its application to\ncybersecurity, the impact of privacy concerns on the cybersecurity data that\ncan be collected and shared externally to the organization, how an AI decision\ncan be explained to the person running the operations center, and the\nimplications of the adversarial nature of cybersecurity in the learning\ntechniques. We then discuss the use of AI by attackers on a level playing field\nincluding several issues in an AI battlefield, and an AI perspective on the old\ncat-and-mouse game including how the adversary may assess your AI power.",
        "author": [
            "Ricardo Morla"
        ],
        "pdfLink": "http://arxiv.org/pdf/1912.06817v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1912.06817v1",
        "arXiv ID": "1912.06817v1"
    },
    {
        "title": "Time for AI (Ethics) Maturity Model Is Now",
        "Published: ": "2021-01-29T17:37:44Z",
        "abstract": "There appears to be a common agreement that ethical concerns are of high\nimportance when it comes to systems equipped with some sort of Artificial\nIntelligence (AI). Demands for ethical AI are declared from all directions. As\na response, in recent years, public bodies, governments, and universities have\nrushed in to provide a set of principles to be considered when AI based systems\nare designed and used. We have learned, however, that high-level principles do\nnot turn easily into actionable advice for practitioners. Hence, also companies\nare publishing their own ethical guidelines to guide their AI development. This\npaper argues that AI software is still software and needs to be approached from\nthe software development perspective. The software engineering paradigm has\nintroduced maturity model thinking, which provides a roadmap for companies to\nimprove their performance from the selected viewpoints known as the key\ncapabilities. We want to voice out a call for action for the development of a\nmaturity model for AI software. We wish to discuss whether the focus should be\non AI ethics or, more broadly, the quality of an AI system, called a maturity\nmodel for the development of AI systems.",
        "author": [
            "Ville Vakkuri",
            "Marianna Jantunen",
            "Erika Halme",
            "Kai-Kristian Kemell",
            "Anh Nguyen-Duc",
            "Tommi Mikkonen",
            "Pekka Abrahamsson"
        ],
        "pdfLink": "http://arxiv.org/pdf/2101.12701v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2101.12701v1",
        "arXiv ID": "2101.12701v1"
    },
    {
        "title": "AI Ethics for Systemic Issues: A Structural Approach",
        "Published: ": "2019-11-08T12:31:49Z",
        "abstract": "The debate on AI ethics largely focuses on technical improvements and\nstronger regulation to prevent accidents or misuse of AI, with solutions\nrelying on holding individual actors accountable for responsible AI\ndevelopment. While useful and necessary, we argue that this \"agency\" approach\ndisregards more indirect and complex risks resulting from AI's interaction with\nthe socio-economic and political context. This paper calls for a \"structural\"\napproach to assessing AI's effects in order to understand and prevent such\nsystemic risks where no individual can be held accountable for the broader\nnegative impacts. This is particularly relevant for AI applied to systemic\nissues such as climate change and food security which require political\nsolutions and global cooperation. To properly address the wide range of AI\nrisks and ensure 'AI for social good', agency-focused policies must be\ncomplemented by policies informed by a structural approach.",
        "author": [
            "Agnes Schim van der Loeff",
            "Iggy Bassi",
            "Sachin Kapila",
            "Jevgenij Gamper"
        ],
        "pdfLink": "http://arxiv.org/pdf/1911.03216v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1911.03216v1",
        "arXiv ID": "1911.03216v1"
    },
    {
        "title": "Could regulating the creators deliver trustworthy AI?",
        "Published: ": "2020-06-26T01:32:53Z",
        "abstract": "Is a new regulated profession, such as Artificial Intelligence (AI) Architect\nwho is responsible and accountable for AI outputs necessary to ensure\ntrustworthy AI? AI is becoming all pervasive and is often deployed in everyday\ntechnologies, devices and services without our knowledge. There is heightened\nawareness of AI in recent years which has brought with it fear. This fear is\ncompounded by the inability to point to a trustworthy source of AI, however\neven the term \"trustworthy AI\" itself is troublesome. Some consider trustworthy\nAI to be that which complies with relevant laws, while others point to the\nrequirement to comply with ethics and standards (whether in addition to or in\nisolation of the law). This immediately raises questions of whose ethics and\nwhich standards should be applied and whether these are sufficient to produce\ntrustworthy AI in any event.",
        "author": [
            "Labhaoise Ni Fhaolain",
            "Andrew Hines"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.14750v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.14750v1",
        "arXiv ID": "2006.14750v1"
    },
    {
        "title": "The corruptive force of AI-generated advice",
        "Published: ": "2021-02-15T13:15:12Z",
        "abstract": "Artificial Intelligence (AI) is increasingly becoming a trusted advisor in\npeople's lives. A new concern arises if AI persuades people to break ethical\nrules for profit. Employing a large-scale behavioural experiment (N = 1,572),\nwe test whether AI-generated advice can corrupt people. We further test whether\ntransparency about AI presence, a commonly proposed policy, mitigates potential\nharm of AI-generated advice. Using the Natural Language Processing algorithm,\nGPT-2, we generated honesty-promoting and dishonesty-promoting advice.\nParticipants read one type of advice before engaging in a task in which they\ncould lie for profit. Testing human behaviour in interaction with actual AI\noutputs, we provide first behavioural insights into the role of AI as an\nadvisor. Results reveal that AI-generated advice corrupts people, even when\nthey know the source of the advice. In fact, AI's corrupting force is as strong\nas humans'.",
        "author": [
            "Margarita Leib",
            "Nils C. K\u00f6bis",
            "Rainer Michael Rilke",
            "Marloes Hagens",
            "Bernd Irlenbusch"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.07536v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "econ.GN",
                "q-fin.EC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.07536v1",
        "arXiv ID": "2102.07536v1"
    },
    {
        "title": "HPC AI500: Representative, Repeatable and Simple HPC AI Benchmarking",
        "Published: ": "2021-02-25T13:40:17Z",
        "abstract": "Recent years witness a trend of applying large-scale distributed deep\nlearning algorithms (HPC AI) in both business and scientific computing areas,\nwhose goal is to speed up the training time to achieve a state-of-the-art\nquality. The HPC AI benchmarks accelerate the process. Unfortunately,\nbenchmarking HPC AI systems at scale raises serious challenges. This paper\npresents a representative, repeatable and simple HPC AI benchmarking\nmethodology. Among the seventeen AI workloads of AIBench Training -- by far the\nmost comprehensive AI Training benchmarks suite -- we choose two representative\nand repeatable AI workloads. The selected HPC AI benchmarks include both\nbusiness and scientific computing: Image Classification and Extreme Weather\nAnalytics. To rank HPC AI systems, we present a new metric named Valid FLOPS,\nemphasizing both throughput performance and a target quality. The\nspecification, source code, datasets, and HPC AI500 ranking numbers are\npublicly available from \\url{https://www.benchcouncil.org/HPCAI500/}.",
        "author": [
            "Zihan Jiang",
            "Wanling Gao",
            "Fei Tang",
            "Xingwang Xiong",
            "Lei Wang",
            "Chuanxin Lan",
            "Chunjie Luo",
            "Hongxiao Li",
            "Jianfeng Zhan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.12848v1.pdf",
        "Categories": [
            [
                "cs.PF"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.12848v1",
        "arXiv ID": "2102.12848v1"
    },
    {
        "title": "Systematic Mapping Study on the Machine Learning Lifecycle",
        "Published: ": "2021-03-11T11:44:23Z",
        "abstract": "The development of artificial intelligence (AI) has made various industries\neager to explore the benefits of AI. There is an increasing amount of research\nsurrounding AI, most of which is centred on the development of new AI\nalgorithms and techniques. However, the advent of AI is bringing an increasing\nset of practical problems related to AI model lifecycle management that need to\nbe investigated. We address this gap by conducting a systematic mapping study\non the lifecycle of AI model. Through quantitative research, we provide an\noverview of the field, identify research opportunities, and provide suggestions\nfor future research. Our study yields 405 publications published from 2005 to\n2020, mapped in 5 different main research topics, and 31 sub-topics. We observe\nthat only a minority of publications focus on data management and model\nproduction problems, and that more studies should address the AI lifecycle from\na holistic perspective.",
        "author": [
            "Yuanhao Xie",
            "Lu\u00eds Cruz",
            "Petra Heck",
            "Jan S. Rellermeyer"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.10248v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.SE",
                "68T01 (Primary)",
                "D.2.9; I.2.5"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.10248v1",
        "arXiv ID": "2103.10248v1"
    },
    {
        "title": "An interdisciplinary conceptual study of Artificial Intelligence (AI)\n  for helping benefit-risk assessment practices: Towards a comprehensive\n  qualification matrix of AI programs and devices (pre-print 2020)",
        "Published: ": "2021-05-07T12:01:31Z",
        "abstract": "This paper proposes a comprehensive analysis of existing concepts coming from\ndifferent disciplines tackling the notion of intelligence, namely psychology\nand engineering, and from disciplines aiming to regulate AI innovations, namely\nAI ethics and law. The aim is to identify shared notions or discrepancies to\nconsider for qualifying AI systems. Relevant concepts are integrated into a\nmatrix intended to help defining more precisely when and how computing tools\n(programs or devices) may be qualified as AI while highlighting critical\nfeatures to serve a specific technical, ethical and legal assessment of\nchallenges in AI development. Some adaptations of existing notions of AI\ncharacteristics are proposed. The matrix is a risk-based conceptual model\ndesigned to allow an empirical, flexible and scalable qualification of AI\ntechnologies in the perspective of benefit-risk assessment practices,\ntechnological monitoring and regulatory compliance: it offers a structured\nreflection tool for stakeholders in AI development that are engaged in\nresponsible research and innovation.Pre-print version (achieved on May 2020)",
        "author": [
            "Gauthier Chassang",
            "Mogens Thomsen",
            "Pierre Rumeau",
            "Florence S\u00e8des",
            "Alejandra Delfin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.03192v1.pdf",
        "Categories": [
            [
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.03192v1",
        "arXiv ID": "2105.03192v1"
    },
    {
        "title": "AI-Native Network Slicing for 6G Networks",
        "Published: ": "2021-05-18T15:01:57Z",
        "abstract": "With the global roll-out of the fifth generation (5G) networks, it is\nnecessary to look beyond 5G and envision the 6G networks. The 6G networks are\nexpected to have space-air-ground integrated networks, advanced network\nvirtualization, and ubiquitous intelligence. This article presents an\nartificial intelligence (AI)-native network slicing architecture for 6G\nnetworks to enable the synergy of AI and network slicing, thereby facilitating\nintelligent network management and supporting emerging AI services. AI-based\nsolutions are first discussed across network slicing lifecycle to intelligently\nmanage network slices, i.e., AI for slicing. Then, network slicing solutions\nare studied to support emerging AI services by constructing AI instances and\nperforming efficient resource management, i.e., slicing for AI. Finally, a case\nstudy is presented, followed by a discussion of open research issues that are\nessential for AI-native network slicing in 6G networks.",
        "author": [
            "Wen Wu",
            "Conghao Zhou",
            "Mushu Li",
            "Huaqing Wu",
            "Haibo Zhou",
            "Ning Zhang",
            "Xuemin",
            "Shen",
            "Weihua Zhuang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.08576v2.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.08576v2",
        "arXiv ID": "2105.08576v2"
    },
    {
        "title": "Explainable AI for medical imaging: Explaining pneumothorax diagnoses\n  with Bayesian Teaching",
        "Published: ": "2021-06-08T20:49:11Z",
        "abstract": "Limited expert time is a key bottleneck in medical imaging. Due to advances\nin image classification, AI can now serve as decision-support for medical\nexperts, with the potential for great gains in radiologist productivity and, by\nextension, public health. However, these gains are contingent on building and\nmaintaining experts' trust in the AI agents. Explainable AI may build such\ntrust by helping medical experts to understand the AI decision processes behind\ndiagnostic judgements. Here we introduce and evaluate explanations based on\nBayesian Teaching, a formal account of explanation rooted in the cognitive\nscience of human learning. We find that medical experts exposed to explanations\ngenerated by Bayesian Teaching successfully predict the AI's diagnostic\ndecisions and are more likely to certify the AI for cases when the AI is\ncorrect than when it is wrong, indicating appropriate trust. These results show\nthat Explainable AI can be used to support human-AI collaboration in medical\nimaging.",
        "author": [
            "Tomas Folke",
            "Scott Cheng-Hsin Yang",
            "Sean Anderson",
            "Patrick Shafto"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.04684v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.04684v1",
        "arXiv ID": "2106.04684v1"
    },
    {
        "title": "Stabilizing Deep Tomographic Reconstruction",
        "Published: ": "2020-08-04T21:35:32Z",
        "abstract": "Tomographic image reconstruction with deep learning is an emerging field, but\na recent landmark study reveals that several deep reconstruction networks are\nunstable for computed tomography (CT) and magnetic resonance imaging (MRI).\nSpecifically, three kinds of instabilities were reported: (1) strong image\nartefacts from tiny perturbations, (2) small features missing in a deeply\nreconstructed image, and (3) decreased imaging performance with increased input\ndata. On the other hand, compressed sensing (CS) inspired reconstruction\nmethods do not suffer from these instabilities because of their built-in kernel\nawareness. For deep reconstruction to realize its full potential and become a\nmainstream approach for tomographic imaging, it is thus critically important to\nmeet this challenge by stabilizing deep reconstruction networks. Here we\npropose an Analytic Compressed Iterative Deep (ACID) framework to address this\nchallenge. ACID synergizes a deep reconstruction network trained on big data,\nkernel awareness from CS-inspired processing, and iterative refinement to\nminimize the data residual relative to real measurement. Our study demonstrates\nthat the deep reconstruction using ACID is accurate and stable, and sheds light\non the converging mechanism of the ACID iteration under a Bounded Relative\nError Norm (BREN) condition. In particular, the study shows that ACID-based\nreconstruction is resilient against adversarial attacks, superior to classic\nsparsity-regularized reconstruction alone, and eliminates the three kinds of\ninstabilities. We anticipate that this integrative data-driven approach will\nhelp promote development and translation of deep tomographic image\nreconstruction networks into clinical applications.",
        "author": [
            "Weiwen Wu",
            "Dianlin Hu",
            "Wenxiang Cong",
            "Hongming Shan",
            "Shaoyu Wang",
            "Chuang Niu",
            "Pingkun Yan",
            "Hengyong Yu",
            "Varut Vardhanabhuti",
            "Ge Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.01846v5.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.01846v5",
        "arXiv ID": "2008.01846v5"
    },
    {
        "title": "Towards Interoperability of Open and Permissionless Blockchains: A\n  Cross-Chain Query Language",
        "Published: ": "2022-09-15T11:35:03Z",
        "abstract": "The rise of open and permissionless blockchains has introduced novel\nplatforms for applications based on distributed data storage. At the\napplication and business levels, long-established query languages such as SQL\nprovide interoperability that can be complemented by blockchain-based data\nstorage today, enabling permissionless and verifiable data storage along with\ndecentralized execution across tens of thousands of nodes. However, when\naccessing one or more blockchains, interoperability is not provided today,\nposing challenges such as inhomogeneous data access in addition to different\nfeatures and trade-offs, e.g. in data and distribution, scalability, and\nsecurity. Towards interoperability in data access among the increasing number\nof blockchain platforms, this paper introduces a cross-chain query language for\ndata access across blockchains. Similar to SQL, the language abstracts from\nimplementation based on a data model compatible with the largest open and\npermissionless blockchains (OPB) today. The language, data model, and\nprocessing architecture are demonstrated and evaluated with an implemented\nprototype, aiming to contribute to the discussion on blockchain\ninteroperability among OPB.",
        "author": [
            "Felix H\u00e4rer"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.07224v2.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.DB",
                "C.2.4; D.3.2; E.2; H.2.3"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.07224v2",
        "arXiv ID": "2209.07224v2"
    },
    {
        "title": "Reliable, Fair and Decentralized Marketplace for Content Sharing Using\n  Blockchain",
        "Published: ": "2020-09-23T10:04:15Z",
        "abstract": "Content sharing platforms such as Youtube and Vimeo have promoted pay per\nview models for artists to monetize their content. Yet, artists remain at the\nmercy of centralized platforms that control content listing and advertisement,\nwith little transparency and fairness in terms of number of views or revenue.\nOn the other hand, consumers are distanced from the publishers and cannot\nauthenticate originality of the content. In this paper, we develop a reliable\nand fair platform for content sharing without a central facilitator. The\nplatform is built as a decentralized data storage layer to store and share\ncontent in a fault-tolerant manner, where the peers also participate in a\nblockchain network. The blockchain is used to manage content listings and as an\nauditable and fair marketplace transaction processor that automatically pays\nout the content creators and the storage facilitators using smart contracts. We\ndemonstrate the system with the blockchain layer built on Hyperledger Fabric\nand the data layer built on Tahoe-LAFS,and show that our design is practical\nand scalable with low overheads.",
        "author": [
            "Prabal Banerjee",
            "Chander Govindarajan",
            "Praveen Jayachandran",
            "Sushmita Ruj"
        ],
        "pdfLink": "http://arxiv.org/pdf/2009.11033v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2009.11033v1",
        "arXiv ID": "2009.11033v1"
    },
    {
        "title": "Blockchain Networks: Data Structures of Bitcoin, Monero, Zcash,\n  Ethereum, Ripple and Iota",
        "Published: ": "2021-03-15T20:49:55Z",
        "abstract": "Blockchain is an emerging technology that has enabled many applications, from\ncryptocurrencies to digital asset management and supply chains. Due to this\nsurge of popularity, analyzing the data stored on blockchains poses a new\ncritical challenge in data science.\n  To assist data scientists in various analytic tasks on a blockchain, in this\ntutorial, we provide a systematic and comprehensive overview of the fundamental\nelements of blockchain network models. We discuss how we can abstract\nblockchain data as various types of networks and further use such associated\nnetwork abstractions to reap important insights on blockchains' structure,\norganization, and functionality.",
        "author": [
            "Cuneyt Gurcan Akcora",
            "Murat Kantarcioglu",
            "Yulia R. Gel"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.08712v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.08712v2",
        "arXiv ID": "2103.08712v2"
    },
    {
        "title": "EtrusChain: File Storage with DNA and Blockchain",
        "Published: ": "2023-06-19T19:37:59Z",
        "abstract": "This article proposes a blockchain-based file storage system that utilizes\nDNA encryption for enhanced security. The system utilizes blockchain technology\nto provide decentralized and tamper-proof file storage, while DNA encryption is\nemployed to further strengthen data protection. The proposed system employs a\nunique approach to encryption by utilizing DNA sequences as keys, which\nenhances data security and privacy. Additionally, the use of blockchain\ntechnology ensures that all file storage and access operations are transparent,\nimmutable, and distributed among a network of nodes, making it resistant to\ntampering and unauthorized access. The proposed system represents a significant\nadvancement in file storage security and provides a foundation for future\nresearch and development in the field of blockchain-based data storage",
        "author": [
            "Onur Y\u0131ld\u0131r\u0131m"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.07074v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.07074v1",
        "arXiv ID": "2310.07074v1"
    },
    {
        "title": "Assuring the Integrity of Videos from Wireless-based IoT Devices using\n  Blockchain",
        "Published: ": "2020-02-28T23:36:13Z",
        "abstract": "Blockchain technology has drawn attention fromvarious communities. The\nunderlying consensus mechanism inBlockchain enables a myriad of applications\nfor the integrityassurance of stored data. In this paper, we utilize\nBlockchaintechnology to verify the authenticity of a video captured by\nastreaming IoT device for forensic investigation purposes. Theproposed approach\ncomputes the hash of video frames beforethey leave the IoT device and are\ntransferred to a remote basestation. To guarantee the transmission, we ensure\nthat this hashis sent through a TCP-based connection. The hash is then storedon\nmultiple nodes on a permissioned blockchain platform. Incase the video is\nmodified, the discrepancy will be detected byinvestigating the previously\nstored hash on the blockchain andcomparing it with the hash of the existing\nframe in question.In this work, we present the prototype as proof-of-concept\nwithexperiment results. The system has been tested on a RaspberryPi with\ndifferent quality of videos to evaluate performance. Theresults show that the\nconcept can be implemented with moderatevideo resolutions.",
        "author": [
            "Dominik Danko",
            "Suat Mercan",
            "Mumin Cebe Kemal Akkaya"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.00118v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.00118v1",
        "arXiv ID": "2003.00118v1"
    },
    {
        "title": "Towards Zero-Shot Code-Switched Speech Recognition",
        "Published: ": "2022-11-02T19:52:54Z",
        "abstract": "In this work, we seek to build effective code-switched (CS) automatic speech\nrecognition systems (ASR) under the zero-shot setting where no transcribed CS\nspeech data is available for training. Previously proposed frameworks which\nconditionally factorize the bilingual task into its constituent monolingual\nparts are a promising starting point for leveraging monolingual data\nefficiently. However, these methods require the monolingual modules to perform\nlanguage segmentation. That is, each monolingual module has to simultaneously\ndetect CS points and transcribe speech segments of one language while ignoring\nthose of other languages -- not a trivial task. We propose to simplify each\nmonolingual module by allowing them to transcribe all speech segments\nindiscriminately with a monolingual script (i.e. transliteration). This simple\nmodification passes the responsibility of CS point detection to subsequent\nbilingual modules which determine the final output by considering multiple\nmonolingual transliterations along with external language model information. We\napply this transliteration-based approach in an end-to-end differentiable\nneural network and demonstrate its efficacy for zero-shot CS ASR on\nMandarin-English SEAME test sets.",
        "author": [
            "Brian Yan",
            "Matthew Wiesner",
            "Ondrej Klejch",
            "Preethi Jyothi",
            "Shinji Watanabe"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.01458v2.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.01458v2",
        "arXiv ID": "2211.01458v2"
    },
    {
        "title": "A Case Study for Blockchain in Manufacturing: \"FabRec\": A Prototype for\n  Peer-to-Peer Network of Manufacturing Nodes",
        "Published: ": "2018-04-03T17:57:01Z",
        "abstract": "With product customization an emerging business opportunity, organizations\nmust find ways to collaborate and enable sharing of information in an\ninherently trustless network. In this paper, we propose - \"FabRec\": a\ndecentralized approach to handle manufacturing information generated by various\norganizations using blockchain technology. We propose a system in which a\ndecentralized network of manufacturing machines and computing nodes can enable\nautomated transparency of an organization's capability, third party\nverification of such capability through a trail of past historic events and\nautomated mechanisms to drive paperless contracts between participants using\n'smart contracts'. Our system decentralizes critical information about the\nmanufacturer and makes it available on a peer-to-peer network composed of\nfiduciary nodes to ensure transparency and data provenance through a verifiable\naudit trail. We present a testbed platform through a combination of\nmanufacturing machines, system-on-chip platforms and computing nodes to\ndemonstrate mechanisms through which a consortium of disparate organizations\ncan communicate through a decentralized network. Our prototype testbed\ndemonstrates the value of computer code residing on a decentralized network for\nverification of information on the blockchain and ways in which actions can be\nautonomously initiated in the physical world. This paper intends to expose\nsystem elements in preparation for much larger field tests through the working\nprototype and discusses the future potential of blockchain for manufacturing\nIT.",
        "author": [
            "Atin Angrish",
            "Benjamin Craver",
            "Mahmud Hasan",
            "Binil Starly"
        ],
        "pdfLink": "http://arxiv.org/pdf/1804.01083v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1804.01083v1",
        "arXiv ID": "1804.01083v1"
    },
    {
        "title": "Secure Regenerating Codes for Reducing Storage and Bootstrap Costs in\n  Sharded Blockchains",
        "Published: ": "2020-11-11T17:23:08Z",
        "abstract": "Blockchain is a distributed ledger with wide applications. Due to the\nincreasing storage requirement for blockchains, the computation can be afforded\nby only a few miners. Sharding has been proposed to scale blockchains so that\nstorage and transaction efficiency of the blockchain improves at the cost of\nsecurity guarantee. This paper aims to consider a new protocol,\nSecure-Repair-Blockchain (SRB), which aims to decrease the storage cost at the\nminers. In addition, SRB also decreases the bootstrapping cost, which allows\nfor new miners to easily join a sharded blockchain. In order to reduce storage,\ncoding-theoretic techniques are used in SRB. In order to decrease the amount of\ndata that is transferred to the new node joining a shard, the concept of exact\nrepair secure regenerating codes is used. The proposed blockchain protocol\nachieves lower storage than those that do not use coding, and achieves lower\nbootstrapping cost as compared to the different baselines.",
        "author": [
            "Divija Swetha Gadiraju",
            "V. Lalitha",
            "Vaneet Aggarwal"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.06201v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC",
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.06201v1",
        "arXiv ID": "2011.06201v1"
    },
    {
        "title": "Protecting the Decentralized Future: An Exploration of Common Blockchain\n  Attacks and their Countermeasures",
        "Published: ": "2023-06-20T20:56:06Z",
        "abstract": "Blockchain technology transformed the digital sphere by providing a\ntransparent, secure, and decentralized platform for data security across a\nrange of industries, including cryptocurrencies and supply chain management.\nBlockchain's integrity and dependability have been jeopardized by the rising\nnumber of security threats, which have attracted cybercriminals as a target. By\nsummarizing suggested fixes, this research aims to offer a thorough analysis of\nmitigating blockchain attacks. The objectives of the paper include identifying\nweak blockchain attacks, evaluating various solutions, and determining how\neffective and effective they are at preventing these attacks. The study also\nhighlights how crucial it is to take into account the particular needs of every\nblockchain application. This study provides beneficial perspectives and\ninsights for blockchain researchers and practitioners, making it essential\nreading for those interested in current and future trends in blockchain\nsecurity research.",
        "author": [
            "Bilash Saha",
            "Md Mehedi Hasan",
            "Nafisa Anjum",
            "Sharaban Tahora",
            "Aiasha Siddika",
            "Hossain Shahriar"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.11884v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "cs.DB",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.11884v1",
        "arXiv ID": "2306.11884v1"
    },
    {
        "title": "When Mobile Blockchain Meets Edge Computing",
        "Published: ": "2017-11-16T05:53:57Z",
        "abstract": "Blockchain, as the backbone technology of the current popular Bitcoin digital\ncurrency, has become a promising decentralized data management framework.\nAlthough blockchain has been widely adopted in many applications, e.g.,\nfinance, healthcare, and logistics, its application in mobile services is still\nlimited. This is due to the fact that blockchain users need to solve preset\nproof-of-work puzzles to add new data, i.e., a block, to the blockchain.\nSolving the proof-of-work, however, consumes substantial resources in terms of\nCPU time and energy, which is not suitable for resource-limited mobile devices.\nTo facilitate blockchain applications in future mobile Internet of Things\nsystems, multiple access mobile edge computing appears to be an auspicious\nsolution to solve the proof-of-work puzzles for mobile users. We first\nintroduce a novel concept of edge computing for mobile blockchain. Then, we\nintroduce an economic approach for edge computing resource management.\nMoreover, a prototype of mobile edge computing enabled blockchain systems is\npresented with experimental results to justify the proposed concept.",
        "author": [
            "Zehui Xiong",
            "Yang Zhang",
            "Dusit Niyato",
            "Ping Wang",
            "Zhu Han"
        ],
        "pdfLink": "http://arxiv.org/pdf/1711.05938v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1711.05938v2",
        "arXiv ID": "1711.05938v2"
    },
    {
        "title": "A PLS blockchain for IoT applications: protocols and architecture",
        "Published: ": "2020-08-11T11:21:47Z",
        "abstract": "This paper proposes an architecture and a protocol suite for a permissioned\nblockchain for a local IoT network. The architecture is based on a sealed\nSequencer and a Fog Server running (post-quantum) Guy Fawkes protocols. The\nblocks of the blockchain are stored in networked Content Addressable Storage\nalongside any user data and validity proofs. We maintain that a typical IoT\ndevice can, despite its resource limitations, use our blockchain protocols\ndirectly, without a trusted intermediary. This includes posting and monitoring\ntransactions as well as off-chain (post-quantum) emergency communications\nwithout an explicit public key. Keywords: blockchain, Guy Fawkes protocol,\npost-quantum, HORS-OTS, LoRa, concurrent transmission",
        "author": [
            "Alex Shafarenko"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.04632v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.04632v2",
        "arXiv ID": "2008.04632v2"
    },
    {
        "title": "Blockchain in Dynamic Networks",
        "Published: ": "2022-08-05T18:43:59Z",
        "abstract": "We consider blockchain in dynamic networks. We define the Blockchain Decision\nProblem. It requires miners that maintain the blockchain to confirm whether a\nparticular block is accepted. We establish the necessary conditions for the\nexistence of a solution. We, however, prove that the solution, even under these\nnecessary conditions is, in general, impossible. We then present two algorithms\nthat solve the Blockchain Decision Problem under either the knowledge of the\nmaximum source pool propagation time or the knowledge of the source pool\nmembership. We evaluate the performance of the two algorithms.",
        "author": [
            "Rachel Bricker",
            "Mikhail Nesterenko",
            "Gokarna Sharma"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.03355v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.03355v1",
        "arXiv ID": "2208.03355v1"
    },
    {
        "title": "healthAIChain: Improving security and safety using Blockchain Technology\n  applications in AI-based healthcare systems",
        "Published: ": "2023-11-01T20:47:36Z",
        "abstract": "Blockchain as a digital ledger for keeping records of digital transactions\nand other information, it is secure and decentralized technology. The globally\ngrowing number of digital population every day possesses a significant threat\nto online data including the medical and patients data. After bitcoin,\nblockchain technology has emerged into a general-purpose technology with\napplications in medical industries and healthcare. Blockchain can promote\nhighly configurable openness while retaining the highest security standards for\ncritical data of medical patients. Referred to as distributed record keeping\nfor healthcare systems which makes digital assets unalterable and transparent\nvia a cryptographic hash and decentralized network. The study delves into the\nsecurity and safety improvement associated with implementing blockchain in\nAI-based healthcare systems. Blockchain-enabled AI tackles the existing issues\nrelated to security, performance efficiencies, and safety in healthcare\nsystems. We have also examined the Artificial Intelligence in healthcare and\nmedical industry, potential areas, open questions concerning the blockchain in\nhealthcare systems. Finally, the article proposed an AI-based healthcare\nblockchain model (healthAIChain) to improve patients data and security.",
        "author": [
            "Naresh Kshetri",
            "James Hutson",
            "Revathy G"
        ],
        "pdfLink": "http://arxiv.org/pdf/2311.00842v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2311.00842v1",
        "arXiv ID": "2311.00842v1"
    },
    {
        "title": "LightSync: Ultra Light Client for PoW Blockchains",
        "Published: ": "2021-12-06T14:58:02Z",
        "abstract": "Full nodes in a blockchain network store and verify a copy of the whole\nblockchain. Unlike full nodes, light clients are low-capacity devices that want\nto validate certain data on a blockchain. They query the data they want from a\nfull node. If light clients do not verify the data they receive, full nodes\nmight deceive them. SPV, introduced in the Bitcoin paper, is a practical\nsolution to this problem currently used in many PoW blockchains. In SPV, the\nresources needed to verify a full node's response grow linearly with the\nblockchain size, making it inefficient over the long run. Another issue with\nSPV is that the full nodes do not get compensated for the services they\nprovide.\n  In this work, we introduce LightSync, a simple and cost-effective solution\nfor light clients to verify the inclusion of certain data in a PoW blockchain.\nThe resources needed for running LightSync remain constant no matter what the\nsize of the blockchain is. LightSync uses an incentive mechanism that\nencourages full nodes to participate in the protocol. We perform a thorough\nanalysis of the security of LightSync and discuss the details of deploying it\nin a real-world environment.",
        "author": [
            "Niusha Moshrefi",
            "Mahyar Daneshpajooh",
            "Chen Feng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.03092v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.03092v1",
        "arXiv ID": "2112.03092v1"
    },
    {
        "title": "Analysis of Committee Selection Mechanism in Blockchain",
        "Published: ": "2019-05-09T12:23:54Z",
        "abstract": "The Committee Selection Mechanism can select multiple users of blockchain\nnetwork to execute a consensus algorithm, such as PBFT. In order to guarantee\ntwo properties, the mathematical form of the mechanism is relatively limited.\nFurther, if the mechanism is used in open network, it will bring about an\nincrease in efficiency, but it will reduce the security and practicability of\nthe blockchain network.",
        "author": [
            "Shiyu Cai"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.05079v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.05079v1",
        "arXiv ID": "1905.05079v1"
    },
    {
        "title": "DFL: High-Performance Blockchain-Based Federated Learning",
        "Published: ": "2021-10-28T22:35:59Z",
        "abstract": "Many researchers have proposed replacing the aggregation server in federated\nlearning with a blockchain system to improve privacy, robustness, and\nscalability. In this approach, clients would upload their updated models to the\nblockchain ledger and use a smart contract to perform model averaging. However,\nthe significant delay and limited computational capabilities of blockchain\nsystems make it inefficient to support machine learning applications on the\nblockchain.\n  In this paper, we propose a new public blockchain architecture called DFL,\nwhich is specially optimized for distributed federated machine learning. Our\narchitecture inherits the merits of traditional blockchain systems while\nachieving low latency and low resource consumption by waiving global consensus.\nTo evaluate the performance and robustness of our architecture, we implemented\na prototype and tested it on a physical four-node network, and also developed a\nsimulator to simulate larger networks and more complex situations. Our\nexperiments show that the DFL architecture can reach over 90\\% accuracy for\nnon-I.I.D. datasets, even in the presence of model poisoning attacks, while\nensuring that the blockchain part consumes less than 5\\% of hardware resources.",
        "author": [
            "Yongding Tian",
            "Zhuoran Guo",
            "Jiaxuan Zhang",
            "Zaid Al-Ars"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.15457v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.15457v2",
        "arXiv ID": "2110.15457v2"
    },
    {
        "title": "Blockchain based Decentralized Applications: Technology Review and\n  Development Guidelines",
        "Published: ": "2020-03-16T11:50:57Z",
        "abstract": "Blockchain or Distributed Ledger Technology is a disruptive technology that\nprovides the infrastructure for developing decentralized applications enabling\nthe implementation of novel business models even in traditionally centralized\ndomains. In the last years it has drawn high interest from the academic\ncommunity, technology developers and startups thus lots of solutions have been\ndeveloped to address blockchain technology limitations and the requirements of\napplications software engineering. In this paper, we provide a comprehensive\noverview of DLT solutions analyzing the addressed challenges, provided\nsolutions and their usage for developing decentralized applications. Our study\nreviews over 100 blockchain papers and startup initiatives from which we\nconstruct a 3-tier based architecture for decentralized applications and we use\nit to systematically classify the technology solutions. Protocol and Network\nTier solutions address the digital assets registration, transactions, data\nstructure, and privacy and business rules implementation and the creation of\npeer-to-peer networks, ledger replication, and consensus-based state\nvalidation. Scaling Tier solutions address the scalability problems in terms of\nstorage size, transaction throughput, and computational capability. Finally,\nFederated Tier aggregates integrative solutions across multiple blockchain\napplications deployments. The paper closes with a discussion on challenges and\nopportunities for developing decentralized applications by providing a\nmulti-step guideline for decentralizing the design of traditional systems and\nimplementing decentralized applications.",
        "author": [
            "Claudia Pop",
            "Tudor Cioara",
            "Ionut Anghel",
            "Marcel Antal",
            "Ioan Salomie"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.07131v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "C.2.4"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.07131v1",
        "arXiv ID": "2003.07131v1"
    },
    {
        "title": "Blockchain for Edge of Things: Applications, Opportunities, and\n  Challenges",
        "Published: ": "2021-10-11T06:23:55Z",
        "abstract": "In recent years, blockchain networks have attracted significant attention in\nmany research areas beyond cryptocurrency, one of them being the Edge of Things\n(EoT) that is enabled by the combination of edge computing and the Internet of\nThings (IoT). In this context, blockchain networks enabled with unique features\nsuch as decentralization, immutability, and traceability, have the potential to\nreshape and transform the conventional EoT systems with higher security levels.\nParticularly, the convergence of blockchain and EoT leads to a new paradigm,\ncalled BEoT that has been regarded as a promising enabler for future services\nand applications. In this paper, we present a state-of-the-art review of recent\ndevelopments in BEoT technology and discover its great opportunities in many\napplication domains. We start our survey by providing an updated introduction\nto blockchain and EoT along with their recent advances. Subsequently, we\ndiscuss the use of BEoT in a wide range of industrial applications, from smart\ntransportation, smart city, smart healthcare to smart home and smart grid.\nSecurity challenges in BEoT paradigm are also discussed and analyzed, with some\nkey services such as access authentication, data privacy preservation, attack\ndetection, and trust management. Finally, some key research challenges and\nfuture directions are also highlighted to instigate further research in this\npromising area.",
        "author": [
            "Thippa Reddy Gadekallu",
            "Quoc-Viet Pham",
            "Dinh C. Nguyen",
            "Praveen Kumar Reddy Maddikunta",
            "N Deepa",
            "Prabadevi B",
            "Pubudu N. Pathirana",
            "Jun Zhao",
            "Won-Joo Hwang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.05022v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.05022v1",
        "arXiv ID": "2110.05022v1"
    },
    {
        "title": "ZebraLancer: Decentralized Crowdsourcing of Human Knowledge atop Open\n  Blockchain",
        "Published: ": "2018-03-03T22:42:14Z",
        "abstract": "We design and implement the first private and anonymous decentralized\ncrowdsourcing system ZebraLancer, and overcome two fundamental challenges of\ndecentralizing crowdsourcing, i.e., data leakage and identity breach.\n  First, our outsource-then-prove methodology resolves the tension between the\nblockchain transparency and the data confidentiality to guarantee the basic\nutilities/fairness requirements of data crowdsourcing, thus ensuring: (i) a\nrequester will not pay more than what data deserve, according to a policy\nannounced when her task is published via the blockchain; (ii) each worker\nindeed gets a payment based on the policy, if he submits data to the\nblockchain; (iii) the above properties are realized not only without a central\narbiter, but also without leaking the data to the open blockchain. Second, the\ntransparency of blockchain allows one to infer private information about\nworkers and requesters through their participation history. Simply enabling\nanonymity is seemingly attempting but will allow malicious workers to submit\nmultiple times to reap rewards. ZebraLancer also overcomes this problem by\nallowing anonymous requests/submissions without sacrificing accountability. The\nidea behind is a subtle linkability: if a worker submits twice to a task,\nanyone can link the submissions, or else he stays anonymous and unlinkable\nacross tasks. To realize this delicate linkability, we put forward a novel\ncryptographic concept, i.e., the common-prefix-linkable anonymous\nauthentication. We remark the new anonymous authentication scheme might be of\nindependent interest. Finally, we implement our protocol for a common image\nannotation task and deploy it in a test net of Ethereum. The experiment results\nshow the applicability of our protocol atop the existing real-world blockchain.",
        "author": [
            "Yuan Lu",
            "Qiang Tang",
            "Guiling Wang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1803.01256v5.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.CR",
                "cs.DC",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1803.01256v5",
        "arXiv ID": "1803.01256v5"
    },
    {
        "title": "Compressive-Sensing Data Reconstruction for Structural Health\n  Monitoring: A Machine-Learning Approach",
        "Published: ": "2019-01-07T01:26:27Z",
        "abstract": "Compressive sensing (CS) has been studied and applied in structural health\nmonitoring for wireless data acquisition and transmission, structural modal\nidentification, and spare damage identification. The key issue in CS is finding\nthe optimal solution for sparse optimization. In the past years, many\nalgorithms have been proposed in the field of applied mathematics. In this\npaper, we propose a machine-learning-based approach to solve the CS\ndata-reconstruction problem. By treating a computation process as a data flow,\nthe process of CS-based data reconstruction is formalized into a standard\nsupervised-learning task. The prior knowledge, i.e., the basis matrix and the\nCS-sampled signals, are used as the input and the target of the network; the\nbasis coefficient matrix is embedded as the parameters of a certain layer; the\nobjective function of conventional compressive sensing is set as the loss\nfunction of the network. Regularized by l1-norm, these basis coefficients are\noptimized to reduce the error between the original CS-sampled signals and the\nmasked reconstructed signals with a common optimization algorithm. Also, the\nproposed network can handle complex bases, such as a Fourier basis. Benefiting\nfrom the nature of a multi-neuron layer, multiple signal channels can be\nreconstructed simultaneously. Meanwhile, the disassembled use of a large-scale\nbasis makes the method memory-efficient. A numerical example of multiple\nsinusoidal waves and an example of field-test wireless data from a suspension\nbridge are carried out to illustrate the data-reconstruction ability of the\nproposed approach. The results show that high reconstruction accuracy can be\nobtained by the machine learning-based approach. Also, the parameters of the\nnetwork have clear meanings; the inference of the mapping between input and\noutput is fully transparent, making the CS data reconstruction neural network\ninterpretable.",
        "author": [
            "Yuequan Bao",
            "Zhiyi Tang",
            "Hui Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.01995v2.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.01995v2",
        "arXiv ID": "1901.01995v2"
    },
    {
        "title": "Attract More Miners to Join in Blochchain Construction for Internet of\n  Things",
        "Published: ": "2020-03-23T21:57:22Z",
        "abstract": "The world-changing blockchain technique provides a novel method to establish\na secure, trusted and decentralized system for solving the security and\npersonal privacy problems in Industrial Internet of Things (IIoT) applications.\nThe mining process in blockchain requires miners to solve a proof-of-work\npuzzle, which requires high computational power. However, the lightweight IIoT\ndevices cannot directly participate in the mining process due to the limitation\nof power and computational resources. The edge computing service makes it\npossible for IIoT applications to build a blockchain network, in which IIoT\ndevices purchase computational resources from edge servers and thus can offload\ntheir computational tasks. The amount of computational resource purchased by\nIIoT devices depends on how many profits they can get in the mining process,\nand will directly affect the security of the blockchain network. In this paper,\nwe investigate the incentive mechanism for the blockchain platform to attract\nIIoT devices to purchase more computational power from edge servers to\nparticipate in the mining process, thereby building a more secure blockchain\nnetwork. We model the interaction between the blockchain platform and IIoT\ndevices as a two-stage Stackelberg game, where the blockchain platform act as\nthe leader, and IIoT devices act as followers. We analyze the existence and\nuniqueness of the Stackelberg equilibrium, and propose an efficient algorithm\nto compute the Stackelberg equilibrium point. Furthermore, we evaluate the\nperformance of our algorithm through extensive simulations, and analyze the\nstrategies of blockchain platform and IIoT devices under different situations.",
        "author": [
            "Xingjian Ding",
            "Jianxiong Guo",
            "Deying Li",
            "Weili Wu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.10560v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.10560v2",
        "arXiv ID": "2003.10560v2"
    },
    {
        "title": "SoK: Blockchain Technology and Its Potential Use Cases",
        "Published: ": "2019-09-27T01:27:52Z",
        "abstract": "Bitcoin's success has led to significant interest in its underlying\ncomponents, particularly Blockchain technology. Over 10 years after Bitcoin's\ninitial release, the community still suffers from a lack of clarity regarding\nwhat properties defines Blockchain technology, its relationship to similar\ntechnologies, and which of its proposed use-cases are tenable and which are\nlittle more than hype. In this paper we answer four common questions regarding\nBlockchain technology: (1) what exactly is Blockchain technology, (2) what\ncapabilities does it provide, and (3) what are good applications for Blockchain\ntechnology, and (4) how does it relate to other approache distributed\ntechnologies (e.g., distributed databases). We accomplish this goal by using\ngrounded theory (a structured approach to gathering and analyzing qualitative\ndata) to thoroughly analyze a large corpus of literature on Blockchain\ntechnology. This method enables us to answer the above questions while limiting\nresearcher bias, separating thought leadership from peddled hype and\nidentifying open research questions related to Blockchain technology. The\naudience for this paper is broad as it aims to help researchers in a variety of\nareas come to a better understanding of Blockchain technology and identify\nwhether it may be of use in their own research.",
        "author": [
            "Scott Ruoti",
            "Ben Kaiser",
            "Arkady Yerukhimovich",
            "Jeremy Clark",
            "Robert Cunningham"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.12454v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.12454v1",
        "arXiv ID": "1909.12454v1"
    },
    {
        "title": "uBaaS: A Unified Blockchain as a Service Platform",
        "Published: ": "2019-07-31T02:50:08Z",
        "abstract": "Blockchain is an innovative distributed ledger technology which has attracted\na wide range of interests for building the next generation of applications to\naddress lack-of-trust issues in business. Blockchain as a service (BaaS) is a\npromising solution to improve the productivity of blockchain application\ndevelopment. However, existing BaaS deployment solutions are mostly\nvendor-locked: they are either bound to a cloud provider or a blockchain\nplatform. In addition to deployment, design and implementation of\nblockchain-based applications is a hard task requiring deep expertise.\nTherefore, this paper presents a unified blockchain as a service platform\n(uBaaS) to support both design and deployment of blockchain-based applications.\nThe services in uBaaS include deployment as a service, design pattern as a\nservice and auxiliary services. In uBaaS, deployment as a service is platform\nagnostic, which can avoid lock-in to specific cloud platforms, while design\npattern as a service applies design patterns for data management and smart\ncontract design to address the scalability and security issues of blockchain.\nThe proposed solutions are evaluated using a real-world quality tracing use\ncase in terms of feasibility and scalability.",
        "author": [
            "Qinghua Lu",
            "Xiwei Xu",
            "Yue Liu",
            "Ingo Weber",
            "Liming Zhu",
            "Weishan Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1907.13293v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1907.13293v1",
        "arXiv ID": "1907.13293v1"
    },
    {
        "title": "An Efficient Framework for Execution of Smart Contracts in Hyperledger\n  Sawtooth",
        "Published: ": "2023-02-16T17:52:38Z",
        "abstract": "Blockchain technology is a distributed, decentralized, and immutable ledger\nsystem. It is the platform of choice for managing smart contract transactions\n(SCTs). Smart contracts are self-executing codes of agreement between\ninterested parties commonly implemented using blockchains. A block contains a\nset of transactions representing changes to the system and a hash of the\nprevious block. The SCTs are executed multiple times during the block\nproduction and validation phases across the network. The execution is\nsequential in most blockchain technologies.\n  In this work, we incorporate a direct acyclic graph (DAG) based parallel\nscheduler framework for concurrent execution of SCTs. The dependencies among a\nblock's transactions are represented through a concurrent DAG data structure\nthat assists in throughput optimization. We have created a DAG scheduler module\nthat can be incorporated into blockchain platforms for concurrent execution\nwith ease. We have also formally established the safety and liveness properties\nof the DAG scheduler. For evaluation, our framework is implemented in\nHyperledger Sawtooth V1.2.6. The performance across multiple smart contract\napplications is measured for various scheduler types. Experimental analysis\nshows that the proposed framework achieves notable performance improvements\nover the parallel SCT execution frameworks.",
        "author": [
            "Manaswini Piduguralla",
            "Saheli Chakraborty",
            "Parwat Singh Anjana",
            "Sathya Peri"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.08452v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.08452v2",
        "arXiv ID": "2302.08452v2"
    },
    {
        "title": "An Empirical Study on Governance in Bitcoin's Consensus Evolution",
        "Published: ": "2023-05-06T15:57:13Z",
        "abstract": "Blockchain systems run consensus rules as code to agree on the state of the\ndistributed ledger and secure the network. Changing these rules can be risky\nand challenging. In addition, it can often be controversial and take much\neffort to make all the necessary participants agree to adopt a change.\nArguably, Bitcoin has seen centralisation tendencies in pools and in\ndevelopment. However, how these tendencies influence blockchain governance has\nreceived minimal community and academic attention. Our study analyses the\ngovernmental structures in a blockchain by looking into the history of Bitcoin.\nWe investigate the process of changing consensus rules through a grounded\ntheory analysis comprising quantitative and qualitative data from 34 consensus\nforks in Bitcoin and Bitcoin Cash. The results reveal the decentralised\nbehaviour in Bitcoin and blockchain. Our results are in contrast to related\nwork, emphasising centralisation among miners and developers. Furthermore, our\nresults show how the consensus-driven deployment techniques and governance of\nconsensus rules are intertwined.",
        "author": [
            "Jakob Svennevik Notland",
            "Mariusz Nowostawski",
            "Jingyue Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.04079v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.04079v1",
        "arXiv ID": "2305.04079v1"
    },
    {
        "title": "A lightweight two-layer blockchain mechanism for reliable\n  crossing-domain communication in smart cities",
        "Published: ": "2021-10-28T02:37:25Z",
        "abstract": "The smart city is an emerging notion that is leveraging the Internet of\nThings (IoT) technique to achieve more comfortable, smart and controllable\ncities. The communications crossing domains between smart cities is\nindispensable to enhance collaborations. However, crossing-domain\ncommunications are more vulnerable since there are in different domains.\nMoreover, there are huge different devices with different computation\ncapabilities, from sensors to the cloud servers. In this paper, we propose a\nlightweight two-layer blockchain mechanism for reliable crossing-domain\ncommunication in smart cities. Our mechanism provides a reliable communication\nmechanism for data sharing and communication between smart cities. We defined a\ntwo-layer blockchain structure for the communications inner and between smart\ncities to achieve reliable communications. We present a new block structure for\nthe lightweight IoT devices. Moreover, we present a reputation-based\nmulti-weight consensus protocol in order to achieve efficient communication\nwhile resistant to the nodes collusion attack for the proposed blockchain\nsystem. We also conduct a secure analysis to demonstrate the security of the\nproposed scheme. Finally, performance evaluation shows that our scheme is\nefficient and practical.",
        "author": [
            "Xiangyu Xu",
            "Jianfei Peng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.14860v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.14860v1",
        "arXiv ID": "2110.14860v1"
    },
    {
        "title": "PoRCH: A Novel Consensus Mechanism for Blockchain-Enabled Future SCADA\n  Systems in Smart Grids and Industry 4.0",
        "Published: ": "2021-09-21T05:15:39Z",
        "abstract": "Smart Grids and Industry 4.0 (I4.0) are neither a dream nor a near-future\nthing anymore, rather it is happening now. The integration of more and more\nembedded systems and IoT devices is pushing smart grids and I4.0 forward at a\nbreakneck speed. To cope up with this, the modification of age-old SCADA\n(Supervisory Control and Data Acquisition) systems in terms of\ndecentralization, near-real-time operation, security, and privacy is necessary.\nIn this context, blockchain technology has the potential of providing not only\nthese essential features of the data acquisition process of future SCADA\nsystems but also many other useful add-ons. On the other side, it is evident\nthat various type of security breach tends to take place more during any\neconomic turmoil. These can cause even more serious devastation to the global\neconomy and human life. Thus, it is necessary to make our industries robust,\nautomated, and resilient with secured and immutable data acquiring systems.\nThis paper deals with the implementation scopes of blockchain in the data\nacquisition part of SCADA systems in the area of the smart grid and I4.0. There\nare several consensus mechanisms to support blockchain integration in the field\nof cryptocurrencies, vehicular networks, healthcare systems, e-commerce, etc.\nBut little attention has been paid to developing efficient and\neasy-to-implement consensus mechanisms in the field of blockchain-enabled SCADA\nsystems. From this perspective, a novel consensus mechanism, which we call\nPoRCH (Proof of Random Count in Hashes), with a customized mining node\nselection scheme has been proposed in this paper. Also, a small-scale prototype\nof a blockchain-enabled data acquisition system has been developed. The\nperformance evaluation of the implemented prototype shows the benefits of\nblockchain technology.",
        "author": [
            "Md Tamjid Hossain",
            "Shahriar Badsha",
            "Haoting Shen"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.09966v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.09966v1",
        "arXiv ID": "2109.09966v1"
    },
    {
        "title": "A Practical and Economical Bayesian Approach to Gas Price Prediction",
        "Published: ": "2023-04-29T20:24:49Z",
        "abstract": "On the Ethereum network, it is challenging to determine a gas price that\nensures a transaction will be included in a block within a user's required\ntimeline without overpaying. One way of addressing this problem is through the\nuse of gas price oracles that utilize historical block data to recommend gas\nprices. However, when transaction volumes increase rapidly, these oracles often\nunderestimate or overestimate the price. In this paper, we demonstrate how\nGaussian process models can predict the distribution of the minimum price in an\nupcoming block when transaction volumes are increasing. This is effective\nbecause these processes account for time correlations between blocks. We\nperformed an empirical analysis using the Gaussian process model on historical\nblock data and compared the performance with GasStation-Express and Geth gas\nprice oracles. The results suggest that when transactions volumes fluctuate\ngreatly, the Gaussian process model offers a better estimation. Further, we\ndemonstrated that GasStation-Express and Geth can be improved upon by using a\nsmaller training sample size which is properly pre-processed. Based on the\nresults of empirical analysis, we recommended a gas price oracle made up of a\nhybrid model consisting of both the Gaussian process and GasStation-Express.\nThis oracle provides efficiency, accuracy, and better cost.",
        "author": [
            "ChihYun Chuang",
            "TingFang Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.00337v1.pdf",
        "Categories": [
            [
                "stat.AP",
                "cs.CE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.00337v1",
        "arXiv ID": "2305.00337v1"
    },
    {
        "title": "A Survey on Blockchain and Edge Computing applied to the Internet of\n  Vehicles",
        "Published: ": "2020-11-27T11:25:20Z",
        "abstract": "With the advent of Intelligent Transportation Systems (ITS), data from\ndiverse sensors either embedded into the vehicles or present along with the\nsmart city infrastructure, are of utmost importance and require both processing\npower and efficient trust mechanisms for information exchange in\nvehicle-to-everything (V2X) communications. To accomplish these requirements,\nboth edge computing and blockchain have been recently adopted towards a secure,\ndistributed, and computation empowered Internet of Vehicles (IoV). This paper\nsurveys prominent solutions for blockchain-based vehicular edge computing\n(VEC), provides a taxonomy, highlights their main features, advantages, and\nlimitations to provide subsidies for further proposals.",
        "author": [
            "Anderson Queiroz",
            "Eduardo Oliveira",
            "Maria Barbosa",
            "Kelvin Dias"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.13676v2.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.13676v2",
        "arXiv ID": "2011.13676v2"
    },
    {
        "title": "Implementation of Ethereum Accounts and Transactions on Embedded IoT\n  Devices",
        "Published: ": "2022-06-29T17:29:48Z",
        "abstract": "The growing interest in Internet of Things (IoT) and Industrial IoT (IIoT)\nposes the challenge of finding robust solutions for the certification and\nnotarization of data produced and collected by embedded devices. The blockchain\nand distributed ledger technologies represent a promising solution to address\nthese issues, but rise other questions, for example regarding their practical\nfeasibility. In fact, IoT devices have limited resources and, consequently, may\nnot be able to easily perform all the operations required to participate in a\nblockchain. In this paper we propose a minimal architecture to allow IoT\ndevices performing data certification and notarization on the Ethereum\nblockchain. We develop a hardware-software platform through which a lightweight\ndevice (e.g., an IoT sensor), holding a secret key and the associated public\naddress, produces signed transactions, which are then submitted to the\nblockchain network. This guarantees data integrity and authenticity and, on the\nother hand, minimizes the computational burden on the lightweight device. To\nshow the practicality of the proposed approach, we report and discuss the\nresults of benchmarks performed on ARM Cortex-M4 hardware architectures,\nsending transactions over the Ropsten testnet. Our results show that all the\nnecessary operations can be performed with small latency, thus proving that an\nIoT device can directly interact with the blockchain, without apparent\nbottlenecks.",
        "author": [
            "Giulia Rafaiani",
            "Paolo Santini",
            "Marco Baldi",
            "Franco Chiaraluce"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.14782v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.14782v1",
        "arXiv ID": "2206.14782v1"
    },
    {
        "title": "Industry 4.0 in Health care: A systematic review",
        "Published: ": "2022-01-13T13:08:50Z",
        "abstract": "Industry 4.0 in health care has evolved drastically over the past century. In\nfact, it is evolving every day, with new tools and strategies being developed\nby physicians and researchers alike. Health care and technology have been\nintertwined together with the advancement of cloud computing and big data. This\nstudy aims to analyze the impact of industry 4.0 in health care systems. To do\nso, a systematic literature review was carried out considering peer-reviewed\narticles extracted from the two popular databases: Scopus and Web of Science\n(WoS). PRISMA statement 2015 was used to include and exclude that data. At\nfirst, a bibliometric analysis was carried out using 346 articles considering\nthe following factors: publication by year, journal, authors, countries,\ninstitutions, authors' keywords, and citations. Finally, qualitative analysis\nwas carried out based on selected 32 articles considering the following\nfactors: a conceptual framework, schedule problems, security, COVID-19, digital\nsupply chain, and blockchain technology. Study finding suggests that during the\nonset of COVID-19, health care and industry 4.0 has been merged and evolved\njointly, considering various crisis such as data security, resource allocation,\nand data transparency. Industry 4.0 enables many technologies such as the\ninternet of things (IoT), blockchain, big data, cloud computing, machine\nlearning, deep learning, information, and communication technologies (ICT) to\ntrack patients' records and helps reduce social transmission COVID-19 and so\non. The study findings will give future researchers and practitioners some\ninsights regarding the integration of health care and Industry 4.0.",
        "author": [
            "Md Manjurul Ahsan",
            "Zahed Siddique"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.06999v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.06999v1",
        "arXiv ID": "2201.06999v1"
    },
    {
        "title": "The design and implementation of Language Learning Chatbot with XAI\n  using Ontology and Transfer Learning",
        "Published: ": "2020-09-29T13:11:40Z",
        "abstract": "In this paper, we proposed a transfer learning-based English language\nlearning chatbot, whose output generated by GPT-2 can be explained by\ncorresponding ontology graph rooted by fine-tuning dataset. We design three\nlevels for systematically English learning, including phonetics level for\nspeech recognition and pronunciation correction, semantic level for specific\ndomain conversation, and the simulation of free-style conversation in English -\nthe highest level of language chatbot communication as free-style conversation\nagent. For academic contribution, we implement the ontology graph to explain\nthe performance of free-style conversation, following the concept of XAI\n(Explainable Artificial Intelligence) to visualize the connections of neural\nnetwork in bionics, and explain the output sentence from language model. From\nimplementation perspective, our Language Learning agent integrated the\nmini-program in WeChat as front-end, and fine-tuned GPT-2 model of transfer\nlearning as back-end to interpret the responses by ontology graph.",
        "author": [
            "Nuobei Shi",
            "Qin Zeng",
            "Raymond Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/2009.13984v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2009.13984v1",
        "arXiv ID": "2009.13984v1"
    },
    {
        "title": "LedgerGuard: Improving Blockchain Ledger Dependability",
        "Published: ": "2018-05-03T01:55:05Z",
        "abstract": "The rise of crypto-currencies has spawned great interest in their underlying\ntechnology, namely, Blockchain. The central component in a Blockchain is a\nshared distributed ledger. A ledger comprises series of blocks, which in turns\ncontains a series of transactions. An identical copy of the ledger is stored on\nall nodes in a blockchain network. Maintaining ledger integrity and security is\none of the crucial design aspects of any blockchain platform. Thus, there are\ntypically built-in validation mechanisms leveraging cryptography to ensure the\nvalidity of incoming blocks before committing them into the ledger. However, a\nblockchain node may run over an extended period of time, during which the\nblocks on the disk can may become corrupted due to software or hardware\nfailures, or due to malicious activity. This paper proposes LedgerGuard, a tool\nto maintain ledger integrity by detecting corrupted blocks and recovering these\nblocks by synchronizing with rest of the network. The experimental\nimplementation of LedgerGuard is based on Hyperledger Fabric, which is a\npopular open source permissioned blockchain platform.",
        "author": [
            "Qi Zhang",
            "Petr Novotny",
            "Salman Baset",
            "Donna Dillenberger",
            "Artem Barger",
            "Yacov Manevich"
        ],
        "pdfLink": "http://arxiv.org/pdf/1805.01081v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1805.01081v1",
        "arXiv ID": "1805.01081v1"
    },
    {
        "title": "To EVM or Not to EVM: Blockchain Compatibility and Network Effects",
        "Published: ": "2022-08-18T03:01:20Z",
        "abstract": "We study the competition between blockchains in a \\emph{multi-chain}\nenvironment, where a dominant EVM-compatible blockchain (e.g., Ethereum)\nco-exists with an alternative EVM-compatible (e.g., Avalanche) and an\nEVM-incompatible (e.g., Algorand) blockchain. While EVM compatibility allows\nexisting Ethereum users and developers to migrate more easily over to the\nalternative layer-1, EVM incompatibility might allow the firms to build more\nloyal and ``sticky'' user base, and in turn a more robust ecosystem. As such,\nthe choice to be EVM-compatible is not merely a technological decision, but\nalso an important strategic decision. In this paper, we develop a game\ntheoretic model to study this competitive dynamic, and find that at\nequilibrium, new entrants/developers tend to adopt the dominant blockchain. To\navoid adoption failure, the alternative blockchains have to either (1) directly\nsubsidize the new entrant firms or (2) offer better features, which in practice\ncan take form in lower transaction costs, faster finality, or larger network\neffects. We find that it is easier for EVM-compatible blockchains to attract\nusers through direct subsidy, while it is more efficient for EVM-incompatible\nblockchains to attract users through offering better features/products.",
        "author": [
            "Ruizhe Jia",
            "Steven Yin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.10269v1.pdf",
        "Categories": [
            [
                "cs.GT",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.10269v1",
        "arXiv ID": "2208.10269v1"
    },
    {
        "title": "Blockchain Function Virtualization: A New Approach for Mobile Networks\n  Beyond 5G",
        "Published: ": "2022-05-19T04:01:00Z",
        "abstract": "Many of the key enabling technologies of the fifth-generation (5G), such as\nnetwork slicing, spectrum sharing, and federated learning, rely on a\ncentralized authority. This may lead to pitfalls in terms of security or single\npoint of failure. Distributed ledger technology, specifically blockchain, is\ncurrently employed by different applications related to the Internet of Things\n(IoT) and 5G to address the drawbacks of centralized systems. For this reason,\nmobile blockchain networks (MBNs) have recently attracted a great deal of\nattention. To add a transaction to the blockchain in MBNs, mobile or IoT users\nmust perform various tasks like encryption, decryption, and mining. These tasks\nrequire energy and processing power, which impose limitations on mobile and IoT\nusers' performance because they are usually battery powered and have a low\nprocessing power. One possible solution is to perform the tasks virtually on\ncommodity servers provided by mobile edge computing (MEC) or cloud computing.\nTo do so, all tasks needed to add a transaction to the blockchain can be\ntreated as virtual blockchain functions that can be executed on commodity\nservers. We introduce a blockchain virtualization framework called blockchain\nfunction virtualization (BFV), through which all blockchain functions can be\nperformed virtually by MEC or cloud computing. Furthermore, we describe\napplications of the BFV framework and resource allocation challenges brought by\nthe BFV framework in mobile networks. In addition, to illustrate the advantages\nof BFV, we define an optimization problem to simultaneously minimize the energy\nconsumption cost and maximize miners' rewards. Finally, simulation results show\nthe performance of the proposed framework in terms of total energy consumption,\ntransaction confirmation rate, and miners' average profit.",
        "author": [
            "Shiva Kazemi Taskou",
            "Mehdi Rasti",
            "Pedro H. J. Nardelli"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.11074v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.11074v1",
        "arXiv ID": "2206.11074v1"
    },
    {
        "title": "A Deep Error Correction Network for Compressed Sensing MRI",
        "Published: ": "2018-03-23T12:18:25Z",
        "abstract": "Compressed sensing for magnetic resonance imaging (CS-MRI) exploits image\nsparsity properties to reconstruct MRI from very few Fourier k-space\nmeasurements. The goal is to minimize any structural errors in the\nreconstruction that could have a negative impact on its diagnostic quality. To\nthis end, we propose a deep error correction network (DECN) for CS-MRI. The\nDECN model consists of three parts, which we refer to as modules: a guide, or\ntemplate, module, an error correction module, and a data fidelity module.\nExisting CS-MRI algorithms can serve as the template module for guiding the\nreconstruction. Using this template as a guide, the error correction module\nlearns a convolutional neural network (CNN) to map the k-space data in a way\nthat adjusts for the reconstruction error of the template image. Our\nexperimental results show the proposed DECN CS-MRI reconstruction framework can\nconsiderably improve upon existing inversion algorithms by supplementing with\nan error-correcting CNN.",
        "author": [
            "Liyan Sun",
            "Zhiwen Fan",
            "Yue Huang",
            "Xinghao Ding",
            "John Paisley"
        ],
        "pdfLink": "http://arxiv.org/pdf/1803.08763v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1803.08763v1",
        "arXiv ID": "1803.08763v1"
    },
    {
        "title": "BlockGC: A Joint Learning Framework for Account Identity Inference on\n  Blockchain with Graph Contrast",
        "Published: ": "2021-12-07T12:26:19Z",
        "abstract": "Blockchain technology has the characteristics of decentralization,\ntraceability and tamper proof, which creates a reliable decentralized\ntransaction mode, further accelerating the development of the blockchain\nplatforms. However, with the popularization of various financial applications,\nsecurity problems caused by blockchain digital assets, such as money\nlaundering, illegal fundraising and phishing fraud, are constantly on the rise.\nTherefore, financial security has become an important issue in the blockchain\necosystem, and identifying the types of accounts in blockchain (e.g. miners,\nphishing accounts, Ponzi contracts, etc.) is of great significance in risk\nassessment and market supervision. In this paper, we construct an account\ninteraction graph using raw blockchain data in a graph perspective, and\nproposes a joint learning framework for account identity inference on\nblockchain with graph contrast. We first capture transaction feature and\ncorrelation feature from interaction graph, and then perform sampling and data\naugmentation to generate multiple views for account subgraphs, finally jointly\ntrain the subgraph contrast and account classification task. Extensive\nexperiments on Ethereum datasets show that our method achieves significant\nadvantages in account identity inference task in terms of classification\nperformance, scalability and generalization.",
        "author": [
            "Jiajun Zhou",
            "Chenkai Hu",
            "Shenbo Gong",
            "Jiaying Xu",
            "Jie Shen",
            "Qi Xuan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.03659v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.03659v1",
        "arXiv ID": "2112.03659v1"
    },
    {
        "title": "Is Blockchain Hashing an Effective Method for Electronic Governance?",
        "Published: ": "2018-10-20T10:02:52Z",
        "abstract": "Governments across the world are testing different uses of the blockchain for\nthe delivery of their public services. Blockchain hashing - or the insertion of\ndata in the blockchain - is one of the potential applications of the blockchain\nin this space. With this method, users can apply special scripts to add their\ndata to blockchain transactions, ensuring both immutability and publicity.\nBlockchain hashing also secures the integrity of the original data stored on\ncentral governmental databases. The paper starts by analysing possible\nscenarios of hashing on the blockchain and assesses in which cases it may work\nand in which it is less likely to add value to a public administration. Second,\nthe paper also compares this method with traditional digital signatures using\nPKI (Public Key Infrastructure) and discusses standardisation in each domain.\nThird, it also addresses issues related to concepts such as distributed ledger\ntechnology and permissioned blockchains. Finally, it raises the question of\nwhether blockchain hashing is an effective solution for electronic governance,\nand concludes that its value is controversial, even if it is improved by PKI\nand other security measures. In this regard, we claim that governments need\nfirst to identify pain points in governance, and then consider the trade-offs\nof the blockchain as a potential solution versus other alternatives.",
        "author": [
            "Oleksii Konashevych",
            "Marta Poblet"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.08783v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.08783v1",
        "arXiv ID": "1810.08783v1"
    },
    {
        "title": "A Survey of State-of-the-Art on Blockchains: Theories, Modelings, and\n  Tools",
        "Published: ": "2020-07-07T14:50:32Z",
        "abstract": "To draw a roadmap of current research activities of the blockchain community,\nwe first conduct a brief overview of state-of-the-art blockchain surveys\npublished in the recent 5 years. We found that those surveys are basically\nstudying the blockchain-based applications, such as blockchain-assisted\nInternet of Things (IoT), business applications, security-enabled solutions,\nand many other applications in diverse fields. However, we think that a\ncomprehensive survey towards the essentials of blockchains by exploiting the\nstate-of-the-art theoretical modelings, analytic models, and useful experiment\ntools is still missing. To fill this gap, we perform a thorough survey by\nidentifying and classifying the most recent high-quality research outputs that\nare closely related to the theoretical findings and essential mechanisms of\nblockchain systems and networks. Several promising open issues are also\nsummarized finally for future research directions. We wish this survey can\nserve as a useful guideline for researchers, engineers, and educators about the\ncutting-edge development of blockchains in the perspectives of theories,\nmodelings, and tools.",
        "author": [
            "Huawei Huang",
            "Wei Kong",
            "Sicong Zhou",
            "Zibin Zheng",
            "Song Guo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.03520v2.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.03520v2",
        "arXiv ID": "2007.03520v2"
    },
    {
        "title": "Unveiling the Landscape of Smart Contract Vulnerabilities: A Detailed\n  Examination and Codification of Vulnerabilities in Prominent Blockchains",
        "Published: ": "2023-12-01T11:01:06Z",
        "abstract": "With the rise in using immature smart contract programming languages to build\na decentralized application, more vulnerabilities have been introduced to the\nBlockchain and were the main reasons behind critical financial losses.\nMoreover, the immutability of Blockchain technology makes deployed smart\ncontracts unfixable for the whole life of the Blockchain itself. The lack of\ncomplete and up-to-date resources that explain those vulnerabilities in detail\nhas also contributed to increasing the number of vulnerabilities in Blockchain.\nIn addition, the lack of a standardized nomination of the existing\nvulnerabilities has made redundant research and made developers more confused.\nTherefore, in this paper, we propose the most complete list of smart contract\nvulnerabilities that exist in the most popular Blockchains with a detailed\nexplanation of each one of them. In addition, we propose a new codification\nsystem that facilitates the communication of those vulnerabilities between\ndevelopers and researchers. This codification, help identify the most uncovered\nvulnerabilities to focus on in future research. Moreover, the discussed list of\nvulnerabilities covers multiple Blockchain and could be used for even future\nbuilt Blockchains.",
        "author": [
            "Oualid Zaazaa",
            "Hanan El Bakkali"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.00499v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.00499v1",
        "arXiv ID": "2312.00499v1"
    },
    {
        "title": "Security and Privacy for Healthcare Blockchains",
        "Published: ": "2021-06-11T02:47:36Z",
        "abstract": "Healthcare blockchains provide an innovative way to store healthcare\ninformation, execute healthcare transactions, and build trust for healthcare\ndata sharing and data integration in a decentralized open healthcare network\nenvironment. Although the healthcare blockchain technology has attracted broad\ninterests and attention in industry, government and academia, the security and\nprivacy concerns remain the focus of debate when deploying blockchains for\ninformation sharing in the healthcare sector from business operation to\nresearch collaboration. This paper focuses on the security and privacy\nrequirements for medical data sharing using blockchain, and provides a\ncomprehensive analysis of the security and privacy risks and requirements,\naccompanied by technical solution techniques and strategies. First, we discuss\nthe security and privacy requirements and attributes required for electronic\nmedical data sharing by deploying the healthcare blockchain. Second, we\ncategorize existing efforts into three reference blockchain usage scenarios for\nelectronic medical data sharing, and discuss the technologies for implementing\nthese security and privacy properties in the three categories of usage\nscenarios for healthcare blockchain, such as anonymous signatures,\nattribute-based encryption, zero-knowledge proofs, verification techniques for\nsmart contract security. Finally, we discuss other potential blockchain\napplication scenarios in healthcare sector. We conjecture that this survey will\nhelp healthcare professionals, decision makers, and healthcare service\ndevelopers to gain technical and intuitive insights into the security and\nprivacy of healthcare blockchains in terms of concepts, risks, requirements,\ndevelopment and deployment technologies and systems.",
        "author": [
            "Rui Zhang",
            "Rui Xue",
            "Ling Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.06136v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.06136v1",
        "arXiv ID": "2106.06136v1"
    },
    {
        "title": "Artificial Intelligence for the Metaverse: A Survey",
        "Published: ": "2022-02-15T03:34:56Z",
        "abstract": "Along with the massive growth of the Internet from the 1990s until now,\nvarious innovative technologies have been created to bring users breathtaking\nexperiences with more virtual interactions in cyberspace. Many virtual\nenvironments with thousands of services and applications, from social networks\nto virtual gaming worlds, have been developed with immersive experience and\ndigital transformation, but most are incoherent instead of being integrated\ninto a platform. In this context, metaverse, a term formed by combining meta\nand universe, has been introduced as a shared virtual world that is fueled by\nmany emerging technologies, such as fifth-generation networks and beyond,\nvirtual reality, and artificial intelligence (AI). Among such technologies, AI\nhas shown the great importance of processing big data to enhance immersive\nexperience and enable human-like intelligence of virtual agents. In this\nsurvey, we make a beneficial effort to explore the role of AI in the foundation\nand development of the metaverse. We first deliver a preliminary of AI,\nincluding machine learning algorithms and deep learning architectures, and its\nrole in the metaverse. We then convey a comprehensive investigation of AI-based\nmethods concerning six technical aspects that have potentials for the\nmetaverse: natural language processing, machine vision, blockchain, networking,\ndigital twin, and neural interface, and being potential for the metaverse.\nSubsequently, several AI-aided applications, such as healthcare, manufacturing,\nsmart cities, and gaming, are studied to be deployed in the virtual worlds.\nFinally, we conclude the key contribution of this survey and open some future\nresearch directions in AI for the metaverse.",
        "author": [
            "Thien Huynh-The",
            "Quoc-Viet Pham",
            "Xuan-Qui Pham",
            "Thanh Thi Nguyen",
            "Zhu Han",
            "Dong-Seong Kim"
        ],
        "pdfLink": "http://arxiv.org/pdf/2202.10336v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2202.10336v1",
        "arXiv ID": "2202.10336v1"
    },
    {
        "title": "The Convergence of Blockchain, IoT and 6G: Potential, Opportunities,\n  Challenges and Research Roadmap",
        "Published: ": "2021-09-07T16:28:21Z",
        "abstract": "The world is undergoing a profound transformation with the advent of\nintelligent information era. 6G networks envisioned being the game changer in\nnext generation wireless communication systems that will address the challenges\nof limited information speed escalated with the augmentation of billions of\ndata applications encountered by the current fifth generation (5G) networks.\nSome key radical technologies in 6G together with existing 5G candidate schemes\nwill guarantee the expected quality of experience (QoE) to attain ubiquitous\nwireless connectivity for the Internet of Everything (IoE) ranging from the\ntelecom industry to digital smart industries. Blockchain technology (BCT) has\ngained significant attention due to undertake the decentralization,\ntransparency, spectrum resource scarcity, inherent privacy and security, poor\ninteroperability, confidentiality, and emerging smart applications domains\nincluding Industrial IoT and Industry 4.0. The mismatch between the\nrequirements of many data intensive disruptive IoT applications and 5G network\ncapabilities steered the demand of decentralized BCT based 6G architecture.\nInspired by these facts, this paper studies an extensive survey to draw a new\ndirection of blockchain integration into 6G mobile networks, IoT technologies,\nand smart industries focusing the potential merits and challenges in terms of\ninfrastructure sharing, computational loads, latency, bandwidth overhead,\nbusiness model, sustainability goals, and edge intelligence. We highlighted the\nconvergence of IoT in blockchain to enable intelligent distribution in future\nindustrial IoT and the technical model of 6G networks to realize the successful\ndeployment of BCT schemes. This paper pointed out the current intriguing\nchallenges, canvassed the mitigation techniques, and plausible future research\nopportunities that may benefit the pursuit of this vision.",
        "author": [
            "Abu Jahid",
            "Mohammed H. Alsharif",
            "Trevor J. Hall"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.03184v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.03184v1",
        "arXiv ID": "2109.03184v1"
    },
    {
        "title": "A position paper on GDPR compliance in sharded blockchains: rehash of\n  old ideas or new interesting challenges?",
        "Published: ": "2020-11-02T22:48:48Z",
        "abstract": "Sharding has emerged as one of the common techniques to address the\nscalability problems of blockchain systems. To this end, various sharding\ntechniques for blockchain systems have been proposed in the literature. When\nsharded blockchains process personal data, the data controllers and the data\nprocessors associated with the sharded blockchains need to be compliant with\nthe General Data Protection Regulation (GDPR). To this end, this article makes\nthe first attempt to address the following key question: to what extent the\nexisting techniques developed by different communities such as the distributed\ncomputing community, the distributed systems community, the database community,\nidentity and access control community and the dependability community can be\nused by the data controllers and data processors for complying with the GDPR\nrequirements of data subject rights in sharded blockchains? As part of\nanswering this question, this article argues that there is a need for\ncross-disciplinary research towards finding optimal solutions for implementing\nthe data subject rights in sharded blockchains.",
        "author": [
            "Narasimha Raghavan Veeraragavan",
            "Kaiwen Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.01367v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.01367v1",
        "arXiv ID": "2011.01367v1"
    },
    {
        "title": "Ledgerdata Refiner: A Powerful Ledger Data Query Platform for\n  Hyperledger Fabric",
        "Published: ": "2019-12-10T06:24:01Z",
        "abstract": "Blockchain is one of the most popular distributed ledger technologies. It can\nsolve the trust issue among enterprises. Hyperledger Fabric is a permissioned\nblockchain aiming at enterprise-grade business applications. However, compared\nto traditional distributed database solutions, one issue of blockchain based\napplication development is the limited data access. For Fabric, the ledger data\ncan only be retrieved by limited interfaces provided by Fabric SDKs or\nchaincode. In order to meet the requirements of data query and provide flexible\nquery functions for real applications built on Fabric, this paper proposed a\nledger data query platform called Ledgerdata Refiner. With ledger data analysis\nmiddleware, we provide sufficient interfaces for users to retrieve block or\ntransaction efficiently. It is also able to track historical operations for any\nspecific state. In addition, schemas of ledger state have been analyzed and\nclustered, which enable users to perform rich queries against ledger data.\nFinally, we validate the effectiveness of our query platform on a real\napplication.",
        "author": [
            "Ence Zhou",
            "Haoli Sun",
            "Bingfeng Pi",
            "Jun Sun",
            "Kazuhiro Yamashita",
            "Yoshihide Nomura"
        ],
        "pdfLink": "http://arxiv.org/pdf/1912.04526v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1912.04526v1",
        "arXiv ID": "1912.04526v1"
    },
    {
        "title": "Design Guidelines for Blockchain-Assisted 5G-UAV Networks",
        "Published: ": "2020-07-30T08:00:32Z",
        "abstract": "Fifth Generation (5G) wireless networks are designed to meet various end-user\nQuality of Service (QoS) requirements through high data rates (typically of\nGbps order) and low latencies. Coupled with Fog and Mobile Edge Computing\n(MEC), 5G can achieve high data rates, enabling complex autonomous smart city\nservices such as the large deployment of self-driving vehicles and large-scale\nArtificial Intelligence (AI)-enabled industrial manufacturing. However, to meet\nthe exponentially growing number of connected IoT devices and irregular data\nand service requests in both low and highly dense locations, the process of\nenacting traditional cells supported through fixed and costly base stations\nrequires rethought to enable on-demand mobile access points in the form of\nUnmanned Aerial Vehicles (UAV) for diversified smart city scenarios. This\narticle envisions a 5G network environment that is supported by\nblockchain-enabled UAVs to meet dynamic user demands with network access\nsupply. The solution enables decentralized service delivery (Drones as a\nService) and routing to and from end-users in a reliable and secure manner.\nBoth public and private blockchains are deployed within the UAVs, supported by\nfog and cloud computing devices and data centers to provide wide range of\ncomplex authenticated service and data availability. Particular attention is\npaid tocomparing data delivery success rates and message exchange in the\nproposed solution against traditional UAV-supported cellular networks.\nChallenges and future research are also discussed with highlights on emerging\ntechnologies such as Federated Learning.",
        "author": [
            "Moayad Aloqaily",
            "Ouns Bouachir",
            "Azzedine Boukerche",
            "Ismaeel Al Ridhawi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.15286v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.15286v1",
        "arXiv ID": "2007.15286v1"
    },
    {
        "title": "Big Geo Data Surface Approximation using Radial Basis Functions: A\n  Comparative Study",
        "Published: ": "2018-06-20T13:13:41Z",
        "abstract": "Approximation of scattered data is often a task in many engineering problems.\nThe Radial Basis Function (RBF) approximation is appropriate for big scattered\ndatasets in $n-$dimensional space. It is a non-separable approximation, as it\nis based on the distance between two points. This method leads to the solution\nof an overdetermined linear system of equations.\n  In this paper the RBF approximation methods are briefly described, a new\napproach to the RBF approximation of big datasets is presented, and a\ncomparison for different Compactly Supported RBFs (CS-RBFs) is made with\nrespect to the accuracy of the computation. The proposed approach uses symmetry\nof a matrix, partitioning the matrix into blocks and data structures for\nstorage of the sparse matrix. The experiments are performed for synthetic and\nreal datasets.",
        "author": [
            "Zuzana Majdisova",
            "Vaclav Skala"
        ],
        "pdfLink": "http://arxiv.org/pdf/1806.07884v1.pdf",
        "Categories": [
            [
                "cs.CE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1806.07884v1",
        "arXiv ID": "1806.07884v1"
    },
    {
        "title": "Enabling Enterprise Blockchain Interoperability with Trusted Data\n  Transfer (industry track)",
        "Published: ": "2019-11-04T07:43:28Z",
        "abstract": "The adoption of permissioned blockchain networks in enterprise settings has\nseen an increase in growth over the past few years. While encouraging, this is\nleading to the emergence of new data, asset and process silos limiting the\npotential value these networks bring to the broader ecosystem. Mechanisms for\nenabling network interoperability help preserve the benefits of independent\nsovereign networks, while allowing for the transfer or sharing of data, assets\nand processes across network boundaries. However, a naive approach to\ninteroperability based on traditional point-to-point integration is\ninsufficient for preserving the underlying trust decentralized networks\nprovide. In this paper, we lay the foundation for an approach to\ninteroperability based on a communication protocol that derives trust from the\nunderlying network consensus protocol. We present an architecture and a set of\nbuilding blocks that can be adapted for use in a range of network\nimplementations and demonstrate a proof-of-concept for trusted data-sharing\nbetween two independent trade finance and supply-chain networks, each running\non Hyperledger Fabric. We show how existing blockchain deployments can be\nadapted for interoperation and discuss the security and extensibility of our\narchitecture and mechanisms.",
        "author": [
            "Ermyas Abebe",
            "Dushyant Behl",
            "Chander Govindarajan",
            "Yining Hu",
            "Dileban Karunamoorthy",
            "Petr Novotny",
            "Vinayaka Pandit",
            "Venkatraman Ramakrishna",
            "Christian Vecchiola"
        ],
        "pdfLink": "http://arxiv.org/pdf/1911.01064v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1911.01064v1",
        "arXiv ID": "1911.01064v1"
    },
    {
        "title": "Deep Attentive Wasserstein Generative Adversarial Networks for MRI\n  Reconstruction with Recurrent Context-Awareness",
        "Published: ": "2020-06-23T11:50:21Z",
        "abstract": "The performance of traditional compressive sensing-based MRI (CS-MRI)\nreconstruction is affected by its slow iterative procedure and noise-induced\nartefacts. Although many deep learning-based CS-MRI methods have been proposed\nto mitigate the problems of traditional methods, they have not been able to\nachieve more robust results at higher acceleration factors. Most of the deep\nlearning-based CS-MRI methods still can not fully mine the information from the\nk-space, which leads to unsatisfactory results in the MRI reconstruction. In\nthis study, we propose a new deep learning-based CS-MRI reconstruction method\nto fully utilise the relationship among sequential MRI slices by coupling\nWasserstein Generative Adversarial Networks (WGAN) with Recurrent Neural\nNetworks. Further development of an attentive unit enables our model to\nreconstruct more accurate anatomical structures for the MRI data. By\nexperimenting on different MRI datasets, we have demonstrated that our method\ncan not only achieve better results compared to the state-of-the-arts but can\nalso effectively reduce residual noise generated during the reconstruction\nprocess.",
        "author": [
            "Yifeng Guo",
            "Chengjia Wang",
            "Heye Zhang",
            "Guang Yang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.12915v1.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.12915v1",
        "arXiv ID": "2006.12915v1"
    },
    {
        "title": "Blockchain-Based and Fuzzy Logic-Enabled False Data Discovery for the\n  Intelligent Autonomous Vehicular System",
        "Published: ": "2023-08-18T01:47:52Z",
        "abstract": "Since the beginning of this decade, several incidents report that false data\ninjection attacks targeting intelligent connected vehicles cause huge\nindustrial damage and loss of lives. Data Theft, Flooding, Fuzzing, Hijacking,\nMalware Spoofing and Advanced Persistent Threats have been immensely growing\nattack that leads to end-user conflict by abolishing trust on autonomous\nvehicle. Looking after those sensitive data that contributes to measure the\nlocalisation factors of the vehicle, conventional centralised techniques can be\nmisused to update the legitimate vehicular status maliciously. As investigated,\nthe existing centralized false data detection approach based on state and\nlikelihood estimation has a reprehensible trade-off in terms of accuracy,\ntrust, cost, and efficiency. Blockchain with Fuzzy-logic Intelligence has shown\nits potential to solve localisation issues, trust and false data detection\nchallenges encountered by today's autonomous vehicular system. The proposed\nBlockchain-based fuzzy solution demonstrates a novel false data detection and\nreputation preservation technique. The illustrated proposed model filters false\nand anomalous data based on the vehicles' rules and behaviours. Besides\nimproving the detection accuracy and eliminating the single point of failure,\nthe contributions include appropriating fuzzy AI functions within the Road-side\nUnit node before authorizing status data by a Blockchain network. Finally,\nthorough experimental evaluation validates the effectiveness of the proposed\nmodel.",
        "author": [
            "Ziaur Rahman",
            "Xun Yi",
            "Ibrahim Khalil",
            "Adnan Anwar",
            "Shantanu Pal"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.09237v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "11T71, 68T05",
                "E.3.1; I.2.1"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.09237v1",
        "arXiv ID": "2308.09237v1"
    },
    {
        "title": "Impact of Scaled Image on Robustness of Deep Neural Networks",
        "Published: ": "2022-09-02T08:06:58Z",
        "abstract": "Deep neural networks (DNNs) have been widely used in computer vision tasks\nlike image classification, object detection and segmentation. Whereas recent\nstudies have shown their vulnerability to manual digital perturbations or\ndistortion in the input images. The accuracy of the networks is remarkably\ninfluenced by the data distribution of their training dataset. Scaling the raw\nimages creates out-of-distribution data, which makes it a possible adversarial\nattack to fool the networks. In this work, we propose a Scaling-distortion\ndataset ImageNet-CS by Scaling a subset of the ImageNet Challenge dataset by\ndifferent multiples. The aim of our work is to study the impact of scaled\nimages on the performance of advanced DNNs. We perform experiments on several\nstate-of-the-art deep neural network architectures on the proposed ImageNet-CS,\nand the results show a significant positive correlation between scaling size\nand accuracy decline. Moreover, based on ResNet50 architecture, we demonstrate\nsome tests on the performance of recent proposed robust training techniques and\nstrategies like Augmix, Revisiting and Normalizer Free on our proposed\nImageNet-CS. Experiment results have shown that these robust training\ntechniques can improve networks' robustness to scaling transformation.",
        "author": [
            "Chengyin Hu",
            "Weiwen Shi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.02132v2.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.02132v2",
        "arXiv ID": "2209.02132v2"
    },
    {
        "title": "How To Optimize My Blockchain? A Multi-Level Recommendation Approach",
        "Published: ": "2023-01-11T20:59:51Z",
        "abstract": "Aside from the conception of new blockchain architectures, existing\nblockchain optimizations in the literature primarily focus on system or\ndata-oriented optimizations within prevailing blockchains. However, since\nblockchains handle multiple aspects ranging from organizational governance to\nsmart contract design, a holistic approach that encompasses all the different\nlayers of a given blockchain system is required to ensure that all optimization\nopportunities are taken into consideration. In this vein, we define a\nmulti-level optimization recommendation approach that identifies optimization\nopportunities within a blockchain at the system, data, and user level. Multiple\nmetrics and attributes are derived from a blockchain log and nine optimization\nrecommendations are formalized. We implement an automated optimization\nrecommendation tool, BlockOptR, based on these concepts. The system is\nextensively evaluated with a wide range of workloads covering multiple\nreal-world scenarios. After implementing the recommended optimizations, we\nobserve an average of 20% improvement in the success rate of transactions and\nan average of 40% improvement in latency.",
        "author": [
            "Jeeta Ann Chacko",
            "Ruben Mayer",
            "Hans-Arno Jacobsen"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.04719v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.04719v1",
        "arXiv ID": "2301.04719v1"
    },
    {
        "title": "Unlocking Metaverse-as-a-Service The three pillars to watch: Privacy and\n  Security, Edge Computing, and Blockchain",
        "Published: ": "2023-01-01T15:34:18Z",
        "abstract": "In this article, the authors provide a comprehensive overview on three core\npillars of metaverse-as-a-service (MaaS) platforms; privacy and security, edge\ncomputing, and blockchain technology. The article starts by investigating\nsecurity aspects for the wireless access to the metaverse. Then it goes through\nthe privacy and security issues inside the metaverse from data-centric,\nlearning-centric, and human-centric points-of-view. The authors address private\nand secure mechanisms for privatizing sensitive data attributes and securing\nmachine learning algorithms running in a distributed manner within the\nmetaverse platforms. Novel visions and less-investigated methods are reviewed\nto help mobile network operators and metaverse service providers facilitate the\nrealization of secure and private MaaS through different layers of the\nmetaverse, ranging from the access layer to the social interactions among\nclients. Later in the article, it has been explained how the paradigm of edge\ncomputing can strengthen different aspects of the metaverse. Along with that,\nthe challenges of using edge computing in the metaverse have been\ncomprehensively investigated. Additionally, the paper has comprehensively\ninvestigated and analyzed 10 main challenges of MaaS platforms and thoroughly\ndiscussed how blockchain technology provides solutions for these constraints.\nAt the final, future vision and directions, such as content-centric security\nand zero-trust metaverse, some blockchain's unsolved challenges are also\ndiscussed to bring further insights for the network designers in the metaverse\nera.",
        "author": [
            "Vesal Ahsani",
            "Ali Rahimi",
            "Mehdi Letafati",
            "Babak Hossein Khalaj"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.01221v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.01221v2",
        "arXiv ID": "2301.01221v2"
    },
    {
        "title": "Privacy by design in big data: An overview of privacy enhancing\n  technologies in the era of big data analytics",
        "Published: ": "2015-12-18T15:52:59Z",
        "abstract": "The extensive collection and processing of personal information in big data\nanalytics has given rise to serious privacy concerns, related to wide scale\nelectronic surveillance, profiling, and disclosure of private data. To reap the\nbenefits of analytics without invading the individuals' private sphere, it is\nessential to draw the limits of big data processing and integrate data\nprotection safeguards in the analytics value chain. ENISA, with the current\nreport, supports this approach and the position that the challenges of\ntechnology (for big data) should be addressed by the opportunities of\ntechnology (for privacy).\n  We first explain the need to shift from \"big data versus privacy\" to \"big\ndata with privacy\". In this respect, the concept of privacy by design is key to\nidentify the privacy requirements early in the big data analytics value chain\nand in subsequently implementing the necessary technical and organizational\nmeasures.\n  After an analysis of the proposed privacy by design strategies in the\ndifferent phases of the big data value chain, we review privacy enhancing\ntechnologies of special interest for the current and future big data landscape.\nIn particular, we discuss anonymization, the \"traditional\" analytics technique,\nthe emerging area of encrypted search and privacy preserving computations,\ngranular access control mechanisms, policy enforcement and accountability, as\nwell as data provenance issues. Moreover, new transparency and access tools in\nbig data are explored, together with techniques for user empowerment and\ncontrol.\n  Achieving \"big data with privacy\" is no easy task and a lot of research and\nimplementation is still needed. Yet, it remains a possible task, as long as all\nthe involved stakeholders take the necessary steps to integrate privacy and\ndata protection safeguards in the heart of big data, by design and by default.",
        "author": [
            "Giuseppe D'Acquisto",
            "Josep Domingo-Ferrer",
            "Panayiotis Kikiras",
            "Vicen\u00e7 Torra",
            "Yves-Alexandre de Montjoye",
            "Athena Bourka"
        ],
        "pdfLink": "http://arxiv.org/pdf/1512.06000v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "94A60",
                "K.4.1; D.4.6; H.2.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/1512.06000v1",
        "arXiv ID": "1512.06000v1"
    },
    {
        "title": "OpenDSU: Digital Sovereignty in PharmaLedger",
        "Published: ": "2022-09-29T15:43:31Z",
        "abstract": "Distributed ledger networks, chiefly those based on blockchain technologies,\ncurrently are heralding a next generation of computer systems that aims to suit\nmodern users' demands. Over the recent years, several technologies for\nblockchains, off-chaining strategies, as well as decentralised and respectively\nself-sovereign identity systems have shot up so fast that standardisation of\nthe protocols is lagging behind, severely hampering the interoperability of\ndifferent approaches. Moreover, most of the currently available solutions for\ndistributed ledgers focus on either home users or enterprise use case\nscenarios, failing to provide integrative solutions addressing the needs of\nboth.\n  Herein we introduce the OpenDSU platform that allows to interoperate generic\nblockchain technologies, organised - and possibly cascaded in a hierarchical\nfashion - in domains. To achieve this flexibility, we seamlessly integrated a\nset of well conceived OpenDSU components to orchestrate off-chain data with\ngranularly resolved and cryptographically secure access levels that are nested\nwith sovereign identities across the different domains.\n  Employing our platform to PharmaLedger, an inter-European network for the\nstandardisation of data handling in the pharmaceutical industry and in\nhealthcare, we demonstrate that OpenDSU can cope with generic demands of\nheterogeneous use cases in both, performance and handling substantially\ndifferent business policies. Importantly, whereas available solutions commonly\nrequire a pre-defined and fixed set of components, no such vendor lock-in\nrestrictions on the blockchain technology or identity system exist in OpenDSU,\nmaking systems built on it flexibly adaptable to new standards evolving in the\nfuture.",
        "author": [
            "Cosmin Ursache",
            "Michael Sammeth",
            "S\u00eenic\u0103 Alboaie"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.14879v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.NI",
                "cs.SI",
                "cs.SY",
                "eess.SY",
                "68M14 (Primary) 91D30, 68Q60 (Secondary)",
                "C.2; F.2; G.2; G.3; H.2; I.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.14879v1",
        "arXiv ID": "2209.14879v1"
    },
    {
        "title": "Blockchain Oracle Design Patterns",
        "Published: ": "2021-06-17T10:08:49Z",
        "abstract": "Blockchain is a form of distributed ledger technology (DLT) where data is\nshared among users connected over the internet. Transactions are data state\nchanges on the blockchain that are permanently recorded in a secure and\ntransparent way without the need of a third party. Besides, the introduction of\nsmart contracts to the blockchain has added programmability to the blockchain\nand revolutionized the software ecosystem leading toward decentralized\napplications (DApps) attracting businesses and organizations to employ this\ntechnology. Although promising, blockchains and smart contracts have no access\nto the external systems (i.e., off-chain) where real-world data and events\nresides; consequently, the usability of smart contracts in terms of performance\nand programmability would be limited to the on-chain data. Hence,\n\\emph{blockchain oracles} are introduced to mitigate the issue and are defined\nas trusted third-party services that send and verify the external information\n(i.e., feedback) and submit it to smart contracts for triggering state changes\nin the blockchain. In this paper, we will study and analyze blockchain oracles\nwith regard to how they provide feedback to the blockchain and smart contracts.\nWe classify the blockchain oracle techniques into two major groups such as\nvoting-based strategies and reputation-based ones. The former mainly relies on\nparticipants' stakes for outcome finalization while the latter considers\nreputation in conjunction with authenticity proof mechanisms for data\ncorrectness and integrity. We then provide a structured description of patterns\nin detail for each classification and discuss research directions in the end.",
        "author": [
            "Amirmohammad Pasdar",
            "Zhongli Dong",
            "Young Choon Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.09349v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.09349v1",
        "arXiv ID": "2106.09349v1"
    },
    {
        "title": "Exploring the data of blockchain-based metaverses",
        "Published: ": "2023-08-31T15:03:44Z",
        "abstract": "In recent years the concept of metaverse has evolved in the attempt of\ndefining richer immersive and interactive environments supporting various types\nof virtual experiences and interactions among users. This has led to the\nemergence of various different metaverse platforms that utilize blockchain\ntechnology and non-fungible tokens (NFTs) to establish ownership of metaverse\nelements and attach features and information to it. This article will delve\ninto the heterogeneity of the data involved in these metaverse platforms, as\nwell as highlight some dynamics and features of them. Moreover, the paper\nintroduces a metaverse analysis tool developed by the authors, which leverages\nmachine learning techniques to collect and analyze daily data, including\nblockchain transactions, platform-specific metadata, and social media trends.\nExperimental results are reported are presented with a use-case scenario\nfocused on the trading of digital parcels, commonly referred to as metaverse\nreal estate.",
        "author": [
            "Simone Casale-Brunet",
            "Leonardo Chiariglione",
            "Marco Mattavelli"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.16787v1.pdf",
        "Categories": [
            [
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.16787v1",
        "arXiv ID": "2308.16787v1"
    },
    {
        "title": "Medusa: Blockchain Powered Log Storage System",
        "Published: ": "2020-02-10T08:08:22Z",
        "abstract": "Blockchain is one of the most heavily invested technologies in recent years.\nDue to its tamper-proof and decentralization properties, blockchain has become\nan ideal utility for data storage that is applicable in many real world\nindustrial scenarios. One important scenario is web log, which is treated as\nsources of technical significance and commercial revenues in major internet\ncompanies. In this paper, we illustrate our design of a web log storage system\nbased on HyperLedger. HyperLedger yields higher throughput and lower latency\ncompared with other blockchain systems. Alongside its efficiency advantages,\nHyperLeger is a permissioned blockchain, which is an ideal fit for enterprise\nsoftware design scenario.",
        "author": [
            "Hao Wang",
            "Desheng Yang",
            "Nian Duan",
            "Yang Guo",
            "Lu Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2002.03588v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.GT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2002.03588v1",
        "arXiv ID": "2002.03588v1"
    },
    {
        "title": "Challenges and pitfalls of partitioning blockchains",
        "Published: ": "2018-04-19T20:03:30Z",
        "abstract": "Blockchain has received much attention in recent years. This immense\npopularity has raised a number of concerns, scalability of blockchain systems\nbeing a common one. In this paper, we seek to understand how Ethereum, a\nwell-established blockchain system, would respond to sharding. Sharding is a\nprevalent technique to increase the scalability of distributed systems. To\nunderstand how sharding would affect Ethereum, we model Ethereum blockchain as\na graph and evaluate five methods to partition the graph. We analyze the\nresults using three metrics: the balance among shards, the number of\ntransactions that would involve multiple shards, and the amount of data that\nwould be relocated across shards upon a repartitioning of the system.",
        "author": [
            "Enrique Fynn",
            "Fernando Pedone"
        ],
        "pdfLink": "http://arxiv.org/pdf/1804.07356v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1804.07356v2",
        "arXiv ID": "1804.07356v2"
    },
    {
        "title": "Enhancing Data Security for Cloud Computing Applications through\n  Distributed Blockchain-based SDN Architecture in IoT Networks",
        "Published: ": "2022-11-28T02:43:47Z",
        "abstract": "Blockchain (BC) and Software Defined Networking (SDN) are some of the most\nprominent emerging technologies in recent research. These technologies provide\nsecurity, integrity, as well as confidentiality in their respective\napplications. Cloud computing has also been a popular comprehensive technology\nfor several years. Confidential information is often shared with the cloud\ninfrastructure to give customers access to remote resources, such as\ncomputation and storage operations. However, cloud computing also presents\nsubstantial security threats, issues, and challenges. Therefore, to overcome\nthese difficulties, we propose integrating Blockchain and SDN in the cloud\ncomputing platform. In this research, we introduce the architecture to better\nsecure clouds. Moreover, we leverage a distributed Blockchain approach to\nconvey security, confidentiality, privacy, integrity, adaptability, and\nscalability in the proposed architecture. BC provides a distributed or\ndecentralized and efficient environment for users. Also, we present an SDN\napproach to improving the reliability, stability, and load balancing\ncapabilities of the cloud infrastructure. Finally, we provide an experimental\nevaluation of the performance of our SDN and BC-based implementation using\ndifferent parameters, also monitoring some attacks in the system and proving\nits efficacy.",
        "author": [
            "Anichur Rahman",
            "Md. Jahidul Islam",
            "Rafiqul Islam",
            "Ayesha Aziz",
            "Dipanjali Kundu",
            "Sadia Sazzad",
            "Md. Razaul Karim",
            "Mahedi Hasan",
            "Ziaur Rahman",
            "Said Elnaffar",
            "Shahab S. Band"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.15013v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "E.3"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.15013v1",
        "arXiv ID": "2211.15013v1"
    },
    {
        "title": "SimBlock: A Blockchain Network Simulator",
        "Published: ": "2019-01-28T16:25:32Z",
        "abstract": "Blockchain, which is a technology for distributedly managing ledger\ninformation over multiple nodes without a centralized system, has elicited\nincreasing attention. Performing experiments on actual blockchains are\ndifficult because a large number of nodes in wide areas are necessary. In this\nstudy, we developed a blockchain network simulator SimBlock for such\nexperiments. Unlike the existing simulators, SimBlock can easily change\nbehavior of node, so that it enables to investigate the influence of nodes'\nbehavior on blockchains. We compared some simulation results with the measured\nvalues in actual blockchains to demonstrate the validity of this simulator.\nFurthermore, to show practical usage, we conducted two experiments which\nclarify the influence of neighbor node selection algorithms and relay networks\non the block propagation time. The simulator could depict the effects of the\ntwo techniques on block propagation time. The simulator will be publicly\navailable in a few months.",
        "author": [
            "Yusuke Aoki",
            "Kai Otsuki",
            "Takeshi Kaneko",
            "Ryohei Banno",
            "Kazuyuki Shudo"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.09777v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.09777v2",
        "arXiv ID": "1901.09777v2"
    },
    {
        "title": "$\u03c0$QLB: A Privacy-preserving with Integrity-assuring Query Language\n  for Blockchain",
        "Published: ": "2022-12-29T01:12:47Z",
        "abstract": "The increase in the adoption of blockchain technology in different\napplication domains e.g., healthcare systems, supplychain management, has\nraised the demand for a data query mechanism on blockchain. Since current\nblockchain systems lack the support for querying data with embedded security\nand privacy guarantees, there exists inherent security and privacy concerns on\nthose systems. In particular, existing systems require users to submit queries\nto blockchain operators (e.g., a node validator) in plaintext. This directly\njeopardizes users' privacy as the submitted queries may contain sensitive\ninformation, e.g., location or gender preferences, that the users may not be\ncomfortable sharing. On the other hand, currently, the only way for users to\nensure integrity of the query result is to maintain the entire blockchain\ndatabase and perform the queries locally. Doing so incurs high storage and\ncomputational costs on the users, precluding this approach to be practically\ndeployable on common light-weight devices (e.g., smartphones). To this end,\nthis paper proposes $\\pi$QLB, a query language for blockchain systems that\nensures both confidentiality of query inputs and integrity of query results.\nAdditionally, $\\pi$QLB enables SQL-like queries over the blockchain data by\nintroducing relational data semantics into the existing blockchain database.\n$\\pi$QLB has applied the recent cryptography primitive, i.e., function secret\nsharing (FSS), to achieve confidentiality. To support integrity, we extend the\ntraditional FSS setting in such a way that integrity of FSS results can be\nefficiently verified. Successful verification indicates absence of malicious\nbehaviors on the servers, allowing the user to establish trust from the result.\nTo the best of our knowledge, $\\pi$QLB is the first query model designed for\nblockchain databases with support for confidentiality, integrity, and SQL-like\nqueries.",
        "author": [
            "Nasrin Sohrabi",
            "Norrathep Rattanavipanon",
            "Zahir Tari"
        ],
        "pdfLink": "http://arxiv.org/pdf/2212.14141v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2212.14141v1",
        "arXiv ID": "2212.14141v1"
    },
    {
        "title": "BlendSM-DDM: BLockchain-ENabled Secure Microservices for Decentralized\n  Data Marketplaces",
        "Published: ": "2019-09-21T15:24:23Z",
        "abstract": "To promote the benefits of the Internet of Things (IoT) in smart communities\nand smart cities, a real-time data marketplace middleware platform, called the\nIntelligent IoT Integrator (I3), has been recently proposed. While facilitating\nthe easy exchanges of real-time IoT data streams between device owners and\nthird-party applications through the marketplace, I3 is presently a monolithic,\ncentralized platform for a single community. Although the service oriented\narchitecture (SOA) has been widely adopted in the IoT and cyber-physical\nsystems (CPS), it is difficult for a monolithic architecture to provide\nscalable, inter-operable and extensible services for large numbers of\ndistributed IoT devices and different application vendors. Traditional security\nsolutions rely on a centralized authority, which can be a performance\nbottleneck or susceptible to a single point of failure. Inspired by\ncontainerized microservices and blockchain technology, this paper proposed a\nBLockchain-ENabled Secure Microservices for Decentralized Data Marketplaces\n(BlendSM-DDM). Within a permissioned blockchain network, a microservices based\nsecurity mechanism is introduced to secure data exchange and payment among\nparticipants in the marketplace. BlendSM-DDM is able to offer a decentralized,\nscalable and auditable data exchanges for the data marketplace.",
        "author": [
            "Ronghua Xu",
            "Gowri Sankar Ramachandran",
            "Yu Chen",
            "Bhaskar Krishnamachari"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.10888v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.10888v1",
        "arXiv ID": "1909.10888v1"
    },
    {
        "title": "TrustVault: A privacy-first data wallet for the European Blockchain\n  Services Infrastructure",
        "Published: ": "2022-10-06T15:23:55Z",
        "abstract": "The European Union is on course to introduce a European Digital Identity that\nwill be available to all EU citizens and businesses. This will have a huge\nimpact on how citizens and businesses interact online. Big Tech companies\ncurrently dictate how digital identities are used. As a result, they have\namassed vast amounts of private user data. Movements like Self-Sovereign\nIdentity aim to give users control over their online identity. TrustVault is\nthe first data wallet that gives users back control of their identity and all\ntheir data. TrustVault allows users to store all their data on their\nsmartphones and control with whom they share it. The user has fine-grained\naccess control based on verifiable user attributes. EBSI connects TrustVault to\nthe European Self-Sovereign Identity Framework allowing users to use Verifiable\nCredentials from public and private institutions in their access control\npolicies. The system is serverless and has no Trusted Third Parties. TrustVault\nreplaces the for-profit infrastructure of Big Tech with a public and\ntransparent platform for innovation.",
        "author": [
            "Sharif Jacobino",
            "Johan Pouwelse"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.02987v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.02987v1",
        "arXiv ID": "2210.02987v1"
    },
    {
        "title": "Blockchain-based Digital Twins: Research Trends, Issues, and Future\n  Challenges",
        "Published: ": "2021-03-22T05:13:48Z",
        "abstract": "Industrial processes rely on sensory data for decision-making processes, risk\nassessment, and performance evaluation. Extracting actionable insights from the\ncollected data calls for an infrastructure that can ensure the dissemination of\ntrustworthy data. For the physical data to be trustworthy, it needs to be\ncross-validated through multiple sensor sources with overlapping fields of\nview. Cross-validated data can then be stored on the blockchain, to maintain\nits integrity and trustworthiness. Once trustworthy data is recorded on the\nblockchain, product lifecycle events can be fed into data-driven systems for\nprocess monitoring, diagnostics, and optimized control. In this regard, Digital\nTwins (DTs) can be leveraged to draw intelligent conclusions from data by\nidentifying the faults and recommending precautionary measures ahead of\ncritical events. Empowering DTs with blockchain in industrial use-cases targets\nkey challenges of disparate data repositories, untrustworthy data\ndissemination, and the need for predictive maintenance. In this survey, while\nhighlighting the key benefits of using blockchain-based DTs, we present a\ncomprehensive review of the state-of-the-art research results for\nblockchain-based DTs. Based on the current research trends, we discuss a\ntrustworthy blockchain-based DTs framework. We highlight the role of Artificial\nIntelligence (AI) in blockchain-based DTs. Furthermore, we discuss current and\nfuture research and deployment challenges of blockchain-supported DTs that\nrequire further investigation.",
        "author": [
            "Sabah Suhail",
            "Rasheed Hussain",
            "Raja Jurdak",
            "Alma Oracevic",
            "Khaled Salah",
            "Raimundas Matulevi\u010dius",
            "Choong Seon Hong"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.11585v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.11585v2",
        "arXiv ID": "2103.11585v2"
    },
    {
        "title": "A Blueprint for Interoperable Blockchains",
        "Published: ": "2019-10-02T14:44:47Z",
        "abstract": "Research in blockchain systems has mainly focused on improving security and\nbridging the performance gaps between blockchains and databases. Despite many\npromising results, we observe a worrying trend that the blockchain landscape is\nfragmented in which many systems exist in silos. Apart from a handful of\ngeneral-purpose blockchains, such as Ethereum or Hyperledger Fabric, there are\nhundreds of others designed for specific applications and typically do not talk\nto each other. In this paper, we describe our vision of interoperable\nblockchains. We argue that supporting interaction among different blockchains\nrequires overcoming challenges that go beyond data standardization. The\nunderlying problem is to allow smart contracts running in different blockchains\nto communicate. We discuss three open problems: access control, general\ncross-chain transactions, and cross-chain communication. We describe partial\nsolutions to some of these problems in the literature. Finally, we propose a\nnovel design to overcome these challenges.",
        "author": [
            "Tien Tuan Anh Dinh",
            "Anwitaman Datta",
            "Beng Chin Ooi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1910.00985v3.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1910.00985v3",
        "arXiv ID": "1910.00985v3"
    },
    {
        "title": "IoT Analytics and Blockchain",
        "Published: ": "2021-12-26T18:20:22Z",
        "abstract": "The Internet of Things (IoT) is revolutionizing human life with the idea of\ninterconnecting everyday used devices (Things) and making them smart. By\nestablishing a communication network between devices, the IoT system aids in\nautomating tasks and making them efficient and powerful. The sensors and the\nphysical world, connected over a network, involve a massive amount of data. The\ndata collection and sharing possess a critical threat of being stolen and\nmanipulated over the network. These inadequate data security and privacy issues\nin IoT systems raise concerns about maintaining authentication of IoT data.\nBlockchain, a tempter-resistant ledger, has emerged as a viable alternative to\nprovide security features. Blockchain technologies with decentralized\nstructures can help resolve IoT structure issues and protect against a single\npoint of failure. While providing robust security features, Blockchain also\nbears various critical challenges in the IoT environment to adapt. This paper\npresents a survey on state-of-the-art Blockchain technologies focusing on IoT\napplications. With Blockchain protocols and data structures, the IoT\napplications are outlined, along with possible advancements and modifications.",
        "author": [
            "Abbas Saleminezhadl",
            "Manuel Remmele",
            "Ravikumar Chaudhari",
            "Rasha Kashef"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.13430v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.13430v1",
        "arXiv ID": "2112.13430v1"
    },
    {
        "title": "Analysis of Arbitrary Content on Blockchain-Based Systems using BigQuery",
        "Published: ": "2022-03-17T15:12:38Z",
        "abstract": "Blockchain-based systems have gained immense popularity as enablers of\nindependent asset transfers and smart contract functionality. They have also,\nsince as early as the first Bitcoin blocks, been used for storing arbitrary\ncontents such as texts and images. On-chain data storage functionality is\nuseful for a variety of legitimate use cases. It does, however, also pose a\nsystematic risk. If abused, for example by posting illegal contents on a public\nblockchain, data storage functionality can lead to legal consequences for\noperators and users that need to store and distribute the blockchain, thereby\nthreatening the operational availability of entire blockchain ecosystems. In\nthis paper, we develop and apply a cloud-based approach for quickly discovering\nand classifying content on public blockchains. Our method can be adapted to\ndifferent blockchain systems and offers insights into content-related usage\npatterns and potential cases of abuse. We apply our method on the two most\nprominent public blockchain systems - Bitcoin and Ethereum - and discuss our\nresults. To the best of our knowledge, the presented study is the first to\nsystematically analyze non-financial content stored on the Ethereum blockchain\nand the first to present a side-by-side comparison between different\nblockchains in terms of the quality and quantity of stored data.",
        "author": [
            "Marcel Gregoriadis",
            "Robert Muth",
            "Martin Florian"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.09379v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.09379v1",
        "arXiv ID": "2203.09379v1"
    },
    {
        "title": "Social Computing for Mobile Big Data in Wireless Networks",
        "Published: ": "2016-09-30T05:20:24Z",
        "abstract": "Mobile big data contains vast statistical features in various dimensions,\nincluding spatial, temporal, and the underlying social domain. Understanding\nand exploiting the features of mobile data from a social network perspective\nwill be extremely beneficial to wireless networks, from planning, operation,\nand maintenance to optimization and marketing. In this paper, we categorize and\nanalyze the big data collected from real wireless cellular networks. Then, we\nstudy the social characteristics of mobile big data and highlight several\nresearch directions for mobile big data in the social computing areas.",
        "author": [
            "Xing Zhang",
            "Zhenglei Yi",
            "Zhi Yan",
            "Geyong Min",
            "Wenbo Wang",
            "Sabita Maharjan",
            "Yan Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1609.09597v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1609.09597v1",
        "arXiv ID": "1609.09597v1"
    },
    {
        "title": "CO-ASnet :A Smart Contract Architecture Design based on Blockchain\n  Technology with Active Sensor Networks",
        "Published: ": "2023-10-08T08:31:49Z",
        "abstract": "The influence of opinion leaders impacts different aspects of social finance.\nHow to analyse the utility of opinion leaders' influence in realizing assets on\nthe blockchain and adopt a compliant regulatory scheme is worth exploring and\npondering. Taking Musk's call on social media to buy Dogecoin as an example,\nthis paper uses an event study to empirically investigate the phenomenon in\nwhich opinion leaders use ICOs (initial coin offerings) to exert influence. The\nresults show that opinion leaders can use ICOs to influence the price of token\nassets with money and data traffic in their social network. They can obtain\nexcess returns and reduce the cost of realization so that the closed loop of\ninfluence realization will be accelerated. Based on this phenomenon and the\nresults of its impact, we use the ChainLink Oracle with Active Sensor\nNetworks(CO-ASnet) to design a safe and applicable decentralized regulatory\nscheme that can constructively provide risk assessment strategies and early\nwarning measures for token issuance. The influence realization of opinion\nleaders in blockchain issuance is bound to receive widespread attention, and\nthis paper will provide an exemplary reference for regulators and enterprises\nto explore the boundaries of blockchain financial product development and\ngovernance.",
        "author": [
            "Feng Liu",
            "Jie Yang",
            "Kun-peng Xu",
            "Cang-long Pu",
            "Jiayin Qi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.05070v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.SI",
                "68-06",
                "C.2.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.05070v1",
        "arXiv ID": "2310.05070v1"
    },
    {
        "title": "Assessing Security and Performances of Consensus algorithms for\n  Permissioned Blockchains",
        "Published: ": "2018-05-09T12:53:05Z",
        "abstract": "Blockchain is a novel technology that is rising a lot of interest in the\nindustrial and re- search sectors because its properties of decentralisation,\nimmutability and data integrity. Initially, the underlying consensus mechanism\nhas been designed for permissionless block- chain on trustless network model\nthrough the proof-of-work, i.e. a mathematical challenge which requires high\ncomputational power. This solution suffers of poor performances, hence\nalternative consensus algorithms as the proof-of-stake have been proposed.\nConversely, for permissioned blockchain, where participants are known and\nauthenti- cated, variants of distributed consensus algorithms have been\nemployed. However, most of them comes out without formal expression of security\nanalysis and trust assumptions because the absence of an established knowledge.\nTherefore the lack of adequate analysis on these algorithms hinders any\ncautious evaluation of their effectiveness in a real-world setting where\nsystems are deployed over trustless networks, i.e. Internet ...",
        "author": [
            "Stefano De Angelis"
        ],
        "pdfLink": "http://arxiv.org/pdf/1805.03490v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1805.03490v1",
        "arXiv ID": "1805.03490v1"
    },
    {
        "title": "Demystifying Quantum Blockchain for Healthcare",
        "Published: ": "2022-10-07T15:47:14Z",
        "abstract": "The application of blockchain technology can be beneficial in the field of\nhealthcare as well as in the fight against the COVID-19 epidemic. In this work,\nthe importance of blockchain is analyzed and it is observed that blockchain\ntechnology and the processes associated with it will be utilised in the\nhealthcare systems of the future for data acquisition from sensors, automatic\npatient monitoring, and secure data storage. This technology substantially\nsimplifies the process of carrying out operations because it can store a\nsubstantial quantity of data in a dispersed and secure manner, as well as\nenable access whenever and wherever it is required to do so. With the\nassistance of quantum blockchain, the benefits of quantum computing, such as\nthe capability to acquire thermal imaging based on quantum computing and the\nspeed with which patients may be located and monitored, can all be exploited to\ntheir full potential. Quantum blockchain is another tool that can be utilised\nto maintain the confidentiality, authenticity, and accessibility of data\nrecords. The processing of medical records could potentially benefit from\ngreater speed and privacy if it combines quantum computing and blockchain\ntechnology. The authors of this paper investigate the possible benefits and\napplications of blockchain and quantum technologies in the field of medicine,\npharmacy and healthcare systems. In this context, this work explored and\ncompared quantum technologies and blockchain-based technologies in conjunction\nwith other cutting-edge information and communications technologies such as\nratification intelligence, machine learning, drones, and so on.",
        "author": [
            "Keshav Kaushik",
            "Adarsh Kumar"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.03638v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.03638v1",
        "arXiv ID": "2210.03638v1"
    },
    {
        "title": "Big Data and Fog Computing",
        "Published: ": "2017-12-27T11:27:30Z",
        "abstract": "Fog computing serves as a computing layer that sits between the edge devices\nand the cloud in the network topology. They have more compute capacity than the\nedge but much less so than cloud data centers. They typically have high uptime\nand always-on Internet connectivity. Applications that make use of the fog can\navoid the network performance limitation of cloud computing while being less\nresource constrained than edge computing. As a result, they offer a useful\nbalance of the current paradigms. This article explores various aspects of fog\ncomputing in the context of big data.",
        "author": [
            "Yogesh Simmhan"
        ],
        "pdfLink": "http://arxiv.org/pdf/1712.09552v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1712.09552v1",
        "arXiv ID": "1712.09552v1"
    },
    {
        "title": "A blockchain-based pattern for confidential and pseudo-anonymous\n  contract enforcement",
        "Published: ": "2021-01-22T08:32:21Z",
        "abstract": "Blockchain has been praised for its capacity to hold data in a decentralized\nand tamper-proof way. It also supports the execution of code through\nblockchain's smart contracts, adding automation of actions to the network with\nhigh trustability. However, as smart contracts are visible by anybody on the\nnetwork, the business data and logic may be at risk, thus companies could be\nreluctant to use such technology. This paper aims to propose a pattern that\nallows the execution of automatable legal contract clauses, where its execution\nstates are stored in an on-chain smart-contract and the logic needed to enforce\nit wraps it off-chain. An engine completes this pattern by running a business\nprocess that corresponds to the legal contract. We then propose a pattern-based\nsolution based on a real-life use case: transportation of refrigerated goods.\nWe argue that this pattern guarantees companies pseudonymity and data\nconfidentiality while ensuring that an audit trail can be reconstituted through\nthe blockchain smart-contract to identify misbehavior or errors. This paper\npaves the way for a future possible implementation of the solution described,\nas well as its evaluation.",
        "author": [
            "Nicolas Six",
            "Claudia Negri Ribalta",
            "Nicolas Herbaut",
            "Camille Salinesi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2101.08997v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2101.08997v1",
        "arXiv ID": "2101.08997v1"
    },
    {
        "title": "Decentralizing Supply Chain Anti-Counterfeiting Systems Using Blockchain\n  Technology",
        "Published: ": "2021-02-02T12:17:10Z",
        "abstract": "An interesting research problem in supply chain industry is evaluating and\ndetermining provenance of physical goods - demonstrating authenticity of luxury\ngoods. Yet, there have been a few innovative software solutions addressing\nproduct anti-counterfeiting and record provenance of today's goods that are\nproduced and transported in complex and internationally-spanning supply chain\nnetworks. However, these supply chain systems have been implemented with\ncentralized system architecture, relying on centralized authorities or any form\nof intermediaries, and leading to issues such as single-point processing,\nstorage and failure, which could be susceptible to malicious modifications of\nproduct records or various potential attacks to system components by dishonest\nparticipant nodes traversing along the supply chain. Blockchain technology has\nevolved from being merely a decentralized, distributed and immutable ledger of\ncryptocurrency transactions to a programmable interactive environment for\nbuilding decentralized and reliable applications addressing different use cases\nand existing problems in the world. In this research, the Decentralized\nNFC-Enabled Anti-Counterfeiting System (dNAS) is proposed and developed,\ndecentralizing a legacy anti-counterfeiting system of supply chain industry\nusing Blockchain technology, to facilitate trustworthy data provenance\nretrieval, verification and management, as well as strengthening capability of\nproduct anti-counterfeiting in supply chain industry. The proposed dNAS\nutilizes decentralized blockchain network on a consensus protocol compatible\nwith the concept of enterprise consortium, programmable smart contracts and a\ndistributed file storage system to develop a secure and immutable scientific\ndata provenance tracking and management platform on which provenance records,\nproviding compelling properties on data integrity, are validated automatically.",
        "author": [
            "Neo C. K. Yiu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.01456v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.01456v1",
        "arXiv ID": "2102.01456v1"
    },
    {
        "title": "Quantum Cyber-Attack on Blockchain-based VANET",
        "Published: ": "2023-04-10T06:46:33Z",
        "abstract": "Blockchain-based Vehicular Ad-hoc Network (VANET) is widely considered as\nsecure communication architecture for a connected transportation system. With\nthe advent of quantum computing, there are concerns regarding the vulnerability\nof this architecture against cyber-attacks. In this study, a potential threat\nis investigated in a blockchain-based VANET, and a corresponding quantum\ncyber-attack is developed. Specifically, a quantum impersonation attack using\nQuantum-Shor algorithm is developed to break the Rivest-Shamir-Adleman (RSA)\nencrypted digital signatures of VANET and thus create a threat for the\ntrust-based blockchain scheme of VANET. A blockchain-based VANET,\nvehicle-to-everything (V2X) communication, and vehicular mobility are simulated\nusing OMNET++, the extended INET library, and vehicles-in-network simulation\n(VEINS) along with simulation of urban mobility (SUMO), respectively. A small\nkey RSA based message encryption is implemented using IBM Qiskit, which is an\nopen-source quantum software development kit. The findings reveal that the\nquantum cyber-attack, example, impersonation attack is able to successfully\nbreak the trust chain of a blockchain-based VANET. This highlights the need for\na quantum secured blockchain.",
        "author": [
            "Kazi Hassan Shakib",
            "Mizanur Rahman",
            "Mhafuzul Islam"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.04411v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.04411v1",
        "arXiv ID": "2304.04411v1"
    },
    {
        "title": "The Implications of Decentralization in Blockchained Federated Learning:\n  Evaluating the Impact of Model Staleness and Inconsistencies",
        "Published: ": "2023-10-11T13:18:23Z",
        "abstract": "Blockchain promises to enhance distributed machine learning (ML) approaches\nsuch as federated learning (FL) by providing further decentralization,\nsecurity, immutability, and trust, which are key properties for enabling\ncollaborative intelligence in next-generation applications. Nonetheless, the\nintrinsic decentralized operation of peer-to-peer (P2P) blockchain nodes leads\nto an uncharted setting for FL, whereby the concepts of FL round and global\nmodel become meaningless, as devices' synchronization is lost without the\nfigure of a central orchestrating server. In this paper, we study the practical\nimplications of outsourcing the orchestration of FL to a democratic network\nsuch as in a blockchain. In particular, we focus on the effects that model\nstaleness and inconsistencies, endorsed by blockchains' modus operandi, have on\nthe training procedure held by FL devices asynchronously. Using simulation, we\nevaluate the blockchained FL operation on the well-known CIFAR-10 dataset and\nfocus on the accuracy and timeliness of the solutions. Our results show the\nhigh impact of model inconsistencies on the accuracy of the models (up to a\n~35% decrease in prediction accuracy), which underscores the importance of\nproperly designing blockchain systems based on the characteristics of the\nunderlying FL application.",
        "author": [
            "Francesc Wilhelmi",
            "Nima Afraz",
            "Elia Guerra",
            "Paolo Dini"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.07471v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.AI",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.07471v1",
        "arXiv ID": "2310.07471v1"
    },
    {
        "title": "Scaling Blockchains with Error Correction Codes: A Survey on Coded\n  Blockchains",
        "Published: ": "2022-08-19T10:23:54Z",
        "abstract": "This paper reviews and highlights how coding schemes have been used to solve\nvarious problems in blockchain systems. Specifically, these problems relate to\nscaling blockchains in terms of their data storage, computation and\ncommunication cost, as well as security. To this end, this paper considers the\nuse of coded blocks or shards that allows participants to store only a fraction\nof the total blockchain, protect against malicious nodes or erasures due to\nnodes leaving a blockchain system, ensure data availability in order to promote\ntransparency, and scale the security of sharded blockchains. Further, it helps\nreduce communication cost when disseminating blocks, which is critical to\nbootstrapping new nodes and helps speed up consensus of blocks. For each\ncategory of solutions, we highlight problems and issues that motivated their\ndesigns and use of coding. Moreover, we provide a qualitative analysis of their\nstorage, communication and computation cost.",
        "author": [
            "Changlin Yang",
            "Kwan-Wu Chin",
            "Jiguang Wang",
            "Xiaodong Wang",
            "Ying Liu",
            "Zibin Zheng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.09255v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.09255v1",
        "arXiv ID": "2208.09255v1"
    },
    {
        "title": "A Distributed Efficient Blockchain Oracle Scheme for Internet of Things",
        "Published: ": "2023-09-30T04:54:50Z",
        "abstract": "In recent years, blockchain has been widely applied in the Internet of Things\n(IoT). Blockchain oracle, as a bridge for data communication between blockchain\nand off-chain, has also received significant attention. However, the numerous\nand heterogeneous devices in the IoT pose great challenges to the efficiency\nand security of data acquisition for oracles. We find that the matching\nrelationship between data sources and oracle nodes greatly affects the\nefficiency and service quality of the entire oracle system. To address these\nissues, this paper proposes a distributed and efficient oracle solution\ntailored for the IoT, enabling fast acquisition of real-time off-chain data.\nSpecifically, we first design a distributed oracle architecture that combines\nboth Trusted Execution Environment (TEE) devices and ordinary devices to\nimprove system scalability, considering the heterogeneity of IoT devices.\nSecondly, based on the trusted node information provided by TEE, we determine\nthe matching relationship between nodes and data sources, assigning appropriate\nnodes for tasks to enhance system efficiency. Through simulation experiments,\nour proposed solution has been shown to effectively improve the efficiency and\nservice quality of the system, reducing the average response time by\napproximately 9.92\\% compared to conventional approaches.",
        "author": [
            "Youquan Xian",
            "Lianghaojie Zhou",
            "Jianyong Jiang",
            "Boyi Wang",
            "Hao Huo",
            "Peng Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.00254v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.DC",
                "cs.ET"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.00254v1",
        "arXiv ID": "2310.00254v1"
    },
    {
        "title": "Internet Protocol Version 6: Dead or Alive?",
        "Published: ": "2018-08-17T20:27:35Z",
        "abstract": "Internet Protocol (IP) is the narrow waist of multilayered Internet protocol\nstack which defines the rules for data sent across networks. IPv4 is the fourth\nversion of IP and first commercially available for deployment set by ARPANET in\n1983 which is a 32 bit long address and can support up to 232 devices. In April\n2017, all Regional Internet Registries (RIRs) confirmed that IPv4 addresses are\nexhausted and cannot be allocated anymore implying any new organization\nrequesting a block of Internet addresses will be allocated IPv6. This creates\ntroubles of interoperability, migration and deployment, and therefore\norganizations hesitated to use IPv6 borrowing IPv4 addresses from other big\norganizations instead. Currently, when IPv4 is not available, and IPv6 is not\nadopted for around 20 years, the question arises whether IPv6 will still be\naccepted by the computer society or will it have an end of life soon with\nalternate better protocol such as ID based networks taking its place. This\npaper claims that IPv6 has lost its deployment window and can be safely skipped\nwhen new ID based protocols are available which not only have simple\ninteroperability, deployment and migration guidelines but also provide advanced\nfeatures as compared to IPv6. The paper provides answers to these questions\nwith a comprehensive comparison of IPv6 with its available alternatives and\nreasons of IPv6 failures in its adoption. Finally, the paper declares IPv6 as a\ndead protocol and suggests to use newer available protocols in future.",
        "author": [
            "Sumit Maheshwari",
            "Richard P. Martin"
        ],
        "pdfLink": "http://arxiv.org/pdf/1809.07836v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1809.07836v1",
        "arXiv ID": "1809.07836v1"
    },
    {
        "title": "Dynamic Practical Byzantine Fault Tolerance and Its Blockchain System: A\n  Large-Scale Markov Modeling",
        "Published: ": "2022-10-25T13:17:08Z",
        "abstract": "In a practical Byzantine fault tolerance (PBFT) blockchain network, the\nvoting nodes may always leave the network while some new nodes can also enter\nthe network, thus the number of voting nodes is constantly changing. Such a new\nPBFT with dynamic nodes is called a dynamic PBFT. Clearly, the dynamic PBFT can\nmore strongly support the decentralization and distributed structure of\nblockchain. However, analyzing dynamic PBFT blockchain systems will become more\ninteresting and challenging.\n  In this paper, we propose a large-scale Markov modeling technique to analyze\nthe dynamic PBFT voting processes and its dynamic PBFT blockchain system. To\nthis end, we set up a large-scale Markov process (and further a\nmulti-dimensional Quasi-Birth-and-Death (QBD) process) and provide performance\nanalysis for both the dynamic PBFT voting processes and the dynamic PBFT\nblockchain system. In particular, we obtain an effective computational method\nfor the throughput of the complicated dynamic PBFT blockchain system. Finally,\nwe use numerical examples to check the validity of our theoretical results and\nindicate how some key system parameters influence the performance measures of\nthe dynamic PBFT voting processes and of the dynamic PBFT blockchain system.\nTherefore, by using the theory of multi-dimensional QBD processes and the\nRG-factorization technique, we hope that the methodology and results developed\nin this paper shed light on the study of dynamic PBFT blockchain systems such\nthat a series of promising research can be developed potentially.",
        "author": [
            "Yan-Xia Chang",
            "Quan-Lin Li",
            "Qing Wang",
            "Xing-Shuo Song"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.14003v1.pdf",
        "Categories": [
            [
                "cs.PF",
                "cs.CR",
                "cs.IT",
                "math.IT",
                "math.PR",
                "90B22, 60J28",
                "H.2.4; H.3.5; E.2; E.3; D.4.6; D.4.8"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.14003v1",
        "arXiv ID": "2210.14003v1"
    },
    {
        "title": "Shallow Overlay Trees Suffice for High-Throughput Consensus",
        "Published: ": "2019-03-07T20:15:45Z",
        "abstract": "All-to-all data transmission is a typical data transmission pattern in\nblockchain systems. Developing an optimization scheme that provides high\nthroughput and low latency data transmission can significantly benefit the\nperformance of those systems. In this work, we consider the problem of\noptimizing all-to-all data transmission in a wide area network(WAN) using\noverlay multicast. We prove that in a congestion-free core network model, using\nshallow broadcast trees with heights up to two is sufficient for all-to-all\ndata transmission to achieve the optimal throughput allowed by the available\nnetwork resources.",
        "author": [
            "Hao Tan",
            "Wojciech Golab"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.03164v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.03164v1",
        "arXiv ID": "1903.03164v1"
    },
    {
        "title": "Balanced End-to-End Monolingual pre-training for Low-Resourced Indic\n  Languages Code-Switching Speech Recognition",
        "Published: ": "2021-06-10T16:12:51Z",
        "abstract": "The success in designing Code-Switching (CS) ASR often depends on the\navailability of the transcribed CS resources. Such dependency harms the\ndevelopment of ASR in low-resourced languages such as Bengali and Hindi. In\nthis paper, we exploit the transfer learning approach to design End-to-End\n(E2E) CS ASR systems for the two low-resourced language pairs using different\nmonolingual speech data and a small set of noisy CS data. We trained the\nCS-ASR, following two steps: (i) building a robust bilingual ASR system using a\nconvolution-augmented transformer (Conformer) based acoustic model and n-gram\nlanguage model, and (ii) fine-tuned the entire E2E ASR with limited noisy CS\ndata. We tested our method on MUCS 2021 challenge and achieved 3rd place in the\nCS track. We then tested the proposed method using noisy CS data released for\nHindi-English and Bengali-English pairs in Multilingual and Code-Switching ASR\nChallenges for Low Resource Indian Languages (MUCS 2021) and achieved 3rd place\nin the CS track. Unlike, the leading two systems that benefited from crawling\nYouTube and learning transliteration pairs, our proposed transfer learning\napproach focused on using only the limited CS data with no data-cleaning or\ndata re-segmentation. Our approach achieved 14.1% relative gain in word error\nrate (WER) in Hindi-English and 27.1% in Bengali-English. We provide detailed\nguidelines on the steps to finetune the self-attention based model for limited\ndata for ASR. Moreover, we release the code and recipe used in this paper.",
        "author": [
            "Amir Hussein",
            "Shammur Chowdhury",
            "Najim Dehak",
            "Ahmed Ali"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.05885v2.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.05885v2",
        "arXiv ID": "2106.05885v2"
    },
    {
        "title": "Moving Smart Contracts -- A Privacy Preserving Method for Off-Chain Data\n  Trust",
        "Published: ": "2022-05-17T15:32:33Z",
        "abstract": "Blockchains provide environments where parties can interact transparently and\nsecurely peer-to-peer without needing a trusted third party. Parties can trust\nthe integrity and correctness of transactions and the verifiable execution of\nbinary code on the blockchain (smart contracts) inside the system. Including\ninformation from outside of the blockchain remains challenging. A challenge is\ndata privacy. In a public system, shared data becomes public and, coming from a\nsingle source, often lacks credibility. A private system gives the parties\ncontrol over their data and sources but trades in positive aspects as\ntransparency. Often, not the data itself is the most critical information but\nthe result of a computation performed on it.\n  An example is research data certification. To keep data private but still\nprove data provenance, researchers can store a hash value of that data on the\nblockchain. This hash value is either calculated locally on private data\nwithout the chance for validation or is calculated on the blockchain, meaning\nthat data must be published and stored on the blockchain -- a problem of the\noverall data amount stored on and distributed with the ledger. A system we\ncalled moving smart contracts bypasses this problem: Data remain local, but\ntrusted nodes can access them and execute trusted smart contract code stored on\nthe blockchain. This method avoids the system-wide distribution of research\ndata and makes it accessible and verifiable with trusted software.",
        "author": [
            "Simon Tschirner",
            "Shashank Shekher Tripathi",
            "Mathias Roeper",
            "Markus M. Becker",
            "Volker Skwarek"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.08440v2.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC",
                "cs.MA",
                "cs.SE",
                "C.2.4; E.2; E.3"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.08440v2",
        "arXiv ID": "2205.08440v2"
    },
    {
        "title": "The Approach to Managing Provenance Metadata and Data Access Rights in\n  Distributed Storage Using the Hyperledger Blockchain Platform",
        "Published: ": "2018-11-30T10:40:23Z",
        "abstract": "The paper suggests a new approach based on blockchain technologies and smart\ncontracts to creation of a distributed system for managing provenance metadata,\nas well as access rights to data in distributed storages, which is\nfault-tolerant, safe and secure from the point of view of preservation of\nmetadata records from accidental or intentional distortions. The implementation\nof the proposed approach is based on the permissioned blockchains and on the\nHyperledger Fabric blockchain platform in conjunction with Hyperledger\nComposer.",
        "author": [
            "Andrey Demichev",
            "Alexander Kryukov",
            "Nikolai Prikhodko"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.12706v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.12706v1",
        "arXiv ID": "1811.12706v1"
    },
    {
        "title": "Evaluating Permissioned Blockchain Using Stochastic Modeling and Chaos\n  Engineering",
        "Published: ": "2023-01-14T14:00:03Z",
        "abstract": "Blockchain and distributed ledger technologies rely on distributed consensus\nalgorithms. In recent years many consensus algorithms and protocols have been\nproposed; most of them are for permissioned blockchain networks. However, the\nperformance of these algorithms is not well understood. This paper introduces\nan approach to evaluating consensus algorithms and blockchain platforms in a\nhostile network environment with the presence of byzantine and other network\nfailures. The approach starts by using stochastic modeling to model the\nbehaviors of consensus algorithms under different typical and faulty\noperational scenarios. Next, we implemented a blockchain application using\ndifferent consensus protocols and tested their performance using chaos\nengineering techniques. To demonstrate our generic evaluation approach, we\nanalyze the performance of four permissioned blockchain platforms and their\nconsensus protocols. Our results showed that stochastic modeling is an\ninexpensive and efficient technique for analyzing consensus protocols. But they\ndo not represent the actual performance of the consensus protocols in a\nproduction environment. Moreover, an experiment with chaos engineering\nindicates that if two different blockchain platforms use the same blockchain\nalgorithm or protocol, we should not assume they will have similar performance.\nTherefore, It is also essential to consider the role of platform architecture\nand how the protocols are engineered in a given platform.",
        "author": [
            "Shiv Sondhi",
            "Sherif Saad",
            "Kevin Shi",
            "Mohammad Mamun",
            "Issa Traore"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.07527v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.07527v1",
        "arXiv ID": "2301.07527v1"
    },
    {
        "title": "Consensus in Blockchain Systems with Low Network Throughput: A\n  Systematic Mapping Study",
        "Published: ": "2021-03-04T09:43:13Z",
        "abstract": "Blockchain technologies originate from cryptocurrencies. Thus, most\nblockchain technologies assume an environment with a fast and stable network.\nHowever, in some blockchain-based systems, e.g., supply chain management (SCM)\nsystems, some Internet of Things (IOT) nodes can only rely on the low-quality\nnetwork sometimes to achieve consensus. Thus, it is critical to understand the\napplicability of existing consensus algorithms in such environments. We\nperformed a systematic mapping study to evaluate and compare existing consensus\nmechanisms' capability to provide integrity and security with varying network\nproperties. Our study identified 25 state-of-the-art consensus algorithms from\npublished and preprint literature. We categorized and compared the consensus\nalgorithms qualitatively based on established performance and integrity metrics\nand well-known blockchain security issues. Results show that consensus\nalgorithms rely on the synchronous network for correctness cannot provide the\nexpected integrity. Such consensus algorithms may also be vulnerable to\ndistributed-denial-of-service (DDOS) and routing attacks, given limited network\nthroughput. Conversely, asynchronous consensus algorithms, e.g.,\nHoney-BadgerBFT, are deemed more robust against many of these attacks and may\nprovide high integrity in asynchrony events.",
        "author": [
            "Henrik Knudsen",
            "Jakob Svennevik Notland",
            "Peter Halland Haro",
            "Truls Bakkejord R\u00e6der",
            "Jingyue Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.02916v1.pdf",
        "Categories": [
            [
                "cs.PF",
                "cs.CC",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.02916v1",
        "arXiv ID": "2103.02916v1"
    },
    {
        "title": "Network Participation and Accessibility of Proof-of-Stake (PoS)\n  Blockchains: A Cross-platform Comparative Analysis",
        "Published: ": "2023-05-22T17:31:27Z",
        "abstract": "The comparative analysis examined eleven Proof-of-Stake (PoS) consensus-based\nblockchain networks to assess their openness based on five indicative metrics.\nThese metrics include those of decentralization-related aspects, such as the\nnumber of validators and capital concentration, and participation-related\naspects, including entry capital requirements and economic network stability.\nThis is to assess and characterize the openness of Proof-of-Stake blockchain\nnetworks. The analysis suggested that networks with higher openness included\nSolana and Avalanche, while BNB Chain, Klaytn, and Polygon measured with lower\nlevels of openness. According to the comparative analysis, Ethereum scored high\non network openness in terms of the number of participants and the cost of\nrunning the chain, but scored relatively low on capital concentration and\nstaking ratio, which is likely due to the low ratio of staked ether (ETH) to\ncirculating supply and the significant stakes in staking pools like Lido.\nPermissioned blockchains such as Klaytn and Polygon have limited openness,\nwhich suggests the need to take the level of openness into account when\ntransitioning into a permissionless blockchain architecture with a more\ndecentralized setting.",
        "author": [
            "Jiseong Noh",
            "Donghwan Kwon",
            "Soohwan Cho",
            "Neo C. K. Yiu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.13259v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.13259v1",
        "arXiv ID": "2305.13259v1"
    },
    {
        "title": "Efficient Logging for Blockchain Applications",
        "Published: ": "2020-01-28T11:49:47Z",
        "abstract": "Second generation blockchain platforms, like Ethereum, can store arbitrary\ndata and execute user-defined smart contracts. Due to the shared nature of\nblockchains, understanding the usage of blockchain-based applications and the\nunderlying network is crucial. Although log analysis is a well-established\nmeans, data extraction from blockchain platforms can be highly inconvenient and\nslow, not least due to the absence of logging libraries. To close the gap, we\nhere introduce the Ethereum Logging Framework (ELF) which is highly\nconfigurable and available as open source. ELF supports users (i) in generating\ncost-efficient logging code readily embeddable into smart contracts and (ii) in\nextracting log analysis data into common formats regardless of whether the code\ngeneration has been used during development. We provide an overview of and\nrationale for the framework's features, outline implementation details, and\ndemonstrate ELF's versatility based on three case studies from the public\nEthereum blockchain.",
        "author": [
            "Christopher Klinkm\u00fcller",
            "Ingo Weber",
            "Alexander Ponomarev",
            "An Binh Tran",
            "Wil van der Aalst"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.10281v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.10281v1",
        "arXiv ID": "2001.10281v1"
    },
    {
        "title": "Blockchain-aided Secure Semantic Communication for AI-Generated Content\n  in Metaverse",
        "Published: ": "2023-01-25T02:32:02Z",
        "abstract": "The construction of virtual transportation networks requires massive data to\nbe transmitted from edge devices to Virtual Service Providers (VSP) to\nfacilitate circulations between the physical and virtual domains in Metaverse.\nLeveraging semantic communication for reducing information redundancy, VSPs can\nreceive semantic data from edge devices to provide varied services through\nadvanced techniques, e.g., AI-Generated Content (AIGC), for users to explore\ndigital worlds. But the use of semantic communication raises a security issue\nbecause attackers could send malicious semantic data with similar semantic\ninformation but different desired content to break Metaverse services and cause\nwrong output of AIGC. Therefore, in this paper, we first propose a\nblockchain-aided semantic communication framework for AIGC services in virtual\ntransportation networks to facilitate interactions of the physical and virtual\ndomains among VSPs and edge devices. We illustrate a training-based targeted\nsemantic attack scheme to generate adversarial semantic data by various loss\nfunctions. We also design a semantic defense scheme that uses the blockchain\nand zero-knowledge proofs to tell the difference between the semantic\nsimilarities of adversarial and authentic semantic data and to check the\nauthenticity of semantic data transformations. Simulation results show that the\nproposed defense method can reduce the semantic similarity of the adversarial\nsemantic data and the authentic ones by up to 30% compared with the attack\nscheme.",
        "author": [
            "Yijing Lin",
            "Hongyang Du",
            "Dusit Niyato",
            "Jiangtian Nie",
            "Jiayi Zhang",
            "Yanyu Cheng",
            "Zhaohui Yang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.11289v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.11289v1",
        "arXiv ID": "2301.11289v1"
    },
    {
        "title": "Distributed Ledger Technology based Integrated Healthcare Solution for\n  Bangladesh",
        "Published: ": "2022-05-30T20:26:31Z",
        "abstract": "Healthcare data is sensitive and requires great protection. Encrypted\nelectronic health records (EHRs) contain personal and sensitive data such as\nnames and addresses. Having access to patient data benefits all of them. This\npaper proposes a blockchain-based distributed healthcare application platform\nfor Bangladeshi public and private healthcare providers. Using data\nimmutability and smart contracts, the suggested application framework allows\nusers to create safe digital agreements for commerce or collaboration. Thus,\nall enterprises may securely collaborate using the same blockchain network,\ngaining data openness and read/write capacity. The proposed application\nconsists of various application interfaces for various system users. For data\nintegrity, privacy, permission and service availability, the proposed solution\nleverages Hyperledger fabric and Blockchain as a Service. Everyone will also\nhave their own profile in the portal. A unique identity for each person and the\ninstallation of digital information centres across the country have greatly\neased the process. It will collect systematic health data from each person\nwhich will be beneficial for research institutes and health-related\norganisations. A national data warehouse in Bangladesh is feasible for this\napplication and It is also possible to keep a clean health sector by analysing\ndata stored in this warehouse and conducting various purification algorithms\nusing technologies like Data Science. Given that Bangladesh has both public and\nprivate health care, a straightforward digital strategy for all organisations\nis essential.",
        "author": [
            "Md. Ariful Islam",
            "Md. Antonin Islam",
            "Md. Amzad Hossain Jacky",
            "Md. Al-Amin",
            "M. Saef Ullah Miah",
            "Md Muhidul Islam Khan",
            "Md. Iqbal Hossain"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.15416v1.pdf",
        "Categories": [
            [
                "cs.IR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.15416v1",
        "arXiv ID": "2205.15416v1"
    },
    {
        "title": "PredictChain: Empowering Collaboration and Data Accessibility for AI in\n  a Decentralized Blockchain-based Marketplace",
        "Published: ": "2023-07-27T19:56:18Z",
        "abstract": "Limited access to computing resources and training data poses significant\nchallenges for individuals and groups aiming to train and utilize predictive\nmachine learning models. Although numerous publicly available machine learning\nmodels exist, they are often unhosted, necessitating end-users to establish\ntheir computational infrastructure. Alternatively, these models may only be\naccessible through paid cloud-based mechanisms, which can prove costly for\ngeneral public utilization. Moreover, model and data providers require a more\nstreamlined approach to track resource usage and capitalize on subsequent usage\nby others, both financially and otherwise. An effective mechanism is also\nlacking to contribute high-quality data for improving model performance. We\npropose a blockchain-based marketplace called \"PredictChain\" for predictive\nmachine-learning models to address these issues. This marketplace enables users\nto upload datasets for training predictive machine learning models, request\nmodel training on previously uploaded datasets, or submit queries to trained\nmodels. Nodes within the blockchain network, equipped with available computing\nresources, will operate these models, offering a range of archetype machine\nlearning models with varying characteristics, such as cost, speed, simplicity,\npower, and cost-effectiveness. This decentralized approach empowers users to\ndevelop improved models accessible to the public, promotes data sharing, and\nreduces reliance on centralized cloud providers.",
        "author": [
            "Matthew T. Pisano",
            "Connor J. Patterson",
            "Oshani Seneviratne"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.15168v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.15168v1",
        "arXiv ID": "2307.15168v1"
    },
    {
        "title": "Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain\n  Governance Communities",
        "Published: ": "2023-10-31T08:23:47Z",
        "abstract": "Blockchain technology is leading a revolutionary transformation across\ndiverse industries, with effective governance standing as a critical\ndeterminant for the success and sustainability of blockchain projects.\nCommunity forums, pivotal in engaging decentralized autonomous organizations\n(DAOs), wield a substantial impact on blockchain governance decisions.\nConcurrently, Natural Language Processing (NLP), particularly sentiment\nanalysis, provides powerful insights from textual data. While prior research\nhas explored the potential of NLP tools in social media sentiment analysis, a\ngap persists in understanding the sentiment landscape of blockchain governance\ncommunities. The evolving discourse and sentiment dynamics on the forums of top\nDAOs remain largely unknown. This paper delves deep into the evolving discourse\nand sentiment dynamics on the public forums of leading DeFi projects -- Aave,\nUniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --\nplacing a primary focus on discussions related to governance issues. Despite\ndiffering activity patterns, participants across these decentralized\ncommunities consistently express positive sentiments in their Discord\ndiscussions, indicating optimism towards governance decisions. Additionally,\nour research suggests a potential interplay between discussion intensity and\nsentiment dynamics, indicating that higher discussion volumes may contribute to\nmore stable and positive emotions. The insights gained from this study are\nvaluable for decision-makers in blockchain governance, underscoring the pivotal\nrole of sentiment analysis in interpreting community emotions and its evolving\nimpact on the landscape of blockchain governance. This research significantly\ncontributes to the interdisciplinary exploration of the intersection of\nblockchain and society, with a specific emphasis on the decentralized\nblockchain governance ecosystem.",
        "author": [
            "Yutong Quan",
            "Xintong Wu",
            "Wanlin Deng",
            "Luyao Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2311.14676v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.CR",
                "cs.HC",
                "econ.GN",
                "q-fin.EC",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2311.14676v1",
        "arXiv ID": "2311.14676v1"
    },
    {
        "title": "Privacy Preserving and Cost Optimal Mobile Crowdsensing using Smart\n  Contracts on Blockchain",
        "Published: ": "2018-08-13T03:57:22Z",
        "abstract": "The popularity and applicability of mobile crowdsensing applications are\ncontinuously increasing due to the widespread of mobile devices and their\nsensing and processing capabilities. However, we need to offer appropriate\nincentives to the mobile users who contribute their resources and preserve\ntheir privacy. Blockchain technologies enable semi-anonymous multi-party\ninteractions and can be utilized in crowdsensing applications to maintain the\nprivacy of the mobile users while ensuring first-rate crowdsensed data. In this\nwork, we propose to use blockchain technologies and smart contracts to\norchestrate the interactions between mobile crowdsensing providers and mobile\nusers for the case of spatial crowdsensing, where mobile users need to be at\nspecific locations to perform the tasks. Smart contracts, by operating as\nprocesses that are executed on the blockchain, are used to preserve users'\nprivacy and make payments. Furthermore, for the assignment of the crowdsensing\ntasks to the mobile users, we design a truthful, cost-optimal auction that\nminimizes the payments from the crowdsensing providers to the mobile users.\nExtensive experimental results show that the proposed privacy preserving\nauction outperforms state-of-the-art proposals regarding cost by ten times for\nhigh numbers of mobile users and tasks.",
        "author": [
            "Dimitris Chatzopoulos",
            "Sujit Gujar",
            "Boi Faltings",
            "Pan Hui"
        ],
        "pdfLink": "http://arxiv.org/pdf/1808.04056v2.pdf",
        "Categories": [
            [
                "cs.GT",
                "cs.CR",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1808.04056v2",
        "arXiv ID": "1808.04056v2"
    },
    {
        "title": "Robust Blockchained Federated Learning with Model Validation and\n  Proof-of-Stake Inspired Consensus",
        "Published: ": "2021-01-09T06:30:38Z",
        "abstract": "Federated learning (FL) is a promising distributed learning solution that\nonly exchanges model parameters without revealing raw data. However, the\ncentralized architecture of FL is vulnerable to the single point of failure. In\naddition, FL does not examine the legitimacy of local models, so even a small\nfraction of malicious devices can disrupt global training. To resolve these\nrobustness issues of FL, in this paper, we propose a blockchain-based\ndecentralized FL framework, termed VBFL, by exploiting two mechanisms in a\nblockchained architecture. First, we introduced a novel decentralized\nvalidation mechanism such that the legitimacy of local model updates is\nexamined by individual validators. Second, we designed a dedicated\nproof-of-stake consensus mechanism where stake is more frequently rewarded to\nhonest devices, which protects the legitimate local model updates by increasing\ntheir chances of dictating the blocks appended to the blockchain. Together,\nthese solutions promote more federation within legitimate devices, enabling\nrobust FL. Our emulation results of the MNIST classification corroborate that\nwith 15% of malicious devices, VBFL achieves 87% accuracy, which is 7.4x higher\nthan Vanilla FL.",
        "author": [
            "Hang Chen",
            "Syed Ali Asif",
            "Jihong Park",
            "Chien-Chung Shen",
            "Mehdi Bennis"
        ],
        "pdfLink": "http://arxiv.org/pdf/2101.03300v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.DC",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2101.03300v1",
        "arXiv ID": "2101.03300v1"
    },
    {
        "title": "Secure Spectrum and Resource Sharing for 5G Networks using a\n  Blockchain-based Decentralized Trusted Computing Platform",
        "Published: ": "2022-01-03T05:40:17Z",
        "abstract": "The 5G network would fuel next-gen, bandwidth-heavy technologies such as\nautomation, IoT, and AI on the factory floor. It will improve efficiency by\npowering AR overlays in workflows, as well as ensure safer practices and reduce\nthe number of defects through predictive analytics and real-time detection of\ndamage. The Dynamic Spectrum Sharing (DSS) in 5G networks will permit 5G NR and\n4G LTE to coexist and will provide cost-effective and efficient solutions that\nenable a smooth transition from 4G to 5G. However, this increases the attack\nsurface in the 5G networks. To the best of our knowledge, none of the current\nworks introduces a real-time secure spectrum-sharing mechanism for 5G networks\nto defend spectrum resources and applications. This paper aims to propose a\nBlockchain-based Decentralized Trusted Computing Platform (BTCP) to\nself-protect large-scale 5G spectrum resources against cyberattacks in a\ntimely, dynamic, and accurate way. Furthermore, the platform provides a\ndecentralized, trusted, and non-repudiating platform to enable secure spectrum\nsharing and data exchange between the 5G spectrum resources",
        "author": [
            "Hisham A. Kholidy",
            "Mohammad A. Rahman",
            "Andrew Karam",
            "Zahid Akhtar"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.00484v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.00484v1",
        "arXiv ID": "2201.00484v1"
    },
    {
        "title": "Vulnerability of Finitely-long Blockchains in Securing Data",
        "Published: ": "2023-04-19T20:55:59Z",
        "abstract": "Recently, blockchain has been applied in various fields to secure data\nexchanges and storage in decentralized systems. In a blockchain application\nwhere the task of the application which makes use of the data stored in a\nblockchain has to be accomplished by a time instant, the employed blockchain is\nessentially finitely-long. In this paper, we consider a general finitely-long\nblockchain model which is generalized from most existing works on finitely-long\nblockchain applications, and take the first step towards characterizing the\nvulnerability of finitely-long blockchains in securing data against\ndouble-spending attacks. For the first time, we develop a general closed-form\nexpression for the probability of success in launching a double-spending attack\non a finitely-long blockchain. This probability essentially characterizes the\nvulnerability of finitely-long blockchains. Then, we prove that the probability\nof success in launching a double-spending attack on a finitely-long blockchain\nis no greater than that on an infinitely-long blockchain, which implies that\nfinitely-long blockchains are less vulnerable to double-spending attacks than\ninfinitely-long blockchains. Moreover, we show that unlike infinitely-long\nblockchains which can be surely paralyzed by a 51% attack, finitely-long\nblockchains are more resistant to 51% attacks.",
        "author": [
            "Yiming Jiang",
            "Jiangfan Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.09965v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.09965v1",
        "arXiv ID": "2304.09965v1"
    },
    {
        "title": "Workflow Management on BFT Blockchains",
        "Published: ": "2019-05-29T18:03:36Z",
        "abstract": "Blockchain technology has been proposed as a new infrastructure technology\nfor a wide variety of novel applications. Blockchains provide an immutable\nrecord of transactions, making them useful when business actors do not trust\neach other. Their distributed nature makes them suitable for\ninter-organizational applications. However, proof-of-work based blockchains are\ncomputationally inefficient and do not provide final consensus, although they\nscale well to large networks. In contrast, blockchains built around Byzantine\nFault Tolerance (BFT) algorithms are more efficient and provide immediate and\nfinal consensus, but do not scale well to large networks. We argue that this\nmakes them well-suited for workflow management applications that typically\ninclude no more than a few dozen participants but require final consensus. In\nthis paper, we discuss architectural options and present a prototype\nimplementation of a BFT-blockchain-based workflow management system (WfMS).",
        "author": [
            "Joerg Evermann",
            "Henry Kim"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.12652v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.12652v2",
        "arXiv ID": "1905.12652v2"
    },
    {
        "title": "Architectural Tactics for Big Data Cybersecurity Analytic Systems: A\n  Review",
        "Published: ": "2018-02-09T09:16:22Z",
        "abstract": "Context: Big Data Cybersecurity Analytics is aimed at protecting networks,\ncomputers, and data from unauthorized access by analysing security event data\nusing big data tools and technologies. Whilst a plethora of Big Data\nCybersecurity Analytic Systems have been reported in the literature, there is a\nlack of a systematic and comprehensive review of the literature from an\narchitectural perspective. Objective: This paper reports a systematic review\naimed at identifying the most frequently reported quality attributes and\narchitectural tactics for Big Data Cybersecurity Analytic Systems. Method: We\nused Systematic Literature Review (SLR) method for reviewing 74 primary studies\nselected using well-defined criteria. Results: Our findings are twofold: (i)\nidentification of 12 most frequently reported quality attributes and the\njustification for their significance for Big Data Cybersecurity Analytic\nSystems; and (ii) identification and codification of 17 architectural tactics\nfor addressing the quality attributes that are commonly associated with Big\nData Cybersecurity Analytic systems. The identified tactics include six\nperformance tactics, four accuracy tactics, two scalability tactics, three\nreliability tactics, and one security and usability tactic each. Conclusion:\nOur findings have revealed that (a) despite the significance of\ninteroperability, modifiability, adaptability, generality, stealthiness, and\nprivacy assurance, these quality attributes lack explicit architectural support\nin the literature (b) empirical investigation is required to evaluate the\nimpact of codified architectural tactics (c) a good deal of research effort\nshould be invested to explore the trade-offs and dependencies among the\nidentified tactics and (d) there is a general lack of effective collaboration\nbetween academia and industry for supporting the field of Big Data\nCybersecurity Analytic Systems.",
        "author": [
            "Faheem Ullah",
            "M. Ali Babar"
        ],
        "pdfLink": "http://arxiv.org/pdf/1802.03178v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1802.03178v1",
        "arXiv ID": "1802.03178v1"
    },
    {
        "title": "Saguaro: An Edge Computing-Enabled Hierarchical Permissioned Blockchain",
        "Published: ": "2021-01-21T19:16:22Z",
        "abstract": "We present Saguaro, a permissioned blockchain system designed specifically\nfor edge computing networks. Saguaro leverages the hierarchical structure of\nedge computing networks to reduce the overhead of wide-area communication by\npresenting several techniques. First, Saguaro proposes coordinator-based and\noptimistic protocols to process cross-domain transactions with low latency\nwhere the lowest common ancestor of the involved domains coordinates the\nprotocol or detects inconsistency. Second, data are collected over hierarchy\nenabling higher-level domains to aggregate their sub-domain data. Finally,\ntransactions initiated by mobile edge devices are processed without relying on\nhigh-level fog and cloud servers. Our experimental results across a wide range\nof workloads demonstrate the scalability of Saguaro in supporting a range of\ncross-domain and mobile transactions.",
        "author": [
            "Mohammad Javad Amiri",
            "Ziliang Lai",
            "Liana Patel",
            "Boon Thau Loo",
            "Eric Lo",
            "Wenchao Zhou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2101.08819v2.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2101.08819v2",
        "arXiv ID": "2101.08819v2"
    },
    {
        "title": "Towards Security Enhancement of Blockchain-based Supply Chain Management",
        "Published: ": "2022-09-11T18:52:11Z",
        "abstract": "The cybersecurity of modern systems has dramatically increased attention from\nboth industrial and academia perspectives. In the recent era, the popularity of\nthe blockchain-based system has traditionally been emergent among various\nindustrials sectors especially in supply chain management due to its\nstreamlined nature. This reveals the importance of the quality aspects from a\nsupply chain management perspective. Many industries realized the importance of\nhaving quality systems for supply chain management and logistics. The emergence\nof blockchain technology has created several potential innovations in handling\nand tracking business activities over the supply chain processes as specific.\nThis paper shed the light on the blockchain and specifically on a smart\ncontract technology which been used to handle the process of creation,\nverification and checking data over the supply chain management process. Then,\ntouch upon the area of blockchain cybersecurity in the supply chain context.\nMore and more, since the smart contract handles the transfer of data over\ndifferent locations, then the security protection should be strong enough to\nsecure the data and the assets from any attacks. Finally, the paper examines\nthe main security attacks that affect the data on the blockchain and propose a\nsolution",
        "author": [
            "Abdul Khalique Shaikh A. K. Al-Alawi",
            "L. R.",
            "Al-Busaidi",
            "R.",
            "Shaikh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.04917v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.04917v1",
        "arXiv ID": "2209.04917v1"
    },
    {
        "title": "Physical Access Control Management System Based on Permissioned\n  Blockchain",
        "Published: ": "2019-01-28T18:27:21Z",
        "abstract": "Using blockchain as a decentralized backend infrastructure has grabbed the\nattention of many startups entrepreneurs and developers. Blockchain records\ntransactions permanently and protects them from undesirable tampering. It\nprovides a reliable tamper-proof database which can be considered as a\ntrustable source for tracking the previous system state. In this paper, we\npresent our access control application based on Hyperledger Fabric Blockchain\nand Hyperledger Composer to control access to physical places. The system\ncomponents and modular architecture are illustrated, and we have extracted\nmetadata include historian transactions details arising from our demo test.\nFinally, the performance metrics and resources consumption are provided using\nHyperledger Caliper, a benchmark framework for measuring Hyperledger\nblockchains performance.",
        "author": [
            "Sara Rouhani",
            "Vahid Pourheidari",
            "Ralph Deters"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.09873v1.pdf",
        "Categories": [
            [
                "cs.SY",
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.09873v1",
        "arXiv ID": "1901.09873v1"
    },
    {
        "title": "Blockchain for the Internet of Vehicles towards Intelligent\n  Transportation Systems: A Survey",
        "Published: ": "2020-07-12T15:53:02Z",
        "abstract": "Internet of Vehicles (IoV) is an emerging concept that is believed to help\nrealise the vision of intelligent transportation systems (ITS). IoV has become\nan important research area of impactful applications in recent years due to the\nrapid advancements in vehicular technologies, high throughput satellite\ncommunication, Internet of Things and cyber-physical systems. IoV enables the\nintegration of smart vehicles with the Internet and system components\nattributing to their environment such as public infrastructures, sensors,\ncomputing nodes, pedestrians and other vehicles. By allowing the development of\na common information exchange platform between vehicles and heterogeneous\nvehicular networks, this integration aims to create a better environment and\npublic space to the people as well as to enhance safety for all road users.\nBeing a participatory data exchange and storage, the underlying information\nexchange platform of IoV needs to be secure, transparent and immutable in order\nto achieve the intended objectives of ITS. In this connection, the adoption of\nblockchain as a system platform for supporting the information exchange needs\nof IoV has been explored. Due to their decentralized and immutable nature, IoV\napplications enabled by blockchain are believed to have a number of desirable\nproperties such as decentralization, security, transparency, immutability, and\nautomation. In this paper, we present a contemporary survey on the latest\nadvancement in blockchain for IoV. Particularly, we highlight the different\napplication scenarios of IoV after carefully reviewing the recent literatures.\nWe also investigate several key challenges where blockchain is applied in IoV.\nFurthermore, we present the future opportunities and explore further research\ndirections of IoV as a key enabler of ITS.",
        "author": [
            "Muhammad Baqer Mollah",
            "Jun Zhao",
            "Dusit Niyato",
            "Yong Liang Guan",
            "Chau Yuen",
            "Sumei Sun",
            "Kwok-Yan Lam",
            "Leong Hai Koh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.06022v2.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.NI",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.06022v2",
        "arXiv ID": "2007.06022v2"
    },
    {
        "title": "Talaria: A Framework for Simulation of Permissioned Blockchains for\n  Logistics and Beyond",
        "Published: ": "2021-03-03T08:43:30Z",
        "abstract": "In this paper, we present Talaria, a novel permissioned blockchain simulator\nthat supports numerous protocols and use cases, most notably in supply chain\nmanagement. Talaria extends the capability of BlockSim, an existing blockchain\nsimulator, to include permissioned blockchains and serves as a foundation for\nfurther private blockchain assessment. Talaria is designed with both practical\nByzantine Fault Tolerance (pBFT) and simplified version of Proof-of-Authority\nconsensus protocols, but can be revised to include other permissioned protocols\nwithin its modular framework. Moreover, Talaria is able to simulate different\ntypes of malicious authorities and a variable daily transaction load at each\nnode. In using Talaria, business practitioners and policy planners have an\nopportunity to measure, evaluate, and adapt a range of blockchain solutions for\ncommercial operations.",
        "author": [
            "Jiali Xing",
            "David Fischer",
            "Nitya Labh",
            "Ryan Piersma",
            "Benjamin C. Lee",
            "Yu Amy Xia",
            "Tuhin Sahai",
            "Vahid Tarokh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2103.02260v2.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "cs.DC",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2103.02260v2",
        "arXiv ID": "2103.02260v2"
    },
    {
        "title": "Turning disruptive power of Blockchain in the insurance market into\n  innovative opportunities",
        "Published: ": "2022-11-03T04:54:02Z",
        "abstract": "Insurance has been around for more than centuries. This risk mitigation\nstrategy has been utilized in maritime commerce as early thousand years ago,\nwhere Asian merchant seafarers were pooling together their wares in collective\nfunds to pay for damages of individual capsized ship. In 2018, insurance\nindustry made up 6 percent of global GDP while financial industry amounted to\nabout 7 to 9 percent of the US GDP.2020, the industry net premiums totaled\nUSD1.28 trillion, by 2030, blockchain insurance market value is estimated to\nreach USD39.5 Billion. Despite of growing reform, the insurance market is\ndominated by intermediaries assisting people to match their insurance needs.\nWhile many predictions focused on artificial intelligence, cloud computing,\nblockchain stands out as the most disruptive technology that can change the\ndriving forces underlying the global economy. This paper presents a blockchain\nbusiness use case and how insurance industry can turn blockchain disruptive\npower into innovative opportunities.",
        "author": [
            "Wadnerson Boileau"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.05830v2.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.05830v2",
        "arXiv ID": "2211.05830v2"
    },
    {
        "title": "Exploring the added value of blockchain technology for the healthcare\n  domain",
        "Published: ": "2019-11-15T17:00:00Z",
        "abstract": "In this report, the University Medical Center Groningen (UMCG) has written\ndown lessons learned on how blockchain technology can have an impact on the\nhealthcare domain. By looking at two use-cases, the hospital challenged several\nteams, participating in an open innovation program and blockchain hackathon, to\nfind a solution that showed the added value of the technology for patient care\nand scientific research. Besides this practical perspective, the report also\nconsiders literature discussing the current state of blockchain technology in\nregard to developments in the healthcare domain (touching on patient\nempowerment, data management, regulations, and interoperability between\nhealthcare systems).",
        "author": [
            "Bas R. J. Bolmer",
            "Monique Taverne",
            "Marco Scherer"
        ],
        "pdfLink": "http://arxiv.org/pdf/1911.08277v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.DB",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1911.08277v1",
        "arXiv ID": "1911.08277v1"
    },
    {
        "title": "Blockchain meets Biometrics: Concepts, Application to Template\n  Protection, and Trends",
        "Published: ": "2020-03-19T08:11:13Z",
        "abstract": "Blockchain technologies provide excellent architectures and practical tools\nfor securing and managing the sensitive and private data stored in biometric\ntemplates, but at a cost. We discuss opportunities and challenges in the\nintegration of blockchain and biometrics, with emphasis in biometric template\nstorage and protection, a key problem in biometrics still largely unsolved. Key\ntradeoffs involved in that integration, namely, latency, processing time,\neconomic cost, and biometric performance are experimentally studied through the\nimplementation of a smart contract on the Ethereum blockchain platform, which\nis publicly available in github for research purposes.",
        "author": [
            "Oscar Delgado-Mohatar",
            "Julian Fierrez",
            "Ruben Tolosana",
            "Ruben Vera-Rodriguez"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.09262v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.09262v1",
        "arXiv ID": "2003.09262v1"
    },
    {
        "title": "Pluralize: a Trustworthy Framework for High-Level Smart Contract-Draft",
        "Published: ": "2018-10-23T06:30:10Z",
        "abstract": "The paper presents Pluralize a formal logical framework able to extend the\nexecution of blockchain transactions to events coming from external oracles,\nlike external time, sensor data, human-made declarations, etc. These events are\nby essence non-reliable, since transaction execution can be triggered by\ninformation whose veracity cannot be established by the blockchain. To overcome\nthis problem, the language features a first-order logic and an authority\nalgebra to allow formal reasoning and establish accountability of agents for\nblockchain-enabled transactions. We provide an accountability model that allows\nto formally prove the accountability of agents by a formal proof locally\nexecutable by each agent of the blockchain.",
        "author": [
            "Zaynah Dargaye",
            "Antonella Pozzo",
            "Sara Tucci-Piergiovanni"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.05444v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.LO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.05444v1",
        "arXiv ID": "1812.05444v1"
    },
    {
        "title": "When Augmented Reality Meets Big Data",
        "Published: ": "2014-07-27T13:21:10Z",
        "abstract": "With computing and sensing woven into the fabric of everyday life, we live in\nan era where we are awash in a flood of data from which we can gain rich\ninsights. Augmented reality (AR) is able to collect and help analyze the\ngrowing torrent of data about user engagement metrics within our personal\nmobile and wearable devices. This enables us to blend information from our\nsenses and the digitalized world in a myriad of ways that was not possible\nbefore. AR and big data have a logical maturity that inevitably converge them.\nThe tread of harnessing AR and big data to breed new interesting applications\nis starting to have a tangible presence. In this paper, we explore the\npotential to capture value from the marriage between AR and big data\ntechnologies, following with several challenges that must be addressed to fully\nrealize this potential.",
        "author": [
            "Zhanpeng Huang",
            "Pan Hui",
            "Christoph Peylo"
        ],
        "pdfLink": "http://arxiv.org/pdf/1407.7223v1.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.MM",
                "cs.SI",
                "H.5.1"
            ]
        ],
        "Link": "http://arxiv.org/abs/1407.7223v1",
        "arXiv ID": "1407.7223v1"
    },
    {
        "title": "Intelligent Vehicle-Trust Point: Reward based Intelligent Vehicle\n  Communication using Blockchain",
        "Published: ": "2017-07-24T09:01:09Z",
        "abstract": "The Intelligent vehicle (IV) is experiencing revolutionary growth in research\nand industry, but it still suffers from many security vulnerabilities.\nTraditional security methods are incapable to provide secure IV communication.\nThe major issues in IV communication, are trust, data accuracy and reliability\nof communication data in the communication channel. Blockchain technology works\nfor the crypto currency, Bit-coin, which is recently used to build trust and\nreliability in peer-to-peer networks having similar topologies as IV\nCommunication. In this paper, we are proposing, Intelligent Vehicle-Trust Point\n(IV-TP) mechanism for IV communication among IVs using Blockchain technology.\nThe IVs communicated data provides security and reliability using our proposed\nIV-TP. Our IV-TP mechanism provides trustworthiness for vehicles behavior, and\nvehicles legal and illegal action. Our proposal presents a reward based system,\nan exchange of some IV-TP among IVs, during successful communication. For the\ndata management of the IV-TP, we are using blockchain technology in the\nintelligent transportation system (ITS), which stores all IV-TP details of\nevery vehicle and is accessed ubiquitously by IVs. In this paper, we evaluate\nour proposal with the help of intersection use case scenario for intelligent\nvehicles communication.",
        "author": [
            "Madhusudan Singh",
            "Shiho Kim"
        ],
        "pdfLink": "http://arxiv.org/pdf/1707.07442v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1707.07442v2",
        "arXiv ID": "1707.07442v2"
    },
    {
        "title": "How to Securely Prune Bitcoin's Blockchain",
        "Published: ": "2020-04-15T07:20:35Z",
        "abstract": "Bitcoin was the first successful decentralized cryptocurrency and remains the\nmost popular of its kind to this day. Despite the benefits of its blockchain,\nBitcoin still faces serious scalability issues, most importantly its\never-increasing blockchain size. While alternative designs introduced schemes\nto periodically create snapshots and thereafter prune older blocks,\nalready-deployed systems such as Bitcoin are often considered incapable of\nadopting corresponding approaches. In this work, we revise this popular belief\nand present CoinPrune, a snapshot-based pruning scheme that is fully compatible\nwith Bitcoin. CoinPrune can be deployed through an opt-in velvet fork, i.e.,\nwithout impeding the established Bitcoin network. By requiring miners to\npublicly announce and jointly reaffirm recent snapshots on the blockchain,\nCoinPrune establishes trust into the snapshots' correctness even in the\npresence of powerful adversaries. Our evaluation shows that CoinPrune reduces\nthe storage requirements of Bitcoin already by two orders of magnitude today,\nwith further relative savings as the blockchain grows. In our experiments,\nnodes only have to fetch and process 5 GiB instead of 230 GiB of data when\njoining the network, reducing the synchronization time on powerful devices from\ncurrently 5 h to 46 min, with even more savings for less powerful devices.",
        "author": [
            "Roman Matzutt",
            "Benedikt Kalde",
            "Jan Pennekamp",
            "Arthur Drichel",
            "Martin Henze",
            "Klaus Wehrle"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.06911v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.06911v1",
        "arXiv ID": "2004.06911v1"
    },
    {
        "title": "Federated Learning for Metaverse: A Survey",
        "Published: ": "2023-03-23T15:15:40Z",
        "abstract": "The metaverse, which is at the stage of innovation and exploration, faces the\ndilemma of data collection and the problem of private data leakage in the\nprocess of development. This can seriously hinder the widespread deployment of\nthe metaverse. Fortunately, federated learning (FL) is a solution to the above\nproblems. FL is a distributed machine learning paradigm with privacy-preserving\nfeatures designed for a large number of edge devices. Federated learning for\nmetaverse (FL4M) will be a powerful tool. Because FL allows edge devices to\nparticipate in training tasks locally using their own data, computational\npower, and model-building capabilities. Applying FL to the metaverse not only\nprotects the data privacy of participants but also reduces the need for high\ncomputing power and high memory on servers. Until now, there have been many\nstudies about FL and the metaverse, respectively. In this paper, we review some\nof the early advances of FL4M, which will be a research direction with\nunlimited development potential. We first introduce the concepts of metaverse\nand FL, respectively. Besides, we discuss the convergence of key metaverse\ntechnologies and FL in detail, such as big data, communication technology, the\nInternet of Things, edge computing, blockchain, and extended reality. Finally,\nwe discuss some key challenges and promising directions of FL4M in detail. In\nsummary, we hope that our up-to-date brief survey can help people better\nunderstand FL4M and build a fair, open, and secure metaverse.",
        "author": [
            "Yao Chen",
            "Shan Huang",
            "Wensheng Gan",
            "Gengsen Huang",
            "Yongdong Wu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.17987v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.17987v1",
        "arXiv ID": "2303.17987v1"
    },
    {
        "title": "Dissecting Bitcoin and Ethereum Transactions: On the Lack of Transaction\n  Contention and Prioritization Transparency in Blockchains",
        "Published: ": "2023-02-14T10:42:17Z",
        "abstract": "In permissionless blockchains, transaction issuers include a fee to\nincentivize miners to include their transactions. To accurately estimate this\nprioritization fee for a transaction, transaction issuers (or blockchain\nparticipants, more generally) rely on two fundamental notions of transparency,\nnamely contention and prioritization transparency. Contention transparency\nimplies that participants are aware of every pending transaction that will\ncontend with a given transaction for inclusion. Prioritization transparency\nstates that the participants are aware of the transaction or prioritization\nfees paid by every such contending transaction. Neither of these notions of\ntransparency holds well today. Private relay networks, for instance, allow\nusers to send transactions privately to miners. Besides, users can offer fees\nto miners via either direct transfers to miners' wallets or off-chain payments\n-- neither of which are public. In this work, we characterize the lack of\ncontention and prioritization transparency in Bitcoin and Ethereum resulting\nfrom such practices. We show that private relay networks are widely used and\nprivate transactions are quite prevalent. We show that the lack of transparency\nfacilitates miners to collude and overcharge users who may use these private\nrelay networks despite them offering little to no guarantees on transaction\nprioritization. The lack of these transparencies in blockchains has crucial\nimplications for transaction issuers as well as the stability of blockchains.\nFinally, we make our data sets and scripts publicly available.",
        "author": [
            "Johnnatan Messias",
            "Vabuk Pahari",
            "Balakrishnan Chandrasekaran",
            "Krishna P. Gummadi",
            "Patrick Loiseau"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.06962v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.06962v2",
        "arXiv ID": "2302.06962v2"
    },
    {
        "title": "Reconstruction-free action inference from compressive imagers",
        "Published: ": "2015-01-18T23:14:15Z",
        "abstract": "Persistent surveillance from camera networks, such as at parking lots, UAVs,\netc., often results in large amounts of video data, resulting in significant\nchallenges for inference in terms of storage, communication and computation.\nCompressive cameras have emerged as a potential solution to deal with the data\ndeluge issues in such applications. However, inference tasks such as action\nrecognition require high quality features which implies reconstructing the\noriginal video data. Much work in compressive sensing (CS) theory is geared\ntowards solving the reconstruction problem, where state-of-the-art methods are\ncomputationally intensive and provide low-quality results at high compression\nrates. Thus, reconstruction-free methods for inference are much desired. In\nthis paper, we propose reconstruction-free methods for action recognition from\ncompressive cameras at high compression ratios of 100 and above. Recognizing\nactions directly from CS measurements requires features which are mostly\nnonlinear and thus not easily applicable. This leads us to search for such\nproperties that are preserved in compressive measurements. To this end, we\npropose the use of spatio-temporal smashed filters, which are compressive\ndomain versions of pixel-domain matched filters. We conduct experiments on\npublicly available databases and show that one can obtain recognition rates\nthat are comparable to the oracle method in uncompressed setup, even for high\ncompression ratios.",
        "author": [
            "Kuldeep Kulkarni",
            "Pavan Turaga"
        ],
        "pdfLink": "http://arxiv.org/pdf/1501.04367v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1501.04367v1",
        "arXiv ID": "1501.04367v1"
    },
    {
        "title": "Compressed Sensing based Protocol for Efficient Reconstruction of Sparse\n  Superimposed Data in a Multi-Hop Wireless Sensor Network",
        "Published: ": "2012-08-07T12:38:57Z",
        "abstract": "We consider a multi-hop wireless sensor network that measures sparse events\nand propose a simple forwarding protocol based on Compressed Sensing (CS) which\ndoes not need any sophisticated Media Access Control (MAC) scheduling, neither\na routing protocol, thereby making significant overhead and energy savings. By\nmeans of flooding, multiple packets with different superimposed measurements\nare received simultaneously at any node. Thanks to our protocol, each node is\nable to recover each measurement and forward it while avoiding cycles.\nNumerical results show that our protocol achieves close to zero reconstruction\nerrors at the sink, while greatly reducing overhead. This initial research\nreveals a new and promising approach to protocol design through CS for wireless\nmesh and sensor networks.",
        "author": [
            "Megumi Kaneko",
            "Khaldoun Al Agha"
        ],
        "pdfLink": "http://arxiv.org/pdf/1208.1410v1.pdf",
        "Categories": [
            [
                "cs.OH"
            ]
        ],
        "Link": "http://arxiv.org/abs/1208.1410v1",
        "arXiv ID": "1208.1410v1"
    },
    {
        "title": "Statistical privacy-preserving message dissemination for peer-to-peer\n  networks",
        "Published: ": "2021-02-02T17:18:16Z",
        "abstract": "Concerns for the privacy of communication is widely discussed in research and\noverall society. For the public financial infrastructure of blockchains, this\ndiscussion encompasses the privacy of transaction data and its broadcasting\nthroughout the network. To tackle this problem, we transform a discrete-time\nprotocol for contact networks over infinite trees into a computer network\nprotocol for peer-to-peer networks. Peer-to-peer networks are modeled as\norganically growing graphs. We show that the distribution of shortest paths in\nsuch a network can be modeled using a normal distribution\n$\\mathcal{N}(\\mu,\\sigma^2).$ We determine statistical estimators for\n$\\mu,\\sigma$ via multivariate models. The model behaves logarithmic over the\nnumber of nodes n and proportional to an inverse exponential over the number of\nadded edges k. These results facilitate the computation of optimal forwarding\nprobabilities during the dissemination phase for optimal privacy in a limited\ninformation environment.",
        "author": [
            "David M\u00f6dinger",
            "Jan-Hendrik Lorenz",
            "Fanz J. Hauck"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.01615v3.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.01615v3",
        "arXiv ID": "2102.01615v3"
    },
    {
        "title": "Innovative Countermeasures to Defeat Cyber Attacks Against Blockchain\n  Wallets: A Crypto Terminal Use Case",
        "Published: ": "2023-03-30T07:58:39Z",
        "abstract": "Blockchain transactions are signed by private keys. Secure key storage and\ntamper-proof computers are essential requirements for deploying a trusted\ninfrastructure. In this paper, we identify some threats against blockchain\nwallets and propose a set of physical and logical countermeasures to thwart\nthem. We present the crypto terminal device, operating with a removable secure\nelement, built on open software and hardware architectures, capable of\ndetecting a cloned device or corrupted software. These technologies are based\non tamper-resistant computing (javacard), smart card anti-cloning, smart card\ncontent attestation, application firewall, bare-metal architecture, remote\nattestation, dynamic Physical Unclonable Function (dPUF), and programming\ntokens as a root of trust.This paper is an extended version of the paper\n''Innovative Countermeasures to Defeat Cyber Attacks Against Blockchain\nWallets,'' 2021 5th Cyber Security in Networking Conference (CSNet), 2021, pp.\n49-54, doi: 10.1109/CSNet52717.2021.9614649",
        "author": [
            "Pascal Urien"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.17206v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.17206v1",
        "arXiv ID": "2303.17206v1"
    },
    {
        "title": "Locality Sensitive Hash Aggregated Nonlinear Neighbourhood Matrix\n  Factorization for Online Sparse Big Data Analysis",
        "Published: ": "2021-11-23T07:07:55Z",
        "abstract": "Matrix factorization (MF) can extract the low-rank features and integrate the\ninformation of the data manifold distribution from high-dimensional data, which\ncan consider the nonlinear neighbourhood information. Thus, MF has drawn wide\nattention for low-rank analysis of sparse big data, e.g., Collaborative\nFiltering (CF) Recommender Systems, Social Networks, and Quality of Service.\nHowever, the following two problems exist: 1) huge computational overhead for\nthe construction of the Graph Similarity Matrix (GSM), and 2) huge memory\noverhead for the intermediate GSM. Therefore, GSM-based MF, e.g., kernel MF,\ngraph regularized MF, etc., cannot be directly applied to the low-rank analysis\nof sparse big data on cloud and edge platforms. To solve this intractable\nproblem for sparse big data analysis, we propose Locality Sensitive Hashing\n(LSH) aggregated MF (LSH-MF), which can solve the following problems: 1) The\nproposed probabilistic projection strategy of LSH-MF can avoid the construction\nof the GSM. Furthermore, LSH-MF can satisfy the requirement for the accurate\nprojection of sparse big data. 2) To run LSH-MF for fine-grained\nparallelization and online learning on GPUs, we also propose CULSH-MF, which\nworks on CUDA parallelization. Experimental results show that CULSH-MF can not\nonly reduce the computational time and memory overhead but also obtain higher\naccuracy. Compared with deep learning models, CULSH-MF can not only save\ntraining time but also achieve the same accuracy performance.",
        "author": [
            "Zixuan Li",
            "Hao Li",
            "Kenli Li",
            "Fan Wu",
            "Lydia Chen",
            "Keqin Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2111.11682v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2111.11682v1",
        "arXiv ID": "2111.11682v1"
    },
    {
        "title": "MRL-PoS: A Multi-agent Reinforcement Learning based Proof of Stake\n  Consensus Algorithm for Blockchain",
        "Published: ": "2023-12-14T16:58:18Z",
        "abstract": "The core of a blockchain network is its consensus algorithm. Starting with\nthe Proof-of-Work, there have been various versions of consensus algorithms,\nsuch as Proof-of-Stake (PoS), Proof-of-Authority (PoA), and Practical Byzantine\nFault Tolerance (PBFT). Each of these algorithms focuses on different aspects\nto ensure efficient and reliable processing of transactions. Blockchain\noperates in a decentralized manner where there is no central authority and the\nnetwork is composed of diverse users. This openness creates the potential for\nmalicious nodes to disrupt the network in various ways. Therefore, it is\ncrucial to embed a mechanism within the blockchain network to constantly\nmonitor, identify, and eliminate these malicious nodes. However, there is no\none-size-fits-all mechanism to identify all malicious nodes. Hence, the dynamic\nadaptability of the blockchain network is important to maintain security and\nreliability at all times. This paper introduces MRL-PoS, a Proof-of-Stake\nconsensus algorithm based on multi-agent reinforcement learning. MRL-PoS\nemploys reinforcement learning for dynamically adjusting to the behavior of all\nusers. It incorporates a system of rewards and penalties to eliminate malicious\nnodes and incentivize honest ones. Additionally, MRL-PoS has the capability to\nlearn and respond to new malicious tactics by continually training its agents.",
        "author": [
            "Tariqul Islam",
            "Faisal Haque Bappy",
            "Tarannum Shaila Zaman",
            "Md Sajidul Islam Sajid",
            "Mir Mehedi Ahsan Pritom"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.09123v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.09123v1",
        "arXiv ID": "2312.09123v1"
    },
    {
        "title": "Big data and big values: When companies need to rethink themselves",
        "Published: ": "2021-05-25T16:26:38Z",
        "abstract": "In order to face the complexity of business environments and detect\npriorities while triggering contingency strategies, we propose a new\nmethodological approach that combines text mining, social network and big data\nanalytics, with the assessment of stakeholders' attitudes towards company core\nvalues. This approach was applied in a case study where we considered the\nTwitter discourse about core values in Italy. We collected more than 94,000\ntweets related to the core values of the firms listed in Fortune's ranking of\nthe World's Most Admired Companies (2013-2017). For the Italian scenario, we\nfound three predominant core values orientations (Customers, Employees and\nExcellence) - which should be at the basis of any business strategy - and three\nlatent ones (Economic-Financial Growth, Citizenship and Social Responsibility),\nwhich need periodic attention. Our contribution is mostly methodological and\nextends the research on text mining and on online big data analytics applied in\ncomplex business contexts.",
        "author": [
            "M. A. Barchiesi",
            "A. Fronzetti Colladon"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.12048v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.CL",
                "physics.soc-ph",
                "J.4; I.2.7; H.4.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.12048v1",
        "arXiv ID": "2105.12048v1"
    },
    {
        "title": "Improving Privacy and Security in Unmanned Aerial Vehicles Network using\n  Blockchain",
        "Published: ": "2022-01-16T17:48:21Z",
        "abstract": "Unmanned Aerial Vehicles (UAVs), also known as drones, have exploded in every\nsegment present in todays business industry. They have scope in reinventing old\nbusinesses, and they are even developing new opportunities for various brands\nand franchisors. UAVs are used in the supply chain, maintaining surveillance\nand serving as mobile hotspots. Although UAVs have potential applications, they\nbring several societal concerns and challenges that need addressing in public\nsafety, privacy, and cyber security. UAVs are prone to various cyber-attacks\nand vulnerabilities; they can also be hacked and misused by malicious entities\nresulting in cyber-crime. The adversaries can exploit these vulnerabilities,\nleading to data loss, property, and destruction of life. One can partially\ndetect the attacks like false information dissemination, jamming, gray hole,\nblackhole, and GPS spoofing by monitoring the UAV behavior, but it may not\nresolve privacy issues. This paper presents secure communication between UAVs\nusing blockchain technology. Our approach involves building smart contracts and\nmaking a secure and reliable UAV adhoc network. This network will be resilient\nto various network attacks and is secure against malicious intrusions.",
        "author": [
            "Hardik Sachdeva",
            "Shivam Gupta",
            "Anushka Misra",
            "Khushbu Chauhan",
            "Mayank Dave"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.06100v2.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.06100v2",
        "arXiv ID": "2201.06100v2"
    },
    {
        "title": "A Scalable Architecture for Monitoring IoT Devices Using Ethereum and\n  Fog Computing",
        "Published: ": "2020-06-06T23:13:56Z",
        "abstract": "With the recent considerable developments in the Internet of Things (IoT),\nbillions of resource-constrained devices are interconnected through the\ninternet. Monitoring this huge number of IoT devices that are heterogeneous in\nterms of underlying communication protocols and data format is challenging. The\nmajority of existing IoT device monitoring solutions heavily rely on\ncentralized architectures. Since using centralized architectures comes at the\nexpense of trusting an authority, it has several inherent drawbacks, including\nvulnerability to security attacks, lack of data privacy, and unauthorized data\nmanipulation. Hence, a new decentralized approach is crucial to remedy these\ndrawbacks. One of the most promising technologies which is widely used to\nprovide decentralization is blockchain. Additionally, to ease the burden of\ncommunication overhead and computational power on resource-constrained IoT\ndevices, fog computing can be exploited to decrease communication latency and\nprovide better network scalability.\n  In this paper, we propose a scalable blockchain-based architecture for\nmonitoring IoT devices using fog computing. To demonstrate the feasibility and\nusability of the proposed solution, we have implemented a proof-of-concept\nprototype, leveraging Ethereum smart contracts. Finally, a comprehensive\nevaluation is conducted. The evaluation results indicate that the proposed\nsolution is significantly scalable and compatible with resource-constrained IoT\ndevices.",
        "author": [
            "Shirin Tahmasebi",
            "Jafar Habibi",
            "Abolhassan Shamsaie"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.03994v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.03994v2",
        "arXiv ID": "2006.03994v2"
    },
    {
        "title": "ACeD: Scalable Data Availability Oracle",
        "Published: ": "2020-10-30T20:51:11Z",
        "abstract": "A popular method in practice offloads computation and storage in blockchains\nby relying on committing only hashes of off-chain data into the blockchain.\nThis mechanism is acknowledged to be vulnerable to a stalling attack: the\nblocks corresponding to the committed hashes may be unavailable at any honest\nnode. The straightforward solution of broadcasting all blocks to the entire\nnetwork sidesteps this data availability attack, but it is not scalable. In\nthis paper, we propose ACeD, a scalable solution to this data availability\nproblem with $O(1)$ communication efficiency, the first to the best of our\nknowledge.\n  The key innovation is a new protocol that requires each of the $N$ nodes to\nreceive only $O(1/N)$ of the block, such that the data is guaranteed to be\navailable in a distributed manner in the network. Our solution creatively\nintegrates coding-theoretic designs inside of Merkle tree commitments to\nguarantee efficient and tamper-proof reconstruction; this solution is distinct\nfrom Asynchronous Verifiable Information Dispersal (in guaranteeing efficient\nproofs of malformed coding) and Coded Merkle Tree (which only provides\nguarantees for random corruption as opposed to our guarantees for worst-case\ncorruption). We implement ACeD with full functionality in 6000 lines of Rust\ncode, integrate the functionality as a smart contract into Ethereum via a\nhigh-performance implementation demonstrating up to 10,000 transactions per\nsecond in throughput and 6000x reduction in gas cost on the Ethereum testnet\nKovan.",
        "author": [
            "Peiyao Sheng",
            "Bowen Xue",
            "Sreeram Kannan",
            "Pramod Viswanath"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.00102v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.00102v2",
        "arXiv ID": "2011.00102v2"
    },
    {
        "title": "Diffusion Adaptation Framework for Compressive Sensing Reconstruction",
        "Published: ": "2017-12-03T03:32:02Z",
        "abstract": "Compressive sensing(CS) has drawn much attention in recent years due to its\nlow sampling rate as well as high recovery accuracy. As an important procedure,\nreconstructing a sparse signal from few measurement data has been intensively\nstudied. Many reconstruction algorithms have been proposed and shown good\nreconstruction performance. However, when dealing with large-scale sparse\nsignal reconstruction problem, the storage requirement will be high, and many\nalgorithms also suffer from high computational cost. In this paper, we propose\na novel diffusion adaptation framework for CS reconstruction, where the\nreconstruction is performed in a distributed network. The data of measurement\nmatrix are partitioned into small parts and are stored in each node, which\nassigns the storage load in a decentralized manner. The local information\ninteraction provides the reconstruction ability. Then, a simple and efficient\ngradient-descend based diffusion algorithm has been proposed to collaboratively\nrecover the sparse signal over network. The convergence of the proposed\nalgorithm is analyzed. To further increase the convergence speed, a mini-batch\nbased diffusion algorithm is also proposed. Simulation results show that the\nproposed algorithms can achieve good reconstruction accuracy as well as fast\nconvergence speed.",
        "author": [
            "Yicong He",
            "Fei Wang",
            "Shiyuan Wang",
            "Badong Chen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1712.00703v3.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1712.00703v3",
        "arXiv ID": "1712.00703v3"
    },
    {
        "title": "EduChain: A Blockchain-based Education Data Management System",
        "Published: ": "2023-06-01T11:16:31Z",
        "abstract": "The predominant centralized paradigm in educational data management currently\nsuffers from several critical issues such as vulnerability to malicious\ntampering, a high prevalence of diploma counterfeiting, and the onerous cost of\ncertificate authentication. Decentralized blockchain technology, with its\ncutting-edge capabilities, presents a viable solution to these pervasive\nproblems. In this paper, we illuminate the inherent limitations of existing\ncentralized systems and introduce EduChain, a novel heterogeneous\nblockchain-based system for managing educational data. EduChain uniquely\nharnesses the strengths of both private and consortium blockchains, offering an\nunprecedented level of security and efficiency. In addition, we propose a\nrobust mechanism for performing database consistency checks and error tracing.\nThis is achieved through the implementation of a secondary consensus, employing\nthe pt-table-checksum tool. This approach effectively addresses the prevalent\nissue of database mismatches. Our system demonstrates superior performance in\nkey areas such as information verification, error traceback, and data security,\nthereby significantly improving the integrity and trustworthiness of\neducational data management. Through EduChain, we offer a powerful solution for\nfuture advancements in secure and efficient educational data management.",
        "author": [
            "Yihan Liu",
            "Ke Li",
            "Zihao Huang",
            "Bowen Li",
            "Guiyan Wang",
            "Wei Cai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.00553v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DB"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.00553v1",
        "arXiv ID": "2306.00553v1"
    },
    {
        "title": "A Blockchain Framework for Secure Task Sharing in Multi-access Edge\n  Computing",
        "Published: ": "2020-06-25T04:24:19Z",
        "abstract": "In the context of Multi-access Edge Computing (MEC), the task sharing\nmechanism among edge servers is an activity of vital importance for speeding up\nthe computing process and thereby improve user experience. The distributed\nresources in the form of edge servers are expected to collaborate with each\nother in order to boost overall performance of a MEC system. However, there are\nmany challenges to adopt global collaboration among the edge computing server\nentities among which the following two are significant: ensuring trust among\nthe servers and developing a unified scheme to enable real-time collaboration\nand task sharing. In this article, a blockchain framework is proposed to\nprovide a trusted collaboration mechanism between edge servers in a MEC\nenvironment. In particular, a permissioned blockchain scheme is investigated to\nsupport a trusted design that also provides incentives for collaboration.\nFinally, Caliper tool and Hyperledger Fabric benchmarks are used to conduct an\nexperimental evaluation of the proposed blockchain scheme embedded in a MEC\nframework.",
        "author": [
            "Angelo Vera Rivera",
            "Ahmed Refaey",
            "Ekram Hossain"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.14166v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.14166v1",
        "arXiv ID": "2006.14166v1"
    },
    {
        "title": "Distributed Runtime Verification of Metric Temporal Properties for\n  Cross-Chain Protocols",
        "Published: ": "2022-04-20T21:53:42Z",
        "abstract": "Transactions involving multiple blockchains are implemented by cross-chain\nprotocols. These protocols are based on smart contracts, programs that run on\nblockchains, executed by a network of computers. Because smart contracts can\nautomatically transfer ownership of cryptocurrencies, electronic securities,\nand other valuable assets among untrusting parties, verifying the runtime\ncorrectness of smart contracts is a problem of compelling practical interest.\nSuch verification is challenging since smart contract execution is\ntime-sensitive, and the clocks on different blockchains may not be perfectly\nsynchronized. This paper describes a method for runtime monitoring of\nblockchain executions. First, we propose a generalized runtime verification\ntechnique for verifying partially synchronous distributed computations for the\nmetric temporal logic (MTL) by exploiting bounded-skew clock synchronization.\nSecond, we introduce a progression-based formula rewriting scheme for\nmonitoring \\MTL specifications which employ SMT solving techniques and report\nexperimental results.",
        "author": [
            "Ritam Ganguly",
            "Yingjie Xue",
            "Aaron Jonckheere",
            "Parker Ljung",
            "Benjamin Schornstein",
            "Borzoo Bonakdarpour",
            "Maurice Herlihy"
        ],
        "pdfLink": "http://arxiv.org/pdf/2204.09796v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.FL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2204.09796v1",
        "arXiv ID": "2204.09796v1"
    },
    {
        "title": "IoT Federated Blockchain Learning at the Edge",
        "Published: ": "2023-04-06T11:32:40Z",
        "abstract": "IoT devices are sorely underutilized in the medical field, especially within\nmachine learning for medicine, yet they offer unrivaled benefits. IoT devices\nare low-cost, energy-efficient, small and intelligent devices. In this paper,\nwe propose a distributed federated learning framework for IoT devices, more\nspecifically for IoMT (Internet of Medical Things), using blockchain to allow\nfor a decentralized scheme improving privacy and efficiency over a centralized\nsystem; this allows us to move from the cloud-based architectures, that are\nprevalent, to the edge. The system is designed for three paradigms: 1) Training\nneural networks on IoT devices to allow for collaborative training of a shared\nmodel whilst decoupling the learning from the dataset to ensure privacy.\nTraining is performed in an online manner simultaneously amongst all\nparticipants, allowing for the training of actual data that may not have been\npresent in a dataset collected in the traditional way and dynamically adapt the\nsystem whilst it is being trained. 2) Training of an IoMT system in a fully\nprivate manner such as to mitigate the issue with confidentiality of medical\ndata and to build robust, and potentially bespoke, models where not much, if\nany, data exists. 3) Distribution of the actual network training, something\nfederated learning itself does not do, to allow hospitals, for example, to\nutilize their spare computing resources to train network models.",
        "author": [
            "James Calo",
            "Benny Lo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.03006v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.03006v1",
        "arXiv ID": "2304.03006v1"
    },
    {
        "title": "Blockchain Technology to Secure Bluetooth",
        "Published: ": "2022-11-11T19:20:33Z",
        "abstract": "Bluetooth is a communication technology used to wirelessly exchange data\nbetween devices. In the last few years there have been found a great number of\nsecurity vulnerabilities, and adversaries are taking advantage of them causing\nharm and significant loss. Numerous system security updates have been approved\nand installed in order to sort out security holes and bugs, and prevent attacks\nthat could expose personal or other valuable information. But those updates are\nnot sufficient and appropriate and new bugs keep showing up. In Bluetooth\ntechnology, pairing is identified as the step where most bugs are found and\nmost attacks target this particular process part of Bluetooth. A new technology\nthat has been proved bulletproof when it comes to security and the exchange of\nsensitive information is Blockchain. Blockchain technology is promising to be\nincorporated well in a network of smart devices, and secure an Internet of\nThings (IoT), where Bluetooth technology is being extensively used. This work\npresents a vulnerability discovered in Bluetooth pairing process, and proposes\na Blockchain solution approach to secure pairing and mitigate this\nvulnerability. The paper first introduces the Bluetooth technology and delves\ninto how Blockchain technology can be a solution to certain security problems.\nThen a solution approach shows how Blockchain can be integrated and implemented\nto ensure the required level of security. Certain attack incidents on Bluetooth\nvulnerable points are examined and discussion and conclusions give the\nextension of the security related problems.",
        "author": [
            "Athanasios Kalogiratos",
            "Ioanna Kantzavelou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.06451v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "C.2.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.06451v1",
        "arXiv ID": "2211.06451v1"
    },
    {
        "title": "Agreements between Enterprises digitized by Smart Contracts in the\n  Domain of Industry 4.0",
        "Published: ": "2020-07-28T13:08:01Z",
        "abstract": "The digital transformation of companies is expected to increase the digital\ninterconnection between different companies to develop optimized, customized,\nhybrid business models. These cross-company business models require secure,\nreliable, and traceable logging and monitoring of contractually agreed\ninformation sharing between machine tools, operators, and service providers.\nThis paper discusses how the major requirements for building hybrid business\nmodels can be tackled by the blockchain for building a chain of trust and smart\ncontracts for digitized contracts. A machine maintenance use case is used to\ndiscuss the readiness of smart contracts for the automation of workflows\ndefined in contracts. Furthermore, it is shown that the number of failures is\nsignificantly improved by using these contracts and a blockchain.",
        "author": [
            "Kevin Wallis",
            "Jan Stodt",
            "Eugen Jastremskoj",
            "Christoph Reich"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.14181v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.14181v1",
        "arXiv ID": "2007.14181v1"
    },
    {
        "title": "ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image\n  Compressive Sensing",
        "Published: ": "2017-06-24T09:02:21Z",
        "abstract": "With the aim of developing a fast yet accurate algorithm for compressive\nsensing (CS) reconstruction of natural images, we combine in this paper the\nmerits of two existing categories of CS methods: the structure insights of\ntraditional optimization-based methods and the speed of recent network-based\nones. Specifically, we propose a novel structured deep network, dubbed\nISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm\n(ISTA) for optimizing a general $\\ell_1$ norm CS reconstruction model. To cast\nISTA into deep network form, we develop an effective strategy to solve the\nproximal mapping associated with the sparsity-inducing regularizer using\nnonlinear transforms. All the parameters in ISTA-Net (\\eg nonlinear transforms,\nshrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than\nbeing hand-crafted. Moreover, considering that the residuals of natural images\nare more compressible, an enhanced version of ISTA-Net in the residual domain,\ndubbed {ISTA-Net}$^+$, is derived to further improve CS reconstruction.\nExtensive CS experiments demonstrate that the proposed ISTA-Nets outperform\nexisting state-of-the-art optimization-based and network-based CS methods by\nlarge margins, while maintaining fast computational speed. Our source codes are\navailable: \\textsl{http://jianzhang.tech/projects/ISTA-Net}.",
        "author": [
            "Jian Zhang",
            "Bernard Ghanem"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.07929v2.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.MM"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.07929v2",
        "arXiv ID": "1706.07929v2"
    },
    {
        "title": "Privacy Preserving Passive DNS",
        "Published: ": "2020-08-14T15:54:00Z",
        "abstract": "The Domain Name System (DNS) was created to resolve the IP addresses of the\nweb servers to easily remembered names. When it was initially created, security\nwas not a major concern; nowadays, this lack of inherent security and trust has\nexposed the global DNS infrastructure to malicious actors. The passive DNS data\ncollection process creates a database containing various DNS data elements,\nsome of which are personal and need to be protected to preserve the privacy of\nthe end users. To this end, we propose the use of distributed ledger\ntechnology. We use Hyperledger Fabric to create a permissioned blockchain,\nwhich only authorized entities can access. The proposed solution supports\nqueries for storing and retrieving data from the blockchain ledger, allowing\nthe use of the passive DNS database for further analysis, e.g. for the\nidentification of malicious domain names. Additionally, it effectively protects\nthe DNS personal data from unauthorized entities, including the administrators\nthat can act as potential malicious insiders, and allows only the data owners\nto perform queries over these data. We evaluated our proposed solution by\ncreating a proof-of-concept experimental setup that passively collects DNS data\nfrom a network and then uses the distributed ledger technology to store the\ndata in an immutable ledger, thus providing a full historical overview of all\nthe records.",
        "author": [
            "Pavlos Papadopoulos",
            "Nikolaos Pitropakis",
            "William J. Buchanan",
            "Owen Lo",
            "Sokratis Katsikas"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.06430v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.06430v1",
        "arXiv ID": "2008.06430v1"
    },
    {
        "title": "SDPMN: Privacy Preserving MapReduce Network Using SDN",
        "Published: ": "2018-03-12T14:22:02Z",
        "abstract": "MapReduce is a popular programming model and an associated implementation for\nparallel processing big data in the distributed environment. Since large scaled\nMapReduce data centers usually provide services to many users, it is an\nessential problem to preserve the privacy between different applications in the\nsame network. In this paper, we propose SDPMN, a framework that using\n\\textit{software defined network} (SDN) to distinguish the network between each\napplication, which is a manageable and scalable method. We design this\nframework based on the existing SDN structure and Hadoop networks. Since the\nrule space of each SDN device is limited, we also propose the rule placement\noptimization for this framework to maximize the hardware supported isolated\napplication networks. We state this problem in a general MapReduce network and\ndesign a heuristic algorithm to find the solution. From the simulation based\nevaluation, with our algorithm, the given network can support more privacy\npreserving application networks with SDN switches.",
        "author": [
            "He Li",
            "Hai Jin"
        ],
        "pdfLink": "http://arxiv.org/pdf/1803.04277v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1803.04277v1",
        "arXiv ID": "1803.04277v1"
    },
    {
        "title": "Transform Learning for Magnetic Resonance Image Reconstruction: From\n  Model-based Learning to Building Neural Networks",
        "Published: ": "2019-03-25T03:13:18Z",
        "abstract": "Magnetic resonance imaging (MRI) is widely used in clinical practice, but it\nhas been traditionally limited by its slow data acquisition. Recent advances in\ncompressed sensing (CS) techniques for MRI reduce acquisition time while\nmaintaining high image quality. Whereas classical CS assumes the images are\nsparse in known analytical dictionaries or transform domains, methods using\nlearned image models for reconstruction have become popular. The model could be\npre-learned from datasets, or learned simultaneously with the reconstruction,\ni.e., blind CS (BCS). Besides the well-known synthesis dictionary model, recent\nadvances in transform learning (TL) provide an efficient alternative framework\nfor sparse modeling in MRI. TL-based methods enjoy numerous advantages\nincluding exact sparse coding, transform update, and clustering solutions,\ncheap computation, and convergence guarantees, and provide high-quality results\nin MRI compared to popular competing methods. This paper provides a review of\nsome recent works in MRI reconstruction from limited data, with focus on the\nrecent TL-based methods. A unified framework for incorporating various TL-based\nmodels is presented. We discuss the connections between transform learning and\nconvolutional or filter bank models and corresponding multi-layer extensions,\nwith connections to deep learning. Finally, we discuss recent trends in MRI,\nopen problems, and future directions for the field.",
        "author": [
            "Bihan Wen",
            "Saiprasad Ravishankar",
            "Luke Pfister",
            "Yoram Bresler"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.11431v2.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.11431v2",
        "arXiv ID": "1903.11431v2"
    },
    {
        "title": "Blockchain-Enabled NextGen Service Architecture for Mobile Internet\n  Offload",
        "Published: ": "2021-04-17T09:34:27Z",
        "abstract": "The amalgamation of different generations of mobile cellular networks around\nthe globe has resulted in diverse data speed experiences for end users. At\npresent there are no defined mechanisms in place for a subscriber of one mobile\nnetwork operator (MNO) to use the services of a WiFi provider. Cellular and\nData Service providers also have no standardized procedures to securely\ninteract with each other, and to allow their subscribers to use third party\nservices on a pay-as-you-go basis. This paper proposes a blockchain-based\noffloading framework that allows a subscriber of a mobile operator to\ntemporarily use another MNO or WiFi provider's higher speed network. Smart\ncontracts allow diverse entities such as MNOs, Brokers and WiFi Providers to\nautomatically execute mutual agreements to enable the utilization of third\nparty infrastructure in a secure and controlled manner. To test the proposed\nframework, the offloading of a subscriber from 3G/4G/4G-LTE/5G networks to a\nfixed broadband WiFi network was carried out and the results analyzed. The\noffloading framework was implemented using the ns-3 network simulator, and the\nEthereum blockchain smart contract features were used for the settlement of\ninvoices.",
        "author": [
            "Raman Singh",
            "Hitesh Tewari"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.08495v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.08495v1",
        "arXiv ID": "2104.08495v1"
    },
    {
        "title": "A Mean Field Game Analysis of Consensus Protocol Design",
        "Published: ": "2021-08-23T08:16:48Z",
        "abstract": "A decentralized blockchain is a distributed ledger that is often used as a\nplatform for exchanging goods and services. This ledger is maintained by a\nnetwork of nodes that obeys a set of rules, called a consensus protocol, which\nhelps to resolve inconsistencies among local copies of a blockchain. In this\npaper, we build a mathematical framework for the consensus protocol designer,\nspecifying (a) the measurement of a resource which nodes strategically invest\nin and compete for to win the right to build new blocks in the blockchain; and\n(b) a payoff function for such efforts. Thus, the equilibrium of an associated\nstochastic differential game can be implemented by selecting nodes in\nproportion to this specified resource and penalizing dishonest nodes by its\nloss. This associated, induced game can be further analyzed using mean field\ngames. The problem can be broken down into two coupled PDEs, where an\nindividual node's optimal control path is solved using a\nHamilton-Jacobi-Bellman equation, and where the evolution of states\ndistribution is characterized by a Fokker-Planck equation. We develop numerical\nmethods to compute the mean field equilibrium for both steady states at the\ninfinite time horizon and evolutionary dynamics. As an example, we show how the\nmean field equilibrium can be applied to the Bitcoin blockchain mechanism\ndesign. We demonstrate that a blockchain can be viewed as a mechanism that\noperates in a decentralized setup and propagates properties of the mean field\nequilibrium over time, such as the underlying security of the blockchain.",
        "author": [
            "Lucy Klinger",
            "Lei Zhang",
            "Zhennan Zhou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2108.09999v3.pdf",
        "Categories": [
            [
                "math.OC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2108.09999v3",
        "arXiv ID": "2108.09999v3"
    },
    {
        "title": "How Can Applications of Blockchain and Artificial Intelligence Improve\n  Performance of Internet of Things? -- A Survey",
        "Published: ": "2021-11-28T01:45:15Z",
        "abstract": "In the era of the Internet of Things (IoT), massive computing devices\nsurrounding us operate and interact with each other to provide several\nsignificant services in industries, medical as well as in daily life activities\nat home, office, education sectors, and so on. The participating devices in an\nIoT network usually have resource constraints and the devices are prone to\ndifferent cyber attacks, leading to the loopholes in the security and\nauthentication. As a revolutionized and innovated technology, blockchain, that\nis applied in cryptocurrency, market prediction, etc., uses a distributed\nledger that records transactions securely and efficiently. To utilize the great\npotential of blockchain, both industries and academia have paid a significant\nattention to integrate it with the IoT, as reported by several existing\nliterature. On the other hand, Artificial Intelligence (AI) is able to embed\nintelligence in a system, and thus the AI can be integrated with IoT devices in\norder to automatically cope with different environments according to the\ndemands. Furthermore, both blockchain and AI can be integrated with the IoT to\ndesign an automated secure and robust IoT model, as mentioned by numerous\nexisting works. In this survey, we present a discussion on the IoT, blockchain,\nand AI, along with the descriptions of several research works that apply\nblockchain and AI in the IoT. In this direction, we point out strengths and\nlimitations of the related existing researches. We also discuss different open\nchallenges to exploit the full capacities of blockchain and AI in designing an\nIoT-based model. Therefore, the highlighted challenging issues can open the\ndoor for the development of future IoT models which will be intelligent and\nsecure based on the integration of blockchain and AI with the IoT.",
        "author": [
            "Priyanka Bothra",
            "Raja Karmakar",
            "Sanjukta Bhattacharya",
            "Sayantani De"
        ],
        "pdfLink": "http://arxiv.org/pdf/2111.14018v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2111.14018v1",
        "arXiv ID": "2111.14018v1"
    },
    {
        "title": "A Random Sample Partition Data Model for Big Data Analysis",
        "Published: ": "2017-12-12T06:49:28Z",
        "abstract": "Big data sets must be carefully partitioned into statistically similar data\nsubsets that can be used as representative samples for big data analysis tasks.\nIn this paper, we propose the random sample partition (RSP) data model to\nrepresent a big data set as a set of non-overlapping data subsets, called RSP\ndata blocks, where each RSP data block has a probability distribution similar\nto the whole big data set. Under this data model, efficient block level\nsampling is used to randomly select RSP data blocks, replacing expensive record\nlevel sampling to select sample data from a big distributed data set on a\ncomputing cluster. We show how RSP data blocks can be employed to estimate\nstatistics of a big data set and build models which are equivalent to those\nbuilt from the whole big data set. In this approach, analysis of a big data set\nbecomes analysis of few RSP data blocks which have been generated in advance on\nthe computing cluster. Therefore, the new method for data analysis based on RSP\ndata blocks is scalable to big data.",
        "author": [
            "Salman Salloum",
            "Yulin He",
            "Joshua Zhexue Huang",
            "Xiaoliang Zhang",
            "Tamer Z. Emara",
            "Chenghao Wei",
            "Heping He"
        ],
        "pdfLink": "http://arxiv.org/pdf/1712.04146v2.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.DS",
                "physics.data-an",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1712.04146v2",
        "arXiv ID": "1712.04146v2"
    },
    {
        "title": "Enigma: Decentralized Computation Platform with Guaranteed Privacy",
        "Published: ": "2015-06-10T20:34:12Z",
        "abstract": "A peer-to-peer network, enabling different parties to jointly store and run\ncomputations on data while keeping the data completely private. Enigma's\ncomputational model is based on a highly optimized version of secure\nmulti-party computation, guaranteed by a verifiable secret-sharing scheme. For\nstorage, we use a modified distributed hashtable for holding secret-shared\ndata. An external blockchain is utilized as the controller of the network,\nmanages access control, identities and serves as a tamper-proof log of events.\nSecurity deposits and fees incentivize operation, correctness and fairness of\nthe system. Similar to Bitcoin, Enigma removes the need for a trusted third\nparty, enabling autonomous control of personal data. For the first time, users\nare able to share their data with cryptographic guarantees regarding their\nprivacy.",
        "author": [
            "Guy Zyskind",
            "Oz Nathan",
            "Alex Pentland"
        ],
        "pdfLink": "http://arxiv.org/pdf/1506.03471v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1506.03471v1",
        "arXiv ID": "1506.03471v1"
    },
    {
        "title": "Universal Knowledge Discovery from Big Data: Towards a Paradigm Shift\n  from 'Knowledge Discovery' to 'Wisdom Discovery'",
        "Published: ": "2014-03-28T23:59:34Z",
        "abstract": "Many people hold a vision that big data will provide big insights and have a\nbig impact in the future, and big-data-assisted scientific discovery is seen as\nan emerging and promising scientific paradigm. However, how to turn big data\ninto deep insights with tremendous value still remains obscure. To meet the\nchallenge, universal knowledge discovery from big data (UKD) is proposed. The\nnew concept focuses on discovering universal knowledge, which exists in the\nstatistical analyses of big data and provides valuable insights into big data.\nUniversal knowledge comes in different forms, e.g., universal patterns, rules,\ncorrelations, models and mechanisms. To accelerate big data assisted universal\nknowledge discovery, a unified research paradigm should be built based on\ntechniques and paradigms from related research domains, especially big data\nmining and complex systems science. Therefore, I propose an iBEST@SEE\nmethodology. This study lays a solid foundation for the future development of\nuniversal knowledge discovery, and offers a pathway to the discovery of\n\"treasure-trove\" hidden in big data.",
        "author": [
            "Bin Shen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1403.7570v5.pdf",
        "Categories": [
            [
                "cs.CY",
                "68T01"
            ]
        ],
        "Link": "http://arxiv.org/abs/1403.7570v5",
        "arXiv ID": "1403.7570v5"
    },
    {
        "title": "Self-Supervised Scalable Deep Compressed Sensing",
        "Published: ": "2023-08-26T06:03:06Z",
        "abstract": "Compressed sensing (CS) is a promising tool for reducing sampling costs.\nCurrent deep neural network (NN)-based CS methods face challenges in collecting\nlabeled measurement-ground truth (GT) data and generalizing to real\napplications. This paper proposes a novel $\\mathbf{S}$elf-supervised\ns$\\mathbf{C}$alable deep CS method, comprising a $\\mathbf{L}$earning scheme\ncalled $\\mathbf{SCL}$ and a family of $\\mathbf{Net}$works named\n$\\mathbf{SCNet}$, which does not require GT and can handle arbitrary sampling\nratios and matrices once trained on a partial measurement set. Our SCL contains\na dual-domain loss and a four-stage recovery strategy. The former encourages a\ncross-consistency on two measurement parts and a sampling-reconstruction\ncycle-consistency regarding arbitrary ratios and matrices to maximize\ndata/information utilization. The latter can progressively leverage common\nsignal prior in external measurements and internal characteristics of test\nsamples and learned NNs to improve accuracy. SCNet combines the explicit\nguidance from optimization algorithms with implicit regularization from\nadvanced NN blocks to learn a collaborative signal representation. Our\ntheoretical analyses and experiments on simulated and real captured data,\ncovering 1-/2-/3-D natural and scientific signals, demonstrate the\neffectiveness, superior performance, flexibility, and generalization ability of\nour method over existing self-supervised methods and its significant potential\nin competing against state-of-the-art supervised methods.",
        "author": [
            "Bin Chen",
            "Xuanyu Zhang",
            "Shuai Liu",
            "Yongbing Zhang",
            "Jian Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2308.13777v1.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.CV",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2308.13777v1",
        "arXiv ID": "2308.13777v1"
    },
    {
        "title": "XRP-NDN Overlay: Improving the Communication Efficiency of\n  Consensus-Validation based Blockchains with an NDN Overlay",
        "Published: ": "2023-01-24T18:31:43Z",
        "abstract": "With the growing adoption of Distributed Ledger Technologies and the\nsubsequent scaling of these networks, there is an inherent need for efficient\nand resilient communication used by the underlying consensus and replication\nmechanisms. While resilient and efficient communication is one of the main\npillars of an efficient blockchain network as a whole, the Distributed Ledger\nTechnology is still relatively new and the task of scaling these networks has\ncome with its own challenges towards ensuring these goals. New content\ndistribution concepts like Information Centric Networking, of which Named Data\nNetworking is a worthy example, create new possibilities towards achieving this\ngoal, through in-network caching or built-in native multicasting, for example.\nWe present and evaluate XRP-NDN Overlay, a solution for increasing the\ncommunication efficiency for consensus-validation based blockchains like the\nXRP Ledger. We experiment by sending the XRP Ledger consensus messages over\ndifferent Named Data Networking communication models and prove that our chosen\nmodel lowers the number of messages at node level to minimum necessary, while\nmaintaining or improving blockchain performance by leveraging the possibilities\noffered by an overlay such as specific communication mechanisms.",
        "author": [
            "Lucian Trestioreanu",
            "Wazen M. Shbair",
            "Flaviene Scheidt de Cristo",
            "Radu State"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.10209v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.10209v1",
        "arXiv ID": "2301.10209v1"
    },
    {
        "title": "SOAR: Minimizing Network Utilization with Bounded In-network Computing",
        "Published: ": "2021-10-27T07:18:41Z",
        "abstract": "In-network computing via smart networking devices is a recent trend for\nmodern datacenter networks. State-of-the-art switches with near line rate\ncomputing and aggregation capabilities are developed to enable, e.g.,\nacceleration and better utilization for modern applications like big data\nanalytics, and large-scale distributed and federated machine learning. We\nformulate and study the problem of activating a limited number of in-network\ncomputing devices within a network, aiming at reducing the overall network\nutilization for a given workload. Such limitations on the number of in-network\ncomputing elements per workload arise, e.g., in incremental upgrades of network\ninfrastructure, and are also due to requiring specialized middleboxes, or\nFPGAs, that should support heterogeneous workloads, and multiple tenants.\n  We present an optimal and efficient algorithm for placing such devices in\ntree networks with arbitrary link rates, and further evaluate our proposed\nsolution in various scenarios and for various tasks. Our results show that\nhaving merely a small fraction of network devices support in-network\naggregation can lead to a significant reduction in network utilization.\nFurthermore, we show that various intuitive strategies for performing such\nplacements exhibit significantly inferior performance compared to our solution,\nfor varying workloads, tasks, and link rates.",
        "author": [
            "Raz Segal",
            "Chen Avin",
            "Gabriel Scalosub"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.14224v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.DC",
                "cs.DS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.14224v1",
        "arXiv ID": "2110.14224v1"
    },
    {
        "title": "A Deep Learning Approach for Parallel Imaging and Compressed Sensing MRI\n  Reconstruction",
        "Published: ": "2022-09-19T07:26:45Z",
        "abstract": "Parallel imaging accelerates MRI data acquisition by acquiring additional\nsensitivity information with an array of receiver coils, resulting in fewer\nphase encoding steps. Because of fewer data requirements than parallel imaging,\ncompressed sensing magnetic resonance imaging (CS-MRI) has gained popularity in\nthe field of medical imaging. Parallel imaging and compressed sensing (CS) both\nreduce the amount of data captured in the k-space, which speeds up traditional\nMRI acquisition. As acquisition time is inversely proportional to sample count,\nforming an image from reduced k-space samples results in faster acquisition but\nwith aliasing artifacts. For de-aliasing the reconstructed image, this paper\nproposes a novel Generative Adversarial Network (GAN) called RECGAN-GR that is\nsupervised with multi-modal losses. In comparison to existing GAN networks, our\nproposed method introduces a novel generator network, RemU-Net, which is\nintegrated with dual-domain loss functions such as weighted magnitude and phase\nloss functions, as well as parallel imaging-based loss, GRAPPA consistency\nloss. As refinement learning, a k-space correction block is proposed to make\nthe GAN network self-resistant to generating unnecessary data, which speeds up\nthe reconstruction process. Comprehensive results show that the proposed\nRECGAN-GR not only improves the PSNR by 4 dB over GAN-based methods but also by\n2 dB over conventional state-of-the-art CNN methods available in the literature\nfor single-coil data. The proposed work significantly improves image quality\nfor low-retained data, resulting in five to ten times faster acquisition.",
        "author": [
            "Farhan Sadik",
            "Md. Kamrul Hasan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.08807v2.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.08807v2",
        "arXiv ID": "2209.08807v2"
    },
    {
        "title": "Adapting Persistent Data Structures for Concurrency and Speculation",
        "Published: ": "2020-03-16T18:26:08Z",
        "abstract": "This work unifies insights from the systems and functional programming\ncommunities, in order to enable compositional reasoning about software which is\nnonetheless efficiently realizable in hardware. It exploits a correspondence\nbetween design goals for efficient concurrent data structures and efficient\nimmutable persistent data structures, to produce novel implementations of\nmutable concurrent trees with low contention and an efficient snapshot\noperation to support speculative execution models. It also exploits\ncommutativity to characterize a design space for integrating traditional\nhigh-performance concurrent data structures into Software Transactional Memory\n(STM) runtimes, and extends this technique to yield a novel algorithm for\nconcurrent execution of so-called ``smart contracts'' (specialized programs\nwhich manipulate the state of blockchain ledgers).",
        "author": [
            "Thomas Dickerson"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.07395v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.DS",
                "cs.PL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.07395v1",
        "arXiv ID": "2003.07395v1"
    },
    {
        "title": "Exploring the Impact of Serverless Computing on Peer To Peer Training\n  Machine Learning",
        "Published: ": "2023-09-25T13:51:07Z",
        "abstract": "The increasing demand for computational power in big data and machine\nlearning has driven the development of distributed training methodologies.\nAmong these, peer-to-peer (P2P) networks provide advantages such as enhanced\nscalability and fault tolerance. However, they also encounter challenges\nrelated to resource consumption, costs, and communication overhead as the\nnumber of participating peers grows. In this paper, we introduce a novel\narchitecture that combines serverless computing with P2P networks for\ndistributed training and present a method for efficient parallel gradient\ncomputation under resource constraints.\n  Our findings show a significant enhancement in gradient computation time,\nwith up to a 97.34\\% improvement compared to conventional P2P distributed\ntraining methods. As for costs, our examination confirmed that the serverless\narchitecture could incur higher expenses, reaching up to 5.4 times more than\ninstance-based architectures. It is essential to consider that these higher\ncosts are associated with marked improvements in computation time, particularly\nunder resource-constrained scenarios. Despite the cost-time trade-off, the\nserverless approach still holds promise due to its pay-as-you-go model.\nUtilizing dynamic resource allocation, it enables faster training times and\noptimized resource utilization, making it a promising candidate for a wide\nrange of machine learning applications.",
        "author": [
            "Amine Barrak",
            "Ranim Trabelsi",
            "Fehmi Jaafar",
            "Fabio Petrillo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.14139v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.14139v1",
        "arXiv ID": "2309.14139v1"
    },
    {
        "title": "Impact of network delays on Hyperledger Fabric",
        "Published: ": "2019-03-21T07:21:33Z",
        "abstract": "Blockchain has become one of the most attractive technologies for\napplications, with a large range of deployments such as production, economy, or\nbanking. Under the hood, Blockchain technology is a type of distributed\ndatabase that supports untrusted parties. In this paper we focus Hyperledger\nFabric, the first blockchain in the market tailored for a private environment,\nallowing businesses to create a permissioned network. Hyperledger Fabric\nimplements a PBFT consensus in order to maintain a non forking blockchain at\nthe application level. We deployed this framework over an area network between\nFrance and Germany in order to evaluate its performance when potentially large\nnetwork delays are observed. Overall we found that when network delay increases\nsignificantly (i.e. up to 3.5 seconds at network layer between two clouds), we\nobserved that the blocks added to our blockchain had up to 134 seconds offset\nafter 100 th block from one cloud to another. Thus by delaying block\npropagation, we demonstrated that Hyperledger Fabric does not provide\nsufficient consistency guaranties to be deployed in critical environments. Our\nwork, is the fist to evidence the negative impact of network delays on a\nPBFT-based blockchain.",
        "author": [
            "Thanh Son Lam Nguyen",
            "Guillaume Jourjon",
            "Maria Potop-Butucaru",
            "Kim Thai"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.08856v1.pdf",
        "Categories": [
            [
                "cs.PF",
                "cs.CR",
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.08856v1",
        "arXiv ID": "1903.08856v1"
    },
    {
        "title": "Decentralized Applications: The Blockchain-Empowered Software System",
        "Published: ": "2018-10-12T05:41:31Z",
        "abstract": "Blockchain technology has attracted tremendous attention in both academia and\ncapital market. However, overwhelming speculations on thousands of available\ncryptocurrencies and numerous initial coin offering (ICO) scams have also\nbrought notorious debates on this emerging technology. This paper traces the\ndevelopment of blockchain systems to reveal the importance of decentralized\napplications (dApps) and the future value of blockchain. We survey the\nstate-of-the-art dApps and discuss the direction of blockchain development to\nfulfill the desirable characteristics of dApps. The readers will gain an\noverview of dApp research and get familiar with recent developments in the\nblockchain.",
        "author": [
            "Wei Cai",
            "Zehua Wang",
            "Jason B. Ernst",
            "Zhen Hong",
            "Chen Feng",
            "Victor C. M. Leung"
        ],
        "pdfLink": "http://arxiv.org/pdf/1810.05365v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1810.05365v1",
        "arXiv ID": "1810.05365v1"
    },
    {
        "title": "Hercule: Representing and Reasoning about Norms as a Foundation for\n  Declarative Contracts over Blockchain",
        "Published: ": "2021-04-16T20:15:57Z",
        "abstract": "Current blockchain approaches for business contracts are based on smart\ncontracts, namely, software programs placed on a blockchain that are\nautomatically executed to realize a contract. However, smart contracts lack\nflexibility and interfere with the autonomy of the parties concerned.\n  We propose Hercule, an approach for declaratively specifying blockchain\napplications in a manner that reflects business contracts. Hercule represents a\ncontract via regulatory norms that capture the involved parties' expectations\nof one another. It computes the states of norms (hence, of contracts) from\nevents in the blockchain. Hercule's novelty and significance lie in that it\noperationalizes declarative contracts over semistructured databases, the\nunderlying representation for practical blockchain such as Hyperledger Fabric\nand Ethereum. Specifically, it exploits the map-reduce capabilities of such\nstores to compute norm states.\n  We demonstrate that our implementation over Hyperledger Fabric can process\nthousands of events per second, sufficient for many applications.",
        "author": [
            "Samuel H. Christie V",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.08355v1.pdf",
        "Categories": [
            [
                "cs.MA"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.08355v1",
        "arXiv ID": "2104.08355v1"
    },
    {
        "title": "Resilient Consensus Sustained Collaboratively",
        "Published: ": "2023-02-05T07:33:57Z",
        "abstract": "The recent growth of blockchain technology has accelerated research on\ndecentralized platforms. Initial blockchain platforms decide on what should be\nadded to the ledger based on Proof-of-Work (PoW) consensus protocol. PoW\nrequires its participants to perform large computations and leads to massive\nenergy wastage. Recent blockchains aim to replace PoW through Proof-of-Stake\n(PoS) and Malicious Fault-Tolerant (MFT) consensus protocols. However, the\nsafety of the ledger created by these protocols is at the mercy of the\nlong-term safe-keeping of the private keys of participants. As a result, these\nblockchains face long-range attacks. To ameliorate this situation, we present\nthe design of our novel Power-of-Collaboration (PoC) protocol, which guards\nexisting PoS and MFT blockchains against long-range attacks. We show that PoC\ncan be easily appended to existing blockchains and only marginally degrades\ntheir throughputs.",
        "author": [
            "Junchao Chen",
            "Suyash Gupta",
            "Alberto Sonnino",
            "Lefteris Kokoris-Kogias",
            "Mohammad Sadoghi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.02325v3.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DB",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.02325v3",
        "arXiv ID": "2302.02325v3"
    },
    {
        "title": "PRAGTHOS:Practical Game Theoretically Secure Proof-of-Work Blockchain",
        "Published: ": "2023-02-13T06:53:54Z",
        "abstract": "Security analysis of blockchain technology is an active domain of research.\nThere has been both cryptographic and game-theoretic security analysis of\nProof-of-Work (PoW) blockchains. Prominent work includes the cryptographic\nsecurity analysis under the Universal Composable framework and Game-theoretic\nsecurity analysis using Rational Protocol Design. These security analysis\nmodels rely on stricter assumptions that might not hold. In this paper, we\nanalyze the security of PoW blockchain protocols. We first show how assumptions\nmade by previous models need not be valid in reality, which attackers can\nexploit to launch attacks that these models fail to capture. These include\nDifficulty Alternating Attack, under which forking is possible for an adversary\nwith less than 0.5 mining power, Quick-Fork Attack, a general bound on selfish\nmining attack and transaction withholding attack. Following this, we argue why\nprevious models for security analysis fail to capture these attacks and propose\na more practical framework for security analysis pRPD. We then propose a\nframework to build PoW blockchains PRAGTHOS, which is secure from the attacks\nmentioned above. Finally, we argue that PoW blockchains complying with the\nPRAGTHOS framework are secure against a computationally bounded adversary under\ncertain conditions on the reward scheme.",
        "author": [
            "Varul Srivastava",
            "Dr. Sujit Gujar"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.06136v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC",
                "cs.GT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.06136v1",
        "arXiv ID": "2302.06136v1"
    },
    {
        "title": "Big Data Driven Vehicular Networks",
        "Published: ": "2018-04-11T20:18:19Z",
        "abstract": "Vehicular communications networks (VANETs) enable information exchange among\nvehicles, other end devices and public networks, which plays a key role in road\nsafety/infotainment, intelligent transportation system, and self-driving\nsystem. As the vehicular connectivity soars, and new on-road mobile\napplications and technologies emerge, VANETs are generating an ever-increasing\namount of data, requiring fast and reliable transmissions through VANETs. On\nthe other hand, a variety of VANETs related data can be analyzed and utilized\nto improve the performance of VANETs. In this article, we first review the\nVANETs technologies to efficiently and reliably transmit the big data. Then,\nthe methods employing big data for studying VANETs characteristics and\nimproving VANETs performance are discussed. Furthermore, we present a case\nstudy where machine learning schemes are applied to analyze the VANETs\nmeasurement data for efficiently detecting negative communication conditions.",
        "author": [
            "Nan Cheng",
            "Feng Lyu",
            "Jiayin Chen",
            "Wenchao Xu",
            "Haibo Zhou",
            "Shan Zhang",
            "Xuemin",
            "Shen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1804.04203v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1804.04203v1",
        "arXiv ID": "1804.04203v1"
    },
    {
        "title": "NETT Regularization for Compressed Sensing Photoacoustic Tomography",
        "Published: ": "2019-01-31T01:01:59Z",
        "abstract": "We discuss several methods for image reconstruction in compressed sensing\nphotoacoustic tomography (CS-PAT). In particular, we apply the deep learning\nmethod of [H. Li, J. Schwab, S. Antholzer, and M. Haltmeier. NETT: Solving\nInverse Problems with Deep Neural Networks (2018), arXiv:1803.00092], which is\nbased on a learned regularizer, for the first time to the CS-PAT problem. We\npropose a network architecture and training strategy for the NETT that we\nexpect to be useful for other inverse problems as well. All algorithms are\ncompared and evaluated on simulated data, and validated using experimental data\nfor two different types of phantoms. The results on the one the hand indicate\ngreat potential of deep learning methods, and on the other hand show that\nsignificant future work is required to improve their performance on real-word\ndata.",
        "author": [
            "Stephan Antholzer",
            "Johannens Schwab",
            "Johannes Bauer-Marschallinger",
            "Peter Burgholzer",
            "Markus Haltmeier"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.11158v1.pdf",
        "Categories": [
            [
                "math.NA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.11158v1",
        "arXiv ID": "1901.11158v1"
    },
    {
        "title": "BPDS: A Blockchain based Privacy-Preserving Data Sharing for Electronic\n  Medical Records",
        "Published: ": "2018-11-08T02:19:06Z",
        "abstract": "Electronic medical record (EMR) is a crucial form of healthcare data,\ncurrently drawing a lot of attention. Sharing health data is considered to be a\ncritical approach to improve the quality of healthcare service and reduce\nmedical costs. However, EMRs are fragmented across decentralized hospitals,\nwhich hinders data sharing and puts patients' privacy at risks. To address\nthese issues, we propose a blockchain based privacy-preserving data sharing for\nEMRs, called BPDS. In BPDS, the original EMRs are stored securely in the cloud\nand the indexes are reserved in a tamper-proof consortium blockchain. By this\nmeans, the risk of the medical data leakage could be greatly reduced, and at\nthe same time, the indexes in blockchain ensure that the EMRs can not be\nmodified arbitrarily. Secure data sharing can be accomplished automatically\naccording to the predefined access permissions of patients through the smart\ncontracts of blockchain. Besides, the joint-design of the CP-ABE-based access\ncontrol mechanism and the content extraction signature scheme provides strong\nprivacy preservation in data sharing. Security analysis shows that BPDS is a\nsecure and effective way to realize data sharing for EMRs.",
        "author": [
            "Jingwei Liu",
            "Xiaolu Li",
            "Lin Ye",
            "Hongli Zhang",
            "Xiaojiang Du",
            "Mohsen Guizani"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.03223v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.03223v1",
        "arXiv ID": "1811.03223v1"
    },
    {
        "title": "Local algorithms for the maximum flow and minimum cut in bounded-degree\n  networks",
        "Published: ": "2010-05-04T13:05:16Z",
        "abstract": "We show a deterministic constant-time local algorithm for constructing an\napproximately maximum flow and minimum fractional cut in\nmultisource-multitarget networks with bounded degrees and bounded edge\ncapacities. Locality means that the decision we make about each edge only\ndepends on its constant radius neighborhood. We show two applications of the\nalgorithms: one is related to the Aldous-Lyons Conjecture, and the other is\nabout approximating the neighborhood distribution of graphs by bounded-size\ngraphs. The scope of our results can be extended to unimodular random graphs\nand networks. As a corollary, we generalize the Maximum Flow Minimum Cut\nTheorem to unimodular random flow networks.",
        "author": [
            "Endre Cs\u00f3ka",
            "Andr\u00e1s Pongr\u00e1cz"
        ],
        "pdfLink": "http://arxiv.org/pdf/1005.0513v2.pdf",
        "Categories": [
            [
                "cs.DS"
            ]
        ],
        "Link": "http://arxiv.org/abs/1005.0513v2",
        "arXiv ID": "1005.0513v2"
    },
    {
        "title": "Big Learning with Bayesian Methods",
        "Published: ": "2014-11-24T07:28:51Z",
        "abstract": "Explosive growth in data and availability of cheap computing resources have\nsparked increasing interest in Big learning, an emerging subfield that studies\nscalable machine learning algorithms, systems, and applications with Big Data.\nBayesian methods represent one important class of statistic methods for machine\nlearning, with substantial recent developments on adaptive, flexible and\nscalable Bayesian learning. This article provides a survey of the recent\nadvances in Big learning with Bayesian methods, termed Big Bayesian Learning,\nincluding nonparametric Bayesian methods for adaptively inferring model\ncomplexity, regularized Bayesian inference for improving the flexibility via\nposterior regularization, and scalable algorithms and systems based on\nstochastic subsampling and distributed computing for dealing with large-scale\napplications.",
        "author": [
            "Jun Zhu",
            "Jianfei Chen",
            "Wenbo Hu",
            "Bo Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1411.6370v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.AP",
                "stat.CO",
                "stat.ME",
                "stat.ML",
                "F.1.2; G.3"
            ]
        ],
        "Link": "http://arxiv.org/abs/1411.6370v2",
        "arXiv ID": "1411.6370v2"
    },
    {
        "title": "Decentralized Complete Dictionary Learning via $\\ell^{4}$-Norm\n  Maximization",
        "Published: ": "2022-11-07T15:36:08Z",
        "abstract": "With the rapid development of information technologies, centralized data\nprocessing is subject to many limitations, such as computational overheads,\ncommunication delays, and data privacy leakage. Decentralized data processing\nover networked terminal nodes becomes an important technology in the era of big\ndata. Dictionary learning is a powerful representation learning method to\nexploit the low-dimensional structure from the high-dimensional data. By\nexploiting the low-dimensional structure, the storage and the processing\noverhead of data can be effectively reduced. In this paper, we propose a novel\ndecentralized complete dictionary learning algorithm, which is based on\n$\\ell^{4}$-norm maximization. Compared with existing decentralized dictionary\nlearning algorithms, comprehensive numerical experiments show that the novel\nalgorithm has significant advantages in terms of per-iteration computational\ncomplexity, communication cost, and convergence rate in many scenarios.\nMoreover, a rigorous theoretical analysis shows that the dictionaries learned\nby the proposed algorithm can converge to the one learned by a centralized\ndictionary learning algorithm at a linear rate with high probability under\ncertain conditions.",
        "author": [
            "Qiheng Lu",
            "Lixiang Lian"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.03628v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.DC",
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.03628v2",
        "arXiv ID": "2211.03628v2"
    },
    {
        "title": "Insightful classification of crystal structures using deep learning",
        "Published: ": "2017-09-07T15:09:27Z",
        "abstract": "Computational methods that automatically extract knowledge from data are\ncritical for enabling data-driven materials science. A reliable identification\nof lattice symmetry is a crucial first step for materials characterization and\nanalytics. Current methods require a user-specified threshold, and are unable\nto detect average symmetries for defective structures. Here, we propose a\nmachine-learning-based approach to automatically classify structures by crystal\nsymmetry. First, we represent crystals by calculating a diffraction image, then\nconstruct a deep-learning neural-network model for classification. Our approach\nis able to correctly classify a dataset comprising more than 100 000 simulated\ncrystal structures, including heavily defective ones. The internal operations\nof the neural network are unraveled through attentive response maps,\ndemonstrating that it uses the same landmarks a materials scientist would use,\nalthough never explicitly instructed to do so. Our study paves the way for\ncrystal-structure recognition of - possibly noisy and incomplete -\nthree-dimensional structural data in big-data materials science.",
        "author": [
            "A. Ziletti",
            "D. Kumar",
            "M. Scheffler",
            "L. M. Ghiringhelli"
        ],
        "pdfLink": "http://arxiv.org/pdf/1709.02298v2.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci",
                "cond-mat.dis-nn"
            ]
        ],
        "Link": "http://arxiv.org/abs/1709.02298v2",
        "arXiv ID": "1709.02298v2"
    },
    {
        "title": "An Investigation of Smart Contract for Collaborative Machine Learning\n  Model Training",
        "Published: ": "2022-09-12T04:25:01Z",
        "abstract": "Machine learning (ML) has penetrated various fields in the era of big data.\nThe advantage of collaborative machine learning (CML) over most conventional ML\nlies in the joint effort of decentralized nodes or agents that results in\nbetter model performance and generalization. As the training of ML models\nrequires a massive amount of good quality data, it is necessary to eliminate\nconcerns about data privacy and ensure high-quality data. To solve this\nproblem, we cast our eyes on the integration of CML and smart contracts. Based\non blockchain, smart contracts enable automatic execution of data preserving\nand validation, as well as the continuity of CML model training. In our\nsimulation experiments, we define incentive mechanisms on the smart contract,\ninvestigate the important factors such as the number of features in the dataset\n(num_words), the size of the training data, the cost for the data holders to\nsubmit data, etc., and conclude how these factors impact the performance\nmetrics of the model: the accuracy of the trained model, the gap between the\naccuracies of the model before and after simulation, and the time to use up the\nbalance of bad agent. For instance, the increase of the value of num_words\nleads to higher model accuracy and eliminates the negative influence of\nmalicious agents in a shorter time from our observation of the experiment\nresults. Statistical analyses show that with the help of smart contracts, the\ninfluence of invalid data is efficiently diminished and model robustness is\nmaintained. We also discuss the gap in existing research and put forward\npossible future directions for further works.",
        "author": [
            "Shengwen Ding",
            "Chenhui Hu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.05017v1.pdf",
        "Categories": [
            [
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.05017v1",
        "arXiv ID": "2209.05017v1"
    },
    {
        "title": "A Platform Architecture for Multi-Tenant Blockchain-Based Systems",
        "Published: ": "2019-01-31T05:51:20Z",
        "abstract": "Blockchain has attracted a broad range of interests from start-ups,\nenterprises and governments to build next generation applications in a\ndecentralized manner. Similar to cloud platforms, a single blockchain-based\nsystem may need to serve multiple tenants simultaneously. However, design of\nmulti-tenant blockchain-based systems is challenging to architects in terms of\ndata and performance isolation, as well as scalability. First, tenants must not\nbe able to read other tenants' data and tenants with potentially higher\nworkload should not affect read/write performance of other tenants. Second,\nmulti-tenant blockchain-based systems usually require both scalability for each\nindividual tenant and scalability with number of tenants. Therefore, in this\npaper, we propose a scalable platform architecture for multi-tenant\nblockchain-based systems to ensure data integrity while maintaining data\nprivacy and performance isolation. In the proposed architecture, each tenant\nhas an individual permissioned blockchain to maintain their own data and smart\ncontracts. All tenant chains are anchored into a main chain, in a way that\nminimizes cost and load overheads. The proposed architecture has been\nimplemented in a proof-of-concept prototype with our industry partner, Laava ID\nPty Ltd (Laava). We evaluate our proposal in a three-fold way: fulfilment of\nthe identified requirements, qualitative comparison with design alternatives,\nand quantitative analysis. The evaluation results show that the proposed\narchitecture can achieve data integrity, performance isolation, data privacy,\nconfiguration flexibility, availability, cost efficiency and scalability.",
        "author": [
            "Ingo Weber",
            "Qinghua Lu",
            "An Binh Tran",
            "Amit Deshmukh",
            "Marek Gorski",
            "Markus Strazds"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.11219v1.pdf",
        "Categories": [
            [
                "cs.SE",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.11219v1",
        "arXiv ID": "1901.11219v1"
    },
    {
        "title": "23-bit Metaknowledge Template Towards Big Data Knowledge Discovery and\n  Management",
        "Published: ": "2015-03-01T09:41:11Z",
        "abstract": "The global influence of Big Data is not only growing but seemingly endless.\nThe trend is leaning towards knowledge that is attained easily and quickly from\nmassive pools of Big Data. Today we are living in the technological world that\nDr. Usama Fayyad and his distinguished research fellows discussed in the\nintroductory explanations of Knowledge Discovery in Databases (KDD) predicted\nnearly two decades ago. Indeed, they were precise in their outlook on Big Data\nanalytics. In fact, the continued improvement of the interoperability of\nmachine learning, statistics, database building and querying fused to create\nthis increasingly popular science- Data Mining and Knowledge Discovery. The\nnext generation computational theories are geared towards helping to extract\ninsightful knowledge from even larger volumes of data at higher rates of speed.\nAs the trend increases in popularity, the need for a highly adaptive solution\nfor knowledge discovery will be necessary. In this research paper, we are\nintroducing the investigation and development of 23 bit-questions for a\nMetaknowledge template for Big Data Processing and clustering purposes. This\nresearch aims to demonstrate the construction of this methodology and proves\nthe validity and the beneficial utilization that brings Knowledge Discovery\nfrom Big Data.",
        "author": [
            "Nima Bari",
            "Roman Vichr",
            "Kamran Kowsari",
            "Simon Y. Berkovich"
        ],
        "pdfLink": "http://arxiv.org/pdf/1503.00244v1.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1503.00244v1",
        "arXiv ID": "1503.00244v1"
    },
    {
        "title": "Nonparametric Distributed Learning Architecture for Big Data: Algorithm\n  and Applications",
        "Published: ": "2015-08-15T16:13:29Z",
        "abstract": "Dramatic increases in the size and complexity of modern datasets have made\ntraditional \"centralized\" statistical inference prohibitive. In addition to\ncomputational challenges associated with big data learning, the presence of\nnumerous data types (e.g. discrete, continuous, categorical, etc.) makes\nautomation and scalability difficult. A question of immediate concern is how to\ndesign a data-intensive statistical inference architecture without changing the\nbasic statistical modeling principles developed for \"small\" data over the last\ncentury. To address this problem, we present MetaLP, a flexible, distributed\nstatistical modeling framework.",
        "author": [
            "Scott Bruce",
            "Zeda Li",
            "Hsiang-Chieh Yang",
            "Subhadeep Mukhopadhyay"
        ],
        "pdfLink": "http://arxiv.org/pdf/1508.03747v5.pdf",
        "Categories": [
            [
                "stat.AP",
                "stat.CO",
                "stat.ME",
                "62G05"
            ]
        ],
        "Link": "http://arxiv.org/abs/1508.03747v5",
        "arXiv ID": "1508.03747v5"
    },
    {
        "title": "Smart Asset Management for Electric Utilities: Big Data and Future",
        "Published: ": "2017-06-18T14:59:06Z",
        "abstract": "This paper discusses about future challenges in terms of big data and new\ntechnologies. Utilities have been collecting data in large amounts but they are\nhardly utilized because they are huge in amount and also there is uncertainty\nassociated with it. Condition monitoring of assets collects large amounts of\ndata during daily operations. The question arises \"How to extract information\nfrom large chunk of data?\" The concept of \"rich data and poor information\" is\nbeing challenged by big data analytics with advent of machine learning\ntechniques. Along with technological advancements like Internet of Things\n(IoT), big data analytics will play an important role for electric utilities.\nIn this paper, challenges are answered by pathways and guidelines to make the\ncurrent asset management practices smarter for the future.",
        "author": [
            "Swasti R. Khuntia",
            "Jose L. Rueda",
            "Mart A. M. M. van der Meijden"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.09711v2.pdf",
        "Categories": [
            [
                "cs.OH",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.09711v2",
        "arXiv ID": "1706.09711v2"
    },
    {
        "title": "Trends of digitalization and adoption of big data & analytics among UK\n  SMEs: Analysis and lessons drawn from a case study of 53 SMEs",
        "Published: ": "2020-02-14T09:51:24Z",
        "abstract": "Small and Medium Enterprises (SMEs) now generate digital data at an\nunprecedented rate from online transactions, social media marketing and\nassociated customer interactions, online product or service reviews and\nfeedback, clinical diagnosis, Internet of Things (IoT) sensors, and production\nprocesses. All these forms of data can be transformed into monetary value if\nput into a proper data value chain. This requires both skills and IT\ninvestments for the long-term benefit of businesses. However, such spending is\nbeyond the capacity of most SMEs due to their limited resources and restricted\naccess to finances. This paper presents lessons learned from a case study of 53\nUK SMEs, mostly from the West Midlands region of England, supported as part of\na 3-year ERDF project, Big Data Corridor, in the areas of big data management,\nanalytics and related IT issues. Based on our study's sample companies, several\nperspectives including the digital technology trends, challenges facing the UK\nSMEs, and the state of their adoption in data analytics and big data, are\npresented in the paper.",
        "author": [
            "Muhidin Mohamed",
            "Philip Weber"
        ],
        "pdfLink": "http://arxiv.org/pdf/2002.11623v2.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2002.11623v2",
        "arXiv ID": "2002.11623v2"
    },
    {
        "title": "A Migratory Near Memory Processing Architecture Applied to Big Data\n  Problems",
        "Published: ": "2020-03-20T02:37:40Z",
        "abstract": "Servers produced by mainstream vendors are inefficient in processing Big Data\nqueries due to bottlenecks inherent in the fundamental architecture of these\nsystems. Current server blades contain multicore processors connected to DRAM\nmemory and disks by an interconnection chipset. The multicore processor chips\nperform all the computations while the DRAM and disks store the data but have\nno processing capability. To perform a database query, data must be moved back\nand forth between DRAM and a small cache as well as between DRAM and disks. For\nBig Data applications this data movement in onerous. Migratory Near Memory\nServers address this bottleneck by placing large numbers of lightweight\nprocessors directly into the memory system. These processors operate directly\non the relations, vertices and edges of Big Data applications in place without\nhaving to shuttle large quantities of data back and forth between DRAM, cache\nand heavyweight multicore processors. This paper addresses the application of\nsuch an architecture to relational database SELECT and JOIN queries.\nPreliminary results indicate end-to-end orders of magnitude speedup.",
        "author": [
            "Ed T. Upchurch"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.09074v1.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.09074v1",
        "arXiv ID": "2003.09074v1"
    },
    {
        "title": "SoK: Blockchain Decentralization",
        "Published: ": "2022-05-09T13:16:22Z",
        "abstract": "Blockchain introduces decentralized trust in peer-to-peer networks, advancing\nsecurity and democratizing systems. Yet, a unified definition for\ndecentralization remains elusive. Our Systematization of Knowledge (SoK) seeks\nto bridge this gap, emphasizing quantification and methodological coherence.\nWe've formulated a taxonomy defining blockchain decentralization across five\nfacets: consensus, network, governance, wealth, and transaction. Despite the\nprevalent focus on consensus decentralization, our novel index, based on\nShannon entropy, provides comprehensive insights. Moreover, we delve into\nalternative metrics like the Gini and Nakamoto Coefficients and the\nHerfindahl-Hirschman Index (HHI), supplemented by an open-source Python tool on\nGitHub. In terms of methodology, blockchain research has often bypassed\nstringent scientific methods. By employing descriptive, predictive, and causal\nmethods, our study showcases the potential of structured research in\nblockchain. Descriptively, we observe a trend of converging decentralization\nlevels over time. Examining DeFi platforms reveals exchange and lending\napplications as more decentralized than their payment and derivatives\ncounterparts. Predictively, there's a notable correlation between Ether's\nreturns and transaction decentralization in Ether-backed stablecoins. Causally,\nEthereum's transition to the EIP-1559 transaction fee model has a profound\nimpact on DeFi transaction decentralization. To conclude, our work outlines\ndirections for blockchain research, emphasizing the delicate balance among\ndecentralization facets, fostering long-term decentralization, and the ties\nbetween decentralization, security, privacy, and efficiency. We end by\nspotlighting challenges in grasping blockchain decentralization intricacies.",
        "author": [
            "Luyao Zhang",
            "Xinshi Ma",
            "Yulin Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.04256v6.pdf",
        "Categories": [
            [
                "econ.GN",
                "cs.CR",
                "cs.DB",
                "cs.SI",
                "q-fin.EC",
                "q-fin.ST",
                "E.0; G.1; G.3; I.6; J.4; J.6"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.04256v6",
        "arXiv ID": "2205.04256v6"
    },
    {
        "title": "Convex Shape Prior for Deep Neural Convolution Network based Eye Fundus\n  Images Segmentation",
        "Published: ": "2020-05-15T11:36:04Z",
        "abstract": "Convex Shapes (CS) are common priors for optic disc and cup segmentation in\neye fundus images. It is important to design proper techniques to represent\nconvex shapes. So far, it is still a problem to guarantee that the output\nobjects from a Deep Neural Convolution Networks (DCNN) are convex shapes. In\nthis work, we propose a technique which can be easily integrated into the\ncommonly used DCNNs for image segmentation and guarantee that outputs are\nconvex shapes. This method is flexible and it can handle multiple objects and\nallow some of the objects to be convex. Our method is based on the dual\nrepresentation of the sigmoid activation function in DCNNs. In the dual space,\nthe convex shape prior can be guaranteed by a simple quadratic constraint on a\nbinary representation of the shapes. Moreover, our method can also integrate\nspatial regularization and some other shape prior using a soft thresholding\ndynamics (STD) method. The regularization can make the boundary curves of the\nsegmentation objects to be simultaneously smooth and convex. We design a very\nstable active set projection algorithm to numerically solve our model. This\nalgorithm can form a new plug-and-play DCNN layer called CS-STD whose outputs\nmust be a nearly binary segmentation of convex objects. In the CS-STD block,\nthe convexity information can be propagated to guide the DCNN in both forward\nand backward propagation during training and prediction process. As an\napplication example, we apply the convexity prior layer to the retinal fundus\nimages segmentation by taking the popular DeepLabV3+ as a backbone network.\nExperimental results on several public datasets show that our method is\nefficient and outperforms the classical DCNN segmentation methods.",
        "author": [
            "Jun Liu",
            "Xue-Cheng Tai",
            "Shousheng Luo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.07476v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.07476v1",
        "arXiv ID": "2005.07476v1"
    },
    {
        "title": "Online Two-Dimensional Vector Packing with Advice",
        "Published: ": "2022-04-21T17:59:30Z",
        "abstract": "We consider the online two-dimensional vector packing problem, showing a\nlower bound of $11/5$ on the competitive ratio of any {\\sc AnyFit} strategy for\nthe problem. We provide strategies with competitive ratio\n$\\max\\!\\left\\{2,6\\big/\\big(1+3\\tan(\\pi/4-\\gamma/2)\\big)+\\epsilon\\right\\}$ and\nlogarithmic advice, for any instance where all the input vectors are restricted\nto have angles in the range $[\\pi/4-\\gamma/2,\\pi/4+\\gamma/2]$, for\n$0\\leq\\gamma<\\pi/3$ and\n$\\max\\left\\{5/2,4\\big/\\big(1+2\\tan(\\pi/4-\\gamma/2)\\big)+\\epsilon\\right\\}$ and\nlogarithmic advice, for any instance where all the input vectors are restricted\nto have angles in the range $[\\pi/4-\\gamma/2,\\pi/4+\\gamma/2]$, for\n$0\\leq\\gamma\\leq\\pi/3$. In addition, we give a $5/2$-competitive strategy also\nusing logarithmic advice for the unrestricted vectors case. These results\nshould be contrasted to the currently best competitive strategy, FirstFit,\nhaving competitive ratio~$27/10$.",
        "author": [
            "Bengt J. Nilsson",
            "Gordana Vujovic"
        ],
        "pdfLink": "http://arxiv.org/pdf/2204.10322v1.pdf",
        "Categories": [
            [
                "cs.DS",
                "F.2.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2204.10322v1",
        "arXiv ID": "2204.10322v1"
    },
    {
        "title": "Deep Network Approximation Characterized by Number of Neurons",
        "Published: ": "2019-06-13T06:15:15Z",
        "abstract": "This paper quantitatively characterizes the approximation power of deep\nfeed-forward neural networks (FNNs) in terms of the number of neurons. It is\nshown by construction that ReLU FNNs with width $\\mathcal{O}\\big(\\max\\{d\\lfloor\nN^{1/d}\\rfloor,\\, N+1\\}\\big)$ and depth $\\mathcal{O}(L)$ can approximate an\narbitrary H\\\"older continuous function of order $\\alpha\\in (0,1]$ on $[0,1]^d$\nwith a nearly tight approximation rate $\\mathcal{O}\\big(\\sqrt{d}\nN^{-2\\alpha/d}L^{-2\\alpha/d}\\big)$ measured in $L^p$-norm for any $N,L\\in\n\\mathbb{N}^+$ and $p\\in[1,\\infty]$. More generally for an arbitrary continuous\nfunction $f$ on $[0,1]^d$ with a modulus of continuity $\\omega_f(\\cdot)$, the\nconstructive approximation rate is $\\mathcal{O}\\big(\\sqrt{d}\\,\\omega_f(\nN^{-2/d}L^{-2/d})\\big)$. We also extend our analysis to $f$ on irregular\ndomains or those localized in an $\\varepsilon$-neighborhood of a\n$d_{\\mathcal{M}}$-dimensional smooth manifold $\\mathcal{M}\\subseteq [0,1]^d$\nwith $d_{\\mathcal{M}}\\ll d$. Especially, in the case of an essentially\nlow-dimensional domain, we show an approximation rate\n$\\mathcal{O}\\big(\\omega_f(\\tfrac{\\varepsilon}{1-\\delta}\\sqrt{\\tfrac{d}{d_\\delta}}+\\varepsilon)+\\sqrt{d}\\,\\omega_f(\\tfrac{\\sqrt{d}}{(1-\\delta)\\sqrt{d_\\delta}}N^{-2/d_\\delta}L^{-2/d_\\delta})\\big)$\nfor ReLU FNNs to approximate $f$ in the $\\varepsilon$-neighborhood, where\n$d_\\delta=\\mathcal{O}\\big(d_{\\mathcal{M}}\\tfrac{\\ln (d/\\delta)}{\\delta^2}\\big)$\nfor any $\\delta\\in(0,1)$ as a relative error for a projection to approximate an\nisometry when projecting $\\mathcal{M}$ to a $d_{\\delta}$-dimensional domain.",
        "author": [
            "Zuowei Shen",
            "Haizhao Yang",
            "Shijun Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.05497v5.pdf",
        "Categories": [
            [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.05497v5",
        "arXiv ID": "1906.05497v5"
    },
    {
        "title": "BigDatasetGAN: Synthesizing ImageNet with Pixel-wise Annotations",
        "Published: ": "2022-01-12T20:28:34Z",
        "abstract": "Annotating images with pixel-wise labels is a time-consuming and costly\nprocess. Recently, DatasetGAN showcased a promising alternative - to synthesize\na large labeled dataset via a generative adversarial network (GAN) by\nexploiting a small set of manually labeled, GAN-generated images. Here, we\nscale DatasetGAN to ImageNet scale of class diversity. We take image samples\nfrom the class-conditional generative model BigGAN trained on ImageNet, and\nmanually annotate 5 images per class, for all 1k classes. By training an\neffective feature segmentation architecture on top of BigGAN, we turn BigGAN\ninto a labeled dataset generator. We further show that VQGAN can similarly\nserve as a dataset generator, leveraging the already annotated data. We create\na new ImageNet benchmark by labeling an additional set of 8k real images and\nevaluate segmentation performance in a variety of settings. Through an\nextensive ablation study we show big gains in leveraging a large generated\ndataset to train different supervised and self-supervised backbone models on\npixel-wise tasks. Furthermore, we demonstrate that using our synthesized\ndatasets for pre-training leads to improvements over standard ImageNet\npre-training on several downstream datasets, such as PASCAL-VOC, MS-COCO,\nCityscapes and chest X-ray, as well as tasks (detection, segmentation). Our\nbenchmark will be made public and maintain a leaderboard for this challenging\ntask. Project Page: https://nv-tlabs.github.io/big-datasetgan/",
        "author": [
            "Daiqing Li",
            "Huan Ling",
            "Seung Wook Kim",
            "Karsten Kreis",
            "Adela Barriuso",
            "Sanja Fidler",
            "Antonio Torralba"
        ],
        "pdfLink": "http://arxiv.org/pdf/2201.04684v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2201.04684v1",
        "arXiv ID": "2201.04684v1"
    },
    {
        "title": "Ethna: Analyzing the Underlying Peer-to-Peer Network of the Ethereum\n  Blockchain",
        "Published: ": "2020-10-03T15:09:04Z",
        "abstract": "The peer-to-peer (P2P) network of blockchain used to transport its\ntransactions and blocks has a high impact on the efficiency and security of the\nsystem. The P2P network topologies of popular blockchains such as Bitcoin and\nEthereum, therefore, deserve our highest attention. The current Ethereum\nblockchain explorers (e.g., Etherscan) focus on the tracking of block and\ntransaction records but omit the characterization of the underlying P2P\nnetwork. This work presents the Ethereum Network Analyzer (Ethna), a tool that\nprobes and analyzes the P2P network of the Ethereum blockchain. Unlike Bitcoin\nthat adopts an unstructured P2P network, Ethereum relies on the Kademlia DHT to\nmanage its P2P network. Therefore, the existing analytical methods for\nBitcoin-like P2P networks are not applicable to Ethereum. Ethna implements a\nnovel method that accurately measures the degrees of Ethereum nodes.\nFurthermore, it incorporates an algorithm that derives the latency metrics of\nmessage propagation in the Ethereum P2P network. We ran Ethna on the Ethereum\nMainnet and conducted extensive experiments to analyze the topological features\nof its P2P network. Our analysis shows that the Ethereum P2P network possesses\na certain effect of small-world networks, and the degrees of nodes follow a\npower-law distribution that characterizes scale-free networks.",
        "author": [
            "Taotao Wang",
            "Chonghe Zhao",
            "Qing Yang",
            "Shengli Zhang",
            "Soung Chang Liew"
        ],
        "pdfLink": "http://arxiv.org/pdf/2010.01373v2.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2010.01373v2",
        "arXiv ID": "2010.01373v2"
    },
    {
        "title": "Formalizing Size-Optimal Sorting Networks: Extracting a Certified Proof\n  Checker",
        "Published: ": "2015-02-18T13:02:02Z",
        "abstract": "Since the proof of the four color theorem in 1976, computer-generated proofs\nhave become a reality in mathematics and computer science. During the last\ndecade, we have seen formal proofs using verified proof assistants being used\nto verify the validity of such proofs.\n  In this paper, we describe a formalized theory of size-optimal sorting\nnetworks. From this formalization we extract a certified checker that\nsuccessfully verifies computer-generated proofs of optimality on up to 8\ninputs. The checker relies on an untrusted oracle to shortcut the search for\nwitnesses on more than 1.6 million NP-complete subproblems.",
        "author": [
            "Lu\u00eds Cruz-Filipe",
            "Peter Schneider-Kamp"
        ],
        "pdfLink": "http://arxiv.org/pdf/1502.05209v2.pdf",
        "Categories": [
            [
                "cs.LO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1502.05209v2",
        "arXiv ID": "1502.05209v2"
    },
    {
        "title": "Point Process Models for Distribution of Cell Phone Antennas",
        "Published: ": "2018-07-28T20:32:03Z",
        "abstract": "We introduce a model for the spatial distribution of cell phone antennas in a\nurban environment. After showing that the complete spatial randomness\n(homogeneous Poisson distribution) hypothesis does not hold, we propose a model\nin which each point is distributed according to a bivariate Gaussian variable\nwith mean given by the barycenter of its neighbors in the Delaunay\ntriangulation. We show that this model is suitable, and can be used to generate\na synthetic distribution of antennas. The generated distribution contains no\nsensitive or proprietary information, and can thus be freely shared with\nresearch groups, fostering further research on the subject.",
        "author": [
            "Ezequiel Fattori",
            "Pablo Groisman",
            "Carlos Sarraute"
        ],
        "pdfLink": "http://arxiv.org/pdf/1807.10975v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1807.10975v1",
        "arXiv ID": "1807.10975v1"
    },
    {
        "title": "An amplitudes-perturbation data augmentation method in convolutional\n  neural networks for EEG decoding",
        "Published: ": "2018-11-06T14:00:05Z",
        "abstract": "Brain-Computer Interface (BCI) system provides a pathway between humans and\nthe outside world by analyzing brain signals which contain potential neural\ninformation. Electroencephalography (EEG) is one of most commonly used brain\nsignals and EEG recognition is an important part of BCI system. Recently,\nconvolutional neural networks (ConvNet) in deep learning are becoming the new\ncutting edge tools to tackle the problem of EEG recognition. However, training\nan effective deep learning model requires a big number of data, which limits\nthe application of EEG datasets with a small number of samples. In order to\nsolve the issue of data insufficiency in deep learning for EEG decoding, we\npropose a novel data augmentation method that add perturbations to amplitudes\nof EEG signals after transform them to frequency domain. In experiments, we\nexplore the performance of signal recognition with the state-of-the-art models\nbefore and after data augmentation on BCI Competition IV dataset 2a and our\nlocal dataset. The results show that our data augmentation technique can\nimprove the accuracy of EEG recognition effectively.",
        "author": [
            "Xian-Rui Zhang",
            "Meng-Ying Lei",
            "Yang Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.02353v1.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.HC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.02353v1",
        "arXiv ID": "1811.02353v1"
    },
    {
        "title": "Explainable Authorship Verification in Social Media via Attention-based\n  Similarity Learning",
        "Published: ": "2019-10-17T20:18:23Z",
        "abstract": "Authorship verification is the task of analyzing the linguistic patterns of\ntwo or more texts to determine whether they were written by the same author or\nnot. The analysis is traditionally performed by experts who consider linguistic\nfeatures, which include spelling mistakes, grammatical inconsistencies, and\nstylistics for example. Machine learning algorithms, on the other hand, can be\ntrained to accomplish the same, but have traditionally relied on so-called\nstylometric features. The disadvantage of such features is that their\nreliability is greatly diminished for short and topically varied social media\ntexts. In this interdisciplinary work, we propose a substantial extension of a\nrecently published hierarchical Siamese neural network approach, with which it\nis feasible to learn neural features and to visualize the decision-making\nprocess. For this purpose, a new large-scale corpus of short Amazon reviews for\ntext comparison research is compiled and we show that the Siamese network\ntopologies outperform state-of-the-art approaches that were built up on\nstylometric features. Our linguistic analysis of the internal attention weights\nof the network shows that the proposed method is indeed able to latch on to\nsome traditional linguistic categories.",
        "author": [
            "Benedikt Boenninghoff",
            "Steffen Hessler",
            "Dorothea Kolossa",
            "Robert M. Nickel"
        ],
        "pdfLink": "http://arxiv.org/pdf/1910.08144v2.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1910.08144v2",
        "arXiv ID": "1910.08144v2"
    },
    {
        "title": "Post-Selections in AI and How to Avoid Them",
        "Published: ": "2021-06-19T22:22:04Z",
        "abstract": "Neural network based Artificial Intelligence (AI) has reported increasing\nscales in experiments. However, this paper raises a rarely reported stage in\nsuch experiments called Post-Selection alter the reader to several possible\nprotocol flaws that may result in misleading results. All AI methods fall into\ntwo broad schools, connectionist and symbolic. The Post-Selection fall into two\nkinds, Post-Selection Using Validation Sets (PSUVS) and Post-Selection Using\nTest Sets (PSUTS). Each kind has two types of post-selectors, machines and\nhumans. The connectionist school received criticisms for its \"black box\" and\nnow the Post-Selection; but the seemingly \"clean\" symbolic school seems more\nbrittle because of its human PSUTS. This paper first presents a controversial\nview: all static \"big data\" are non-scalable. We then analyze why\nerror-backprop from randomly initialized weights suffers from severe local\nminima, why PSUVS lacks cross-validation, why PSUTS violates well-established\nprotocols, and why every paper involved should transparently report the\nPost-Selection stage. To avoid future pitfalls in AI competitions, this paper\nproposes a new AI metrics, called developmental errors for all networks\ntrained, under Three Learning Conditions: (1) an incremental learning\narchitecture (due to a \"big data\" flaw), (2) a training experience and (3) a\nlimited amount of computational resources. Developmental Networks avoid\nPost-Selections because they automatically discover context-rules on the fly by\ngenerating emergent Turing machines (not black boxes) that are optimal in the\nsense of maximum-likelihood across lifetime, conditioned on the Three Learning\nConditions.",
        "author": [
            "Juyang Weng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.13233v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.13233v2",
        "arXiv ID": "2106.13233v2"
    },
    {
        "title": "Probing CMB Cold Spot through Local Minkowski Functionals",
        "Published: ": "2012-09-18T16:34:32Z",
        "abstract": "Both WMAP and PLANCK missions reported the extremely Cold Spot (CS) centered\nat Galactic coordinate ($l=209^{\\circ}$, $b=-57^{\\circ}$) in CMB map. In this\npaper, we study the local non-Gaussianity of CS by defining the local Minkowski\nfunctions. We find that the third Minkowski function $\\nu_2$ is quite sensitive\nto the non-Gaussianity caused by CS. Compared with the random Gaussian\nsimulations, WMAP CS deviates from Gaussianity at more than 99% confident level\nat the scale $R\\sim10^{\\circ}$. Meanwhile, we find that cosmic texture provides\nan excellent explanation for these anomalies related to WMAP CS, which could be\nfurther tested by the future polarization data.",
        "author": [
            "Wen Zhao"
        ],
        "pdfLink": "http://arxiv.org/pdf/1209.4021v4.pdf",
        "Categories": [
            [
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1209.4021v4",
        "arXiv ID": "1209.4021v4"
    },
    {
        "title": "One Bad Apple Spoils the Bunch: Transaction DoS in MimbleWimble\n  Blockchains",
        "Published: ": "2021-12-24T09:52:52Z",
        "abstract": "As adoption of blockchain-based systems grows, more attention is being given\nto privacy of these systems. Early systems like BitCoin provided few privacy\nfeatures. As a result, systems with strong privacy guarantees, including\nMonero, Zcash, and MimbleWimble have been developed. Compared to BitCoin, these\ncryptocurrencies are much less understood. In this paper, we focus on\nMimbleWimble, which uses the Dandelion++ protocol for private transaction relay\nand transaction aggregation to provide transaction content privacy. We find\nthat in combination these two features make MimbleWimble susceptible to a new\ntype of denial-of-service attacks. We design, prototype, and evaluate this\nattack on the Beam network using a private test network and a network\nsimulator. We find that by controlling only 10% of the network nodes, the\nadversary can prevent over 45% of all transactions from ending up in the\nblockchain. We also discuss several potential approaches for mitigating this\nattack.",
        "author": [
            "Seyed Ali Tabatabaee",
            "Charlene Nicer",
            "Ivan Beschastnikh",
            "Chen Feng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.13009v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.13009v1",
        "arXiv ID": "2112.13009v1"
    },
    {
        "title": "Compressive sensing as a new paradigm for model building",
        "Published: ": "2012-07-31T20:49:59Z",
        "abstract": "The widely-accepted intuition that the important properties of solids are\ndetermined by a few key variables underpins many methods in physics. Though\nthis reductionist paradigm is applicable in many physical problems, its utility\ncan be limited because the intuition for identifying the key variables often\ndoes not exist or is difficult to develop. Machine learning algorithms (genetic\nprogramming, neural networks, Bayesian methods, etc.) attempt to eliminate the\na priori need for such intuition but often do so with increased computational\nburden and human time. A recently-developed technique in the field of signal\nprocessing, compressive sensing (CS), provides a simple, general, and efficient\nway of finding the key descriptive variables. CS is a new paradigm for model\nbuilding-we show that its models are just as robust as those built by current\nstate-of-the-art approaches, but can be constructed at a fraction of the\ncomputational cost and user effort.",
        "author": [
            "Lance J. Nelson",
            "Fei Zhou",
            "Gus L. W. Hart",
            "Vidvuds Ozolins"
        ],
        "pdfLink": "http://arxiv.org/pdf/1208.0030v2.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/1208.0030v2",
        "arXiv ID": "1208.0030v2"
    },
    {
        "title": "Fully Character-Level Neural Machine Translation without Explicit\n  Segmentation",
        "Published: ": "2016-10-10T18:19:34Z",
        "abstract": "Most existing machine translation systems operate at the level of words,\nrelying on explicit segmentation to extract tokens. We introduce a neural\nmachine translation (NMT) model that maps a source character sequence to a\ntarget character sequence without any segmentation. We employ a character-level\nconvolutional network with max-pooling at the encoder to reduce the length of\nsource representation, allowing the model to be trained at a speed comparable\nto subword-level models while capturing local regularities. Our\ncharacter-to-character model outperforms a recently proposed baseline with a\nsubword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable\nperformance on FI-EN and RU-EN. We then demonstrate that it is possible to\nshare a single character-level encoder across multiple languages by training a\nmodel on a many-to-one translation task. In this multilingual setting, the\ncharacter-level encoder significantly outperforms the subword-level encoder on\nall the language pairs. We observe that on CS-EN, FI-EN and RU-EN, the quality\nof the multilingual character-level translation even surpasses the models\nspecifically trained on that language pair alone, both in terms of BLEU score\nand human judgment.",
        "author": [
            "Jason Lee",
            "Kyunghyun Cho",
            "Thomas Hofmann"
        ],
        "pdfLink": "http://arxiv.org/pdf/1610.03017v3.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1610.03017v3",
        "arXiv ID": "1610.03017v3"
    },
    {
        "title": "Deep Learning in Bioinformatics",
        "Published: ": "2016-03-21T13:55:02Z",
        "abstract": "In the era of big data, transformation of biomedical big data into valuable\nknowledge has been one of the most important challenges in bioinformatics. Deep\nlearning has advanced rapidly since the early 2000s and now demonstrates\nstate-of-the-art performance in various fields. Accordingly, application of\ndeep learning in bioinformatics to gain insight from data has been emphasized\nin both academia and industry. Here, we review deep learning in bioinformatics,\npresenting examples of current research. To provide a useful and comprehensive\nperspective, we categorize research both by the bioinformatics domain (i.e.,\nomics, biomedical imaging, biomedical signal processing) and deep learning\narchitecture (i.e., deep neural networks, convolutional neural networks,\nrecurrent neural networks, emergent architectures) and present brief\ndescriptions of each study. Additionally, we discuss theoretical and practical\nissues of deep learning in bioinformatics and suggest future research\ndirections. We believe that this review will provide valuable insights and\nserve as a starting point for researchers to apply deep learning approaches in\ntheir bioinformatics studies.",
        "author": [
            "Seonwoo Min",
            "Byunghan Lee",
            "Sungroh Yoon"
        ],
        "pdfLink": "http://arxiv.org/pdf/1603.06430v5.pdf",
        "Categories": [
            [
                "cs.LG",
                "q-bio.GN"
            ]
        ],
        "Link": "http://arxiv.org/abs/1603.06430v5",
        "arXiv ID": "1603.06430v5"
    },
    {
        "title": "Learning Theory of Distributed Regression with Bias Corrected\n  Regularization Kernel Network",
        "Published: ": "2017-08-07T01:54:56Z",
        "abstract": "Distributed learning is an effective way to analyze big data. In distributed\nregression, a typical approach is to divide the big data into multiple blocks,\napply a base regression algorithm on each of them, and then simply average the\noutput functions learnt from these blocks. Since the average process will\ndecrease the variance, not the bias, bias correction is expected to improve the\nlearning performance if the base regression algorithm is a biased one.\nRegularization kernel network is an effective and widely used method for\nnonlinear regression analysis. In this paper we will investigate a bias\ncorrected version of regularization kernel network. We derive the error bounds\nwhen it is applied to a single data set and when it is applied as a base\nalgorithm in distributed regression. We show that, under certain appropriate\nconditions, the optimal learning rates can be reached in both situations.",
        "author": [
            "Zhengchu Guo",
            "Lei Shi",
            "Qiang Wu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1708.01960v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML",
                "68T05"
            ]
        ],
        "Link": "http://arxiv.org/abs/1708.01960v1",
        "arXiv ID": "1708.01960v1"
    },
    {
        "title": "Short-term Electric Load Forecasting Using TensorFlow and Deep\n  Auto-Encoders",
        "Published: ": "2019-07-21T09:31:35Z",
        "abstract": "This paper conducts research on the short-term electric load forecast method\nunder the background of big data. It builds a new electric load forecast model\nbased on Deep Auto-Encoder Networks (DAENs), which takes into account\nmultidimensional load-related data sets including historical load value,\ntemperature, day type, etc. A new distributed short-term load forecast method\nbased on TensorFlow and DAENs is therefore proposed, with an algorithm\nflowchart designed. This method overcomes the shortcomings of traditional\nneural network methods, such as over-fitting, slow convergence and local\noptimum, etc. Case study results show that the proposed method has obvious\nadvantages in prediction accuracy, stability, and expansibility compared with\nthose based on traditional neural networks. Thus, this model can better meet\nthe demands of short-term electric load forecasting under big data scenario.",
        "author": [
            "Xin Shi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1907.08941v1.pdf",
        "Categories": [
            [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1907.08941v1",
        "arXiv ID": "1907.08941v1"
    },
    {
        "title": "A Security Monitoring Framework For Virtualization Based HEP\n  Infrastructures",
        "Published: ": "2017-04-16T14:59:21Z",
        "abstract": "High Energy Physics (HEP) distributed computing infrastructures require\nautomatic tools to monitor, analyze and react to potential security incidents.\nThese tools should collect and inspect data such as resource consumption, logs\nand sequence of system calls for detecting anomalies that indicate the presence\nof a malicious agent. They should also be able to perform automated reactions\nto attacks without administrator intervention. We describe a novel framework\nthat accomplishes these requirements, with a proof of concept implementation\nfor the ALICE experiment at CERN. We show how we achieve a fully virtualized\nenvironment that improves the security by isolating services and Jobs without a\nsignificant performance impact. We also describe a collected dataset for\nMachine Learning based Intrusion Prevention and Detection Systems on Grid\ncomputing. This dataset is composed of resource consumption measurements (such\nas CPU, RAM and network traffic), logfiles from operating system services, and\nsystem call data collected from production Jobs running in an ALICE Grid test\nsite and a big set of malware. This malware was collected from security\nresearch sites. Based on this dataset, we will proceed to develop Machine\nLearning algorithms able to detect malicious Jobs.",
        "author": [
            "A. Gomez Ramirez",
            "M. Martinez Pedreira",
            "C. Grigoras",
            "L. Betev",
            "C. Lara",
            "U. Kebschull"
        ],
        "pdfLink": "http://arxiv.org/pdf/1704.04782v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.AI",
                "cs.CR",
                "hep-ex"
            ]
        ],
        "Link": "http://arxiv.org/abs/1704.04782v1",
        "arXiv ID": "1704.04782v1"
    },
    {
        "title": "DRONE: a Distributed Subgraph-Centric Framework for Processing Large\n  Scale Power-law Graphs",
        "Published: ": "2018-12-11T13:17:55Z",
        "abstract": "Nowadays, in the big data era, social networks, graph databases, knowledge\ngraphs, electronic commerce etc. demand efficient and scalable capability to\nprocess an ever increasing volume of graph-structured data. To meet the\nchallenge, two mainstream distributed programming models, vertex-centric (VC)\nand subgraph-centric (SC) were proposed. Compared to the VC model, the SC model\nconverges faster with less communication overhead on well-partitioned graphs,\nand is easy to program due to the \"think like a graph\" philosophy. The edge-cut\nmethod is considered as a natural choice of subgraph-centric model for graph\npartitioning, and has been adopted by Giraph++, Blogel and GRAPE. However, the\nedge-cut method causes significant performance bottleneck for processing large\nscale power-law graphs. Thus, the SC model is less competitive in practice. In\nthis paper, we present an innovative distributed graph computing framework,\nDRONE (Distributed gRaph cOmputiNg Engine). It combines the subgraph-centric\nmodel and the vertex-cut graph partitioning strategy. Experiments show that\nDRONE outperforms the state-of-art distributed graph computing engines on\nreal-world graphs and synthetic power-law graphs. DRONE is capable of scaling\nup to process one-trillion-edge synthetic power-law graphs, which is orders of\nmagnitude larger than previously reported by existing SC-based frameworks.",
        "author": [
            "Xiaole Wen",
            "Shuai Zhang",
            "Haihang You"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.04380v2.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.04380v2",
        "arXiv ID": "1812.04380v2"
    },
    {
        "title": "An Hierarchical Approach to Big Data",
        "Published: ": "2016-11-04T10:32:01Z",
        "abstract": "The increasing volumes of astronomical data require practical methods for\ndata exploration, access and visualisation. The Hierarchical Progressive Survey\n(HiPS) is a HEALPix based scheme that enables a multi-resolution approach to\nastronomy data from the individual pixels up to the whole sky. We highlight the\ndecisions and approaches that have been taken to make this scheme a practical\nsolution for managing large volumes of heterogeneous data. Early implementors\nof this system have formed a network of HiPS nodes, with some 250 diverse data\nsets currently available, with multiple mirror implementations for important\ndata sets. This hierarchical approach can be adapted to expose Big Data in\ndifferent ways. We describe how the ease of implementation, and local\ncustomisation of the Aladin Lite embeddable HiPS visualiser have been keys for\npromoting collaboration on HiPS.",
        "author": [
            "M. G. Allen",
            "P. Fernique",
            "T. Boch",
            "D. Durand",
            "A. Oberto",
            "B. Merin",
            "F. Stoehr",
            "F. Genova",
            "F-X. Pineau",
            "J. Salgado"
        ],
        "pdfLink": "http://arxiv.org/pdf/1611.01312v1.pdf",
        "Categories": [
            [
                "astro-ph.IM"
            ]
        ],
        "Link": "http://arxiv.org/abs/1611.01312v1",
        "arXiv ID": "1611.01312v1"
    },
    {
        "title": "High-Performance Routing with Multipathing and Path Diversity in\n  Ethernet and HPC Networks",
        "Published: ": "2020-07-07T20:16:54Z",
        "abstract": "The recent line of research into topology design focuses on lowering network\ndiameter. Many low-diameter topologies such as Slim Fly or Jellyfish that\nsubstantially reduce cost, power consumption, and latency have been proposed. A\nkey challenge in realizing the benefits of these topologies is routing. On one\nhand, these networks provide shorter path lengths than established topologies\nsuch as Clos or torus, leading to performance improvements. On the other hand,\nthe number of shortest paths between each pair of endpoints is much smaller\nthan in Clos, but there is a large number of non-minimal paths between router\npairs. This hampers or even makes it impossible to use established multipath\nrouting schemes such as ECMP. In this work, to facilitate high-performance\nrouting in modern networks, we analyze existing routing protocols and\narchitectures, focusing on how well they exploit the diversity of minimal and\nnon-minimal paths. We first develop a taxonomy of different forms of support\nfor multipathing and overall path diversity. Then, we analyze how existing\nrouting schemes support this diversity. Among others, we consider multipathing\nwith both shortest and non-shortest paths, support for disjoint paths, or\nenabling adaptivity. To address the ongoing convergence of HPC and \"Big Data\"\ndomains, we consider routing protocols developed for both HPC systems and for\ndata centers as well as general clusters. Thus, we cover architectures and\nprotocols based on Ethernet, InfiniBand, and other HPC networks such as\nMyrinet. Our review will foster developing future high-performance multipathing\nrouting protocols in supercomputers and data centers.",
        "author": [
            "Maciej Besta",
            "Jens Domke",
            "Marcel Schneider",
            "Marek Konieczny",
            "Salvatore Di Girolamo",
            "Timo Schneider",
            "Ankit Singla",
            "Torsten Hoefler"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.03776v3.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.DC",
                "cs.PF"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.03776v3",
        "arXiv ID": "2007.03776v3"
    },
    {
        "title": "Discourse Analysis of Covid-19 in Persian Twitter Social Networks Using\n  Graph Mining and Natural Language Processing",
        "Published: ": "2021-09-01T10:39:20Z",
        "abstract": "One of the new scientific ways of understanding discourse dynamics is\nanalyzing the public data of social networks. This research's aim is\nPost-structuralist Discourse Analysis (PDA) of Covid-19 phenomenon (inspired by\nLaclau and Mouffe's Discourse Theory) by using Intelligent Data Mining for\nPersian Society. The examined big data is five million tweets from 160,000\nusers of the Persian Twitter network to compare two discourses. Besides\nanalyzing the tweet texts individually, a social network graph database has\nbeen created based on retweets relationships. We use the VoteRank algorithm to\nintroduce and rank people whose posts become word of mouth, provided that the\ntotal information spreading scope is maximized over the network. These users\nare also clustered according to their word usage pattern (the Gaussian Mixture\nModel is used). The constructed discourse of influential spreaders is compared\nto the most active users. This analysis is done based on Covid-related posts\nover eight episodes. Also, by relying on the statistical content analysis and\npolarity of tweet words, discourse analysis is done for the whole mentioned\nsubpopulations, especially for the top individuals. The most important result\nof this research is that the Twitter subjects' discourse construction is\ngovernment-based rather than community-based. The analyzed Iranian society does\nnot consider itself responsible for the Covid-19 wicked problem, does not\nbelieve in participation, and expects the government to solve all problems. The\nmost active and most influential users' similarity is that political, national,\nand critical discourse construction is the predominant one. In addition to the\nadvantages of its research methodology, it is necessary to pay attention to the\nstudy's limitations. Suggestion for future encounters of Iranian society with\nsimilar crises is given.",
        "author": [
            "Omid Shokrollahi",
            "Niloofar Hashemi",
            "Mohammad Dehghani"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.00298v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.00298v1",
        "arXiv ID": "2109.00298v1"
    },
    {
        "title": "A Divide-and-Conquer Algorithm for Distributed Optimization on Networks",
        "Published: ": "2021-12-03T23:55:05Z",
        "abstract": "In this paper, we consider networks with topologies described by some\nconnected undirected graph ${\\mathcal{G}}=(V, E)$ and with some agents (fusion\ncenters) equipped with processing power and local peer-to-peer communication,\nand optimization problem $\\min_{{\\boldsymbol x}}\\big\\{F({\\boldsymbol\nx})=\\sum_{i\\in V}f_i({\\boldsymbol x})\\big\\}$ with local objective functions\n$f_i$ depending only on neighboring variables of the vertex $i\\in V$. We\nintroduce a divide-and-conquer algorithm to solve the above optimization\nproblem in a distributed and decentralized manner. The proposed\ndivide-and-conquer algorithm has exponential convergence, its computational\ncost is almost linear with respect to the size of the network, and it can be\nfully implemented at fusion centers of the network. Our numerical\ndemonstrations also indicate that the proposed divide-and-conquer algorithm has\nsuperior performance than popular decentralized optimization methods do for the\nleast squares problem with/without $\\ell^1$ penalty.",
        "author": [
            "Nazar Emirov",
            "Guohui Song",
            "Qiyu Sun"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.02197v1.pdf",
        "Categories": [
            [
                "math.OC",
                "cs.DC",
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.02197v1",
        "arXiv ID": "2112.02197v1"
    },
    {
        "title": "IterLara: A Turing Complete Algebra for Big Data, AI, Scientific\n  Computing, and Database",
        "Published: ": "2023-07-17T08:23:09Z",
        "abstract": "\\textsc{Lara} is a key-value algebra that aims at unifying linear and\nrelational algebra with three types of operation abstraction. The study of\n\\textsc{Lara}'s expressive ability reports that it can represent relational\nalgebra and most linear algebra operations. However, several essential\ncomputations, such as matrix inversion and determinant, cannot be expressed in\n\\textsc{Lara}. \\textsc{Lara} cannot represent global and iterative computation,\neither. This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with\niterative operators, to provide an algebraic model that unifies operations in\ngeneral-purpose computing, like big data, AI, scientific computing, and\ndatabase. We study the expressive ability of \\textsc{Lara} and\n\\textsc{IterLara} and prove that \\textsc{IterLara} with aggregation functions\ncan represent matrix inversion, determinant. Besides, we demonstrate that\n\\textsc{IterLara} with no limitation of function utility is Turing complete. We\nalso propose the Operation Count (OP) as a metric of computation amount for\n\\textsc{IterLara} and ensure that the OP metric is in accordance with the\nexisting computation metrics.",
        "author": [
            "Hongxiao Li",
            "Wanling Gao",
            "Lei Wang",
            "Jianfeng Zhan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.08315v1.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.CL",
                "cs.DS"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.08315v1",
        "arXiv ID": "2307.08315v1"
    },
    {
        "title": "Tourists' digital footprint in cities: comparing big data sources",
        "Published: ": "2017-05-22T19:05:01Z",
        "abstract": "There is little knowledge available on the spatial behaviour of urban\ntourists, and yet tourists generate an enormous quantity of data (Big Data)\nwhen they visit cities. These data sources can be used to track their presence\nthrough their activities. The aim of this paper is to analyse the digital\nfootprint of urban tourists through Big Data. Unlike other papers that use a\nsingle data source, this article examines three sources of data to reflect\ndifferent tourism activities in cities: Panoramio (sightseeing), Foursquare\n(consumption), and Twitter (being connected). Tourist density in the three data\nsources is compared via maps, correlation analysis (OLS) and spatial\nself-correlation analysis (Global Moran's I statistic and LISA). Finally the\ndata are integrated using cluster analysis and combining the spatial clusters\nidentified in the LISA analysis in the different data sources. The results show\nthat the data from the three activities are partly spatially redundant and\npartly complementary, and allow the characterisation of multifunction tourist\nspaces (with several activities) and spaces specialising in one or various\nactivities (for example, sightseeing and consumption). The case study analysed\n(Madrid) reveals a significant presence of tourists in the city centre, and\nincreasing specialisation from the centre outwards towards the periphery. The\nmain conclusion of the paper is that it is not sufficient to use one data\nsource to analyse the presence of tourists in cities; several must be used in a\ncomplementary manner.",
        "author": [
            "Maria Henar Salas-Olmedo",
            "Juan Carlos Garcia-Palomares",
            "Javier Gutierrez"
        ],
        "pdfLink": "http://arxiv.org/pdf/1705.07951v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1705.07951v1",
        "arXiv ID": "1705.07951v1"
    },
    {
        "title": "A Unified Approach for Multi-Scale Synchronous Correlation Search in Big\n  Time Series -- Full Version",
        "Published: ": "2022-04-19T20:58:58Z",
        "abstract": "The wide deployment of IoT sensors has enabled the collection of very big\ntime series across different domains, from which advanced analytics can be\nperformed to find unknown relationships, most importantly the correlations\nbetween them. However, current approaches for correlation search on time series\nare limited to only a single temporal scale and simple types of relations, and\ncannot handle noise effectively. This paper presents the integrated SYnchronous\nCOrrelation Search (iSYCOS) framework to find multi-scale correlations in big\ntime series. Specifically, iSYCOS integrates top-down and bottom-up approaches\ninto a single auto-configured framework capable of efficiently extracting\ncomplex window-based correlations from big time series using mutual information\n(MI). Moreover, iSYCOS includes a novel MI-based theory to identify noise in\nthe data, and is used to perform pruning to improve iSYCOS performance.\nBesides, we design a distributed version of iSYCOS that can scale out in a\nSpark cluster to handle big time series. Our extensive experimental evaluation\non synthetic and real-world datasets shows that iSYCOS can auto-configure on a\ngiven dataset to find complex multi-scale correlations. The pruning and\noptimisations can improve iSYCOS performance up to an order of magnitude, and\nthe distributed iSYCOS can scale out linearly on a computing cluster.",
        "author": [
            "Nguyen Ho",
            "Van Long Ho",
            "Torben Bach Pedersen",
            "Mai Vu",
            "Christophe A. N. Biscio"
        ],
        "pdfLink": "http://arxiv.org/pdf/2204.09131v1.pdf",
        "Categories": [
            [
                "cs.DB"
            ]
        ],
        "Link": "http://arxiv.org/abs/2204.09131v1",
        "arXiv ID": "2204.09131v1"
    },
    {
        "title": "Evaluating Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and\n  GPUDirect",
        "Published: ": "2019-03-11T21:21:21Z",
        "abstract": "High performance multi-GPU computing becomes an inevitable trend due to the\never-increasing demand on computation capability in emerging domains such as\ndeep learning, big data and planet-scale simulations. However, the lack of deep\nunderstanding on how modern GPUs can be connected and the real impact of\nstate-of-the-art interconnect technology on multi-GPU application performance\nbecome a hurdle. In this paper, we fill the gap by conducting a thorough\nevaluation on five latest types of modern GPU interconnects: PCIe, NVLink-V1,\nNVLink-V2, NVLink-SLI and NVSwitch, from six high-end servers and HPC\nplatforms: NVIDIA P100-DGX-1, V100-DGX-1, DGX-2, OLCF's SummitDev and Summit\nsupercomputers, as well as an SLI-linked system with two NVIDIA Turing RTX-2080\nGPUs. Based on the empirical evaluation, we have observed four new types of GPU\ncommunication network NUMA effects: three are triggered by NVLink's topology,\nconnectivity and routing, while one is caused by PCIe chipset design issue.\nThese observations indicate that, for an application running in a multi-GPU\nnode, choosing the right GPU combination can impose considerable impact on GPU\ncommunication efficiency, as well as the application's overall performance. Our\nevaluation can be leveraged in building practical multi-GPU performance models,\nwhich are vital for GPU task allocation, scheduling and migration in a shared\nenvironment (e.g., AI cloud and HPC centers), as well as communication-oriented\nperformance tuning.",
        "author": [
            "Ang Li",
            "Shuaiwen Leon Song",
            "Jieyang Chen",
            "Jiajia Li",
            "Xu Liu",
            "Nathan Tallent",
            "Kevin Barker"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.04611v1.pdf",
        "Categories": [
            [
                "cs.AR",
                "cs.DC",
                "cs.NI",
                "cs.PF"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.04611v1",
        "arXiv ID": "1903.04611v1"
    },
    {
        "title": "A Random Gossip BMUF Process for Neural Language Modeling",
        "Published: ": "2019-09-19T14:11:36Z",
        "abstract": "Neural network language model (NNLM) is an essential component of industrial\nASR systems. One important challenge of training an NNLM is to leverage between\nscaling the learning process and handling big data. Conventional approaches\nsuch as block momentum provides a blockwise model update filtering (BMUF)\nprocess and achieves almost linear speedups with no performance degradation for\nspeech recognition. However, it needs to calculate the model average from all\ncomputing nodes (e.g., GPUs) and when the number of computing nodes is large,\nthe learning suffers from the severe communication latency. As a consequence,\nBMUF is not suitable under restricted network conditions. In this paper, we\npresent a decentralized BMUF process, in which the model is split into\ndifferent components, each of which is updated by communicating to some\nrandomly chosen neighbor nodes with the same component, followed by a BMUF-like\nprocess. We apply this method to several LSTM language modeling tasks.\nExperimental results show that our approach achieves consistently better\nperformance than conventional BMUF. In particular, we obtain a lower perplexity\nthan the single-GPU baseline on the wiki-text-103 benchmark using 4 GPUs. In\naddition, no performance degradation is observed when scaling to 8 and 16 GPUs.",
        "author": [
            "Yiheng Huang",
            "Jinchuan Tian",
            "Lei Han",
            "Guangsen Wang",
            "Xingcheng Song",
            "Dan Su",
            "Dong Yu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.09010v3.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.09010v3",
        "arXiv ID": "1909.09010v3"
    },
    {
        "title": "An efficient and flexible inference system for serving heterogeneous\n  ensembles of deep neural networks",
        "Published: ": "2022-08-30T08:05:43Z",
        "abstract": "Ensembles of Deep Neural Networks (DNNs) have achieved qualitative\npredictions but they are computing and memory intensive. Therefore, the demand\nis growing to make them answer a heavy workload of requests with available\ncomputational resources. Unlike recent initiatives on inference servers and\ninference frameworks, which focus on the prediction of single DNNs, we propose\na new software layer to serve with flexibility and efficiency ensembles of\nDNNs.\n  Our inference system is designed with several technical innovations. First,\nwe propose a novel procedure to find a good allocation matrix between devices\n(CPUs or GPUs) and DNN instances. It runs successively a worst-fit to allocate\nDNNs into the memory devices and a greedy algorithm to optimize allocation\nsettings and speed up the ensemble. Second, we design the inference system\nbased on multiple processes to run asynchronously: batching, prediction, and\nthe combination rule with an efficient internal communication scheme to avoid\noverhead.\n  Experiments show the flexibility and efficiency under extreme scenarios: It\nsuccesses to serve an ensemble of 12 heavy DNNs into 4 GPUs and at the\nopposite, one single DNN multi-threaded into 16 GPUs. It also outperforms the\nsimple baseline consisting of optimizing the batch size of DNNs by a speedup up\nto 2.7X on the image classification task.",
        "author": [
            "Pierrick Pochelu",
            "Serge G. Petiton",
            "Bruno Conche"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.14049v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.14049v1",
        "arXiv ID": "2208.14049v1"
    },
    {
        "title": "Deterministic Distributed Ruling Sets of Line Graphs",
        "Published: ": "2018-05-18T13:52:42Z",
        "abstract": "An $(\\alpha,\\beta)$-ruling set of a graph $G=(V,E)$ is a set $R\\subseteq V$\nsuch that for any node $v\\in V$ there is a node $u\\in R$ in distance at most\n$\\beta$ from $v$ and such that any two nodes in $R$ are at distance at least\n$\\alpha$ from each other. The concept of ruling sets can naturally be extended\nto edges, i.e., a subset $F\\subseteq E$ is an $(\\alpha,\\beta)$-ruling edge set\nof a graph $G=(V,E)$ if the corresponding nodes form an $(\\alpha,\\beta)$-ruling\nset in the line graph of $G$. This paper presents a simple deterministic,\ndistributed algorithm, in the $\\mathsf{CONGEST}$ model, for computing\n$(2,2)$-ruling edge sets in $O(\\log^* n)$ rounds. Furthermore, we extend the\nalgorithm to compute ruling sets of graphs with bounded diversity. Roughly\nspeaking, the diversity of a graph is the maximum number of maximal cliques a\nvertex belongs to. We devise $(2,O(\\mathcal{D}))$-ruling sets on graphs with\ndiversity $\\mathcal{D}$ in $O(\\mathcal{D}+\\log^* n)$ rounds. This also implies\na fast, deterministic $(2,O(\\ell))$-ruling edge set algorithm for hypergraphs\nwith rank at most $\\ell$.\n  Furthermore, we provide a ruling set algorithm for general graphs that for\nany $B\\geq 2$ computes an $\\big(\\alpha, \\alpha \\lceil \\log_B n \\rceil\n\\big)$-ruling set in $O(\\alpha \\cdot B \\cdot \\log_B n)$ rounds in the\n$\\mathsf{CONGEST}$ model. The algorithm can be modified to compute a $\\big(2,\n\\beta \\big)$-ruling set in $O(\\beta \\Delta^{2/\\beta} + \\log^* n)$ rounds in the\n$\\mathsf{CONGEST}$~ model, which matches the currently best known such\nalgorithm in the more general $\\mathsf{LOCAL}$ model.",
        "author": [
            "Fabian Kuhn",
            "Yannic Maus",
            "Simon Weidner"
        ],
        "pdfLink": "http://arxiv.org/pdf/1805.07209v1.pdf",
        "Categories": [
            [
                "cs.DS",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1805.07209v1",
        "arXiv ID": "1805.07209v1"
    },
    {
        "title": "Statistical Compressive Sensing of Gaussian Mixture Models",
        "Published: ": "2010-10-20T20:22:26Z",
        "abstract": "A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models.",
        "author": [
            "Guoshen Yu",
            "Guillermo Sapiro"
        ],
        "pdfLink": "http://arxiv.org/pdf/1010.4314v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1010.4314v1",
        "arXiv ID": "1010.4314v1"
    },
    {
        "title": "How to find real-world applications for compressive sensing",
        "Published: ": "2013-05-06T14:00:07Z",
        "abstract": "The potential of compressive sensing (CS) has spurred great interest in the\nresearch community and is a fast growing area of research. However, research\ntranslating CS theory into practical hardware and demonstrating clear and\nsignificant benefits with this hardware over current, conventional imaging\ntechniques has been limited. This article helps researchers to find those niche\napplications where the CS approach provides substantial gain over conventional\napproaches by articulating lessons learned in finding one such application; sea\nskimming missile detection. As a proof of concept, it is demonstrated that a\nsimplified CS missile detection architecture and algorithm provides comparable\nresults to the conventional imaging approach but using a smaller FPA. The\nprimary message is that all of the excitement surrounding CS is necessary and\nappropriate for encouraging our creativity but we all must also take off our\n\"rose colored glasses\" and critically judge our ideas, methods and results\nrelative to conventional imaging approaches.",
        "author": [
            "Leslie N. Smith"
        ],
        "pdfLink": "http://arxiv.org/pdf/1305.1199v4.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1305.1199v4",
        "arXiv ID": "1305.1199v4"
    },
    {
        "title": "On the Complexity of Bounded Context Switching",
        "Published: ": "2016-09-30T13:44:32Z",
        "abstract": "Bounded context switching (BCS) is an under-approximate method for finding\nviolations to safety properties in shared memory concurrent programs.\nTechnically, BCS is a reachability problem that is known to be NP-complete. Our\ncontribution is a parameterized analysis of BCS.\n  The first result is an algorithm that solves BCS when parameterized by the\nnumber of context switches (cs) and the size of the memory (m) in\nO*(m^(cs)2^(cs)). This is achieved by creating instances of the easier problem\nShuff which we solve via fast subset convolution. We also present a lower bound\nfor BCS of the form m^o(cs / log(cs)), based on the exponential time\nhypothesis. Interestingly, closing the gap means settling a conjecture that has\nbeen open since FOCS'07. Further, we prove that BCS admits no polynomial\nkernel.\n  Next, we introduce a measure, called scheduling dimension, that captures the\ncomplexity of schedules. We study BCS parameterized by the scheduling dimension\n(sdim) and show that it can be solved in O*((2m)^(4sdim)4^t)$, where t is the\nnumber of threads. We consider variants of the problem for which we obtain\n(matching) upper and lower bounds.",
        "author": [
            "Peter Chini",
            "Jonathan Kolberg",
            "Andreas Krebs",
            "Roland Meyer",
            "Prakash Saivasan"
        ],
        "pdfLink": "http://arxiv.org/pdf/1609.09728v2.pdf",
        "Categories": [
            [
                "cs.FL",
                "cs.LO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1609.09728v2",
        "arXiv ID": "1609.09728v2"
    },
    {
        "title": "Charge multipoles correlations and order in Cs$_2$TaCl$_6$",
        "Published: ": "2022-07-20T17:10:43Z",
        "abstract": "We examine the role of charge, structural, and spin degrees of freedom in the\npreviously poorly understood phase transition in the 5$d^1$ transition-metal\ndouble perovskite Cs$_2$TaCl$_6$, using a combination of computational and\nexperimental techniques. Our heat capacity measurements of single-crystalline\nCs$_2$TaCl$_6$, reveal a clear anomaly at the transition temperature,\n$T_\\mathrm{Q}$, which was not previously observed in polycrystalline samples.\nDensity functional calculations indicate the emergence of local charge\nquadrupoles in the cubic phase, mediated by the paramagnetic spins or local\nstructural distortions which then develop into long-range ordered charge\nquadrupoles in the tetragonal phase. Our resonant elastic x-ray scattering on\nCs$_2$TaCl$_6$, single crystals lend support to our calculations. Our work\nprovides new insight into the phase transition in Cs$_2$TaCl$_6$, at\n$T_\\mathrm{Q}$, and demonstrates the utility of this combination of techniques\nin understanding the complex physics of hidden orders in paramagnetic\nspin-orbit-entangled compounds.",
        "author": [
            "Aria Mansouri Tehrani",
            "Jian-Rui Soh",
            "Jana P\u00e1sztorov\u00e1",
            "Maximilian E. Merkel",
            "Ivica \u017divkovi\u0107",
            "Henrik M. R\u00f8nnow",
            "Nicola A. Spaldin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2207.10042v1.pdf",
        "Categories": [
            [
                "cond-mat.mtrl-sci"
            ]
        ],
        "Link": "http://arxiv.org/abs/2207.10042v1",
        "arXiv ID": "2207.10042v1"
    },
    {
        "title": "REBD:A Conceptual Framework for Big Data Requirements Engineering",
        "Published: ": "2020-06-19T15:49:00Z",
        "abstract": "Requirements engineering (RE), as a part of the project development life\ncycle, has increasingly been recognized as the key to ensuring on-time,\non-budget, and goal-based delivery of software projects;compromising this vital\nphase is nothing but project failures. RE of big data projects is even more\ncrucial because of the main characteristics of big data, including high volume,\nvelocity, and variety. As the traditional RE methods and tools are user-centric\nrather than data-centric, employing these methodologies is insufficient to\nfulfill the RE processes for big data projects. Because of the importance of RE\nand limitations of traditional RE methodologies in the context of big data\nsoftware projects, in this paper, a big data requirements engineering\nframework, named REBD, has been proposed. This conceptual framework describes\nthe systematic plan to carry out big data projects starting from requirements\nengineering to the development, assuring successful execution, and increased\nproductivity of the big data projects.",
        "author": [
            "Sandhya Rani Kourla",
            "Eesha Putti",
            "Mina Maleki"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.11195v1.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.11195v1",
        "arXiv ID": "2006.11195v1"
    },
    {
        "title": "Classification with Boosting of Extreme Learning Machine Over\n  Arbitrarily Partitioned Data",
        "Published: ": "2016-02-09T08:09:26Z",
        "abstract": "Machine learning based computational intelligence methods are widely used to\nanalyze large scale data sets in this age of big data. Extracting useful\npredictive modeling from these types of data sets is a challenging problem due\nto their high complexity. Analyzing large amount of streaming data that can be\nleveraged to derive business value is another complex problem to solve. With\nhigh levels of data availability (\\textit{i.e. Big Data}) automatic\nclassification of them has become an important and complex task. Hence, we\nexplore the power of applying MapReduce based Distributed AdaBoosting of\nExtreme Learning Machine (ELM) to build a predictive bag of classification\nmodels. Accordingly, (i) data set ensembles are created; (ii) ELM algorithm is\nused to build weak learners (classifier functions); and (iii) builds a strong\nlearner from a set of weak learners. We applied this training model to the\nbenchmark knowledge discovery and data mining data sets.",
        "author": [
            "Ferhat \u00d6zg\u00fcr \u00c7atak"
        ],
        "pdfLink": "http://arxiv.org/pdf/1602.02887v1.pdf",
        "Categories": [
            [
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1602.02887v1",
        "arXiv ID": "1602.02887v1"
    },
    {
        "title": "Data Science Methodology for Cybersecurity Projects",
        "Published: ": "2018-03-12T12:34:12Z",
        "abstract": "Cyber-security solutions are traditionally static and signature-based. The\ntraditional solutions along with the use of analytic models, machine learning\nand big data could be improved by automatically trigger mitigation or provide\nrelevant awareness to control or limit consequences of threats. This kind of\nintelligent solutions is covered in the context of Data Science for\nCyber-security. Data Science provides a significant role in cyber-security by\nutilising the power of data (and big data), high-performance computing and data\nmining (and machine learning) to protect users against cyber-crimes. For this\npurpose, a successful data science project requires an effective methodology to\ncover all issues and provide adequate resources. In this paper, we are\nintroducing popular data science methodologies and will compare them in\naccordance with cyber-security challenges. A comparison discussion has also\ndelivered to explain methodologies strengths and weaknesses in case of\ncyber-security projects.",
        "author": [
            "Farhad Foroughi",
            "Peter Luksch"
        ],
        "pdfLink": "http://arxiv.org/pdf/1803.04219v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1803.04219v1",
        "arXiv ID": "1803.04219v1"
    },
    {
        "title": "Smart Contracts Software Metrics: a First Study",
        "Published: ": "2018-02-05T17:21:53Z",
        "abstract": "Smart contracts (SC) are software codes which reside and run over a\nblockchain. The code can be written in different languages with the common\npurpose of implementing various kinds of transactions onto the hosting\nblockchain, They are ruled by the blockchain infrastructure and work in order\nto satisfy conditions typical of traditional contracts. The software code must\nsatisfy constrains strongly context dependent which are quite different from\ntraditional software code. In particular, since the bytecode is uploaded in the\nhosting blockchain, size, computational resources, interaction between\ndifferent parts of software are all limited and even if the specific software\nlanguages implement more or less the same constructs of traditional languages\nthere is not the same freedom as in normal software development. SC software is\nexpected to reflect these constrains on SC software metrics which should\ndisplay metric values characteristic of the domain and different from more\ntraditional software metrics. We tested this hypothesis on the code of more\nthan twelve thousands SC written in Solidity and uploaded on the Ethereum\nblockchain. We downloaded the SC from a public repository and computed the\nstatistics of a set of software metrics related to SC and compared them to the\nmetrics extracted from more traditional software projects. Our results show\nthat generally Smart Contracts metrics have ranges more restricted than the\ncorresponding metrics in traditional software systems. Some of the stylized\nfacts, like power law in the tail of the distribution of some metrics, are only\napproximate but the lines of code follow a log normal distribution which\nreminds of the same behavior already found in traditional software systems.",
        "author": [
            "Roberto Tonelli",
            "Giuseppe Destefanis",
            "Michele Marchesi",
            "Marco Ortu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1802.01517v2.pdf",
        "Categories": [
            [
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1802.01517v2",
        "arXiv ID": "1802.01517v2"
    },
    {
        "title": "A New Theoretical Framework of Pyramid Markov Processes for Blockchain\n  Selfish Mining",
        "Published: ": "2020-07-03T02:02:35Z",
        "abstract": "In this paper, we provide a new theoretical framework of pyramid Markov\nprocesses to solve some open and fundamental problems of blockchain selfish\nmining under a rigorous mathematical setting. We first describe a more general\nmodel of blockchain selfish mining with both a two-block leading competitive\ncriterion and a new economic incentive mechanism. Then we establish a pyramid\nMarkov process and show that it is irreducible and positive recurrent, and its\nstationary probability vector is matrix-geometric with an explicitly\nrepresentable rate matrix. Also, we use the stationary probability vector to\nstudy the influence of many orphan blocks on the waste of computing resource.\nNext, we set up a pyramid Markov reward process to investigate the long-run\naverage profits of the honest and dishonest mining pools, respectively. As a\nby-product, we build three approximative Markov processes and provide some new\ninteresting interpretation on the Markov chain and the revenue analysis\nreported in the seminal work by Eyal and Sirer (2014). Note that the pyramid\nMarkov (reward) processes can open up a new avenue in the study of blockchain\nselfish mining. Thus we hope that the methodology and results developed in this\npaper shed light on the blockchain selfish mining such that a series of\npromising research can be developed potentially.",
        "author": [
            "Quan-Lin Li",
            "Yan-Xia Chang",
            "Xiaole Wu",
            "Guoqing Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.01459v4.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC",
                "cs.PF",
                "math.DS",
                "math.PR",
                "90B22, 60J28, 94A15",
                "H.2.4; H.3.5; E.2; E.3; D.4.6; D.4.8"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.01459v4",
        "arXiv ID": "2007.01459v4"
    },
    {
        "title": "EtherClue: Digital investigation of attacks on Ethereum smart contracts",
        "Published: ": "2021-04-12T08:55:33Z",
        "abstract": "Programming errors in Ethereum smart contracts can result in catastrophic\nfinancial losses from stolen cryptocurrency. While vulnerability detectors can\nprevent vulnerable contracts from being deployed, this does not mean that such\ncontracts will not be deployed. Once a vulnerable contract is instantiated on\nthe blockchain and becomes the target of attacks, the identification of exploit\ntransactions becomes indispensable in assessing whether it has been actually\nexploited and identifying which malicious or subverted accounts were involved.\n  In this work, we study the problem of post-factum investigation of Ethereum\nattacks using Indicators of Compromise (IoCs) specially crafted for use in the\nblockchain. IoC definitions need to capture the side-effects of successful\nexploitation in the context of the Ethereum blockchain. Therefore, we define a\nmodel for smart contract execution, comprising multiple abstraction levels that\nmirror the multiple views of code execution on a blockchain. Subsequently, we\ncompare IoCs defined across the different levels in terms of their\neffectiveness and practicality through EtherClue, a prototype tool for\ninvestigating Ethereum security incidents. Our results illustrate that\ncoarse-grained IoCs defined over blocks of transactions can detect exploit\ntransactions with less computation; however, they are contract-specific and\nsuffer from false negatives. On the other hand, fine-grained IoCs defined over\nvirtual machine instructions can avoid these pitfalls at the expense of\nincreased computation which are nevertheless applicable for practical use.",
        "author": [
            "Simon Joseph Aquilina",
            "Fran Casino",
            "Mark Vella",
            "Joshua Ellul",
            "Constantinos Patsakis"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.05293v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.05293v2",
        "arXiv ID": "2104.05293v2"
    },
    {
        "title": "Network Medicine in the age of biomedical big data",
        "Published: ": "2019-03-13T12:31:44Z",
        "abstract": "Network medicine is an emerging area of research dealing with molecular and\ngenetic interactions, network biomarkers of disease, and therapeutic target\ndiscovery. Large-scale biomedical data generation offers a unique opportunity\nto assess the effect and impact of cellular heterogeneity and environmental\nperturbations on the observed phenotype. Marrying the two, network medicine\nwith biomedical data provides a framework to build meaningful models and\nextract impactful results at a network level. In this review, we survey\nexisting network types and biomedical data sources. More importantly, we delve\ninto ways in which the network medicine approach, aided by phenotype-specific\nbiomedical data, can be gainfully applied. We provide three paradigms, mainly\ndealing with three major biological network archetypes: protein-protein\ninteraction, expression-based, and gene regulatory networks. For each of these\nparadigms, we discuss a broad overview of philosophies under which various\nnetwork methods work. We also provide a few examples in each paradigm as a test\ncase of its successful application. Finally, we delineate several opportunities\nand challenges in the field of network medicine. Taken together, the\nunderstanding gained from combining biomedical data with networks can be useful\nfor characterizing disease etiologies and identifying therapeutic targets,\nwhich, in turn, will lead to better preventive medicine with translational\nimpacts on personalized healthcare.",
        "author": [
            "Abhijeet R. Sonawane",
            "Scott T. Weiss",
            "Kimberly Glass",
            "Amitabh Sharma"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.05449v1.pdf",
        "Categories": [
            [
                "q-bio.MN"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.05449v1",
        "arXiv ID": "1903.05449v1"
    },
    {
        "title": "Data science and Machine learning in the Clouds: A Perspective for the\n  Future",
        "Published: ": "2021-09-02T17:36:24Z",
        "abstract": "As we are fast approaching the beginning of a paradigm shift in the field of\nscience, Data driven science (the so called fourth science paradigm) is going\nto be the driving force in research and innovation. From medicine to\nbiodiversity and astronomy to geology, all these terms are somehow going to be\naffected by this paradigm shift. The huge amount of data to be processed under\nthis new paradigm will be a major concern in the future and one will strongly\nrequire cloud based services in all the aspects of these computations (from\nstorage to compute and other services). Another aspect will be energy\nconsumption and performance of prediction jobs and tasks within such a\nscientific paradigm which will change the way one sees computation. Data\nscience has heavily impacted or rather triggered the emergence of Machine\nLearning, Signal/Image/Video processing related algorithms, Artificial\nintelligence, Robotics, health informatics, geoinformatics, and many more such\nareas of interest. Hence, we envisage an era where Data science can deliver its\npromises with the help of the existing cloud based platforms and services with\nthe addition of new services. In this article, we discuss about data driven\nscience and Machine learning and how they are going to be linked through cloud\nbased services in the future. It also discusses the rise of paradigms like\napproximate computing, quantum computing and many more in recent times and\ntheir applicability in big data processing, data science, analytics, prediction\nand machine learning in the cloud environments.",
        "author": [
            "Hrishav Bakul Barua"
        ],
        "pdfLink": "http://arxiv.org/pdf/2109.01661v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.LG",
                "cs.PF",
                "Artificial intelligence, Data Science, Big data, Data Analytics,\n  Data mining, Machine learning, Deep learning, Cloud computing, Cloud services",
                "I.2; A.1; E.0"
            ]
        ],
        "Link": "http://arxiv.org/abs/2109.01661v1",
        "arXiv ID": "2109.01661v1"
    },
    {
        "title": "Parallel Computing for Copula Parameter Estimation with Big Data: A\n  Simulation Study",
        "Published: ": "2016-09-18T19:19:37Z",
        "abstract": "Copula-based modeling has seen rapid advances in recent years. However, in\nbig data applications, the lengthy computation time for estimating copula\nparameters is a major difficulty. Here, we develop a novel method to speed\ncomputation time in estimating copula parameters, using communication-free\nparallel computing. Our procedure partitions full data sets into disjoint\nindependent subsets, performs copula parameter estimation on the subsets, and\ncombines the results to produce an approximation to the full data copula\nparameter. We show in simulation studies that the computation time is greatly\nreduced through our method, using three well-known one-parameter bivariate\ncopulas within the elliptical and Archimedean families: Gaussian, Frank and\nGumbel. In addition, our simulation studies find small values for estimated\nbias, estimated mean squared error, and estimated relative L1 and L2 errors for\nour method, when compared to the full data parameter estimates.",
        "author": [
            "Zheng Wei",
            "Daeyoung Kim",
            "Erin Marie Conlon"
        ],
        "pdfLink": "http://arxiv.org/pdf/1609.05530v1.pdf",
        "Categories": [
            [
                "stat.ME"
            ]
        ],
        "Link": "http://arxiv.org/abs/1609.05530v1",
        "arXiv ID": "1609.05530v1"
    },
    {
        "title": "Identifying the potential of Near Data Computing for Apache Spark",
        "Published: ": "2017-05-09T03:56:36Z",
        "abstract": "While cluster computing frameworks are continuously evolving to provide\nreal-time data analysis capabilities, Apache Spark has managed to be at the\nforefront of big data analytics for being a unified framework for both, batch\nand stream data processing. There is also a renewed interest is Near Data\nComputing (NDC) due to technological advancement in the last decade. However,\nit is not known if NDC architectures can improve the performance of big data\nprocessing frameworks such as Apache Spark. In this position paper, we\nhypothesize in favour of NDC architecture comprising programmable logic based\nhybrid 2D integrated processing-in-memory and in-storage processing for Apache\nSpark, by extensive profiling of Apache Spark based workloads on Ivy Bridge\nServer.",
        "author": [
            "Ahsan Javed Awan",
            "Mats Brorsson",
            "Vladimir Vlassov",
            "Eduard Ayguade"
        ],
        "pdfLink": "http://arxiv.org/pdf/1707.09323v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1707.09323v1",
        "arXiv ID": "1707.09323v1"
    },
    {
        "title": "Persistent Black Holes in Bouncing Cosmologies",
        "Published: ": "2017-01-20T10:38:52Z",
        "abstract": "In this paper we explore the idea that black holes can persist in a universe\nthat collapses to a big crunch and then bounces into a new phase of expansion.\nWe use a scalar field to model the matter content of such a universe {near the\ntime} of the bounce, and look for solutions that represent a network of black\nholes within a dynamical cosmology. We find exact solutions to Einstein's\nconstraint equations that provide the geometry of space at the minimum of\nexpansion and that can be used as initial data for the evolution of\nhyperspherical cosmologies. These solutions illustrate that there exist models\nin which multiple distinct black holes can persist through a bounce, and allow\nfor concrete computations of quantities such as the black hole filling factor.\nWe then consider solutions in flat cosmologies, as well as in\nhigher-dimensional spaces (with up to nine spatial dimensions). We derive\nconditions for the black holes to remain distinct (i.e. avoid merging) and\nhence persist into the new expansion phase. Some potentially interesting\nconsequences of these models are also discussed.",
        "author": [
            "Timothy Clifton",
            "Bernard Carr",
            "Alan Coley"
        ],
        "pdfLink": "http://arxiv.org/pdf/1701.05750v2.pdf",
        "Categories": [
            [
                "gr-qc",
                "astro-ph.CO"
            ]
        ],
        "Link": "http://arxiv.org/abs/1701.05750v2",
        "arXiv ID": "1701.05750v2"
    },
    {
        "title": "Brain Intelligence: Go Beyond Artificial Intelligence",
        "Published: ": "2017-06-04T08:16:03Z",
        "abstract": "Artificial intelligence (AI) is an important technology that supports daily\nsocial life and economic activities. It contributes greatly to the sustainable\ngrowth of Japan's economy and solves various social problems. In recent years,\nAI has attracted attention as a key for growth in developed countries such as\nEurope and the United States and developing countries such as China and India.\nThe attention has been focused mainly on developing new artificial intelligence\ninformation communication technology (ICT) and robot technology (RT). Although\nrecently developed AI technology certainly excels in extracting certain\npatterns, there are many limitations. Most ICT models are overly dependent on\nbig data, lack a self-idea function, and are complicated. In this paper, rather\nthan merely developing next-generation artificial intelligence technology, we\naim to develop a new concept of general-purpose intelligence cognition\ntechnology called Beyond AI. Specifically, we plan to develop an intelligent\nlearning model called Brain Intelligence (BI) that generates new ideas about\nevents without having experienced them by using artificial life with an imagine\nfunction. We will also conduct demonstrations of the developed BI intelligence\nlearning model on automatic driving, precision medical care, and industrial\nrobots.",
        "author": [
            "Huimin Lu",
            "Yujie Li",
            "Min Chen",
            "Hyoungseop Kim",
            "Seiichi Serikawa"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.01040v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.01040v1",
        "arXiv ID": "1706.01040v1"
    },
    {
        "title": "When Do Users Change Their Profile Information on Twitter?",
        "Published: ": "2017-11-25T15:26:14Z",
        "abstract": "We can see profile information such as name, description and location in\norder to know the user on social media. However, this profile information is\nnot always fixed. If there is a change in the user's life, the profile\ninformation will be changed. In this study, we focus on user's profile\ninformation changes and analyze the timing and reasons for these changes on\nTwitter. The results indicate that the peak of profile information change\noccurs in April among Japanese users, but there was no such trend observed for\nEnglish users throughout the year. Our analysis also shows that English users\nmost frequently change their names on their birthdays, while Japanese users\nchange their names as their Twitter engagement and activities decrease over\ntime.",
        "author": [
            "Jinsei Shima",
            "Mitsuo Yoshida",
            "Kyoji Umemura"
        ],
        "pdfLink": "http://arxiv.org/pdf/1711.09251v1.pdf",
        "Categories": [
            [
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1711.09251v1",
        "arXiv ID": "1711.09251v1"
    },
    {
        "title": "Partial Labeled Gastric Tumor Segmentation via patch-based Reiterative\n  Learning",
        "Published: ": "2017-12-20T14:12:13Z",
        "abstract": "Gastric cancer is the second leading cause of cancer-related deaths\nworldwide, and the major hurdle in biomedical image analysis is the\ndetermination of the cancer extent. This assignment has high clinical relevance\nand would generally require vast microscopic assessment by pathologists. Recent\nadvances in deep learning have produced inspiring results on biomedical image\nsegmentation, while its outcome is reliant on comprehensive annotation. This\nrequires plenty of labor costs, for the ground truth must be annotated\nmeticulously by pathologists. In this paper, a reiterative learning framework\nwas presented to train our network on partial annotated biomedical images, and\nsuperior performance was achieved without any pre-trained or further manual\nannotation. We eliminate the boundary error of patch-based model through our\noverlapped region forecast algorithm. Through these advisable methods, a mean\nintersection over union coefficient (IOU) of 0.883 and mean accuracy of 91.09%\non the partial labeled dataset was achieved, which made us win the 2017 China\nBig Data & Artificial Intelligence Innovation and Entrepreneurship\nCompetitions.",
        "author": [
            "Yang Nan",
            "Gianmarc Coppola",
            "Qiaokang Liang",
            "Kunglin Zou",
            "Wei Sun",
            "Dan Zhang",
            "Yaonan Wang",
            "Guanzhen Yu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1712.07488v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1712.07488v1",
        "arXiv ID": "1712.07488v1"
    },
    {
        "title": "Face morphing detection in the presence of printing/scanning and\n  heterogeneous image sources",
        "Published: ": "2019-01-25T10:10:47Z",
        "abstract": "Face morphing represents nowadays a big security threat in the context of\nelectronic identity documents as well as an interesting challenge for\nresearchers in the field of face recognition. Despite of the good performance\nobtained by state-of-the-art approaches on digital images, no satisfactory\nsolutions have been identified so far to deal with cross-database testing and\nprinted-scanned images (typically used in many countries for document issuing).\nIn this work, novel approaches are proposed to train Deep Neural Networks for\nmorphing detection: in particular generation of simulated printed-scanned\nimages together with other data augmentation strategies and pre-training on\nlarge face recognition datasets, allowed to reach state-of-the-art accuracy on\nchallenging datasets from heterogeneous image sources.",
        "author": [
            "Matteo Ferrara",
            "Annalisa Franco",
            "Davide Maltoni"
        ],
        "pdfLink": "http://arxiv.org/pdf/1901.08811v4.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1901.08811v4",
        "arXiv ID": "1901.08811v4"
    },
    {
        "title": "A Fast Content-Based Image Retrieval Method Using Deep Visual Features",
        "Published: ": "2019-08-05T08:09:36Z",
        "abstract": "Fast and scalable Content-Based Image Retrieval using visual features is\nrequired for document analysis, Medical image analysis, etc. in the present\nage. Convolutional Neural Network (CNN) activations as features achieved their\noutstanding performance in this area. Deep Convolutional representations using\nthe softmax function in the output layer are also ones among visual features.\nHowever, almost all the image retrieval systems hold their index of visual\nfeatures on main memory in order to high responsiveness, limiting their\napplicability for big data applications. In this paper, we propose a fast\ncalculation method of cosine similarity with L2 norm indexed in advance on\nElasticsearch. We evaluate our approach with ImageNet Dataset and VGG-16\npre-trained model. The evaluation results show the effectiveness and efficiency\nof our proposed method.",
        "author": [
            "Hiroki Tanioka"
        ],
        "pdfLink": "http://arxiv.org/pdf/1908.01505v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.IR",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1908.01505v1",
        "arXiv ID": "1908.01505v1"
    },
    {
        "title": "Natural Language Adversarial Defense through Synonym Encoding",
        "Published: ": "2019-09-15T03:35:18Z",
        "abstract": "In the area of natural language processing, deep learning models are recently\nknown to be vulnerable to various types of adversarial perturbations, but\nrelatively few works are done on the defense side. Especially, there exists few\neffective defense method against the successful synonym substitution based\nattacks that preserve the syntactic structure and semantic information of the\noriginal text while fooling the deep learning models. We contribute in this\ndirection and propose a novel adversarial defense method called Synonym\nEncoding Method (SEM). Specifically, SEM inserts an encoder before the input\nlayer of the target model to map each cluster of synonyms to a unique encoding\nand trains the model to eliminate possible adversarial perturbations without\nmodifying the network architecture or adding extra data. Extensive experiments\ndemonstrate that SEM can effectively defend the current synonym substitution\nbased attacks and block the transferability of adversarial examples. SEM is\nalso easy and efficient to scale to large models and big datasets.",
        "author": [
            "Xiaosen Wang",
            "Hao Jin",
            "Yichen Yang",
            "Kun He"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.06723v4.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.06723v4",
        "arXiv ID": "1909.06723v4"
    },
    {
        "title": "A Dual-hierarchy Semantic Graph for Robust Object Recognition",
        "Published: ": "2019-09-15T19:49:58Z",
        "abstract": "We present a system for object recognition based on a semantic graph\nrepresentation, which the system can learn from image examples. This graph is\nbased on intrinsic properties of objects such as structure and geometry, so it\nis more robust than the current machine learning methods that can be fooled by\nchanging a few pixels. Current methods have proved to be powerful but brittle\nbecause they ignore the structure and semantics of the objects. We define\nsemantics as a form of abstraction, in terms of the intrinsic properties of the\nobject, not in terms of human perception. Thus, it can be learned\nautomatically. This is facilitated by the graph having two distinct\nhierarchies: abstraction and parts, which also makes its representation of\nobjects more accurate and versatile. Previous semantic networks had only one\namorphous hierarchy and were difficult to build and traverse. Our system\nperforms both the learning and recognition by an algorithm that traverses both\nhierarchies at the same time, combining the advantages of top-down and\nbottom-up strategies. This reduces dimensionality and obviates the need for the\nbrute force of big data training.",
        "author": [
            "Isaac Weiss"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.06867v3.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.06867v3",
        "arXiv ID": "1909.06867v3"
    },
    {
        "title": "Identifying Malicious Players in GWAP-based Disaster Monitoring\n  Crowdsourcing System",
        "Published: ": "2019-09-14T14:49:11Z",
        "abstract": "Disaster monitoring is challenging due to the lake of infrastructures in\nmonitoring areas. Based on the theory of Game-With-A-Purpose (GWAP), this paper\ncontributes to a novel large-scale crowdsourcing disaster monitoring system.\nThe system analyzes tagged satellite pictures from anonymous players, and then\nreports aggregated and evaluated monitoring results to its stakeholders. An\nalgorithm based on directed graph centralities is presented to address the core\nissues of malicious user detection and disaster level calculation. Our method\ncan be easily applied in other human computation systems. In the end, some\nissues with possible solutions are discussed for our future work.",
        "author": [
            "Changkun Ou",
            "Yifei Zhan",
            "Yaxi Chen"
        ],
        "pdfLink": "http://arxiv.org/pdf/1910.01459v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.AI",
                "cs.HC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1910.01459v1",
        "arXiv ID": "1910.01459v1"
    },
    {
        "title": "ERA: A Dataset and Deep Learning Benchmark for Event Recognition in\n  Aerial Videos",
        "Published: ": "2020-01-30T15:25:54Z",
        "abstract": "Along with the increasing use of unmanned aerial vehicles (UAVs), large\nvolumes of aerial videos have been produced. It is unrealistic for humans to\nscreen such big data and understand their contents. Hence methodological\nresearch on the automatic understanding of UAV videos is of paramount\nimportance. In this paper, we introduce a novel problem of event recognition in\nunconstrained aerial videos in the remote sensing community and present a\nlarge-scale, human-annotated dataset, named ERA (Event Recognition in Aerial\nvideos), consisting of 2,864 videos each with a label from 25 different classes\ncorresponding to an event unfolding 5 seconds. The ERA dataset is designed to\nhave a significant intra-class variation and inter-class similarity and\ncaptures dynamic events in various circumstances and at dramatically various\nscales. Moreover, to offer a benchmark for this task, we extensively validate\nexisting deep networks. We expect that the ERA dataset will facilitate further\nprogress in automatic aerial video comprehension. The website is\nhttps://lcmou.github.io/ERA_Dataset/",
        "author": [
            "Lichao Mou",
            "Yuansheng Hua",
            "Pu Jin",
            "Xiao Xiang Zhu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.11394v4.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.11394v4",
        "arXiv ID": "2001.11394v4"
    },
    {
        "title": "CrisisBench: Benchmarking Crisis-related Social Media Datasets for\n  Humanitarian Information Processing",
        "Published: ": "2020-04-14T19:51:04Z",
        "abstract": "Time-critical analysis of social media streams is important for humanitarian\norganizations for planing rapid response during disasters. The \\textit{crisis\ninformatics} research community has developed several techniques and systems\nfor processing and classifying big crisis-related data posted on social media.\nHowever, due to the dispersed nature of the datasets used in the literature\n(e.g., for training models), it is not possible to compare the results and\nmeasure the progress made towards building better models for crisis informatics\ntasks. In this work, we attempt to bridge this gap by combining various\nexisting crisis-related datasets. We consolidate eight human-annotated datasets\nand provide 166.1k and 141.5k tweets for \\textit{informativeness} and\n\\textit{humanitarian} classification tasks, respectively. We believe that the\nconsolidated dataset will help train more sophisticated models. Moreover, we\nprovide benchmarks for both binary and multiclass classification tasks using\nseveral deep learning architecrures including, CNN, fastText, and transformers.\nWe make the dataset and scripts available at:\nhttps://crisisnlp.qcri.org/crisis_datasets_benchmarks.html",
        "author": [
            "Firoj Alam",
            "Hassan Sajjad",
            "Muhammad Imran",
            "Ferda Ofli"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.06774v4.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.AI",
                "cs.CY",
                "cs.IR",
                "68T50",
                "I.2.7"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.06774v4",
        "arXiv ID": "2004.06774v4"
    },
    {
        "title": "Maximum Entropy Model Rollouts: Fast Model Based Policy Optimization\n  without Compounding Errors",
        "Published: ": "2020-06-08T21:38:15Z",
        "abstract": "Model usage is the central challenge of model-based reinforcement learning.\nAlthough dynamics model based on deep neural networks provide good\ngeneralization for single step prediction, such ability is over exploited when\nit is used to predict long horizon trajectories due to compounding errors. In\nthis work, we propose a Dyna-style model-based reinforcement learning\nalgorithm, which we called Maximum Entropy Model Rollouts (MEMR). To eliminate\nthe compounding errors, we only use our model to generate single-step rollouts.\nFurthermore, we propose to generate \\emph{diverse} model rollouts by\nnon-uniform sampling of the environment states such that the entropy of the\nmodel rollouts is maximized. We mathematically derived the maximum entropy\nsampling criteria for one data case under Gaussian prior. To accomplish this\ncriteria, we propose to utilize a prioritized experience replay. Our\npreliminary experiments in challenging locomotion benchmarks show that our\napproach achieves the same sample efficiency of the best model-based\nalgorithms, matches the asymptotic performance of the best model-free\nalgorithms, and significantly reduces the computation requirements of other\nmodel-based methods.",
        "author": [
            "Chi Zhang",
            "Sanmukh Rao Kuppannagari",
            "Viktor K Prasanna"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.04802v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.04802v2",
        "arXiv ID": "2006.04802v2"
    },
    {
        "title": "Convergence Rate Improvement of Richardson and Newton-Schulz Iterations",
        "Published: ": "2020-08-26T10:35:10Z",
        "abstract": "Fast convergent, accurate, computationally efficient, parallelizable, and\nrobust matrix inversion and parameter estimation algorithms are required in\nmany time-critical and accuracy-critical applications such as system\nidentification, signal and image processing, network and big data analysis,\nmachine learning and in many others. This paper introduces new composite power\nseries expansion with optionally chosen rates (which can be calculated\nsimultaneously on parallel units with different computational capacities) for\nfurther convergence rate improvement of high order Newton-Schulz iteration. New\nexpansion was integrated into the Richardson iteration and resulted in\nsignificant convergence rate improvement. The improvement is quantified via\nexplicit transient models for estimation errors and by simulations. In\naddition, the recursive and computationally efficient version of the\ncombination of Richardson iteration and Newton-Schulz iteration with composite\nexpansion is developed for simultaneous calculations. Moreover, unified\nfactorization is developed in this paper in the form of tool-kit for power\nseries expansion, which results in a new family of computationally efficient\nNewton-Schulz algorithms.",
        "author": [
            "Alexander Stotsky"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.11480v1.pdf",
        "Categories": [
            [
                "math.OC",
                "cs.NA",
                "math.NA"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.11480v1",
        "arXiv ID": "2008.11480v1"
    },
    {
        "title": "Robust Conversational AI with Grounded Text Generation",
        "Published: ": "2020-09-07T23:49:28Z",
        "abstract": "This article presents a hybrid approach based on a Grounded Text Generation\n(GTG) model to building robust task bots at scale. GTG is a hybrid model which\nuses a large-scale Transformer neural network as its backbone, combined with\nsymbol-manipulation modules for knowledge base inference and prior knowledge\nencoding, to generate responses grounded in dialog belief state and real-world\nknowledge for task completion. GTG is pre-trained on large amounts of raw text\nand human conversational data, and can be fine-tuned to complete a wide range\nof tasks.\n  The hybrid approach and its variants are being developed simultaneously by\nmultiple research teams. The primary results reported on task-oriented dialog\nbenchmarks are very promising, demonstrating the big potential of this\napproach. This article provides an overview of this progress and discusses\nrelated methods and technologies that can be incorporated for building robust\nconversational AI systems.",
        "author": [
            "Jianfeng Gao",
            "Baolin Peng",
            "Chunyuan Li",
            "Jinchao Li",
            "Shahin Shayandeh",
            "Lars Liden",
            "Heung-Yeung Shum"
        ],
        "pdfLink": "http://arxiv.org/pdf/2009.03457v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2009.03457v1",
        "arXiv ID": "2009.03457v1"
    },
    {
        "title": "Markov Neighborhood Regression for High-Dimensional Inference",
        "Published: ": "2020-10-17T21:00:37Z",
        "abstract": "This paper proposes an innovative method for constructing confidence\nintervals and assessing p-values in statistical inference for high-dimensional\nlinear models. The proposed method has successfully broken the high-dimensional\ninference problem into a series of low-dimensional inference problems: For each\nregression coefficient $\\beta_i$, the confidence interval and $p$-value are\ncomputed by regressing on a subset of variables selected according to the\nconditional independence relations between the corresponding variable $X_i$ and\nother variables. Since the subset of variables forms a Markov neighborhood of\n$X_i$ in the Markov network formed by all the variables $X_1,X_2,\\ldots,X_p$,\nthe proposed method is coined as Markov neighborhood regression. The proposed\nmethod is tested on high-dimensional linear, logistic and Cox regression. The\nnumerical results indicate that the proposed method significantly outperforms\nthe existing ones. Based on the Markov neighborhood regression, a method of\nlearning causal structures for high-dimensional linear models is proposed and\napplied to identification of drug sensitive genes and cancer driver genes. The\nidea of using conditional independence relations for dimension reduction is\ngeneral and potentially can be extended to other high-dimensional or big data\nproblems as well.",
        "author": [
            "Faming Liang",
            "Jingnan Xue",
            "Bochao Jia"
        ],
        "pdfLink": "http://arxiv.org/pdf/2010.08864v1.pdf",
        "Categories": [
            [
                "stat.ME",
                "62F25, 62J20"
            ]
        ],
        "Link": "http://arxiv.org/abs/2010.08864v1",
        "arXiv ID": "2010.08864v1"
    },
    {
        "title": "Attention-Based LSTM Network for COVID-19 Clinical Trial Parsing",
        "Published: ": "2020-12-18T05:55:52Z",
        "abstract": "COVID-19 clinical trial design is a critical task in developing therapeutics\nfor the prevention and treatment of COVID-19. In this study, we apply a deep\nlearning approach to extract eligibility criteria variables from COVID-19\ntrials to enable quantitative analysis of trial design and optimization.\nSpecifically, we train attention-based bidirectional Long Short-Term Memory\n(Att-BiLSTM) models and use the optimal model to extract entities (i.e.,\nvariables) from the eligibility criteria of COVID-19 trials. We compare the\nperformance of Att-BiLSTM with traditional ontology-based method. The result on\na benchmark dataset shows that Att-BiLSTM outperforms the ontology model.\nAtt-BiLSTM achieves a precision of 0.942, recall of 0.810, and F1 of 0.871,\nwhile the ontology model only achieves a precision of 0.715, recall of 0.659,\nand F1 of 0.686. Our analyses demonstrate that Att-BiLSTM is an effective\napproach for characterizing patient populations in COVID-19 clinical trials.",
        "author": [
            "Xiong Liu",
            "Luca A. Finelli",
            "Greg L. Hersch",
            "Iya Khalil"
        ],
        "pdfLink": "http://arxiv.org/pdf/2012.10063v1.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2012.10063v1",
        "arXiv ID": "2012.10063v1"
    },
    {
        "title": "Event-driven timeseries analysis and the comparison of public reactions\n  on COVID-19",
        "Published: ": "2021-04-30T06:14:53Z",
        "abstract": "The rapid spread of COVID-19 has already affected human lives throughout the\nglobe. Governments of different countries have taken various measures, but how\nthey affected people lives is not clear. In this study, a rule-based and a\nmachine-learning based models are applied to answer the above question using\npublic tweets from Japan, USA, UK, and Australia. Two polarity timeseries\n(meanPol and pnRatio) and two events, namely \"lockdown or emergency (LED)\" and\n\"the economic support package (ESP)\", are considered in this study. Statistical\ntesting on the sub-series around LED and ESP events showed their positive\nimpacts to the people of (UK and Australia) and (USA and UK), respectively\nunlike Japanese people that showed opposite effects. Manual validation with the\nrelevant tweets showed an agreement with the statistical results. A case study\nwith Japanese tweets using supervised logistic regression classifies tweets\ninto heath-worry, economy-worry and other classes with 83.11% accuracy.\nPredicted tweets around events re-confirm the statistical outcomes.",
        "author": [
            "Md. Khayrul Bashar"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.14777v1.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.14777v1",
        "arXiv ID": "2104.14777v1"
    },
    {
        "title": "DeepFilterNet2: Towards Real-Time Speech Enhancement on Embedded Devices\n  for Full-Band Audio",
        "Published: ": "2022-05-11T13:19:41Z",
        "abstract": "Deep learning-based speech enhancement has seen huge improvements and\nrecently also expanded to full band audio (48 kHz). However, many approaches\nhave a rather high computational complexity and require big temporal buffers\nfor real time usage e.g. due to temporal convolutions or attention. Both make\nthose approaches not feasible on embedded devices. This work further extends\nDeepFilterNet, which exploits harmonic structure of speech allowing for\nefficient speech enhancement (SE). Several optimizations in the training\nprocedure, data augmentation, and network structure result in state-of-the-art\nSE performance while reducing the real-time factor to 0.04 on a notebook\nCore-i5 CPU. This makes the algorithm applicable to run on embedded devices in\nreal-time. The DeepFilterNet framework can be obtained under an open source\nlicense.",
        "author": [
            "Hendrik Schr\u00f6ter",
            "Alberto N. Escalante-B.",
            "Tobias Rosenkranz",
            "Andreas Maier"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.05474v1.pdf",
        "Categories": [
            [
                "eess.AS",
                "cs.LG",
                "cs.SD",
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.05474v1",
        "arXiv ID": "2205.05474v1"
    },
    {
        "title": "Revisiting Facial Key Point Detection: An Efficient Approach Using Deep\n  Neural Networks",
        "Published: ": "2022-05-14T19:49:03Z",
        "abstract": "Facial landmark detection is a widely researched field of deep learning as\nthis has a wide range of applications in many fields. These key points are\ndistinguishing characteristic points on the face, such as the eyes center, the\neye's inner and outer corners, the mouth center, and the nose tip from which\nhuman emotions and intent can be explained. The focus of our work has been\nevaluating transfer learning models such as MobileNetV2 and NasNetMobile,\nincluding custom CNN architectures. The objective of the research has been to\ndevelop efficient deep learning models in terms of model size, parameters, and\ninference time and to study the effect of augmentation imputation and\nfine-tuning on these models. It was found that while augmentation techniques\nproduced lower RMSE scores than imputation techniques, they did not affect the\ninference time. MobileNetV2 architecture produced the lowest RMSE and inference\ntime. Moreover, our results indicate that manually optimized CNN architectures\nperformed similarly to Auto Keras tuned architecture. However, manually\noptimized architectures yielded better inference time and training curves.",
        "author": [
            "Prathima Dileep",
            "Bharath Kumar Bolla",
            "Sabeesh Ethiraj"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.07121v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.07121v1",
        "arXiv ID": "2205.07121v1"
    },
    {
        "title": "Learning on Large-scale Text-attributed Graphs via Variational Inference",
        "Published: ": "2022-10-26T13:40:57Z",
        "abstract": "This paper studies learning on text-attributed graphs (TAGs), where each node\nis associated with a text description. An ideal solution for such a problem\nwould be integrating both the text and graph structure information with large\nlanguage models and graph neural networks (GNNs). However, the problem becomes\nvery challenging when graphs are large due to the high computational complexity\nbrought by training large language models and GNNs together. In this paper, we\npropose an efficient and effective solution to learning on large\ntext-attributed graphs by fusing graph structure and language learning with a\nvariational Expectation-Maximization (EM) framework, called GLEM. Instead of\nsimultaneously training large language models and GNNs on big graphs, GLEM\nproposes to alternatively update the two modules in the E-step and M-step. Such\na procedure allows training the two modules separately while simultaneously\nallowing the two modules to interact and mutually enhance each other. Extensive\nexperiments on multiple data sets demonstrate the efficiency and effectiveness\nof the proposed approach.",
        "author": [
            "Jianan Zhao",
            "Meng Qu",
            "Chaozhuo Li",
            "Hao Yan",
            "Qian Liu",
            "Rui Li",
            "Xing Xie",
            "Jian Tang"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.14709v2.pdf",
        "Categories": [
            [
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.14709v2",
        "arXiv ID": "2210.14709v2"
    },
    {
        "title": "Machine learning methods for prediction of breakthrough curves in\n  reactive porous media",
        "Published: ": "2023-01-12T13:25:13Z",
        "abstract": "Reactive flows in porous media play an important role in our life and are\ncrucial for many industrial, environmental and biomedical applications. Very\noften the concentration of the species at the inlet is known, and the so-called\nbreakthrough curves, measured at the outlet, are the quantities which could be\nmeasured or computed numerically. The measurements and the simulations could be\ntime-consuming and expensive, and machine learning and Big Data approaches can\nhelp to predict breakthrough curves at lower costs. Machine learning (ML)\nmethods, such as Gaussian processes and fully-connected neural networks, and a\ntensor method, cross approximation, are well suited for predicting breakthrough\ncurves. In this paper, we demonstrate their performance in the case of pore\nscale reactive flow in catalytic filters.",
        "author": [
            "Daria Fokina",
            "Pavel Toktaliev",
            "Oleg Iliev",
            "Ivan Oseledets"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.04998v1.pdf",
        "Categories": [
            [
                "physics.flu-dyn",
                "cs.LG",
                "68T99, 76S05"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.04998v1",
        "arXiv ID": "2301.04998v1"
    },
    {
        "title": "Generator-Retriever-Generator: A Novel Approach to Open-domain Question\n  Answering",
        "Published: ": "2023-07-21T00:34:38Z",
        "abstract": "Open-domain question answering (QA) tasks usually require the retrieval of\nrelevant information from a large corpus to generate accurate answers. We\npropose a novel approach called Generator-Retriever-Generator (GRG) that\ncombines document retrieval techniques with a large language model (LLM), by\nfirst prompting the model to generate contextual documents based on a given\nquestion. In parallel, a dual-encoder network retrieves documents that are\nrelevant to the question from an external corpus. The generated and retrieved\ndocuments are then passed to the second LLM, which generates the final answer.\nBy combining document retrieval and LLM generation, our approach addresses the\nchallenges of open-domain QA, such as generating informative and contextually\nrelevant answers. GRG outperforms the state-of-the-art generate-then-read and\nretrieve-then-read pipelines (GENREAD and RFiD) improving their performance at\nleast by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.\nWe provide code, datasets, and checkpoints\n\\footnote{\\url{https://github.com/abdoelsayed2016/GRG}}",
        "author": [
            "Abdelrahman Abdallah",
            "Adam Jatowt"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.11278v1.pdf",
        "Categories": [
            [
                "cs.CL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.11278v1",
        "arXiv ID": "2307.11278v1"
    },
    {
        "title": "Activating Frequency and ViT for 3D Point Cloud Quality Assessment\n  without Reference",
        "Published: ": "2023-12-10T19:13:34Z",
        "abstract": "Deep learning-based quality assessments have significantly enhanced\nperceptual multimedia quality assessment, however it is still in the early\nstages for 3D visual data such as 3D point clouds (PCs). Due to the high volume\nof 3D-PCs, such quantities are frequently compressed for transmission and\nviewing, which may affect perceived quality. Therefore, we propose no-reference\nquality metric of a given 3D-PC. Comparing to existing methods that mostly\nfocus on geometry or color aspects, we propose integrating frequency magnitudes\nas indicator of spatial degradation patterns caused by the compression. To map\nthe input attributes to quality score, we use a light-weight hybrid deep model;\ncombined of Deformable Convolutional Network (DCN) and Vision Transformers\n(ViT). Experiments are carried out on ICIP20 [1], PointXR [2] dataset, and a\nnew big dataset called BASICS [3]. The results show that our approach\noutperforms state-of-the-art NR-PCQA measures and even some FR-PCQA on PointXR.\nThe implementation code can be found at: https://github.com/o-messai/3D-PCQA",
        "author": [
            "Oussama Messai",
            "Abdelouahid Bentamou",
            "Abbass Zein-Eddine",
            "Yann Gavet"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.05972v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.05972v1",
        "arXiv ID": "2312.05972v1"
    },
    {
        "title": "Universal Adversarial Framework to Improve Adversarial Robustness for\n  Diabetic Retinopathy Detection",
        "Published: ": "2023-12-13T14:58:17Z",
        "abstract": "Diabetic Retinopathy (DR) is a prevalent illness associated with Diabetes\nwhich, if left untreated, can result in irreversible blindness. Deep Learning\nbased systems are gradually being introduced as automated support for clinical\ndiagnosis. Since healthcare has always been an extremely important domain\ndemanding error-free performance, any adversaries could pose a big threat to\nthe applicability of such systems. In this work, we use Universal Adversarial\nPerturbations (UAPs) to quantify the vulnerability of Medical Deep Neural\nNetworks (DNNs) for detecting DR. To the best of our knowledge, this is the\nvery first attempt that works on attacking complete fine-grained classification\nof DR images using various UAPs. Also, as a part of this work, we use UAPs to\nfine-tune the trained models to defend against adversarial samples. We\nexperiment on several models and observe that the performance of such models\ntowards unseen adversarial attacks gets boosted on average by $3.41$\nCohen-kappa value and maximum by $31.92$ Cohen-kappa value. The performance\ndegradation on normal data upon ensembling the fine-tuned models was found to\nbe statistically insignificant using t-test, highlighting the benefits of\nUAP-based adversarial fine-tuning.",
        "author": [
            "Samrat Mukherjee",
            "Dibyanayan Bandyopadhyay",
            "Baban Gain",
            "Asif Ekbal"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.08193v1.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.08193v1",
        "arXiv ID": "2312.08193v1"
    },
    {
        "title": "Analysis of Psychographic Indicators via LIWC and Their Correlation with\n  CTR for Instagram Ads",
        "Published: ": "2023-12-13T15:57:06Z",
        "abstract": "The online advertising industry continues to grow and accounts for over 40%\nof global advertising spending. Online display advertising consists of images\nand text, and advertisers maximize sales revenue by contacting consumers\nthrough advertisements and encouraging them to make purchases. In today's\nsociety, where products are becoming more homogenized and needs are\ndiversifying, appealing to consumer psychology through advertisements is\nbecoming increasingly important. However, it is not sufficiently clear what\nkind of appeal influences consumer psychology. In this study, we quantified the\nappeal of the text in advertisements for health products and cosmetics, which\nwere actually delivered in Instagram advertisements (one of display\nadvertisements), by applying linguistic inquiry and word count (LIWC). The\ncorrelation between click-through rate (CTR) and the text was analyzed. The\nresults showed that negative appeals that arouse consumer anxiety and a sense\nof crisis were related to CTR.",
        "author": [
            "Kenjiro Inoue",
            "Mitsuo Yoshida"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.08235v1.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.DL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.08235v1",
        "arXiv ID": "2312.08235v1"
    },
    {
        "title": "Verifiable Manufacturing Using Blockchain",
        "Published: ": "2023-02-26T17:10:48Z",
        "abstract": "We propose a blockchain-based solution for enabling verifiability of\nmanufacturing processes. We base our solution on the methodology of verifiable\ncomputing which, originally developed for cloud computing, enables clients to\noutsource computations to more powerful servers without the need to trust that\nthe server correctly performed desired computation. Verifiable computing\naccomplishes this by enabling the client to generate cryptographic objects that\nthe server must use to produce a cryptographic proof that verifies the\ncorrectness of results. The black box nature of servers in cloud computing is\nanalogous to that of the manufacturing processes of an upstream manufacturer.\nIn this work, we develop a one-to-one correspondence between physical processes\nand their digital representations as state sequences which is needed for the\nimplementation of verifiable computing. Because direct application of\nverifiable computing in this case would be computationally prohibitive, we\nintroduce a blockchain to provide a computationally feasible methodology for\nverifiable computing applied to physical processes. We implement and show the\nresults of our implementation on a proof of concept, developed on Hyperledger\nFabric.",
        "author": [
            "Michael Chiu",
            "Jyotiraditya Panda",
            "Abraham Goldsmith",
            "Uros Kalabic"
        ],
        "pdfLink": "http://arxiv.org/pdf/2302.13353v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2302.13353v1",
        "arXiv ID": "2302.13353v1"
    },
    {
        "title": "A robust modeling framework for energy analysis of data centers",
        "Published: ": "2020-06-11T21:05:20Z",
        "abstract": "Global digitalization has given birth to the explosion of digital services in\napproximately every sector of contemporary life. Applications of artificial\nintelligence, blockchain technologies, and internet of things are promising to\naccelerate digitalization further. As a consequence, the number of data\ncenters, which provide the services of data processing, storage, and\ncommunication services, is also increasing rapidly. Because data centers are\nenergy-intensive with significant and growing electricity demand, an energy\nmodel of data centers with temporal, spatial, and predictive analysis\ncapability is critical for guiding industry and governmental authorities for\nmaking technology investment decisions. However, current models fail to provide\nconsistent and high dimensional energy analysis for data centers due to severe\ndata gaps. This can be further attributed to the lack of the modeling\ncapabilities for energy analysis of data center components including IT\nequipment and data center cooling and power provisioning infrastructure in\ncurrent energy models. In this research, a technology-based modeling framework,\nin hybrid with a data-driven approach, is proposed to address the knowledge\ngaps in current data center energy models. The research aims to provide policy\nmakers and data center energy analysts with comprehensive understanding of data\ncenter energy use and efficiency opportunities and a better understanding of\nmacro-level data center energy demand and energy saving potentials, in addition\nto the technological barriers for adopting energy efficiency measures.",
        "author": [
            "Nuoa Lei"
        ],
        "pdfLink": "http://arxiv.org/pdf/2006.06819v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2006.06819v1",
        "arXiv ID": "2006.06819v1"
    },
    {
        "title": "EpiMob: Interactive Visual Analytics of Citywide Human Mobility\n  Restrictions for Epidemic Control",
        "Published: ": "2020-07-07T03:01:59Z",
        "abstract": "The outbreak of coronavirus disease (COVID-19) has swept across more than 180\ncountries and territories since late January 2020. As a worldwide emergency\nresponse, governments have implemented various measures and policies, such as\nself-quarantine, travel restrictions, work from home, and regional lockdown, to\ncontrol the spread of the epidemic. These countermeasures seek to restrict\nhuman mobility because COVID-19 is a highly contagious disease that is spread\nby human-to-human transmission. Medical experts and policymakers have expressed\nthe urgency to effectively evaluate the outcome of human restriction policies\nwith the aid of big data and information technology. Thus, based on big human\nmobility data and city POI data, an interactive visual analytics system called\nEpidemic Mobility (EpiMob) was designed in this study. The system interactively\nsimulates the changes in human mobility and infection status in response to the\nimplementation of a certain restriction policy or a combination of policies\n(e.g., regional lockdown, telecommuting, screening). Users can conveniently\ndesignate the spatial and temporal ranges for different mobility restriction\npolicies. Then, the results reflecting the infection situation under different\npolicies are dynamically displayed and can be flexibly compared and analyzed in\ndepth. Multiple case studies consisting of interviews with domain experts were\nconducted in the largest metropolitan area of Japan (i.e., Greater Tokyo Area)\nto demonstrate that the system can provide insight into the effects of\ndifferent human mobility restriction policies for epidemic control, through\nmeasurements and comparisons.",
        "author": [
            "Chuang Yang",
            "Zhiwen Zhang",
            "Zipei Fan",
            "Renhe Jiang",
            "Quanjun Chen",
            "Xuan Song",
            "Ryosuke Shibasaki"
        ],
        "pdfLink": "http://arxiv.org/pdf/2007.03180v3.pdf",
        "Categories": [
            [
                "cs.HC",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2007.03180v3",
        "arXiv ID": "2007.03180v3"
    },
    {
        "title": "Quantifying Carbon Emissions due to Online Third-Party Tracking",
        "Published: ": "2023-04-03T12:30:28Z",
        "abstract": "In the past decade, global warming made several headlines and turned the\nattention of the whole world to it. Carbon footprint is the main factor that\ndrives greenhouse emissions up and results in the temperature increase of the\nplanet with dire consequences. While the attention of the public is turned to\nreducing carbon emissions by transportation, food consumption and household\nactivities, we ignore the contribution of CO2eq emissions produced by online\nactivities. In the current information era, we spend a big amount of our days\nbrowsing online. This activity consumes electricity which in turn produces\nCO2eq. While website browsing contributes to the production of greenhouse gas\nemissions, the impact of the Internet on the environment is further exacerbated\nby the web-tracking practice. Indeed, most webpages are heavily loaded by\ntracking content used mostly for advertising, data analytics and usability\nimprovements. This extra content implies big data transmissions which results\nin higher electricity consumption and thus higher greenhouse gas emissions. In\nthis work, we focus on the overhead caused by web tracking and analyse both its\nnetwork and carbon footprint. By leveraging the browsing telemetry of 100k\nusers and the results of a crawling experiment of 2.7M websites, we find that\nweb tracking increases data transmissions upwards of 21%, which in turn implies\nthe additional emission of around 11 Mt of greenhouse gases in the atmosphere\nevery year. We find such contribution to be far from negligible, and comparable\nto many activities of modern life, such as meat production, transportation, and\neven cryptocurrency mining. Our study also highlights that there exist\nsignificant inequalities when considering the footprint of different countries,\nwebsite categories, and tracking organizations, with a few actors contributing\nto a much greater extent than the remaining ones.",
        "author": [
            "Michalis Pachilakis",
            "Savino Dambra",
            "Iskander Sanchez-Rola",
            "Leyla Bilge"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.00927v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.00927v1",
        "arXiv ID": "2304.00927v1"
    },
    {
        "title": "A transparent referendum protocol with immutable proceedings and\n  verifiable outcome for trustless networks",
        "Published: ": "2019-09-13T21:41:05Z",
        "abstract": "High voter turnout in elections and referendums is very desirable in order to\nensure a robust democracy. Secure electronic voting is a vision for the future\nof elections and referendums. Such a system can counteract factors that hinder\nstrong voter turnout such as the requirement of physical presence during\nlimited hours at polling stations. However, this vision brings transparency and\nconfidentiality requirements that render the design of such solutions\nchallenging. Specifically, the counting must be implemented in a reproducible\nway and the ballots of individual voters must remain concealed. In this paper,\nwe propose and evaluate a referendum protocol that ensures transparency,\nconfidentiality, and integrity, in trustless networks. The protocol is built by\ncombining Secure Multi-Party Computation (SMPC) and Distributed Ledger or\nBlockchain technology. The persistence and immutability of the protocol\ncommunication allows verifiability of the referendum outcome on the client\nside. Voters therefore do not need to trust in third parties. We provide a\nformal description and conduct a thorough security evaluation of our proposal.",
        "author": [
            "Maximilian Schiedermeier",
            "Omar Hasan",
            "Tobias Mayer",
            "Lionel Brunie",
            "Harald Kosch"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.06462v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.06462v1",
        "arXiv ID": "1909.06462v1"
    },
    {
        "title": "ServiceNet: A P2P Service Network",
        "Published: ": "2020-09-04T08:58:41Z",
        "abstract": "Given a large number of online services on the Internet, from time to time,\npeople are still struggling to find out the services that they need. On the\nother hand, when there are considerable research and development on service\ndiscovery and service recommendation, most of the related work are centralized\nand thus suffers inherent shortages of the centralized systems, e.g.,\nadv-driven, lack at trust, transparence and fairness. In this paper, we propose\na ServiceNet - a peer-to-peer (P2P) service network for service discovery and\nservice recommendation. ServiceNet is inspired by blockchain technology and\naims at providing an open, transparent and self-growth, and self-management\nservice ecosystem. The paper will present the basic idea, an architecture\ndesign of the prototype, and an initial implementation and performance\nevaluation the prototype design.",
        "author": [
            "Ji Liu",
            "Hang Zhao",
            "Jiyuan Yang",
            "Yu Shi",
            "Ruichang Liu",
            "Dong Yuan",
            "Shiping Chen"
        ],
        "pdfLink": "http://arxiv.org/pdf/2009.09800v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2009.09800v1",
        "arXiv ID": "2009.09800v1"
    },
    {
        "title": "Snap-and-Chat Protocols: System Aspects",
        "Published: ": "2020-10-20T17:02:58Z",
        "abstract": "The availability-finality dilemma says that blockchain protocols cannot be\nboth available under dynamic participation and safe under network partition.\nSnap-and-chat protocols have recently been proposed as a resolution to this\ndilemma. A snap-and-chat protocol produces an always available ledger\ncontaining a finalized prefix ledger which is always safe and catches up with\nthe available ledger whenever network conditions permit. In contrast to\nexisting handcrafted finality gadget based designs like Ethereum 2.0's\nconsensus protocol Gasper, snap-and-chat protocols are constructed as a\nblack-box composition of off-the-shelf BFT and longest chain protocols. In this\npaper, we consider system aspects of snap-and-chat protocols and show how they\ncan provide two important features: 1) accountability, 2) support of light\nclients. Through this investigation, a deeper understanding of the strengths\nand challenges of snap-and-chat protocols is gained.",
        "author": [
            "Joachim Neu",
            "Ertem Nusret Tas",
            "David Tse"
        ],
        "pdfLink": "http://arxiv.org/pdf/2010.10447v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2010.10447v1",
        "arXiv ID": "2010.10447v1"
    },
    {
        "title": "Methodology and Analysis of Smart Contracts in Blockchain-Based\n  International Trade Application",
        "Published: ": "2021-07-15T02:14:30Z",
        "abstract": "Blokchain is used in a variety of applications where trustworthy computing is\nre-quired. Trade finance is one of these areas that would benefit immensely\nfrom a decentralized way of doing transactions. This paper presents the\npreliminary as-sessment of Accepire-BT, a software platform developed for the\npractice of col-laborative Trade Finance. The proposed solution is enforced by\nsmart contracts using Solidity, the underlying programming language for the\nEthereum block-chain. We evaluated the performance in the Rinkeby test network\nby using Remix and MetaMask. The results of the preliminary trial show that\nsmart contracts take less than one minute per cycle. Also, we present a\ndiscussion about costs for us-ing the public Ethereum Rinkeby network.",
        "author": [
            "Asif Bhat",
            "Rizal Mohd Nor",
            "Md Amiruzzaman",
            "Md. Rajibul Islam"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.14140v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.14140v2",
        "arXiv ID": "2107.14140v2"
    },
    {
        "title": "Presentation and Publication: Loss and Slippage in Networks of Automated\n  Market Makers",
        "Published: ": "2021-10-18T01:13:00Z",
        "abstract": "Automated market makers (AMMs) are smart contracts that automatically trade\nelectronic assets according to a mathematical formula. This paper investigates\nhow an AMM's formula affects the interests of liquidity providers, who endow\nthe AMM with assets, and traders, who exchange one asset for another at the\nAMM's rates. *Linear slippage* measures how a trade's size affects the trader's\nreturn, *angular slippage* measures how a trade's size affects the subsequent\nmarket price, *divergence loss* measures the opportunity cost of providers'\ninvestments, and *load* balances the costs to traders and providers. We give\nformal definitions for these costs, show that they obey certain conservation\nlaws: these costs can be shifted around but never fully eliminated. We analyze\nhow these costs behave under *composition*, when simple individual AMMs are\nlinked to form more complex networks of AMMs.",
        "author": [
            "Daniel Engel",
            "Maurice Herlihy"
        ],
        "pdfLink": "http://arxiv.org/pdf/2110.09872v1.pdf",
        "Categories": [
            [
                "cs.OH"
            ]
        ],
        "Link": "http://arxiv.org/abs/2110.09872v1",
        "arXiv ID": "2110.09872v1"
    },
    {
        "title": "Quick Order Fairness",
        "Published: ": "2021-12-13T12:54:26Z",
        "abstract": "Leader-based protocols for consensus, i.e., atomic broadcast, allow some\nprocesses to unilaterally affect the final order of transactions. This has\nbecome a problem for blockchain networks and decentralized finance because it\nfacilitates front-running and other attacks. To address this, order fairness\nfor payload messages has been introduced recently as a new safety property for\natomic broadcast complementing traditional agreement and liveness. We relate\norder fairness to the standard validity notions for consensus protocols and\nhighlight some limitations with the existing formalization. Based on this, we\nintroduce a new differential order fairness property that fixes these issues.\nWe also present the quick order-fair atomic broadcast protocol that guarantees\npayload message delivery in a differentially fair order and is much more\nefficient than existing order-fair consensus protocols. It works for\nasynchronous and for eventually synchronous networks with optimal resilience,\ntolerating corruptions of up to one third of the processes. Previous solutions\nrequired there to be less than one fourth of faults. Furthermore, our protocol\nincurs only quadratic cost, in terms of amortized message complexity per\ndelivered payload.",
        "author": [
            "Christian Cachin",
            "Jovana Mi\u0107i\u0107",
            "Nathalie Steinhauer",
            "Luca Zanolini"
        ],
        "pdfLink": "http://arxiv.org/pdf/2112.06615v3.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2112.06615v3",
        "arXiv ID": "2112.06615v3"
    },
    {
        "title": "How centralized is decentralized? Comparison of wealth distribution in\n  coins and tokens",
        "Published: ": "2022-07-04T11:51:34Z",
        "abstract": "Rapidly growing distributed ledger technologies (DLTs) have recently received\nattention among researchers in both industry and academia. While a lot of\nexisting analysis (mainly) of the Bitcoin and Ethereum networks is available,\nthe lack of measurements for other crypto projects is observed. This article\naddresses questions about tokenomics and wealth distributions in\ncryptocurrencies. We analyze the time-dependent statistical properties of top\ncryptocurrency holders for 14 different distributed ledger projects. The\nprovided metrics include approximated Zipf coefficient, Shannon entropy, Gini\ncoefficient, and Nakamoto coefficient. We show that there are quantitative\ndifferences between the coins (cryptocurrencies operating on their own\nindependent network) and tokens (which operate on top of a smart contract\nplatform). Presented results show that coins and tokens have different values\nof approximated Zipf coefficient and centralization levels. This work is\nrelevant for DLTs as it might be useful in modeling and improving the committee\nselection process, especially in decentralized autonomous organizations (DAOs)\nand delegated proof of stake (DPoS) blockchains.",
        "author": [
            "Bartosz Ku\u015bmierz",
            "Roman Overko"
        ],
        "pdfLink": "http://arxiv.org/pdf/2207.01340v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2207.01340v1",
        "arXiv ID": "2207.01340v1"
    },
    {
        "title": "Autopsy of Ethereum's Post-Merge Reward System",
        "Published: ": "2023-03-17T09:12:07Z",
        "abstract": "Like most modern blockchain networks, Ethereum has relied on economic\nincentives to promote honest participation in the chain's consensus. The\ndistributed character of the platform, together with the \"randomness\" or \"luck\"\nfactor that both proof of work (PoW) and proof of stake (PoS) provide when\nelecting the next block proposer, pushed the industry to model and improve the\nreward system of the system. With several improvements to predict PoW block\nproposal rewards and to maximize the extractable rewards of the same ones, the\nultimate Ethereum's transition to PoS applied in the Paris Hard-Fork, more\ngenerally known as \"The Merge\", has meant a significant modification on the\nreward system in the platform. In this paper, we aim to break down both\ntheoretically and empirically the new reward system in this post-merge era. We\npresent a highly detailed description of the different rewards and their share\namong validators' rewards. Ultimately, we offer a study that uses the presented\nreward model to analyze the performance of the network during this transition.",
        "author": [
            "Mikel Cortes-Goicoechea",
            "Tarun Mohandas-Daryanani",
            "Jose Luis Mu\u00f1oz-Tapia",
            "Leonardo Bautista-Gomez"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.09850v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.GT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.09850v1",
        "arXiv ID": "2303.09850v1"
    },
    {
        "title": "Liveness Checking of the HotStuff Protocol Family",
        "Published: ": "2023-10-13T11:03:13Z",
        "abstract": "Byzantine consensus protocols aim at maintaining safety guarantees under any\nnetwork synchrony model and at providing liveness in partially or fully\nsynchronous networks. However, several Byzantine consensus protocols have been\nshown to violate liveness properties under certain scenarios. Existing testing\nmethods for checking the liveness of consensus protocols check for time-bounded\nliveness violations, which generate a large number of false positives. In this\nwork, for the first time, we check the liveness of Byzantine consensus\nprotocols using the temperature and lasso detection methods, which require the\ndefinition of ad-hoc system state abstractions. We focus on the HotStuff\nprotocol family that has been recently developed for blockchain consensus. In\nthis family, the HotStuff protocol is both safe and live under the partial\nsynchrony assumption, while the 2-Phase Hotstuff and Sync HotStuff protocols\nare known to violate liveness in subtle fault scenarios. We implemented our\nliveness checking methods on top of the Twins automated unit test generator to\ntest the HotStuff protocol family. Our results indicate that our methods\nsuccessfully detect all known liveness violations and produce fewer false\npositives than the traditional time-bounded liveness checks.",
        "author": [
            "J\u00e9r\u00e9mie Decouchant",
            "Burcu Kulahcioglu Ozkan",
            "Yanzhuo Zhou"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.09006v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.SE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.09006v1",
        "arXiv ID": "2310.09006v1"
    },
    {
        "title": "ApproxCS: Near-Sensor Approximate Compressed Sensing for IoT-Healthcare\n  Systems",
        "Published: ": "2018-11-18T13:56:40Z",
        "abstract": "Internet of Things (IoTs) is an emerging trend that has enabled an upgrade in\nthe design of wearable healthcare monitoring systems through the (integrated)\nedge, fog, and cloud computing paradigm. Energy efficiency is one of the most\nimportant design metrics in such IoT-healthcare systems especially, for the\nedge and fog nodes. Due to the sensing noise and inherent redundancy in the\ninput data, even the most safety-critical biomedical applications can sometimes\nafford a slight degradation in the output quality. Hence, such inherent error\ntolerance in the bio-signals can be exploited to achieve high energy savings\nthrough the emerging trends like, the Approximate Computing which is applicable\nat both software and hardware levels. In this paper, we propose to leverage the\napproximate computing in digital Compressed Sensing (CS), through low-power\napproximate adders (LPAA) in an accurate Bernoulli sensing-based CS acquisition\n(BCS). We demonstrate that approximations can indeed be safely employed in IoT\nhealthcare without affecting the detection of critical events in the biomedical\nsignals. Towards this, we explored the trade-of between energy efficiency and\noutput quality using the state-of-the-art lp2d RLS reconstruction algorithm.\nThe proposed framework is validated with the MIT-BIH Arrhythmia database. Our\nresults demonstrated approximately 59% energy savings as compared to the\naccurate design.",
        "author": [
            "Ayesha Siddique",
            "Osman Hasan",
            "Faiq Khalid",
            "Muhammad Shafique"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.07330v1.pdf",
        "Categories": [
            [
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.07330v1",
        "arXiv ID": "1811.07330v1"
    },
    {
        "title": "Block Chain based Intelligent Industrial Network (DSDIN)",
        "Published: ": "2018-09-18T06:38:49Z",
        "abstract": "The manufacturing industry featured centralization in the past due to\ntechnical limitations, and factories (especially large manufacturers) gathered\nalmost all of the resources for manufacturing, including: technologies, raw\nmaterials, equipment, workers, market information, etc. However, such\ncentralized production is costly, inefficient and inflexible, and difficult to\nrespond to rapidly changing, diverse and personalized user needs. This paper\nintroduces an Intelligent Industrial Network (DSDIN), which provides a fully\ndistributed manufacturing network where everyone can participate in\nmanufacturing due to decentralization and no intermediate links, allowing them\nto quickly get the products or services they want and also to be authorized,\nrecognized and get returns in a low-cost way due to their efforts (such as\nproviding creative ideas, designs or equipment, raw materials or physical\nstrength). DSDIN is a blockchain based IoT and AI technology platform, and also\nan IoT based intelligent service standard. Due to the intelligent network\nformed by DSDIN, the manufacturing center is no longer a factory, and actually\nthere are no manufacturing centers. DSDIN provides a multi-participation\npeer-to-peer network for people and things (including raw materials, equipment,\nfinished / semi-finished products, etc.). The information transmitted through\nthe network is called Intelligent Service Algorithm (ISA). The user can send a\nprocess model, formula or control parameter to a device via an ISA, and every\ntransaction in DSDIN is an intelligent service defined by ISA.",
        "author": [
            "Barco You",
            "Matthias Hub",
            "Mengzhe You",
            "Bo Xu",
            "Mingzhi Yu",
            "Ivan Uemlianin"
        ],
        "pdfLink": "http://arxiv.org/pdf/1809.06551v1.pdf",
        "Categories": [
            [
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/1809.06551v1",
        "arXiv ID": "1809.06551v1"
    },
    {
        "title": "Griefing-Penalty: Countermeasure for Griefing Attack in Lightning\n  Network",
        "Published: ": "2020-05-19T09:45:16Z",
        "abstract": "Lightning Network can execute unlimited number of off-chain payments, without\nincurring the cost of recording each of them in the blockchain. However,\nconditional payments in such networks is susceptible to Griefing Attack. In\nthis attack, an adversary doesn't resolve the payment with the intention of\nblocking channel capacity of the network. We propose an efficient\ncountermeasure for the attack, known as Griefing-Penalty. If any party in the\nnetwork mounts a griefing attack, it needs to pay a penalty proportional to the\ncollateral cost of executing a payment. The penalty is used for compensating\naffected parties in the network. We propose a new payment protocol HTLC-GP or\nHashed Timelock Contract with Griefing-Penalty to demonstrate the utility of\nthe countermeasure. Upon comparing our protocol with existing payment protocol\nHashed Timelock Contract, we observe that the average revenue earned by the\nattacker decreases substantially for HTLC-GP as compared to HTLC. We also study\nthe impact of path length for routing a transaction and rate of\ngriefing-penalty on the budget invested by an adversary for mounting the\nattack. The budget needed for mounting griefing attack in HTLC-GP is 12 times\nmore than the budget needed by attacker in HTLC, given that each payment\ninstance being routed via path length of hop count 20.",
        "author": [
            "Subhra Mazumdar",
            "Prabal Banerjee",
            "Sushmita Ruj"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.09327v3.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.09327v3",
        "arXiv ID": "2005.09327v3"
    },
    {
        "title": "A Contemporary Survey on 6G Wireless Networks: Potentials, Recent\n  Advances, Technical Challenges and Future Trends",
        "Published: ": "2023-06-14T05:58:51Z",
        "abstract": "Smart services based on Internet of everything (IoE) are prophesied to reap\nnotable attention by both academia and industry in the future. Although\nfifth-generation (5G) is a promising communication technology, however it\ncannot fulfill complete demands of novel applications. Sixth-generation (6G)\ntechnology is envisaged to overcome limitations of 5G technology. The vision\nand planning of future 6G network has been started with this aim to meet the\nstringent requirements of mobile communication. Our aim is to explore recent\nadvances and potential challenges to enable 6G technology in this review. We\nhave devised a taxonomy based on computing technologies, networking\ntechnologies, communication technologies, use cases, machine learning\nalgorithms and key enabler technologies. In this regard, we subsequently\nhighlight potential features and key areas of 6G. Key technological\nbreakthroughs which include quantum communication, tactile communication,\nholographic communication, terahertz communication, visible light communication\n(VLC) Internet of Bio Nano Things, which can put profound impact on wireless\ncommunication, have been elaborated at length in this review. In this review,\nour prime focus is to discuss potential enabling technologies which can develop\nseamless and sustainable network, encompassing symbiotic radio, blockchain, new\ncommunication paradigm, VLC and terahertz. In addition, we have investigated\nopen research challenges which can hamper the performance of 6G network.\nFinally, we have outlined several practical considerations, 6G key projects and\nfuture directions. We envision 6G undergoing unprecedented breakthroughs to\neliminate technical uncertainties and provide enlightening research directions\nfor subsequent future studies. Although it is impossible to envisage complete\ndetails of 6G, we believe this study will pave the way for future research\nwork.",
        "author": [
            "Syed Agha Hassnain Mohsan",
            "Yanlong Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.08265v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "eess.SP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.08265v1",
        "arXiv ID": "2306.08265v1"
    },
    {
        "title": "Longest Chain Consensus Under Bandwidth Constraint",
        "Published: ": "2021-11-24T08:29:34Z",
        "abstract": "Spamming attacks are a serious concern for consensus protocols, as witnessed\nby recent outages of a major blockchain, Solana. They cause congestion and\nexcessive message delays in a real network due to its bandwidth constraints. In\ncontrast, longest chain (LC), an important family of consensus protocols, has\npreviously only been proven secure assuming an idealized network model in which\nall messages are delivered within bounded delay. This model-reality mismatch is\nfurther aggravated for Proof-of-Stake (PoS) LC where the adversary can spam the\nnetwork with equivocating blocks. Hence, we extend the network model to capture\nbandwidth constraints, under which nodes now need to choose carefully which\nblocks to spend their limited download budget on. To illustrate this point, we\nshow that 'download along the longest header chain', a natural download rule\nfor Proof-of-Work (PoW) LC, is insecure for PoS LC. We propose a simple rule\n'download towards the freshest block', formalize two common heuristics 'not\ndownloading equivocations' and 'blocklisting', and prove in a unified framework\nthat PoS LC with any one of these download rules is secure in\nbandwidth-constrained networks. In experiments, we validate our claims and\nshowcase the behavior of these download rules under attack. By composing\nmultiple instances of a PoS LC protocol with a suitable download rule in\nparallel, we obtain a PoS consensus protocol that achieves a constant fraction\nof the network's throughput limit even under worst-case adversarial strategies.",
        "author": [
            "Joachim Neu",
            "Srivatsan Sridhar",
            "Lei Yang",
            "David Tse",
            "Mohammad Alizadeh"
        ],
        "pdfLink": "http://arxiv.org/pdf/2111.12332v3.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2111.12332v3",
        "arXiv ID": "2111.12332v3"
    },
    {
        "title": "Hunting for open clusters in \\textit{Gaia} DR2: $582$ new OCs in the\n  Galactic disc",
        "Published: ": "2020-01-20T14:38:03Z",
        "abstract": "Open clusters are key targets for both Galaxy structure and evolution and\nstellar physics studies. Since \\textit{Gaia} DR2 publication, the discovery of\nundetected clusters has proven that our samples were not complete. Our aim is\nto exploit the Big Data capabilities of machine learning to detect new open\nclusters in \\textit{Gaia} DR2, and to complete the open cluster sample to\nenable further studies on the Galactic disc. We use a machine learning based\nmethodology to systematically search in the Galactic disc, looking for\noverdensities in the astrometric space and identifying them as open clusters\nusing photometric information. First, we use an unsupervised clustering\nalgorithm, DBSCAN, to blindly search for these overdensities in \\textit{Gaia}\nDR2 $(l,b,\\varpi,\\mu_{\\alpha^*},\\mu_\\delta)$. After that, we use a deep\nlearning artificial neural network trained on colour-magnitude diagrams to\nidentify isochrone patterns in these overdensities, and to confirm them as open\nclusters. We find $582$ new open clusters distributed along the Galactic disc,\nin the region $|b| < 20$. We can detect substructure in complex regions, and\nidentify the tidal tails of a disrupting cluster UBC~$274$ of $\\sim 3$ Gyr\nlocated at $\\sim 2$ kpc. Adapting the methodology into a Big Data environment\nallows us to target the search driven by physical properties of the open\nclusters, instead of being driven by its computational requirements. This blind\nsearch for open clusters in the Galactic disc increases in a $45\\%$ the number\nof known open clusters.",
        "author": [
            "A. Castro-Ginard",
            "C. Jordi",
            "X. Luri",
            "J. \u00c1lvarez Cid-Fuentes",
            "L. Casamiquela",
            "F. Anders",
            "T. Cantat-Gaudin",
            "M. Mongui\u00f3",
            "L. Balaguer-N\u00fa\u00f1ez",
            "S. Sol\u00e0",
            "R. M. Badia"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.07122v1.pdf",
        "Categories": [
            [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.07122v1",
        "arXiv ID": "2001.07122v1"
    },
    {
        "title": "UAV-ReID: A Benchmark on Unmanned Aerial Vehicle Re-identification in\n  Video Imagery",
        "Published: ": "2021-04-13T14:13:09Z",
        "abstract": "As unmanned aerial vehicles (UAVs) become more accessible with a growing\nrange of applications, the potential risk of UAV disruption increases. Recent\ndevelopment in deep learning allows vision-based counter-UAV systems to detect\nand track UAVs with a single camera. However, the coverage of a single camera\nis limited, necessitating the need for multicamera configurations to match UAVs\nacross cameras - a problem known as re-identification (reID). While there has\nbeen extensive research on person and vehicle reID to match objects across time\nand viewpoints, to the best of our knowledge, there has been no research in UAV\nreID. UAVs are challenging to re-identify: they are much smaller than\npedestrians and vehicles and they are often detected in the air so appear at a\ngreater range of angles. Because no UAV data sets currently use multiple\ncameras, we propose the first new UAV re-identification data set, UAV-reID,\nthat facilitates the development of machine learning solutions in this emerging\narea. UAV-reID has two settings: Temporally-Near to evaluate performance across\nviews to assist tracking frameworks, and Big-to-Small to evaluate reID\nperformance across scale and to allow early reID when UAVs are detected from a\nlong distance. We conduct a benchmark study by extensively evaluating different\nreID backbones and loss functions. We demonstrate that with the right setup,\ndeep networks are powerful enough to learn good representations for UAVs,\nachieving 81.9% mAP on the Temporally-Near setting and 46.5% on the challenging\nBig-to-Small setting. Furthermore, we find that vision transformers are the\nmost robust to extreme variance of scale.",
        "author": [
            "Daniel Organisciak",
            "Matthew Poyser",
            "Aishah Alsehaim",
            "Shanfeng Hu",
            "Brian K. S. Isaac-Medina",
            "Toby P. Breckon",
            "Hubert P. H. Shum"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.06219v3.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.06219v3",
        "arXiv ID": "2104.06219v3"
    },
    {
        "title": "Deuterated Thioformaldehyde in the Barnard 1 Cloud",
        "Published: ": "2004-10-21T17:04:50Z",
        "abstract": "We present observations of the singly and doubly deuterated species of\nthioformaldehyde, HDCS and D$_2$CS, towards the dark cloud Barnard 1. This is\nthe first detection of D$_2$CS in Space and in dense and cold prestellar\nregions. Column densities obtained using rotational diagrams and a Large\nVelocity Gradient model show an extremely high D-enhancement in\nthioformaldehyde in Barnard 1. Although the column density of H$_2$CS is\nsmaller than that of H$_2$CO, both species show similar D-enhancements in their\nsingly and doubly deuterated species. A chemical model -including multiply\ndeuterated species- has been used in order to interpret the observations.\n  Predicted rotational frequencies from laboratory data for HDCS and D$_2$CS\nare significantly in error when compared to the observed frequencies in Space.\nConsequently, we have derived new rotational constants for these two species\nand for H$_2$CS and H$_2$C$^{34}$S using the observed frequencies in Barnard 1.\nThe new rotational constants allow to predict the rotational transitions of\nthese species with the accuracy needed for the narrow line emerging from dark\nclouds. Rotational constants for HDCS and D$_2$CS have been obtained from the\nobserved transitions in the laboratory and in Space.",
        "author": [
            "N. Marcelino",
            "J. Cernicharo",
            "E. Roueff",
            "M. Gerin",
            "R. Mauersberger"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0410515v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0410515v1",
        "arXiv ID": "0410515v1"
    },
    {
        "title": "Extragalactic CS survey",
        "Published: ": "2009-10-22T10:25:21Z",
        "abstract": "We present a coherent and homogeneous multi-line study of the CS molecule in\nnearby (D$<$10Mpc) galaxies. We include, from the literature, all the available\nobservations from the $J=1-0$ to the $J=7-6$ transitions towards NGC 253, NGC\n1068, IC 342, Henize~2-10, M~82, the Antennae Galaxies and M~83. We have, for\nthe first time, detected the CS(7-6) line in NGC 253, M~82 (both in the\nNorth-East and South-West molecular lobes), NGC 4038, M~83 and tentatively in\nNGC 1068, IC 342 and Henize~2-10. We use the CS molecule as a tracer of the\ndensest gas component of the ISM in extragalactic star-forming regions,\nfollowing previous theoretical and observational studies by Bayet et al.\n(2008a,b and 2009). In this first paper out of a series, we analyze the CS data\nsample under both Local Thermodynamical Equilibrium (LTE) and non-LTE (Large\nVelocity Gradient-LVG) approximations. We show that except for M~83 and Overlap\n(a shifted gas-rich position from the nucleus NGC 4039 in the Antennae\nGalaxies), the observations in NGC 253, IC 342, M~82-NE, M~82-SW and NGC 4038\nare not well reproduced by a single set of gas component properties and that,\nat least, two gas components are required. For each gas component, we provide\nestimates of the corresponding kinetic temperature, total CS column density and\ngas density.",
        "author": [
            "E. Bayet",
            "R. Aladro",
            "S. Martin",
            "S. Viti",
            "J. Martin-Pintado"
        ],
        "pdfLink": "http://arxiv.org/pdf/0910.4282v1.pdf",
        "Categories": [
            [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/0910.4282v1",
        "arXiv ID": "0910.4282v1"
    },
    {
        "title": "Structured Compressed Sensing: From Theory to Applications",
        "Published: ": "2011-06-30T13:38:44Z",
        "abstract": "Compressed sensing (CS) is an emerging field that has attracted considerable\nresearch interest over the past few years. Previous review articles in CS limit\ntheir scope to standard discrete-to-discrete measurement architectures using\nmatrices of randomized nature and signal models based on standard sparsity. In\nrecent years, CS has worked its way into several new application areas. This,\nin turn, necessitates a fresh look on many of the basics of CS. The random\nmatrix measurement operator must be replaced by more structured sensing\narchitectures that correspond to the characteristics of feasible acquisition\nhardware. The standard sparsity prior has to be extended to include a much\nricher class of signals and to encode broader data models, including\ncontinuous-time signals. In our overview, the theme is exploiting signal and\nmeasurement structure in compressive sensing. The prime focus is bridging\ntheory and practice; that is, to pinpoint the potential of structured CS\nstrategies to emerge from the math to the hardware. Our summary highlights new\ndirections as well as relations to more traditional CS, with the hope of\nserving both as a review to practitioners wanting to join this emerging field,\nand as a reference for researchers that attempts to put some of the existing\nideas in perspective of practical applications.",
        "author": [
            "Marco F. Duarte",
            "Yonina C. Eldar"
        ],
        "pdfLink": "http://arxiv.org/pdf/1106.6224v2.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1106.6224v2",
        "arXiv ID": "1106.6224v2"
    },
    {
        "title": "Randomized Dynamic Mode Decomposition",
        "Published: ": "2017-02-07T18:26:28Z",
        "abstract": "This paper presents a randomized algorithm for computing the near-optimal\nlow-rank dynamic mode decomposition (DMD). Randomized algorithms are emerging\ntechniques to compute low-rank matrix approximations at a fraction of the cost\nof deterministic algorithms, easing the computational challenges arising in the\narea of `big data'. The idea is to derive a small matrix from the\nhigh-dimensional data, which is then used to efficiently compute the dynamic\nmodes and eigenvalues. The algorithm is presented in a modular probabilistic\nframework, and the approximation quality can be controlled via oversampling and\npower iterations. The effectiveness of the resulting randomized DMD algorithm\nis demonstrated on several benchmark examples of increasing complexity,\nproviding an accurate and efficient approach to extract spatiotemporal coherent\nstructures from big data in a framework that scales with the intrinsic rank of\nthe data, rather than the ambient measurement dimension. For this work we\nassume that the dynamics of the problem under consideration is evolving on a\nlow-dimensional subspace that is well characterized by a fast decaying singular\nvalue spectrum.",
        "author": [
            "N. Benjamin Erichson",
            "Lionel Mathelin",
            "Steven L. Brunton",
            "J. Nathan Kutz"
        ],
        "pdfLink": "http://arxiv.org/pdf/1702.02912v3.pdf",
        "Categories": [
            [
                "math.NA",
                "cs.NA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1702.02912v3",
        "arXiv ID": "1702.02912v3"
    },
    {
        "title": "On the Solution of Linear Programming Problems in the Age of Big Data",
        "Published: ": "2017-06-30T05:44:36Z",
        "abstract": "The Big Data phenomenon has spawned large-scale linear programming problems.\nIn many cases, these problems are non-stationary. In this paper, we describe a\nnew scalable algorithm called NSLP for solving high-dimensional, non-stationary\nlinear programming problems on modern cluster computing systems. The algorithm\nconsists of two phases: Quest and Targeting. The Quest phase calculates a\nsolution of the system of inequalities defining the constraint system of the\nlinear programming problem under the condition of dynamic changes in input\ndata. To this end, the apparatus of Fejer mappings is used. The Targeting phase\nforms a special system of points having the shape of an n-dimensional\naxisymmetric cross. The cross moves in the n-dimensional space in such a way\nthat the solution of the linear programming problem is located all the time in\nan \"-vicinity of the central point of the cross.",
        "author": [
            "Irina Sokolinskaya",
            "Leonid B. Sokolinsky"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.10030v2.pdf",
        "Categories": [
            [
                "cs.DS",
                "math.OC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.10030v2",
        "arXiv ID": "1706.10030v2"
    },
    {
        "title": "User's Privacy in Recommendation Systems Applying Online Social Network\n  Data, A Survey and Taxonomy",
        "Published: ": "2018-06-20T09:23:00Z",
        "abstract": "Recommender systems have become an integral part of many social networks and\nextract knowledge from a user's personal and sensitive data both explicitly,\nwith the user's knowledge, and implicitly. This trend has created major privacy\nconcerns as users are mostly unaware of what data and how much data is being\nused and how securely it is used. In this context, several works have been done\nto address privacy concerns for usage in online social network data and by\nrecommender systems. This paper surveys the main privacy concerns, measurements\nand privacy-preserving techniques used in large-scale online social networks\nand recommender systems. It is based on historical works on security,\nprivacy-preserving, statistical modeling, and datasets to provide an overview\nof the technical difficulties and problems associated with privacy preserving\nin online social networks.",
        "author": [
            "Erfan Aghasian",
            "Saurabh Garg",
            "James Montgomery"
        ],
        "pdfLink": "http://arxiv.org/pdf/1806.07629v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1806.07629v1",
        "arXiv ID": "1806.07629v1"
    },
    {
        "title": "Causal inference, social networks, and chain graphs",
        "Published: ": "2018-12-12T15:36:55Z",
        "abstract": "Traditionally, statistical and causal inference on human subjects rely on the\nassumption that individuals are independently affected by treatments or\nexposures. However, recently there has been increasing interest in settings,\nsuch as social networks, where individuals may interact with one another such\nthat treatments may spill over from the treated individual to their social\ncontacts and outcomes may be contagious. Existing models proposed for causal\ninference using observational data from networks of interacting individuals\nhave two major shortcomings. First, they often require a level of granularity\nin the data that is practically infeasible to collect in most settings, and\nsecond, the models are high-dimensional and often too big to fit to the\navailable data. In this paper we illustrate and justify a parsimonious\nparameterization for network data with interference and contagion. Our\nparameterization corresponds to a particular family of graphical models known\nas chain graphs. We argue that, in some settings, chain graph models\napproximate the marginal distribution of a snapshot of a longitudinal data\ngenerating process on interacting units. We illustrate the use of chain graphs\nfor causal inference about collective decision making in social networks using\ndata from U.S. Supreme Court decisions between 1994 and 2004 and in\nsimulations.",
        "author": [
            "Elizabeth L. Ogburn",
            "Ilya Shpitser",
            "Youjin Lee"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.04990v2.pdf",
        "Categories": [
            [
                "stat.ME"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.04990v2",
        "arXiv ID": "1812.04990v2"
    },
    {
        "title": "Cross-chain Deals and Adversarial Commerce",
        "Published: ": "2019-05-23T16:06:25Z",
        "abstract": "Modern distributed data management systems face a new challenge: how can\nautonomous, mutually-distrusting parties cooperate safely and effectively?\nAddressing this challenge brings up questions familiar from classical\ndistributed systems: how to combine multiple steps into a single atomic action,\nhow to recover from failures, and how to synchronize concurrent access to data.\nNevertheless, each of these issues requires rethinking when participants are\nautonomous and potentially adversarial.\n  We propose the notion of a *cross-chain deal*, a new way to structure complex\ndistributed computations that manage assets in an adversarial setting. Deals\nare inspired by classical atomic transactions, but are necessarily different,\nin important ways, to accommodate the decentralized and untrusting nature of\nthe exchange. We describe novel safety and liveness properties, along with two\nalternative protocols for implementing cross-chain deals in a system of\nindependent blockchain ledgers. One protocol, based on synchronous\ncommunication, is fully decentralized, while the other, based on\nsemi-synchronous communication, requires a globally shared ledger.",
        "author": [
            "Maurice Herlihy",
            "Barbara Liskov",
            "Liuba Shrira"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.09743v5.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.09743v5",
        "arXiv ID": "1905.09743v5"
    },
    {
        "title": "Directed Graph Hashing",
        "Published: ": "2020-02-16T19:08:14Z",
        "abstract": "This paper presents several algorithms for hashing directed graphs. The\nalgorithms given are capable of hashing entire graphs as well as assigning hash\nvalues to specific nodes in a given graph. The notion of node symmetry is made\nprecise via computation of vertex orbits and the graph automorphism group, and\nnodes that are symmetrically identical are assigned equal hashes. We also\npresent a novel Merkle-style hashing algorithm that seeks to fulfill the\nrecursive principle that a hash of a node should depend only on the hash of its\nneighbors. This algorithm works even in the presence of cycles, which would not\nbe possible with a naive approach. Structurally hashing trees has seen\nwidespread use in blockchain, source code version control, and web\napplications. Despite the popularity of tree hashing, directed graph hashing\nremains unstudied in the literature. Our algorithms open new possibilities to\nhashing both directed graphs and more complex data structures that can be\nreduced to directed graphs such as hypergraphs.",
        "author": [
            "Caleb Helbling"
        ],
        "pdfLink": "http://arxiv.org/pdf/2002.06653v3.pdf",
        "Categories": [
            [
                "cs.DM",
                "cs.DS",
                "68R10",
                "G.2.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2002.06653v3",
        "arXiv ID": "2002.06653v3"
    },
    {
        "title": "iDML: Incentivized Decentralized Machine Learning",
        "Published: ": "2023-04-10T17:28:51Z",
        "abstract": "With the rising emergence of decentralized and opportunistic approaches to\nmachine learning, end devices are increasingly tasked with training deep\nlearning models on-devices using crowd-sourced data that they collect\nthemselves. These approaches are desirable from a resource consumption\nperspective and also from a privacy preservation perspective. When the devices\nbenefit directly from the trained models, the incentives are implicit -\ncontributing devices' resources are incentivized by the availability of the\nhigher-accuracy model that results from collaboration. However, explicit\nincentive mechanisms must be provided when end-user devices are asked to\ncontribute their resources (e.g., computation, communication, and data) to a\ntask performed primarily for the benefit of others, e.g., training a model for\na task that a neighbor device needs but the device owner is uninterested in. In\nthis project, we propose a novel blockchain-based incentive mechanism for\ncompletely decentralized and opportunistic learning architectures. We leverage\na smart contract not only for providing explicit incentives to end devices to\nparticipate in decentralized learning but also to create a fully decentralized\nmechanism to inspect and reflect on the behavior of the learning architecture.",
        "author": [
            "Haoxiang Yu",
            "Hsiao-Yuan Chen",
            "Sangsu Lee",
            "Sriram Vishwanath",
            "Xi Zheng",
            "Christine Julien"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.05354v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.05354v1",
        "arXiv ID": "2304.05354v1"
    },
    {
        "title": "P-Immune Sets with Holes Lack Self-Reducibility Properties",
        "Published: ": "2001-02-23T17:10:50Z",
        "abstract": "No P-immune set having exponential gaps is positive-Turing self-reducible.",
        "author": [
            "Lane A. Hemaspaandra",
            "Harald Hempel"
        ],
        "pdfLink": "http://arxiv.org/pdf/cs/0102024v1.pdf",
        "Categories": [
            [
                "cs.CC",
                "F.1.3; F.1.2; F.1.1"
            ]
        ],
        "Link": "http://arxiv.org/abs/cs/0102024v1",
        "arXiv ID": "0102024v1"
    },
    {
        "title": "Driver Safety Reward with Cooperative Platooning using Blockchain",
        "Published: ": "2023-10-24T23:21:20Z",
        "abstract": "Cooperative driving (or Platooning) focuses on improving the safety and\nefficiency by connecting two or more vehicles on a road by vehicular\ncommunication protocols. The leader is crucial as it manages the platoon,\nestablishes communication between cars, and perform platoon maneuvers. In this\npaper, we proposed a driver incentive model which encourages platooning on\nroads leading to driver safety. As, the leader of platoon have multiple\nresponsibilities than followers, our model rewards more incentives to leader\nthan followers. These incentives will be rewarded as crypto tokens. This\ndigital monetization method for both leaders and followers of a platoon is\naccomplished by secure transactions using blockchain.",
        "author": [
            "Sruthi Rachamalla",
            "Henry Hexmoor"
        ],
        "pdfLink": "http://arxiv.org/pdf/2312.02164v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2312.02164v1",
        "arXiv ID": "2312.02164v1"
    },
    {
        "title": "Fast Approximate Construction of Best Complex Antipodal Spherical Codes",
        "Published: ": "2017-05-09T11:31:27Z",
        "abstract": "Compressive Sensing (CS) theory states that real-world signals can often be\nrecovered from much fewer measurements than those suggested by the Shannon\nsampling theorem. Nevertheless, recoverability does not only depend on the\nsignal, but also on the measurement scheme. The measurement matrix should\nbehave as close as possible to an isometry for the signals of interest.\nTherefore the search for optimal CS measurement matrices of size $m\\times n$\ntranslates into the search for a set of $n$ $m$-dimensional vectors with\nminimal coherence. Best Complex Antipodal Spherical Codes (BCASCs) are known to\nbe optimal in terms of coherence. An iterative algorithm for BCASC generation\nhas been recently proposed that tightly approaches the theoretical lower bound\non coherence. Unfortunately, the complexity of each iteration depends\nquadratically on $m$ and $n$. In this work we propose a modification of the\nalgorithm that allows reducing the quadratic complexity to linear on both $m$\nand $n$. Numerical evaluation showed that the proposed approach does not worsen\nthe coherence of the resulting BCASCs. On the contrary, an improvement was\nobserved for large $n$. The reduction of the computational complexity paves the\nway for using the BCASCs as CS measurement matrices in problems with large $n$.\nWe evaluate the CS performance of the BCASCs for recovering sparse signals. The\nBCASCs are shown to outperform both complex random matrices and Fourier\nensembles as CS measurement matrices, both in terms of coherence and sparse\nrecovery performance, especially for low $m/n$, which is the case of interest\nin CS.",
        "author": [
            "Miguel Heredia Conde",
            "Otmar Loffeld"
        ],
        "pdfLink": "http://arxiv.org/pdf/1705.03280v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1705.03280v1",
        "arXiv ID": "1705.03280v1"
    },
    {
        "title": "High-resolution single-shot spiral diffusion-weighted imaging at 7T\n  using expanded encoding with compressed sensing",
        "Published: ": "2022-11-14T17:03:55Z",
        "abstract": "Purpose: The expanded encoding model incorporates spatially- and time-varying\nfield perturbations for correction during reconstruction. So far, these\nreconstructions have used the conjugate gradient method with early stopping\nused as implicit regularization. However, this approach is likely suboptimal\nfor low-SNR cases like diffusion or high-resolution MRI. Here, we investigate\nthe extent that l1-wavelet regularization, or equivalently compressed sensing\n(CS), combined with expanded encoding improves trade-offs between spatial\nresolution, readout time and SNR for single-shot spiral diffusion-weighted\nimaging at 7T. The reconstructions were performed using our open-source\nGPU-enabled reconstruction toolbox, MatMRI, that allows inclusion of the\ndifferent components of the expanded encoding model, with or without CS.\nMethods: In vivo accelerated single-shot spirals were acquired with five\nacceleration factors (2-6) and three in-plane spatial resolutions (1.5, 1.3,\nand 1.1 mm). From the in vivo reconstructions, we estimated diffusion tensors\nand computed fractional anisotropy maps. Then, simulations were used to\nquantitatively investigate and validate the impact of CS-based regularization\non image quality when compared to a known ground truth. Results: In vivo\nreconstructions revealed improved image quality with retainment of small\nfeatures when CS was used. Simulations showed that the joint use of the\nexpanded encoding model and CS improves accuracy of image reconstructions\n(reduced mean-squared error) over the range of acceleration factors\ninvestigated. Conclusion: The expanded encoding model and CS regularization are\ncomplementary tools for single-shot spiral diffusion MRI, which enables both\nhigher spatial resolutions and higher acceleration factors.",
        "author": [
            "Gabriel Varela-Mattatall",
            "Paul I. Dubovan",
            "Tales Santini",
            "Kyle M. Gilbert",
            "Ravi S. Menon",
            "Corey A. Baron"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.07532v1.pdf",
        "Categories": [
            [
                "physics.med-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.07532v1",
        "arXiv ID": "2211.07532v1"
    },
    {
        "title": "Numerical Algorithmic Science and Engineering within Computer Science:\n  Rationale, Foundations and Organization",
        "Published: ": "2019-03-20T00:44:25Z",
        "abstract": "A re-calibration is proposed for \"numerical analysis\" as it arises\nspecifically within the broader, embracing field of modern computer science\n(CS). This would facilitate research into theoretical and practicable models of\nreal-number computation at the foundations of CS, and it would also advance the\ninstructional objectives of the CS field. Our approach is premised on the key\nobservation that the great \"watershed\" in numerical computation is much more\nbetween finite- and infinite-dimensional numerical problems than it is between\ndiscrete and continuous numerical problems. A revitalized discipline for\nnumerical computation within modern CS can more accurately be defined as\n\"numerical algorithmic science & engineering (NAS&E), or more compactly, as\n\"numerical algorithmics,\" its focus being the algorithmic solution of numerical\nproblems that are either discrete, or continuous over a space of finite\ndimension, or a combination of the two. It is the counterpart within modern CS\nof the numerical analysis discipline, whose primary focus is the algorithmic\nsolution of continuous, infinite-dimensional numerical problems and their\nfinite-dimensional approximates, and whose specialists today have largely been\nrepatriated to departments of mathematics. Our detailed overview of NAS&E from\nthe viewpoints of rationale, foundations, and organization is preceded by a\nrecounting of the role played by numerical analysts in the evolution of\nacademic departments of computer science, in order to provide background for\nNAS&E and place the newly-emerging discipline within its larger historical\ncontext.",
        "author": [
            "John Lawrence Nazareth"
        ],
        "pdfLink": "http://arxiv.org/pdf/1903.08647v1.pdf",
        "Categories": [
            [
                "cs.NA",
                "cs.OH"
            ]
        ],
        "Link": "http://arxiv.org/abs/1903.08647v1",
        "arXiv ID": "1903.08647v1"
    },
    {
        "title": "Comparing hundreds of machine learning classifiers and discrete choice\n  models in predicting travel behavior: an empirical benchmark",
        "Published: ": "2021-02-01T19:45:47Z",
        "abstract": "Researchers have compared machine learning (ML) classifiers and discrete\nchoice models (DCMs) in predicting travel behavior, but the generalizability of\nthe findings is limited by the specifics of data, contexts, and authors'\nexpertise. This study seeks to provide a generalizable empirical benchmark by\ncomparing hundreds of ML and DCM classifiers in a highly structured manner. The\nexperiments evaluate both prediction accuracy and computational cost by\nspanning four hyper-dimensions, including 105 ML and DCM classifiers from 12\nmodel families, 3 datasets, 3 sample sizes, and 3 outputs. This experimental\ndesign leads to an immense number of 6,970 experiments, which are corroborated\nwith a meta dataset of 136 experiment points from 35 previous studies. This\nstudy is hitherto the most comprehensive and almost exhaustive comparison of\nthe classifiers for travel behavioral prediction. We found that the ensemble\nmethods and deep neural networks achieve the highest predictive performance,\nbut at a relatively high computational cost. Random forests are the most\ncomputationally efficient, balancing between prediction and computation. While\ndiscrete choice models offer accuracy with only 3-4 percentage points lower\nthan the top ML classifiers, they have much longer computational time and\nbecome computationally impossible with large sample size, high input\ndimensions, or simulation-based estimation. The relative ranking of the ML and\nDCM classifiers is highly stable, while the absolute values of the prediction\naccuracy and computational time have large variations. Overall, this paper\nsuggests using deep neural networks, model ensembles, and random forests as\nbaseline models for future travel behavior prediction. For choice modeling, the\nDCM community should switch more attention from fitting models to improving\ncomputational efficiency, so that the DCMs can be widely adopted in the big\ndata context.",
        "author": [
            "Shenhao Wang",
            "Baichuan Mo",
            "Stephane Hess",
            "Jinhua Zhao"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.01130v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "econ.EM"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.01130v1",
        "arXiv ID": "2102.01130v1"
    },
    {
        "title": "Local Gaussian Processes for Efficient Fine-Grained Traffic Speed\n  Prediction",
        "Published: ": "2017-08-27T11:41:16Z",
        "abstract": "Traffic speed is a key indicator for the efficiency of an urban\ntransportation system. Accurate modeling of the spatiotemporally varying\ntraffic speed thus plays a crucial role in urban planning and development. This\npaper addresses the problem of efficient fine-grained traffic speed prediction\nusing big traffic data obtained from static sensors. Gaussian processes (GPs)\nhave been previously used to model various traffic phenomena, including flow\nand speed. However, GPs do not scale with big traffic data due to their cubic\ntime complexity. In this work, we address their efficiency issues by proposing\nlocal GPs to learn from and make predictions for correlated subsets of data.\nThe main idea is to quickly group speed variables in both spatial and temporal\ndimensions into a finite number of clusters, so that future and unobserved\ntraffic speed queries can be heuristically mapped to one of such clusters. A\nlocal GP corresponding to that cluster can then be trained on the fly to make\npredictions in real-time. We call this method localization. We use non-negative\nmatrix factorization for localization and propose simple heuristics for cluster\nmapping. We additionally leverage on the expressiveness of GP kernel functions\nto model road network topology and incorporate side information. Extensive\nexperiments using real-world traffic data collected in the two U.S. cities of\nPittsburgh and Washington, D.C., show that our proposed local GPs significantly\nimprove both runtime performances and prediction accuracies compared to the\nbaseline global and local GPs.",
        "author": [
            "Truc Viet Le",
            "Richard J. Oentaryo",
            "Siyuan Liu",
            "Hoong Chuin Lau"
        ],
        "pdfLink": "http://arxiv.org/pdf/1708.08079v1.pdf",
        "Categories": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1708.08079v1",
        "arXiv ID": "1708.08079v1"
    },
    {
        "title": "Big Data Science Over the Past Web",
        "Published: ": "2021-08-03T16:10:52Z",
        "abstract": "Web archives preserve unique and historically valuable information. They hold\na record of past events and memories published by all kinds of people, such as\njournalists, politicians and ordinary people who have shared their testimony\nand opinion on multiple subjects. As a result, researchers such as historians\nand sociologists have used web archives as a source of information to\nunderstand the recent past since the early days of the World Wide Web. The\ntypical way to extract knowledge from a web archive is by using its search\nfunctionalities to find and analyse historical content. This can be a slow and\nsuperficial process when analysing complex topics, due to the huge amount of\ndata that web archives have been preserving over time. Big data science tools\ncan cope with this order of magnitude, enabling researchers to automatically\nextract meaningful knowledge from the archived data. This knowledge helps not\nonly to explain the past but also to predict the future through the\ncomputational modelling of events and behaviours. Currently, there is an\nimmense landscape of big data tools, machine learning frameworks and deep\nlearning algorithms that significantly increase the scalability and performance\nof several computational tasks, especially over text, image and audio. Web\narchives have been taking advantage of this panoply of technologies to provide\ntheir users with more powerful tools to explore and exploit historical data.\nThis chapter presents several examples of these tools and gives an overview of\ntheir application to support longitudinal studies over web archive collections.",
        "author": [
            "Miguel Costa",
            "Julien Masan\u00e8s"
        ],
        "pdfLink": "http://arxiv.org/pdf/2108.01605v1.pdf",
        "Categories": [
            [
                "cs.DL"
            ]
        ],
        "Link": "http://arxiv.org/abs/2108.01605v1",
        "arXiv ID": "2108.01605v1"
    },
    {
        "title": "Advancements in Big Data Processing in the ATLAS and CMS Experiments",
        "Published: ": "2013-03-08T11:06:44Z",
        "abstract": "The ever-increasing volumes of scientific data present new challenges for\ndistributed computing and Grid technologies. The emerging Big Data revolution\ndrives exploration in scientific fields including nanotechnology, astrophysics,\nhigh-energy physics, biology and medicine. New initiatives are transforming\ndata-driven scientific fields enabling massive data analysis in new ways. In\npetascale data processing scientists deal with datasets, not individual files.\nAs a result, a task (comprised of many jobs) became a unit of petascale data\nprocessing on the Grid. Splitting of a large data processing task into jobs\nenabled fine-granularity checkpointing analogous to the splitting of a large\nfile into smaller TCP/IP packets during data transfers. Transferring large data\nin small packets achieves reliability through automatic re-sending of the\ndropped TCP/IP packets. Similarly, transient job failures on the Grid can be\nrecovered by automatic re-tries to achieve reliable six sigma production\nquality in petascale data processing on the Grid. The computing experience of\nthe ATLAS and CMS experiments provides foundation for reliability engineering\nscaling up Grid technologies for data processing beyond the petascale.",
        "author": [
            "A. V. Vaniachine"
        ],
        "pdfLink": "http://arxiv.org/pdf/1303.1950v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.DB",
                "hep-ex"
            ]
        ],
        "Link": "http://arxiv.org/abs/1303.1950v1",
        "arXiv ID": "1303.1950v1"
    },
    {
        "title": "Controlling network dynamics",
        "Published: ": "2020-01-09T20:49:56Z",
        "abstract": "Network science has experienced unprecedented rapid development in the past\ntwo decades. The network perspective has also been widely applied to explore\nvarious complex systems in great depth. In the first decade, fundamental\ncharacteristics of complex network structure, such as the small-worldness,\nscale-freeness, and modularity, of various complex networked systems were\nharvested from analyzing big empirical data. The associated dynamical processes\non complex networks were also heavily studied. In the second decade, more\nattention was devoted to investigating the control of complex networked\nsystems, ranging from fundamental theories to practical applications. Here we\nbriefly review recent progress regarding network dynamics and control, mainly\nconcentrating on research questions proposed in the six papers we collected for\nthe topical issue entitled \"Network Dynamics and Control\" at\n$Advances~in~Complex~Systems$. This review closes with possible research\ndirections along this line, and several important problems to be solved. We\nexpect that, in the near future, network control will play an even bigger role\nin more fields, helping us understand and control many complex natural and\nengineered systems.",
        "author": [
            "Aming Li",
            "Yang-Yu Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.03218v1.pdf",
        "Categories": [
            [
                "physics.soc-ph",
                "math.OC",
                "nlin.AO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.03218v1",
        "arXiv ID": "2001.03218v1"
    },
    {
        "title": "First stars XVI. STIS/HST abundances of heavy-elements in the\n  uranium-rich star CS 31082-001",
        "Published: ": "2012-12-02T14:44:06Z",
        "abstract": "Detailed abundances of the elements produced by r-process nucleosynthesis in\nvarious circumstances are our best observational clues to their origin, since\nthe site(s) of r-element production is(are) still not known with certainty. A\nsmall fraction of extremely metal-poor (EMP) stars exhibit excesses of heavy\nneutron-capture elements produced in the r-process, and CS 31082-001 is among\nthe 4 well-known r-process-enhanced EMP stars. Observations with HST/STIS\nprovide abundances for elements observable only from the UV region. Here we aim\nto supplement the optical data with abundances from near-UV spectroscopy of the\nfirst and second peak of the r-elements, which are crucial to giving insight\ninto the nucleosynthesis of the elements beyond iron. The UVES spectrum\nprovided additional measurements, thereby improving the previous results. The\nspectra were analyzed with the OSMARCS LTE model atmosphere and with a\nconsistent approach based on the spectrum synthesis code Turbospectrum to\nderive abundances of heavy elements in CS 31082-001, using updated oscillator\nstrengths from the recent literature. We computed synthetic spectra for all\nlines of the elements of interest, checking for proper intensities and possible\nblends. We combined the abundances of heavy elements derived in previous works\nwith the derivation of abundances from all reliable new list of lines, for the\nfirst and second peaks of r-elements. We were able to derive new abundances for\n23 n-elements, 6 of them - Ge, Mo, Lu, Ta, W, and Re - were not available in\nprevious works, making this star the most complete r-II object studied, with a\ntotal of 37 detections of n-capture elements. We also present the first NLTE+3D\nlead abundance in this star. The results provide improved constraints on the\nnature of the r-process.",
        "author": [
            "C. Siqueira Mello",
            "M. Spite",
            "B. Barbuy",
            "F. Spite",
            "E. Caffau",
            "V. Hill",
            "S. Wanajo",
            "F. Primas",
            "B. Plez",
            "R. Cayrel",
            "J. Andersen",
            "B. Nordstr\u00f6m",
            "C. Sneden",
            "T. C. Beers",
            "P. Bonifacio",
            "P. Fran\u00e7ois",
            "P. Molaro"
        ],
        "pdfLink": "http://arxiv.org/pdf/1212.0211v1.pdf",
        "Categories": [
            [
                "astro-ph.SR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1212.0211v1",
        "arXiv ID": "1212.0211v1"
    },
    {
        "title": "Using Multi-Core HW/SW Co-design Architecture for Accelerating K-means\n  Clustering Algorithm",
        "Published: ": "2018-07-09T17:38:42Z",
        "abstract": "The capability of classifying and clustering a desired set of data is an\nessential part of building knowledge from data. However, as the size and\ndimensionality of input data increases, the run-time for such clustering\nalgorithms is expected to grow superlinearly, making it a big challenge when\ndealing with BigData. K-mean clustering is an essential tool for many big data\napplications including data mining, predictive analysis, forecasting studies,\nand machine learning. However, due to large size (volume) of Big-Data, and\nlarge dimensionality of its data points, even the application of a simple\nk-mean clustering may become extremely time and resource demanding. Specially\nwhen it is necessary to have a fast and modular dataset analysis flow. In this\npaper, we demonstrate that using a two-level filtering algorithm based on\nbinary kd-tree structure is able to decrease the time of convergence in K-means\nalgorithm for large datasets. The two-level filtering algorithm based on binary\nkd-tree structure evolves the SW to naturally divide the classification into\nsmaller data sets, based on the number of available cores and size of logic\navailable in a target FPGA. The empirical result on this two-level structure\nover multi-core FPGA-based architecture provides 330X speed-up compared to a\nconventional software-only solution.",
        "author": [
            "Hadi Mardani Kamali"
        ],
        "pdfLink": "http://arxiv.org/pdf/1807.09250v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.AR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1807.09250v1",
        "arXiv ID": "1807.09250v1"
    },
    {
        "title": "Validating IP Prefixes and AS-Paths with Blockchains",
        "Published: ": "2019-06-07T15:38:54Z",
        "abstract": "Networks (Autonomous Systems-AS) allocate or revoke IP prefixes with the\nintervention of official Internet resource number authorities, and select and\nadvertise policy-compliant paths towards these prefixes using the inter-domain\nrouting system and its primary enabler, the Border Gateway Protocol (BGP).\nSecuring BGP has been a long-term objective of several research and industrial\nefforts during the last decades, that have culminated in the Resource Public\nKey Infrastructure (RPKI) for the cryptographic verification of prefix-to-AS\nassignments. However, there is still no widely adopted solution for securing IP\nprefixes and the (AS-)paths leading to them; approaches such as BGPsec have\nseen minuscule deployment. In this work, we design and implement a\nBlockchain-based system that (i) can be used to validate both of these resource\ntypes, (ii) can work passively and does not require any changes in the\ninter-domain routing system (BGP, RPKI), and (iii) can be combined with\ncurrently available systems for the detection and mitigation of routing\nattacks. We present early results and insights w.r.t. scalability.",
        "author": [
            "Ilias Sfirakis",
            "Vasileios Kotronis"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.03172v1.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.03172v1",
        "arXiv ID": "1906.03172v1"
    },
    {
        "title": "Modeling the Block Verification Time of Zcash",
        "Published: ": "2021-06-28T14:35:38Z",
        "abstract": "An important aspect of the propagation delay in blockchain networks is the\nblock verification time, which is also responsible for the so-called verifier's\ndilemma. Models for the block verification time can help to understand and\nimprove the verification process. Moreover, modeling the verification time is\nnecessary for blockchain network simulations. In this paper, we present JOIST,\na new model for the block verification time of Zcash. We identify\ncomputationally complex operations in the verification process of Zcash, and\nderive our model based on characteristic transaction features. We evaluate\nJOIST and show that the model is consistently more accurate than existing\nmodels, which consider the block size only.",
        "author": [
            "Fabian Stiehle",
            "Erik Daniel",
            "Florian Tschorsch"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.14760v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.14760v1",
        "arXiv ID": "2106.14760v1"
    },
    {
        "title": "Blockchain Application on the Internet of Vehicles (IoV)",
        "Published: ": "2022-05-08T10:18:04Z",
        "abstract": "With the rapid development of the Internet of Things (IoT) and its potential\nintegration with the traditional Vehicular Ad-Hoc Networks (VANETs), we have\nwitnessed the emergence of the Internet of Vehicles (IoV), which promises to\nseamlessly integrate into smart transportation systems. However, the key\ncharacteristics of IoV, such as high-speed mobility and frequent disconnections\nmake it difficult to manage its security and privacy. The Blockchain, as a\ndistributed tamper-resistant ledge, has been proposed as an innovative solution\nthat guarantees privacy-preserving yet secure schemes. In this paper, we review\nrecent literature on the application of blockchain to IoV, in particular, and\nintelligent transportation systems in general.",
        "author": [
            "Nyothiri Aung",
            "Tahar Kechadi",
            "Tao Zhu",
            "Saber Zerdoumi",
            "Tahar Guerbouz",
            "Sahraoui Dhelim"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.03832v3.pdf",
        "Categories": [
            [
                "cs.NI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.03832v3",
        "arXiv ID": "2205.03832v3"
    },
    {
        "title": "A Neural Tangent Kernel View on Federated Averaging for Deep Linear\n  Neural Network",
        "Published: ": "2023-10-09T07:56:56Z",
        "abstract": "Federated averaging (FedAvg) is a widely employed paradigm for\ncollaboratively training models from distributed clients without sharing data.\nNowadays, the neural network has achieved remarkable success due to its\nextraordinary performance, which makes it a preferred choice as the model in\nFedAvg. However, the optimization problem of the neural network is often\nnon-convex even non-smooth. Furthermore, FedAvg always involves multiple\nclients and local updates, which results in an inaccurate updating direction.\nThese properties bring difficulties in analyzing the convergence of FedAvg in\ntraining neural networks. Recently, neural tangent kernel (NTK) theory has been\nproposed towards understanding the convergence of first-order methods in\ntackling the non-convex problem of neural networks. The deep linear neural\nnetwork is a classical model in theoretical subject due to its simple\nformulation. Nevertheless, there exists no theoretical result for the\nconvergence of FedAvg in training the deep linear neural network. By applying\nNTK theory, we make a further step to provide the first theoretical guarantee\nfor the global convergence of FedAvg in training deep linear neural networks.\nSpecifically, we prove FedAvg converges to the global minimum at a linear rate\n$\\mathcal{O}\\big((1-\\eta K /N)^t\\big)$, where $t$ is the number of iterations,\n$\\eta$ is the learning rate, $N$ is the number of clients and $K$ is the number\nof local updates. Finally, experimental evaluations on two benchmark datasets\nare conducted to empirically validate the correctness of our theoretical\nfindings.",
        "author": [
            "Xin Liu",
            "Dazhi Zhan",
            "Wei Tao",
            "Xin Ma",
            "Yu Pan",
            "Yu Ding",
            "Zhisong Pan"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.05495v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.05495v1",
        "arXiv ID": "2310.05495v1"
    },
    {
        "title": "The Least-core and Nucleolus of Path Cooperative Games",
        "Published: ": "2015-03-16T09:11:01Z",
        "abstract": "Cooperative games provide an appropriate framework for fair and stable profit\ndistribution in multiagent systems. In this paper, we study the algorithmic\nissues on path cooperative games that arise from the situations where some\ncommodity flows through a network. In these games, a coalition of edges or\nvertices is successful if it enables a path from the source to the sink in the\nnetwork, and lose otherwise. Based on dual theory of linear programming and the\nrelationship with flow games, we provide the characterizations on the CS-core,\nleast-core and nucleolus of path cooperative games. Furthermore, we show that\nthe least-core and nucleolus are polynomially solvable for path cooperative\ngames defined on both directed and undirected network.",
        "author": [
            "Qizhi Fang",
            "Bo Li",
            "Xiaohan Shan",
            "Xiaoming Sun"
        ],
        "pdfLink": "http://arxiv.org/pdf/1503.04575v1.pdf",
        "Categories": [
            [
                "cs.GT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1503.04575v1",
        "arXiv ID": "1503.04575v1"
    },
    {
        "title": "Regularizing Class-wise Predictions via Self-knowledge Distillation",
        "Published: ": "2020-03-31T06:03:51Z",
        "abstract": "Deep neural networks with millions of parameters may suffer from poor\ngeneralization due to overfitting. To mitigate the issue, we propose a new\nregularization method that penalizes the predictive distribution between\nsimilar samples. In particular, we distill the predictive distribution between\ndifferent samples of the same label during training. This results in\nregularizing the dark knowledge (i.e., the knowledge on wrong predictions) of a\nsingle network (i.e., a self-knowledge distillation) by forcing it to produce\nmore meaningful and consistent predictions in a class-wise manner.\nConsequently, it mitigates overconfident predictions and reduces intra-class\nvariations. Our experimental results on various image classification tasks\ndemonstrate that the simple yet powerful method can significantly improve not\nonly the generalization ability but also the calibration performance of modern\nconvolutional neural networks.",
        "author": [
            "Sukmin Yun",
            "Jongjin Park",
            "Kimin Lee",
            "Jinwoo Shin"
        ],
        "pdfLink": "http://arxiv.org/pdf/2003.13964v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2003.13964v2",
        "arXiv ID": "2003.13964v2"
    },
    {
        "title": "Smart Flood Resilience: Harnessing Community-Scale Big Data for\n  Predictive Flood Risk Monitoring, Rapid Impact Assessment, and Situational\n  Awareness",
        "Published: ": "2021-11-11T21:02:34Z",
        "abstract": "Smart resilience is the beneficial result of the collision course of the\nfields of data science and urban resilience to flooding. The objective of this\nstudy is to propose and demonstrate a smart flood resilience framework that\nleverages heterogeneous community-scale big data and infrastructure sensor data\nto enhance predictive risk monitoring and situational awareness. The smart\nflood resilience framework focuses on four core capabilities that could be\naugmented by the use of heterogeneous community-scale big data and analytics\ntechniques: (1) predictive flood risk mapping; (2) automated rapid impact\nassessment; (3) predictive infrastructure failure prediction and monitoring;\nand (4) smart situational awareness capabilities. We demonstrate the components\nof these core capabilities of the smart flood resilience framework in the\ncontext of the 2017 Hurricane Harvey in Harris County, Texas. First, we\ndemonstrate the use of flood sensors for the prediction of floodwater overflow\nin channel networks and inundation of co-located road networks. Second, we\ndiscuss the use of social media and machine learning techniques for assessing\nthe impacts of floods on communities and sensing emotion signals to examine\nsocietal impacts. Third, we illustrate the use of high-resolution traffic data\nin network-theoretic models for nowcasting of flood propagation on road\nnetworks and the disrupted access to critical facilities, such as hospitals.\nFourth, we leverage location-based and credit card transaction data in spatial\nanalyses to proactively evaluate the recovery of communities and the impacts of\nfloods on businesses. These analyses show that the significance of core\ncapabilities of the smart flood resilience framework in helping emergency\nmanagers, city planners, public officials, responders, and volunteers to better\ncope with the impacts of catastrophic flooding events.",
        "author": [
            "Faxi Yuan",
            "Chao Fan",
            "Hamed Farahmand",
            "Natalie Coleman",
            "Amir Esmalian",
            "Cheng-Chun Lee",
            "Flavia I. Patrascu",
            "Cheng Zhang",
            "Shangjia Dong",
            "Ali Mostafavi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2111.06461v2.pdf",
        "Categories": [
            [
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2111.06461v2",
        "arXiv ID": "2111.06461v2"
    },
    {
        "title": "Massive Science with VO and Grids",
        "Published: ": "2005-10-31T11:26:54Z",
        "abstract": "There is a growing need for massive computational resources for the analysis\nof new astronomical datasets. To tackle this problem, we present here our first\nsteps towards marrying two new and emerging technologies; the Virtual\nObservatory (e.g, AstroGrid) and the computational grid (e.g. TeraGrid, COSMOS\netc.). We discuss the construction of VOTechBroker, which is a modular software\ntool designed to abstract the tasks of submission and management of a large\nnumber of computational jobs to a distributed computer system. The broker will\nalso interact with the AstroGrid workflow and MySpace environments. We discuss\nour planned usages of the VOTechBroker in computing a huge number of n-point\ncorrelation functions from the SDSS data and massive model-fitting of millions\nof CMBfast models to WMAP data. We also discuss other applications including\nthe determination of the XMM Cluster Survey selection function and the\nconstruction of new WMAP maps.",
        "author": [
            "Robert Nichol",
            "Garry Smith",
            "Christopher Miller",
            "Peter Freeman",
            "Chris Genovese",
            "Larry Wasserman",
            "Brent Bryan",
            "Alexander Gray",
            "Jeff Schneider",
            "Andrew Moore"
        ],
        "pdfLink": "http://arxiv.org/pdf/astro-ph/0510844v1.pdf",
        "Categories": [
            [
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/astro-ph/0510844v1",
        "arXiv ID": "0510844v1"
    },
    {
        "title": "A Systematic Literature Review on Blockchain Enabled Federated Learning\n  Framework for Internet of Vehicles",
        "Published: ": "2022-03-10T07:06:04Z",
        "abstract": "While the convergence of Artificial Intelligence (AI) techniques with\nimproved information technology systems ensured enormous benefits to the\nInternet of Vehicles (IoVs) systems, it also introduced an increased amount of\nsecurity and privacy threats. To ensure the security of IoVs data, privacy\npreservation methodologies have gained significant attention in the literature.\nHowever, these strategies also need specific adjustments and modifications to\ncope with the advances in IoVs design. In the interim, Federated Learning (FL)\nhas been proven as an emerging idea to protect IoVs data privacy and security.\nOn the other hand, Blockchain technology is showing prominent possibilities\nwith secured, dispersed, and auditable data recording and sharing schemes. In\nthis paper, we present a comprehensive survey on the application and\nimplementation of Blockchain-Enabled Federated Learning frameworks for IoVs.\nBesides, probable issues, challenges, solutions, and future research directions\nfor BC-Enabled FL frameworks for IoVs are also presented. This survey can\nfurther be used as the basis for developing modern BC-Enabled FL solutions to\nresolve different data privacy issues and scenarios of IoVs.",
        "author": [
            "Mustain Billah",
            "Sk. Tanzir Mehedi",
            "Adnan Anwar",
            "Ziaur Rahman",
            "Rafiqul Islam"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.05192v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.AI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.05192v1",
        "arXiv ID": "2203.05192v1"
    },
    {
        "title": "Multi-objective optimization based network control principles for\n  identifying personalized drug targets with cancer",
        "Published: ": "2023-06-23T07:56:39Z",
        "abstract": "It is a big challenge to develop efficient models for identifying\npersonalized drug targets (PDTs) from high-dimensional personalized genomic\nprofile of individual patients. Recent structural network control principles\nhave introduced a new approach to discover PDTs by selecting an optimal set of\ndriver genes in personalized gene interaction network (PGIN). However, most of\ncurrent methods only focus on controlling the system through a minimum\ndriver-node set and ignore the existence of multiple candidate driver-node sets\nfor therapeutic drug target identification in PGIN. Therefore, this paper\nproposed multi-objective optimization-based structural network control\nprinciples (MONCP) by considering minimum driver nodes and maximum prior-known\ndrug-target information. To solve MONCP, a discrete multi-objective\noptimization problem is formulated with many constrained variables, and a novel\nevolutionary optimization model called LSCV-MCEA was developed by adapting a\nmulti-tasking framework and a rankings-based fitness function method. With\ngenomics data of patients with breast or lung cancer from The Cancer Genome\nAtlas database, the effectiveness of LSCV-MCEA was validated. The experimental\nresults indicated that compared with other advanced methods, LSCV-MCEA can more\neffectively identify PDTs with the highest Area Under the Curve score for\npredicting clinically annotated combinatorial drugs. Meanwhile, LSCV-MCEA can\nmore effectively solve MONCP than other evolutionary optimization methods in\nterms of algorithm convergence and diversity. Particularly, LSCV-MCEA can\nefficiently detect disease signals for individual patients with BRCA cancer.\nThe study results show that multi-objective optimization can solve structural\nnetwork control principles effectively and offer a new perspective for\nunderstanding tumor heterogeneity in cancer precision medicine.",
        "author": [
            "Jing Liang",
            "Zhuo Hu",
            "Zong-Wei Li",
            "Kang-Jia Qiao",
            "Wei-Feng Guo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2306.13349v1.pdf",
        "Categories": [
            [
                "cs.NE",
                "None",
                "H.4.2; D.2.7"
            ]
        ],
        "Link": "http://arxiv.org/abs/2306.13349v1",
        "arXiv ID": "2306.13349v1"
    },
    {
        "title": "Convolutional Sparse Kernel Network for Unsupervised Medical Image\n  Analysis",
        "Published: ": "2018-07-16T01:33:00Z",
        "abstract": "The availability of large-scale annotated image datasets and recent advances\nin supervised deep learning methods enable the end-to-end derivation of\nrepresentative image features that can impact a variety of image analysis\nproblems. Such supervised approaches, however, are difficult to implement in\nthe medical domain where large volumes of labelled data are difficult to obtain\ndue to the complexity of manual annotation and inter- and intra-observer\nvariability in label assignment. We propose a new convolutional sparse kernel\nnetwork (CSKN), which is a hierarchical unsupervised feature learning framework\nthat addresses the challenge of learning representative visual features in\nmedical image analysis domains where there is a lack of annotated training\ndata. Our framework has three contributions: (i) We extend kernel learning to\nidentify and represent invariant features across image sub-patches in an\nunsupervised manner. (ii) We initialise our kernel learning with a layer-wise\npre-training scheme that leverages the sparsity inherent in medical images to\nextract initial discriminative features. (iii) We adapt a multi-scale spatial\npyramid pooling (SPP) framework to capture subtle geometric differences between\nlearned visual features. We evaluated our framework in medical image retrieval\nand classification on three public datasets. Our results show that our CSKN had\nbetter accuracy when compared to other conventional unsupervised methods and\ncomparable accuracy to methods that used state-of-the-art supervised\nconvolutional neural networks (CNNs). Our findings indicate that our\nunsupervised CSKN provides an opportunity to leverage unannotated big data in\nmedical imaging repositories.",
        "author": [
            "Euijoon Ahn",
            "Jinman Kim",
            "Ashnil Kumar",
            "Michael Fulham",
            "Dagan Feng"
        ],
        "pdfLink": "http://arxiv.org/pdf/1807.05648v4.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1807.05648v4",
        "arXiv ID": "1807.05648v4"
    },
    {
        "title": "NetDP: An Industrial-Scale Distributed Network Representation Framework\n  for Default Prediction in Ant Credit Pay",
        "Published: ": "2020-04-01T02:22:33Z",
        "abstract": "Ant Credit Pay is a consumer credit service in Ant Financial Service Group.\nSimilar to credit card, loan default is one of the major risks of this credit\nproduct. Hence, effective algorithm for default prediction is the key to losses\nreduction and profits increment for the company. However, the challenges facing\nin our scenario are different from those in conventional credit card service.\nThe first one is scalability. The huge volume of users and their behaviors in\nAnt Financial requires the ability to process industrial-scale data and perform\nmodel training efficiently. The second challenges is the cold-start problem.\nDifferent from the manual review for credit card application in conventional\nbanks, the credit limit of Ant Credit Pay is automatically offered to users\nbased on the knowledge learned from big data. However, default prediction for\nnew users is suffered from lack of enough credit behaviors. It requires that\nthe proposal should leverage other new data source to alleviate the cold-start\nproblem. Considering the above challenges and the special scenario in Ant\nFinancial, we try to incorporate default prediction with network information to\nalleviate the cold-start problem. In this paper, we propose an industrial-scale\ndistributed network representation framework, termed NetDP, for default\nprediction in Ant Credit Pay. The proposal explores network information\ngenerated by various interaction between users, and blends unsupervised and\nsupervised network representation in a unified framework for default prediction\nproblem. Moreover, we present a parameter-server-based distributed implement of\nour proposal to handle the scalability challenge. Experimental results\ndemonstrate the effectiveness of our proposal, especially in cold-start\nproblem, as well as the efficiency for industrial-scale dataset.",
        "author": [
            "Jianbin Lin",
            "Zhiqiang Zhang",
            "Jun Zhou",
            "Xiaolong Li",
            "Jingli Fang",
            "Yanming Fang",
            "Quan Yu",
            "Yuan Qi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2004.00201v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "q-fin.ST",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/2004.00201v1",
        "arXiv ID": "2004.00201v1"
    },
    {
        "title": "Prototype Propagation Networks (PPN) for Weakly-supervised Few-shot\n  Learning on Category Graph",
        "Published: ": "2019-05-10T09:57:23Z",
        "abstract": "A variety of machine learning applications expect to achieve rapid learning\nfrom a limited number of labeled data. However, the success of most current\nmodels is the result of heavy training on big data. Meta-learning addresses\nthis problem by extracting common knowledge across different tasks that can be\nquickly adapted to new tasks. However, they do not fully explore\nweakly-supervised information, which is usually free or cheap to collect. In\nthis paper, we show that weakly-labeled data can significantly improve the\nperformance of meta-learning on few-shot classification. We propose prototype\npropagation network (PPN) trained on few-shot tasks together with data\nannotated by coarse-label. Given a category graph of the targeted fine-classes\nand some weakly-labeled coarse-classes, PPN learns an attention mechanism which\npropagates the prototype of one class to another on the graph, so that the\nK-nearest neighbor (KNN) classifier defined on the propagated prototypes\nresults in high accuracy across different few-shot tasks. The training tasks\nare generated by subgraph sampling, and the training objective is obtained by\naccumulating the level-wise classification loss on the subgraph. The resulting\ngraph of prototypes can be continually re-used and updated for new tasks and\nclasses. We also introduce two practical test/inference settings which differ\naccording to whether the test task can leverage any weakly-supervised\ninformation as in training. On two benchmarks, PPN significantly outperforms\nmost recent few-shot learning methods in different settings, even when they are\nalso allowed to train on weakly-labeled data.",
        "author": [
            "Lu Liu",
            "Tianyi Zhou",
            "Guodong Long",
            "Jing Jiang",
            "Lina Yao",
            "Chengqi Zhang"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.04042v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.CV",
                "cs.NE",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.04042v2",
        "arXiv ID": "1905.04042v2"
    },
    {
        "title": "Ghost Cities Analysis Based on Positioning Data in China",
        "Published: ": "2015-10-28T21:51:51Z",
        "abstract": "Real estate projects are developed excessively in China in this decade. Many\nnew housing districts are built, but they far exceed the actual demand in some\ncities. These cities with a high housing vacancy rate are called ghost cities.\nThe real situation of vacant housing areas in China has not been studied in\nprevious research. This study, using Baidu positioning data, presents the\nspatial distribution of the vacant housing areas in China and classifies cities\nwith a large vacant housing area as cities or tourism sites. To the best of our\nknowledge, it is the first time that we detected and analyzed the ghost cities\nin China at such fine scale. To understand the human dynamic in ghost cities,\nwe select one city and one tourism sites as cases to analyze the features of\nhuman dynamics. This study illustrates the capability of big data in sensing\nour cities objectively and comprehensively.",
        "author": [
            "Guanghua Chi",
            "Yu Liu",
            "Zhengwei Wu",
            "Haishan Wu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1510.08505v2.pdf",
        "Categories": [
            [
                "cs.SI",
                "cs.CY",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1510.08505v2",
        "arXiv ID": "1510.08505v2"
    },
    {
        "title": "An Adversarial Domain Separation Framework for Septic Shock Early\n  Prediction Across EHR Systems",
        "Published: ": "2020-10-26T23:41:33Z",
        "abstract": "Modeling patient disease progression using Electronic Health Records (EHRs)\nis critical to assist clinical decision making. While most of prior work has\nmainly focused on developing effective disease progression models using EHRs\ncollected from an individual medical system, relatively little work has\ninvestigated building robust yet generalizable diagnosis models across\ndifferent systems. In this work, we propose a general domain adaptation (DA)\nframework that tackles two categories of discrepancies in EHRs collected from\ndifferent medical systems: one is caused by heterogeneous patient populations\n(covariate shift) and the other is caused by variations in data collection\nprocedures (systematic bias). Prior research in DA has mainly focused on\naddressing covariate shift but not systematic bias. In this work, we propose an\nadversarial domain separation framework that addresses both categories of\ndiscrepancies by maintaining one globally-shared invariant latent\nrepresentation across all systems} through an adversarial learning process,\nwhile also allocating a domain-specific model for each system to extract local\nlatent representations that cannot and should not be unified across systems.\nMoreover, our proposed framework is based on variational recurrent neural\nnetwork (VRNN) because of its ability to capture complex temporal dependencies\nand handling missing values in time-series data. We evaluate our framework for\nearly diagnosis of an extremely challenging condition, septic shock, using two\nreal-world EHRs from distinct medical systems in the U.S. The results show that\nby separating globally-shared from domain-specific representations, our\nframework significantly improves septic shock early prediction performance in\nboth EHRs and outperforms the current state-of-the-art DA models.",
        "author": [
            "Farzaneh Khoshnevisan",
            "Min Chi"
        ],
        "pdfLink": "http://arxiv.org/pdf/2010.13952v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.NE"
            ]
        ],
        "Link": "http://arxiv.org/abs/2010.13952v1",
        "arXiv ID": "2010.13952v1"
    },
    {
        "title": "PIFu for the Real World: A Self-supervised Framework to Reconstruct\n  Dressed Human from Single-view Images",
        "Published: ": "2022-08-23T07:00:44Z",
        "abstract": "It is very challenging to accurately reconstruct sophisticated human geometry\ncaused by various poses and garments from a single image. Recently, works based\non pixel-aligned implicit function (PIFu) have made a big step and achieved\nstate-of-the-art fidelity on image-based 3D human digitization. However, the\ntraining of PIFu relies heavily on expensive and limited 3D ground truth data\n(i.e. synthetic data), thus hindering its generalization to more diverse real\nworld images. In this work, we propose an end-to-end self-supervised network\nnamed SelfPIFu to utilize abundant and diverse in-the-wild images, resulting in\nlargely improved reconstructions when tested on unconstrained in-the-wild\nimages. At the core of SelfPIFu is the depth-guided volume-/surface-aware\nsigned distance fields (SDF) learning, which enables self-supervised learning\nof a PIFu without access to GT mesh. The whole framework consists of a normal\nestimator, a depth estimator, and a SDF-based PIFu and better utilizes extra\ndepth GT during training. Extensive experiments demonstrate the effectiveness\nof our self-supervised framework and the superiority of using depth as input.\nOn synthetic data, our Intersection-Over-Union (IoU) achieves to 93.5%, 18%\nhigher compared with PIFuHD. For in-the-wild images, we conduct user studies on\nthe reconstructed results, the selection rate of our results is over 68%\ncompared with other state-of-the-art methods.",
        "author": [
            "Zhangyang Xiong",
            "Dong Du",
            "Yushuang Wu",
            "Jingqi Dong",
            "Di Kang",
            "Linchao Bao",
            "Xiaoguang Han"
        ],
        "pdfLink": "http://arxiv.org/pdf/2208.10769v1.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2208.10769v1",
        "arXiv ID": "2208.10769v1"
    },
    {
        "title": "Incremental Learning for Heterogeneous Structure Segmentation in Brain\n  Tumor MRI",
        "Published: ": "2023-05-30T20:39:03Z",
        "abstract": "Deep learning (DL) models for segmenting various anatomical structures have\nachieved great success via a static DL model that is trained in a single source\ndomain. Yet, the static DL model is likely to perform poorly in a continually\nevolving environment, requiring appropriate model updates. In an incremental\nlearning setting, we would expect that well-trained static models are updated,\nfollowing continually evolving target domain data -- e.g., additional lesions\nor structures of interest -- collected from different sites, without\ncatastrophic forgetting. This, however, poses challenges, due to distribution\nshifts, additional structures not seen during the initial model training, and\nthe absence of training data in a source domain. To address these challenges,\nin this work, we seek to progressively evolve an ``off-the-shelf\" trained\nsegmentation model to diverse datasets with additional anatomical categories in\na unified manner. Specifically, we first propose a divergence-aware dual-flow\nmodule with balanced rigidity and plasticity branches to decouple old and new\ntasks, which is guided by continuous batch renormalization. Then, a\ncomplementary pseudo-label training scheme with self-entropy regularized\nmomentum MixUp decay is developed for adaptive network optimization. We\nevaluated our framework on a brain tumor segmentation task with continually\nchanging target domains -- i.e., new MRI scanners/modalities with incremental\nstructures. Our framework was able to well retain the discriminability of\npreviously learned structures, hence enabling the realistic life-long\nsegmentation model extension along with the widespread accumulation of big\nmedical data.",
        "author": [
            "Xiaofeng Liu",
            "Helen A. Shih",
            "Fangxu Xing",
            "Emiliano Santarnecchi",
            "Georges El Fakhri",
            "Jonghye Woo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2305.19404v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "physics.med-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2305.19404v1",
        "arXiv ID": "2305.19404v1"
    },
    {
        "title": "Real-time stream processing in radio astronomy",
        "Published: ": "2019-12-19T07:10:12Z",
        "abstract": "A major challenge in modern radio astronomy is dealing with the massive data\nvolumes generated by wide-bandwidth receivers. Such massive data rates are\noften too great for a single device to cope, and so processing must be split\nacross multiple devices working in parallel. These devices must work in unison\nto process incoming data in real time, reduce the data volume to a manageable\nsize, and output a science-ready data product. The aim of this chapter is to\ngive a broad overview of how digital systems for radio telescopes are commonly\nimplemented, with a focus on real-time stream processing over multiple compute\ndevices.",
        "author": [
            "Danny C. Price"
        ],
        "pdfLink": "http://arxiv.org/pdf/1912.09041v1.pdf",
        "Categories": [
            [
                "astro-ph.IM"
            ]
        ],
        "Link": "http://arxiv.org/abs/1912.09041v1",
        "arXiv ID": "1912.09041v1"
    },
    {
        "title": "From Internet of Things to Internet of Data Apps",
        "Published: ": "2023-09-08T18:26:05Z",
        "abstract": "We introduce the Internet of Data Apps (IoDA), representing the next natural\nprogression of the Internet, Big Data, AI, and the Internet of Things. Despite\nadvancements in these fields, the full potential of universal data access - the\ncapability to seamlessly consume and contribute data via data applications -\nremains stifled by organizational and technological silos. To address these\nconstraints, we propose the designs of an IoDA layer borrowing inspirations\nfrom the standard Internet protocols. This layer facilitates the\ninterconnection of data applications across different devices and domains. This\nshort paper serves as an invitation to dialogue over this proposal.",
        "author": [
            "Silvery Fu",
            "Sylvia Ratnasamy"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.04546v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.04546v1",
        "arXiv ID": "2309.04546v1"
    },
    {
        "title": "Data Science in Biomedicine",
        "Published: ": "2019-09-09T11:31:40Z",
        "abstract": "We highlight the role of Data Science in Biomedicine. Our manuscript goes\nfrom the general to the particular, presenting a global definition of Data\nScience and showing the trend for this discipline together with the terms of\ncloud computing and big data. In addition, since Data Science is mostly related\nto areas like economy or business, we describe its importance in biomedicine.\nBiomedical Data Science (BDS) presents the challenge of dealing with data\ncoming from a range of biological and medical research, focusing on\nmethodologies to advance the biomedical science discoveries, in an\ninterdisciplinary context.",
        "author": [
            "Yovaninna Alarc\u00f3n-Soto",
            "Jenifer Espasand\u00edn-Dom\u00ednguez",
            "Ipek Guler",
            "Mercedes Conde-Amboage",
            "Francisco Gude-Sampedro",
            "Klaus Langohr",
            "Carmen Cadarso-Su\u00e1rez",
            "Guadalupe G\u00f3mez-Melis"
        ],
        "pdfLink": "http://arxiv.org/pdf/1909.04486v1.pdf",
        "Categories": [
            [
                "stat.OT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1909.04486v1",
        "arXiv ID": "1909.04486v1"
    },
    {
        "title": "MIND THE GAP: Is The Too Big To Fail Problem Resolved?",
        "Published: ": "2019-04-23T18:00:21Z",
        "abstract": "The faintness of satellite systems in galaxy groups has contributed to the\nwidely discussed \"missing satellite\" and \"too big to fail\" issues. Using\ntechniques based on Tremaine & Richstone (1977), we show that there is no\nproblem with the luminosity function computed from modern codes per se, but\nthat the gap between first and second brightest systems is too big {\\it given}\nthe luminosity function, that the same large gap is found in modern, large\nscale baryonic $\\Lambda$CDM simulations such as EAGLE and IllustrisTNG, is even\ngreater in dark matter only simulations, and finally, that this is most likely\ndue to gravitationally induced merging caused by classical dynamical friction.\nQuantitatively the gap is larger in the computed simulations than in the\nrandomized ones by $1.79 \\pm 1.04$, $1.51 \\pm 0.93$, $3.43 \\pm 1.44$ and $3.33\n\\pm 1.35$ magnitudes in the EAGLE, IllustrisTNG, and dark matter only\nsimulations of EAGLE and IllustrisTNG respectively. Furthermore the anomalous\ngaps in the simulated systems are even larger than in the real data by over\nhalf a magnitude and are still larger in the dark matter only simulations.\nBriefly stated, $\\Lambda$CDM does not have a problem with an absence of \"too\nbig to fail\" galaxies. Statistically significant large gaps between first and\nsecond brightest galaxies are to be expected.",
        "author": [
            "Jeremiah P. Ostriker",
            "Ena Choi",
            "Anthony Chow",
            "Kundan Guha"
        ],
        "pdfLink": "http://arxiv.org/pdf/1904.10471v2.pdf",
        "Categories": [
            [
                "astro-ph.GA"
            ]
        ],
        "Link": "http://arxiv.org/abs/1904.10471v2",
        "arXiv ID": "1904.10471v2"
    },
    {
        "title": "Fast Disparity Estimation from a Single Compressed Light Field\n  Measurement",
        "Published: ": "2022-09-22T22:59:09Z",
        "abstract": "The abundant spatial and angular information from light fields has allowed\nthe development of multiple disparity estimation approaches. However, the\nacquisition of light fields requires high storage and processing cost, limiting\nthe use of this technology in practical applications. To overcome these\ndrawbacks, the compressive sensing (CS) theory has allowed the development of\noptical architectures to acquire a single coded light field measurement. This\nmeasurement is decoded using an optimization algorithm or deep neural network\nthat requires high computational costs. The traditional approach for disparity\nestimation from compressed light fields requires first recovering the entire\nlight field and then a post-processing step, thus requiring long times. In\ncontrast, this work proposes a fast disparity estimation from a single\ncompressed measurement by omitting the recovery step required in traditional\napproaches. Specifically, we propose to jointly optimize an optical\narchitecture for acquiring a single coded light field snapshot and a\nconvolutional neural network (CNN) for estimating the disparity maps.\nExperimentally, the proposed method estimates disparity maps comparable with\nthose obtained from light fields reconstructed using deep learning approaches.\nFurthermore, the proposed method is 20 times faster in training and inference\nthan the best method that estimates the disparity from reconstructed light\nfields.",
        "author": [
            "Emmanuel Martinez",
            "Edwin Vargas",
            "Henry Arguello"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.11342v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.11342v1",
        "arXiv ID": "2209.11342v1"
    },
    {
        "title": "Dataspace architecture and manage its components class projection",
        "Published: ": "2019-05-03T16:18:19Z",
        "abstract": "Big Data technology is described. Big data is a popular term used to describe\nthe exponential growth and availability of data, both structured and\nunstructured. There is constructed dataspace architecture. Dataspace has\nfocused solely - and passionately - on providing unparalleled expertise in\nbusiness intelligence and data warehousing strategy and implementation.\nDataspaces are an abstraction in data management that aims to overcome some of\nthe problems encountered in data integration system. In our case it is block\nvector for heterogeneous data representation. Traditionally, data integration\nand data exchange systems have aimed to offer many of the purported services of\ndataspace systems. Dataspaces can be viewed as a next step in the evolution of\ndata integration architectures, but are distinct from current data integration\nsystems in the following way. Data integration systems require semantic\nintegration before any services can be provided. Hence, although there is not a\nsingle schema to which all the data conforms and the data resides in a\nmultitude of host systems, the data integration system knows the precise\nrelationships between the terms used in each schema. As a result, significant\nup-front effort is required in order to set up a data integration system. For\nrealization of data integration from different sources we used SQL Server\nIntegration Services, SSIS. For developing the portal as an architectural\npattern there is used pattern Model-View-Controller (MVC). There is specifics\ndebug operation data space as a complex system. The query translator in\nBackus/Naur Form is give.",
        "author": [
            "Nataliya Shakhovska",
            "Yurii Bolubash"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.01307v1.pdf",
        "Categories": [
            [
                "cs.DB",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.01307v1",
        "arXiv ID": "1905.01307v1"
    },
    {
        "title": "Classifying Network Data with Deep Kernel Machines",
        "Published: ": "2010-01-22T15:20:11Z",
        "abstract": "Inspired by a growing interest in analyzing network data, we study the\nproblem of node classification on graphs, focusing on approaches based on\nkernel machines. Conventionally, kernel machines are linear classifiers in the\nimplicit feature space. We argue that linear classification in the feature\nspace of kernels commonly used for graphs is often not enough to produce good\nresults. When this is the case, one naturally considers nonlinear classifiers\nin the feature space. We show that repeating this process produces something we\ncall \"deep kernel machines.\" We provide some examples where deep kernel\nmachines can make a big difference in classification performance, and point out\nsome connections to various recent literature on deep architectures in\nartificial intelligence and machine learning.",
        "author": [
            "Xiao Tang",
            "Mu Zhu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1001.4019v1.pdf",
        "Categories": [
            [
                "stat.ML",
                "stat.ME"
            ]
        ],
        "Link": "http://arxiv.org/abs/1001.4019v1",
        "arXiv ID": "1001.4019v1"
    },
    {
        "title": "Simple Combinatorial Construction of the $k^{o(1)}$-Lower Bound for\n  Approximating the Parameterized $k$-Clique",
        "Published: ": "2023-04-15T09:56:28Z",
        "abstract": "In the parameterized $k$-clique problem, or $k$-Clique for short, we are\ngiven a graph $G$ and a parameter $k\\ge 1$. The goal is to decide whether there\nexist $k$ vertices in $G$ that induce a complete subgraph (i.e., a $k$-clique).\nThis problem plays a central role in the theory of parameterized intractability\nas one of the first W[1]-complete problems. Existing research has shown that\neven an FPT-approximation algorithm for $k$-Clique with arbitrary ratio does\nnot exist, assuming the Gap-Exponential-Time Hypothesis (Gap-ETH) [Chalermsook\net al., FOCS'17 and SICOMP]. However, whether this inapproximability result can\nbe based on the standard assumption of $\\mathrm{W} 1\\ne \\mathrm{FPT}$ remains\nunclear. The recent breakthrough of Bingkai Lin [STOC'21] and subsequent works\nby Karthik C.S. and Khot [CCC'22], and by Lin, Ren, Sun Wang [ICALP'22] give a\ntechnique that bypasses Gap-ETH, thus leading to the inapproximability ratio of\n$O(1)$ and $k^{o(1)}$ under $\\mathrm{W}[1]$-hardness (the first two) and ETH\n(for the latter one). All the work along this line follows the framework\ndeveloped by Lin, which starts from the $k$-vector-sum problem and requires\nsome involved algebraic techniques.\n  This paper presents an alternative framework for proving the W[1]-hardness of\nthe $k^{o(1)}$-FPT-inapproximability of $k$-Clique. Using this framework, we\nobtain a gap-producing self-reduction of $k$-Clique without any intermediate\nalgebraic problem. More precisely, we reduce from $(k,k-1)$-Gap Clique to\n$(q^k, q^{k-1})$-Gap Clique, for any function $q$ depending only on the\nparameter $k$, thus implying the $k^{o(1)}$-inapproximability result when $q$\nis sufficiently large. Our proof is relatively simple and mostly combinatorial.\nAt the core of our construction is a novel encoding of $k$-element subset\nstemming from the theory of \"network coding\" and a \"Sidon set\" representation\nof a graph.",
        "author": [
            "Yijia Chen",
            "Yi Feng",
            "Bundit Laekhanukit",
            "Yanlin Liu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2304.07516v1.pdf",
        "Categories": [
            [
                "cs.CC",
                "cs.DM",
                "cs.DS",
                "math.CO",
                "68Q27, 68Q17",
                "F.2.2; G.2.1; G.2.2"
            ]
        ],
        "Link": "http://arxiv.org/abs/2304.07516v1",
        "arXiv ID": "2304.07516v1"
    },
    {
        "title": "Perceptual Compressive Sensing",
        "Published: ": "2018-02-01T07:19:18Z",
        "abstract": "Compressive sensing (CS) works to acquire measurements at sub-Nyquist rate\nand recover the scene images. Existing CS methods always recover the scene\nimages in pixel level. This causes the smoothness of recovered images and lack\nof structure information, especially at a low measurement rate. To overcome\nthis drawback, in this paper, we propose perceptual CS to obtain high-level\nstructured recovery. Our task no longer focuses on pixel level. Instead, we\nwork to make a better visual effect. In detail, we employ perceptual loss,\ndefined on feature level, to enhance the structure information of the recovered\nimages. Experiments show that our method achieves better visual results with\nstronger structure information than existing CS methods at the same measurement\nrate.",
        "author": [
            "Jiang Du",
            "Xuemei Xie",
            "Chenye Wang",
            "Guangming Shi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1802.00176v2.pdf",
        "Categories": [
            [
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/1802.00176v2",
        "arXiv ID": "1802.00176v2"
    },
    {
        "title": "Alignment-free Genomic Analysis via a Big Data Spark Platform",
        "Published: ": "2020-05-02T23:33:28Z",
        "abstract": "Motivation: Alignment-free distance and similarity functions (AF functions,\nfor short) are a well established alternative to two and multiple sequence\nalignments for many genomic, metagenomic and epigenomic tasks. Due to\ndata-intensive applications, the computation of AF functions is a Big Data\nproblem, with the recent Literature indicating that the development of fast and\nscalable algorithms computing AF functions is a high-priority task. Somewhat\nsurprisingly, despite the increasing popularity of Big Data technologies in\nComputational Biology, the development of a Big Data platform for those tasks\nhas not been pursued, possibly due to its complexity. Results: We fill this\nimportant gap by introducing FADE, the first extensible, efficient and scalable\nSpark platform for Alignment-free genomic analysis. It supports natively\neighteen of the best performing AF functions coming out of a recent hallmark\nbenchmarking study. FADE development and potential impact comprises novel\naspects of interest. Namely, (a) a considerable effort of distributed\nalgorithms, the most tangible result being a much faster execution time of\nreference methods like MASH and FSWM; (b) a software design that makes FADE\nuser-friendly and easily extendable by Spark non-specialists; (c) its ability\nto support data- and compute-intensive tasks. About this, we provide a novel\nand much needed analysis of how informative and robust AF functions are, in\nterms of the statistical significance of their output. Our findings naturally\nextend the ones of the highly regarded benchmarking study, since the functions\nthat can really be used are reduced to a handful of the eighteen included in\nFADE.",
        "author": [
            "Umberto Ferraro Petrillo",
            "Francesco Palini",
            "Giuseppe Cattaneo",
            "Raffaele Giancarlo"
        ],
        "pdfLink": "http://arxiv.org/pdf/2005.00942v4.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2005.00942v4",
        "arXiv ID": "2005.00942v4"
    },
    {
        "title": "Flow: Separating Consensus and Compute -- Block Formation and Execution",
        "Published: ": "2020-02-18T06:48:51Z",
        "abstract": "Most current blockchains require all full nodes to execute all tasks limits\nthe throughput of existing blockchains, which are well documented and among the\nmost significant hurdles for the widespread adoption of decentralized\ntechnology.\n  This paper extends out presentation of Flow, a pipelined blockchain\narchitecture, which separates the process of consensus on the transaction order\nfrom transaction computation. As we experimentally showed in our previous white\npaper, our architecture provides a significant throughput improvement while\npreserving the security of the system. Flow exploits the heterogeneity offered\nby the nodes, in terms of bandwidth, storage, and computational capacity, and\ndefines the roles for the nodes based on their tasks in the pipeline, i.e.,\nCollector, Consensus, Execution, and Verification. While transaction collection\nfrom the user agents is completed through the bandwidth-optimized Collector\nNodes, the execution of them is done by the compute-optimized Execution Nodes.\nChecking the execution result is then distributed among a more extensive set of\nVerification Nodes, which confirm the result is correct in a distributed and\nparallel manner. In contrast to more traditional blockchain architectures,\nFlow's Consensus Nodes do not execute the transaction. Instead, Verification\nNodes report observed faulty executions to the Consensus Nodes, which\nadjudicate the received challenges and slash malicious actors.\n  In this paper, we detail the lifecycle of the transactions from the\nsubmission to the system until they are getting executed. The paper covers the\nCollector, Consensus, and Execution role. We provide a protocol specification\nof collecting the transactions, forming a block, and executing the resulting\nblock. Moreover, we elaborate on the safety and liveness of the system\nconcerning these processes.",
        "author": [
            "Alexander Hentschel",
            "Yahya Hassanzadeh-Nazarabadi",
            "Ramtin Seraj",
            "Dieter Shirley",
            "Layne Lafrance"
        ],
        "pdfLink": "http://arxiv.org/pdf/2002.07403v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2002.07403v1",
        "arXiv ID": "2002.07403v1"
    },
    {
        "title": "Proof of User Similarity: the Spatial Measurer of Blockchain",
        "Published: ": "2022-10-28T06:12:59Z",
        "abstract": "Although proof of work (PoW) consensus dominates the current blockchain-based\nsystems mostly, it has always been criticized for the uneconomic brute-force\ncalculation. As alternatives, energy-conservation and energy-recycling\nmechanisms heaved in sight. In this paper, we propose proof of user similarity\n(PoUS), a distinct energy-recycling consensus mechanism, harnessing the\nvaluable computing power to calculate the similarities of users, and enact the\ncalculation results into the packing rule. However, the expensive calculation\nrequired in PoUS challenges miners in participating, and may induce plagiarism\nand lying risks. To resolve these issues, PoUS embraces the best-effort schema\nby allowing miners to compute partially. Besides, a voting mechanism based on\nthe two-parties computation and Bayesian truth serum is proposed to guarantee\nprivacy-preserved voting and truthful reports. Noticeably, PoUS distinguishes\nitself in recycling the computing power back to blockchain since it turns the\nresource wastage to facilitate refined cohort analysis of users, serving as the\nspatial measurer and enabling a searchable blockchain. We build a prototype of\nPoUS and compare its performance with PoW. The results show that PoUS\noutperforms PoW in achieving an average TPS improvement of 24.01% and an\naverage confirmation latency reduction of 43.64%. Besides, PoUS functions well\nin mirroring the spatial information of users, with negligible computation time\nand communication cost.",
        "author": [
            "Shengling Wang",
            "Lina Shi",
            "Hongwei Shi",
            "Yifang Zhang",
            "Qin Hu",
            "Xiuzhen Cheng"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.01143v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "14J60",
                "F.2.2; I.2.7"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.01143v1",
        "arXiv ID": "2211.01143v1"
    },
    {
        "title": "Floods impact dynamics quantified from big data sources",
        "Published: ": "2018-04-24T16:45:27Z",
        "abstract": "Natural disasters affect hundreds of millions of people worldwide every year.\nEarly warning, humanitarian response and recovery mechanisms can be improved by\nusing big data sources. Measuring the different dimensions of the impact of\nnatural disasters is critical for designing policies and building up\nresilience. Detailed quantification of the movement and behaviours of affected\npopulations requires the use of high granularity data that entails privacy\nrisks. Leveraging all this data is costly and has to be done ensuring privacy\nand security of large amounts of data. Proxies based on social media and data\naggregates would streamline this process by providing evidences and narrowing\nrequirements. We propose a framework that integrates environmental data, social\nmedia, remote sensing, digital topography and mobile phone data to understand\ndifferent types of floods and how data can provide insights useful for managing\nhumanitarian action and recovery plans. Thus, data is dynamically requested\nupon data-based indicators forming a multi-granularity and multi-access data\npipeline. We present a composed study of three cases to show potential\nvariability in the natures of floodings,as well as the impact and applicability\nof data sources. Critical heterogeneity of the available data in the different\ncases has to be addressed in order to design systematic approaches based on\ndata. The proposed framework establishes the foundation to relate the physical\nand socio-economical impacts of floods.",
        "author": [
            "David Pastor-Escuredo",
            "Yolanda Torres",
            "Maria Martinez",
            "Pedro J. Zufiria"
        ],
        "pdfLink": "http://arxiv.org/pdf/1804.09129v1.pdf",
        "Categories": [
            [
                "cs.CY",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/1804.09129v1",
        "arXiv ID": "1804.09129v1"
    },
    {
        "title": "PALM: An Incremental Construction of Hyperplanes for Data Stream\n  Regression",
        "Published: ": "2018-05-11T07:23:20Z",
        "abstract": "Data stream has been the underlying challenge in the age of big data because\nit calls for real-time data processing with the absence of a retraining process\nand/or an iterative learning approach. In realm of fuzzy system community, data\nstream is handled by algorithmic development of self-adaptive neurofuzzy\nsystems (SANFS) characterized by the single-pass learning mode and the open\nstructure property which enables effective handling of fast and rapidly\nchanging natures of data streams. The underlying bottleneck of SANFSs lies in\nits design principle which involves a high number of free parameters (rule\npremise and rule consequent) to be adapted in the training process. This figure\ncan even double in the case of type-2 fuzzy system. In this work, a novel\nSANFS, namely parsimonious learning machine (PALM), is proposed. PALM features\nutilization of a new type of fuzzy rule based on the concept of hyperplane\nclustering which significantly reduces the number of network parameters because\nit has no rule premise parameters. PALM is proposed in both type-1 and type-2\nfuzzy systems where all of which characterize a fully dynamic rule-based\nsystem. That is, it is capable of automatically generating, merging and tuning\nthe hyperplane-based fuzzy rule in the single pass manner. Moreover, an\nextension of PALM, namely recurrent PALM (rPALM), is proposed and adopts the\nconcept of teacher-forcing mechanism in the deep learning literature. The\nefficacy of PALM has been evaluated through numerical study with six real-world\nand synthetic data streams from public database and our own real-world project\nof autonomous vehicles. The proposed model showcases significant improvements\nin terms of computational complexity and number of required parameters against\nseveral renowned SANFSs, while attaining comparable and often better predictive\naccuracy.",
        "author": [
            "Md Meftahul Ferdaus",
            "Mahardhika Pratama",
            "Sreenatha G. Anavatti",
            "Matthew A. Garratt"
        ],
        "pdfLink": "http://arxiv.org/pdf/1805.04258v2.pdf",
        "Categories": [
            [
                "cs.NE"
            ]
        ],
        "Link": "http://arxiv.org/abs/1805.04258v2",
        "arXiv ID": "1805.04258v2"
    },
    {
        "title": "Knowledge Discovery in Cryptocurrency Transactions: A Survey",
        "Published: ": "2020-10-02T14:38:08Z",
        "abstract": "Cryptocurrencies gain trust in users by publicly disclosing the full creation\nand transaction history. In return, the transaction history faithfully records\nthe whole spectrum of cryptocurrency user behaviors. This article analyzes and\nsummarizes the existing research on knowledge discovery in the cryptocurrency\ntransactions using data mining techniques. Specifically, we classify the\nexisting research into three aspects, i.e., transaction tracings and blockchain\naddress linking, the analyses of collective user behaviors, and the study of\nindividual user behaviors. For each aspect, we present the problems, summarize\nthe methodologies, and discuss major findings in the literature. Furthermore,\nan enumeration of transaction data parsing and visualization tools and services\nis also provided. Finally, we outline several future directions in this\nresearch area, such as the current rapid development of Decentralized Finance\n(De-Fi) and digital fiat money.",
        "author": [
            "Xiao Fan Liu",
            "Xin-Jian Jiang",
            "Si-Hao Liu",
            "Chi Kong Tse"
        ],
        "pdfLink": "http://arxiv.org/pdf/2010.01031v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY",
                "q-fin.ST"
            ]
        ],
        "Link": "http://arxiv.org/abs/2010.01031v1",
        "arXiv ID": "2010.01031v1"
    },
    {
        "title": "Towards reliable and transparent vaccine phase III trials with smart\n  contracts",
        "Published: ": "2021-02-13T22:38:36Z",
        "abstract": "Transforming a vaccine concept into a real vaccine product is a complicated\nprocess and includes finding suitable antigens and regulatory, technical, and\nmanufacturing obstacles. A relevant issue within this scope is the clinical\ntrial process. Monitoring and ensuring the integrity of trial data using the\ntraditional system is not always feasible. The search for a vaccine against the\ncoronavirus SARS-CoV-2 illustrates this situation. The scientific credibility\nof findings from several vaccines' clinical trials contributed to distorted\nperceptions concerning the benefits and risks of the drug. This scenario is\nideal for applying technologies such as Blockchain and Smart Contracts in\nhealthcare issues. This paper proposes a protocol based on Smart Contracts,\nnamed VaccSC, to enable transparency, accounting, and confidentiality to Phase\nIII of vaccine experiments. The protocol was implemented in Solidity language,\nand results show that the VaccSC enables double-blindness, randomization, and\nthe auditability of clinical data, even in the presence of dishonest\nparticipants.",
        "author": [
            "Ivan da Silva Sendin",
            "Rodrigo Sanches Miani"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.07022v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.CY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.07022v1",
        "arXiv ID": "2102.07022v1"
    },
    {
        "title": "A decentralized FAIR platform to facilitate data sharing in the life\n  sciences",
        "Published: ": "2021-02-08T11:38:14Z",
        "abstract": "The Hybrid Technology Hub and many other research centers work in\ncross-functional teams whose workflow is not necessarily linear and where in\nmany cases technology advances are done through parallel work. The lack of\nproper tools and platforms for a collaborative environment can create time lags\nin coordination and limited sharing of research findings. To solve this, we\nhave developed a simple, user-friendly platform built for academic and\nscientific research collaboration. To ensure FAIRness compliance, the platform\nconsists of a metadata quality control based on blockchain technologies. The\ndata is stored separately in a distributed object storage that functions as a\ncloud. The platform also implements a version control system; it provides a\nhistory track of the project along with the possibility of reviewing the\nproject's development. This platform aims to be a standardized tool within the\nHybrid Technology Hub to ease collaboration, speed research workflow and\nimprove research quality.",
        "author": [
            "Pavel Vazquez",
            "Kayoko Shoji",
            "Steffen Novik",
            "Stefan Krauss",
            "Simon Rayner"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.08947v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.08947v1",
        "arXiv ID": "2102.08947v1"
    },
    {
        "title": "An Overview of Federated Learning at the Edge and Distributed Ledger\n  Technologies for Robotic and Autonomous Systems",
        "Published: ": "2021-04-20T17:31:33Z",
        "abstract": "Autonomous systems are becoming inherently ubiquitous with the advancements\nof computing and communication solutions enabling low-latency offloading and\nreal-time collaboration of distributed devices. Decentralized technologies with\nblockchain and distributed ledger technologies (DLTs) are playing a key role.\nAt the same time, advances in deep learning (DL) have significantly raised the\ndegree of autonomy and level of intelligence of robotic and autonomous systems.\nWhile these technological revolutions were taking place, raising concerns in\nterms of data security and end-user privacy has become an inescapable research\nconsideration. Federated learning (FL) is a promising solution to\nprivacy-preserving DL at the edge, with an inherently distributed nature by\nlearning on isolated data islands and communicating only model updates.\nHowever, FL by itself does not provide the levels of security and robustness\nrequired by today's standards in distributed autonomous systems. This survey\ncovers applications of FL to autonomous robots, analyzes the role of DLT and FL\nfor these systems, and introduces the key background concepts and\nconsiderations in current research.",
        "author": [
            "Yu Xianjia",
            "Jorge Pe\u00f1a Queralta",
            "Jukka Heikkonen",
            "Tomi Westerlund"
        ],
        "pdfLink": "http://arxiv.org/pdf/2104.10141v2.pdf",
        "Categories": [
            [
                "cs.RO"
            ]
        ],
        "Link": "http://arxiv.org/abs/2104.10141v2",
        "arXiv ID": "2104.10141v2"
    },
    {
        "title": "A Comprehensive Survey of Incentive Mechanism for Federated Learning",
        "Published: ": "2021-06-27T12:24:15Z",
        "abstract": "Federated learning utilizes various resources provided by participants to\ncollaboratively train a global model, which potentially address the data\nprivacy issue of machine learning. In such promising paradigm, the performance\nwill be deteriorated without sufficient training data and other resources in\nthe learning process. Thus, it is quite crucial to inspire more participants to\ncontribute their valuable resources with some payments for federated learning.\nIn this paper, we present a comprehensive survey of incentive schemes for\nfederate learning. Specifically, we identify the incentive problem in federated\nlearning and then provide a taxonomy for various schemes. Subsequently, we\nsummarize the existing incentive mechanisms in terms of the main techniques,\nsuch as Stackelberg game, auction, contract theory, Shapley value,\nreinforcement learning, blockchain. By reviewing and comparing some impressive\nresults, we figure out three directions for the future study.",
        "author": [
            "Rongfei Zeng",
            "Chao Zeng",
            "Xingwei Wang",
            "Bo Li",
            "Xiaowen Chu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2106.15406v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.GT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2106.15406v1",
        "arXiv ID": "2106.15406v1"
    },
    {
        "title": "A Data Science Pipeline for Algorithmic Trading: A Comparative Study of\n  Applications for Finance and Cryptoeconomics",
        "Published: ": "2022-06-29T22:24:49Z",
        "abstract": "Recent advances in Artificial Intelligence (AI) have made algorithmic trading\nplay a central role in finance. However, current research and applications are\ndisconnected information islands. We propose a generally applicable pipeline\nfor designing, programming, and evaluating the algorithmic trading of stock and\ncrypto assets. Moreover, we demonstrate how our data science pipeline works\nwith respect to four conventional algorithms: the moving average crossover,\nvolume-weighted average price, sentiment analysis, and statistical arbitrage\nalgorithms. Our study offers a systematic way to program, evaluate, and compare\ndifferent trading strategies. Furthermore, we implement our algorithms through\nobject-oriented programming in Python3, which serves as open-source software\nfor future academic research and applications.",
        "author": [
            "Luyao Zhang",
            "Tianyu Wu",
            "Saad Lahrichi",
            "Carlos-Gustavo Salas-Flores",
            "Jiayi Li"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.14932v1.pdf",
        "Categories": [
            [
                "cs.HC",
                "econ.GN",
                "q-fin.CP",
                "q-fin.EC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.14932v1",
        "arXiv ID": "2206.14932v1"
    },
    {
        "title": "Anomaly detection and community detection in networks",
        "Published: ": "2022-05-12T10:48:49Z",
        "abstract": "Anomaly detection is a relevant problem in the area of data analysis. In\nnetworked systems, where individual entities interact in pairs, anomalies are\nobserved when pattern of interactions deviates from patterns considered\nregular. Properly defining what regular patterns entail relies on developing\nexpressive models for describing the observed interactions. It is crucial to\naddress anomaly detection in networks. Among the many well-known models for\nnetworks, latent variable models - a class of probabilistic models - offer\npromising tools to capture the intrinsic features of the data. In this work, we\npropose a probabilistic generative approach that incorporates domain knowledge,\ni.e., community membership, as a fundamental model for regular behavior, and\nthus flags potential anomalies deviating from this pattern. In fact, community\nmembership serves as the building block of a null model to identify the regular\ninteraction patterns. The structural information is included in the model\nthrough latent variables for community membership and anomaly parameter. The\nalgorithm aims at inferring these latent parameters and then output the labels\nidentifying anomalies on the network edges.",
        "author": [
            "Hadiseh Safdari",
            "Caterina De Bacco"
        ],
        "pdfLink": "http://arxiv.org/pdf/2205.06012v2.pdf",
        "Categories": [
            [
                "cs.SI",
                "68-XX",
                "J.4"
            ]
        ],
        "Link": "http://arxiv.org/abs/2205.06012v2",
        "arXiv ID": "2205.06012v2"
    },
    {
        "title": "CODAG: Characterizing and Optimizing Decompression Algorithms for GPUs",
        "Published: ": "2023-07-07T08:27:01Z",
        "abstract": "Data compression and decompression have become vital components of big-data\napplications to manage the exponential growth in the amount of data collected\nand stored. Furthermore, big-data applications have increasingly adopted GPUs\ndue to their high compute throughput and memory bandwidth. Prior works presume\nthat decompression is memory-bound and have dedicated most of the GPU's threads\nto data movement and adopted complex software techniques to hide memory latency\nfor reading compressed data and writing uncompressed data. This paper shows\nthat these techniques lead to poor GPU resource utilization as most threads end\nup waiting for the few decoding threads, exposing compute and synchronization\nlatencies.\n  Based on this observation, we propose CODAG, a novel and simple kernel\narchitecture for high throughput decompression on GPUs. CODAG eliminates the\nuse of specialized groups of threads, frees up compute resources to increase\nthe number of parallel decompression streams, and leverages the ample compute\nactivities and the GPU's hardware scheduler to tolerate synchronization,\ncompute, and memory latencies. Furthermore, CODAG provides a framework for\nusers to easily incorporate new decompression algorithms without being burdened\nwith implementing complex optimizations to hide memory latency. We validate our\nproposed architecture with three different encoding techniques, RLE v1, RLE v2,\nand Deflate, and a wide range of large datasets from different domains. We show\nthat CODAG provides 13.46x, 5.69x, and 1.18x speed up for RLE v1, RLE v2, and\nDeflate, respectively, when compared to the state-of-the-art decompressors from\nNVIDIA RAPIDS.",
        "author": [
            "Jeongmin Park",
            "Zaid Qureshi",
            "Vikram Mailthody",
            "Andrew Gacek",
            "Shunfan Shao",
            "Mohammad AlMasri",
            "Isaac Gelado",
            "Jinjun Xiong",
            "Chris Newburn",
            "I-hsin Chung",
            "Michael Garland",
            "Nikolay Sakharnykh",
            "Wen-mei Hwu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.03760v1.pdf",
        "Categories": [
            [
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.03760v1",
        "arXiv ID": "2307.03760v1"
    },
    {
        "title": "A Game-theoretic Approach for Provably-Uniform Random Number Generation\n  in Decentralized Networks",
        "Published: ": "2023-09-20T12:21:39Z",
        "abstract": "Many protocols in distributed computing rely on a source of randomness,\nusually called a random beacon, both for their applicability and security. This\nis especially true for proof-of-stake blockchain protocols in which the next\nminer or set of miners have to be chosen randomly and each party's likelihood\nto be selected is in proportion to their stake in the cryptocurrency.\n  Current random beacons used in proof-of-stake protocols, such as Ouroboros\nand Algorand, have two fundamental limitations: Either (i)~they rely on\npseudorandomness, e.g.~assuming that the output of a hash function is uniform,\nwhich is a widely-used but unproven assumption, or (ii)~they generate their\nrandomness using a distributed protocol in which several participants are\nrequired to submit random numbers which are then used in the generation of a\nfinal random result. However, in this case, there is no guarantee that the\nnumbers provided by the parties are uniformly random and there is no incentive\nfor the parties to honestly generate uniform randomness. Most random beacons\nhave both limitations.\n  In this thesis, we provide a protocol for distributed generation of\nrandomness. Our protocol does not rely on pseudorandomness at all. Similar to\nsome of the previous approaches, it uses random inputs by different\nparticipants to generate a final random result. However, the crucial difference\nis that we provide a game-theoretic guarantee showing that it is in everyone's\nbest interest to submit uniform random numbers. Hence, our approach is the\nfirst to incentivize honest behavior instead of just assuming it. Moreover, the\napproach is trustless and generates unbiased random numbers. It is also\ntamper-proof and no party can change the output or affect its distribution.\nFinally, it is designed with modularity in mind and can be easily plugged into\nexisting distributed protocols such as proof-of-stake blockchains.",
        "author": [
            "Zhuo Cai"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.11250v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.11250v1",
        "arXiv ID": "2309.11250v1"
    },
    {
        "title": "From Big-Step to Small-Step Semantics and Back with Interpreter\n  Specialisation",
        "Published: ": "2020-08-07T01:23:04Z",
        "abstract": "We investigate representations of imperative programs as constrained Horn\nclauses. Starting from operational semantics transition rules, we proceed by\nwriting interpreters as constrained Horn clause programs directly encoding the\nrules. We then specialise an interpreter with respect to a given source program\nto achieve a compilation of the source language to Horn clauses (an instance of\nthe first Futamura projection). The process is described in detail for an\ninterpreter for a subset of C, directly encoding the rules of big-step\noperational semantics for C. A similar translation based on small-step\nsemantics could be carried out, but we show an approach to obtaining a\nsmall-step representation using a linear interpreter for big-step Horn clauses.\nThis interpreter is again specialised to achieve the translation from big-step\nto small-step style. The linear small-step program can be transformed back to a\nbig-step non-linear program using a third interpreter. A regular path\nexpression is computed for the linear program using Tarjan's algorithm, and\nthis regular expression then guides an interpreter to compute a program path.\nThe transformation is realised by specialisation of the path interpreter. In\nall of the transformation phases, we use an established partial evaluator and\nexploit standard logic program transformation to remove redundant data\nstructures and arguments in predicates and rename predicates to make clear\ntheir link to statements in the original source program.",
        "author": [
            "John P. Gallagher",
            "Manuel Hermenegildo",
            "Bishoksan Kafle",
            "Maximiliano Klemen",
            "Pedro L\u00f3pez Garc\u00eda",
            "Jos\u00e9 Morales"
        ],
        "pdfLink": "http://arxiv.org/pdf/2008.02931v1.pdf",
        "Categories": [
            [
                "cs.PL",
                "cs.LO",
                "cs.SC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2008.02931v1",
        "arXiv ID": "2008.02931v1"
    },
    {
        "title": "Parallel Markov Chain Monte Carlo for Bayesian Hierarchical Models with\n  Big Data, in Two Stages",
        "Published: ": "2017-12-16T06:14:18Z",
        "abstract": "Due to the escalating growth of big data sets in recent years, new Bayesian\nMarkov chain Monte Carlo (MCMC) parallel computing methods have been developed.\nThese methods partition large data sets by observations into subsets. However,\nfor Bayesian nested hierarchical models, typically only a few parameters are\ncommon for the full data set, with most parameters being group-specific. Thus,\nparallel Bayesian MCMC methods that take into account the structure of the\nmodel and split the full data set by groups rather than by observations are a\nmore natural approach for analysis. Here, we adapt and extend a recently\nintroduced two-stage Bayesian hierarchical modeling approach, and we partition\ncomplete data sets by groups. In stage 1, the group-specific parameters are\nestimated independently in parallel. The stage 1 posteriors are used as\nproposal distributions in stage 2, where the target distribution is the full\nmodel. Using three-level and four-level models, we show in both simulation and\nreal data studies that results of our method agree closely with the full data\nanalysis, with greatly increased MCMC efficiency and greatly reduced\ncomputation times. The advantages of our method versus existing parallel MCMC\ncomputing methods are also described.",
        "author": [
            "Zheng Wei",
            "Erin M. Conlon"
        ],
        "pdfLink": "http://arxiv.org/pdf/1712.05907v2.pdf",
        "Categories": [
            [
                "stat.ME",
                "cs.DC",
                "stat.CO",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1712.05907v2",
        "arXiv ID": "1712.05907v2"
    },
    {
        "title": "Security Issues in Data Warehouse",
        "Published: ": "2015-07-20T20:29:21Z",
        "abstract": "Data Warehouse provides storage for huge amounts of historical data from\nheterogeneous operational sources in the form of multidimensional views, thus\nsupplying sensitive and useful information which help decision-makers to\nimprove the organizations business processes. A data warehouse environment must\nensure that data collected and stored in one big repository are not vulnerable.\nA review of security approaches specifically for data warehouse environment and\nissues concerning each type of security approach have been provided in this\npaper.",
        "author": [
            "Saiqa Aleem",
            "Luiz Fernando Capretz",
            "Faheem Ahmed"
        ],
        "pdfLink": "http://arxiv.org/pdf/1507.05644v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1507.05644v1",
        "arXiv ID": "1507.05644v1"
    },
    {
        "title": "A Big Data Architecture for Log Data Storage and Analysis",
        "Published: ": "2018-12-01T00:50:45Z",
        "abstract": "We propose an architecture for analysing database connection logs across\ndifferent instances of databases within an intranet comprising over 10,000\nusers and associated devices. Our system uses Flume agents to send\nnotifications to a Hadoop Distributed File System for long-term storage and\nElasticSearch and Kibana for short-term visualisation, effectively creating a\ndata lake for the extraction of log data. We adopt machine learning models with\nan ensemble of approaches to filter and process the indicators within the data\nand aim to predict anomalies or outliers using feature vectors built from this\nlog data.",
        "author": [
            "Swapneel Mehta",
            "Prasanth Kothuri",
            "Daniel Lanza Garcia"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.00111v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.00111v1",
        "arXiv ID": "1812.00111v1"
    },
    {
        "title": "Authentication and encryption for a robotic ad hoc network using\n  identity-based cryptography",
        "Published: ": "2022-09-23T21:17:46Z",
        "abstract": "In some situations the communications of a place can be affected, totally\nlost, or not even exist. In these cases, the MANETs play an important role,\nallowing to establish a communications point using the different nodes of the\nnetwork to reach the destination using decentralized communications. This paper\nproposes the implementation of a Robotic MANET, a decentralized network using\nrobots as its nodes, which allows to move the network nodes to the desired\nlocation remotely. For this, each robot has as a core a Raspberry Pi with the\ncapabilities to perform audio and video streaming, remote control of robots,\ntracking of objects, and deployment of wireless networks. To protect the\nnetwork, different security mechanisms are used that allow secure\nauthentication on the network by different nodes and encryption of information\ntransmitted between them. All communications are protected through\nIdentity-Based Cryptography, specifically with an Identity-Based Signcryption\nscheme.",
        "author": [
            "J Su\u00e1rez-Armas",
            "C Caballero-Gil",
            "A Rivero-Garc\u00eda",
            "P Caballero-Gil"
        ],
        "pdfLink": "http://arxiv.org/pdf/2209.11861v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2209.11861v1",
        "arXiv ID": "2209.11861v1"
    },
    {
        "title": "B-Ride: Ride Sharing with Privacy-preservation, Trust and Fair Payment\n  atop Public Blockchain",
        "Published: ": "2019-06-21T17:40:37Z",
        "abstract": "Ride-sharing is a service that enables drivers to share their trips with\nother riders, contributing to appealing benefits of shared travel costs.\nHowever, the majority of existing platforms rely on a central third party,\nwhich make them subject to a single point of failure and privacy disclosure\nissues. Moreover, they are vulnerable to DDoS and Sybil attacks due to\nmalicious users involvement. Besides, high fees should be paid to the service\nprovider. In this paper, we propose a decentralized ride-sharing service based\non public Blockchain, named B-Ride. Both riders and drivers can find rides\nmatch while preserving their trip data, including pick-up/drop-off location,\nand departure/arrival date. However, under the anonymity of the public\nblockchain, a malicious user may submit multiple ride requests or offers, while\nnot committing to any of them, to discover better offer or to make the system\nunreliable. B-Ride solves this problem by introducing a time-locked deposit\nprotocol for a ride-sharing by leveraging smart contract and zero-knowledge set\nmembership proof. In a nutshell, both a driver and a rider have to show their\ncommitment by sending a deposit to the blockchain. Later, a driver has to prove\nto the blockchain on the agreed departure time that he has arrived at the\npick-up location. To preserve rider/driver location privacy by hiding the exact\npick-up location, the proof is done using zero-knowledge set membership\nprotocol. Moreover, to ensure a fair payment, a pay-as-you-drive methodology is\nintroduced based on the elapsed distance of the driver and the rider. Also, we\nintroduce a reputation-based trust model to rate drivers based on their past\ntrips to allow riders to select them based on their history on the system.\nFinally, we implement B-Ride in a test net of Ethereum. The experiment results\nshow the applicability of our protocol atop the existing real-world blockchain.",
        "author": [
            "Mohamed Baza",
            "Noureddine Lasla",
            "Mohamed Mahmoud",
            "Gautam Srivastava",
            "Mohamed Abdallah"
        ],
        "pdfLink": "http://arxiv.org/pdf/1906.09968v2.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/1906.09968v2",
        "arXiv ID": "1906.09968v2"
    },
    {
        "title": "StrongChain: Transparent and Collaborative Proof-of-Work Consensus",
        "Published: ": "2019-05-23T13:50:31Z",
        "abstract": "Bitcoin is the most successful cryptocurrency so far. This is mainly due to\nits novel consensus algorithm, which is based on proof-of-work combined with a\ncryptographically-protected data structure and a rewarding scheme that\nincentivizes nodes to participate. However, despite its unprecedented success\nBitcoin suffers from many inefficiencies. For instance, Bitcoin's consensus\nmechanism has been proved to be incentive-incompatible, its high reward\nvariance causes centralization, and its hardcoded deflation raises questions\nabout its long-term sustainability.\n  In this work, we revise the Bitcoin consensus mechanism by proposing\nStrongChain, a scheme that introduces transparency and incentivizes\nparticipants to collaborate rather than to compete. The core design of our\nprotocol is to reflect and utilize the computing power aggregated on the\nblockchain which is invisible and \"wasted\" in Bitcoin today. Introducing\nrelatively easy, although important changes to Bitcoin's design enables us to\nimprove many crucial aspects of Bitcoin-like cryptocurrencies making it more\nsecure, efficient, and profitable for participants. We thoroughly analyze our\napproach and we present an implementation of StrongChain. The obtained results\nconfirm its efficiency, security, and deployability.",
        "author": [
            "Pawel Szalachowski",
            "Daniel Reijsbergen",
            "Ivan Homoliak",
            "Siwei Sun"
        ],
        "pdfLink": "http://arxiv.org/pdf/1905.09655v1.pdf",
        "Categories": [
            [
                "cs.CR",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/1905.09655v1",
        "arXiv ID": "1905.09655v1"
    },
    {
        "title": "Grassroots Flash: A Payment System for Grassroots Cryptocurrencies",
        "Published: ": "2023-09-22T21:39:09Z",
        "abstract": "The goal of grassroots cryptocurrencies is to provide a foundation with which\nlocal digital economies can emerge independently of each other and of global\ndigital platforms and global cryptocurrencies; can form and grow without\ninitial capital or external credit; can trade with each other; and can\ngradually merge into a global digital economy. Grassroots cryptocurrencies turn\nmutual trust into liquidity and thus could be a powerful means for 'banking the\nunbanked'. Grassroots cryptocurrencies have not been provided yet with a\npayment system, which is the goal of this paper. Here, we present Grassroots\nFlash, a payment system for grassroots cryptocurrencies that employs the\nblocklace -- a DAG-like counterpart of the blockchain data structure. We\nanalyze its security (safety, liveness, and privacy) and efficiency, prove that\nit is indeed grassroots.",
        "author": [
            "Andrew Lewis-Pye",
            "Oded Naor",
            "Ehud Shapiro"
        ],
        "pdfLink": "http://arxiv.org/pdf/2309.13191v1.pdf",
        "Categories": [
            [
                "cs.MA",
                "cs.CE",
                "cs.DC"
            ]
        ],
        "Link": "http://arxiv.org/abs/2309.13191v1",
        "arXiv ID": "2309.13191v1"
    },
    {
        "title": "Characteristics of price related fluctuations in Non-Fungible Token\n  (NFT) market",
        "Published: ": "2023-10-30T17:15:18Z",
        "abstract": "Non-fungible token (NFT) market is a new trading invention based on the\nblockchain technology which parallels the cryptocurrency market. In the present\nwork we study capitalization, floor price, the number of transactions, the\ninter-transaction times, and the transaction volume value of a few selected\npopular token collections. The results show that the fluctuations of all these\nquantities are characterized by heavy-tailed probability distribution\nfunctions, in most cases well described by the stretched exponentials, with a\ntrace of power-law scaling at times, long-range memory, and in several cases\neven the fractal organization of fluctuations, mostly restricted to the larger\nfluctuations, however. We conclude that the NFT market - even though young and\ngoverned by a somewhat different mechanisms of trading - shares several\nstatistical properties with the regular financial markets. However, some\ndifferences are visible in the specific quantitative indicators.",
        "author": [
            "Pawe\u0142 Szyd\u0142o",
            "Marcin W\u0105torek",
            "Jaros\u0142aw Kwapie\u0144",
            "Stanis\u0142aw Dro\u017cd\u017c"
        ],
        "pdfLink": "http://arxiv.org/pdf/2310.19747v1.pdf",
        "Categories": [
            [
                "q-fin.CP",
                "cs.CE",
                "econ.EM",
                "physics.data-an",
                "stat.AP"
            ]
        ],
        "Link": "http://arxiv.org/abs/2310.19747v1",
        "arXiv ID": "2310.19747v1"
    },
    {
        "title": "Soft Computing Framework for Routing in Wireless Mesh Networks: An\n  Integrated Cost Function Approach",
        "Published: ": "2013-07-11T08:22:16Z",
        "abstract": "Dynamic behaviour of a WMN imposes stringent constraints on the routing\npolicy of the network. In the shortest path based routing the shortest paths\nneeds to be evaluated within a given time frame allowed by the WMN dynamics.\nThe exact reasoning based shortest path evaluation methods usually fail to meet\nthis rigid requirement. Thus, requiring some soft computing based approaches\nwhich can replace \"best for sure\" solutions with \"good enough\" solutions. This\npaper proposes a framework for optimal routing in the WMNs; where we\ninvestigate the suitability of Big Bang-Big Crunch (BB-BC), a soft computing\nbased approach to evaluate shortest/near-shortest path. In order to make\nrouting optimal we first propose to replace distance between the adjacent nodes\nwith an integrated cost measure that takes into account throughput, delay,\njitter and residual energy of a node. A fuzzy logic based inference mechanism\nevaluates this cost measure at each node. Using this distance measure we apply\nBB-BC optimization algorithm to evaluate shortest/near shortest path to update\nthe routing tables periodically as dictated by network requirements. A large\nnumber of simulations were conducted and it has been observed that BB-BC\nalgorithm appears to be a high potential candidate suitable for routing in\nWMNs.",
        "author": [
            "Shakti Kumar",
            "Brahmjit Singh",
            "Sharad Sharma"
        ],
        "pdfLink": "http://arxiv.org/pdf/1307.3011v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "cs.AI",
                "94Axx"
            ]
        ],
        "Link": "http://arxiv.org/abs/1307.3011v1",
        "arXiv ID": "1307.3011v1"
    },
    {
        "title": "Computation harvesting in road traffic dynamics",
        "Published: ": "2020-11-21T08:22:19Z",
        "abstract": "Owing to recent advances in artificial intelligence and internet of things\n(IoT) technologies, collected big data facilitates high computational\nperformance, while its computational resources and energy cost are large.\nMoreover, data are often collected but not used. To solve these problems, we\npropose a framework for a computational model that follows a natural\ncomputational system, such as the human brain, and does not rely heavily on\nelectronic computers. In particular, we propose a methodology based on the\nconcept of `computation harvesting', which uses IoT data collected from rich\nsensors and leaves most of the computational processes to real-world phenomena\nas collected data. This aspect assumes that large-scale computations can be\nfast and resilient. Herein, we perform prediction tasks using real-world road\ntraffic data to show the feasibility of computation harvesting. First, we show\nthat the substantial computation in traffic flow is resilient against sensor\nfailure and real-time traffic changes due to several combinations of harvesting\nfrom spatiotemporal dynamics to synthesize specific patterns. Next, we show the\npracticality of this method as a real-time prediction because of its low\ncomputational cost. Finally, we show that, compared to conventional methods,\nour method requires lower resources while providing a comparable performance.",
        "author": [
            "Hiroyasu Ando",
            "T. Okamoto",
            "H. Chang",
            "T. Noguchi",
            "Shinji Nakaoka"
        ],
        "pdfLink": "http://arxiv.org/pdf/2011.10744v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.ET"
            ]
        ],
        "Link": "http://arxiv.org/abs/2011.10744v1",
        "arXiv ID": "2011.10744v1"
    },
    {
        "title": "Big Science with a Small Budget: Non-Embarrassingly Parallel\n  Applications in a Non-Dedicated Network of Workstations",
        "Published: ": "2005-10-31T14:55:57Z",
        "abstract": "Many astronomers and astrophysicists require large computing resources for\ntheir research, which are usually obtained via dedicated (and expensive)\nparallel machines. Depending on the type of the problem to be solved, an\nalternative solution can be provided by creating dynamically a computer cluster\nout of non-dedicated workstations using the Condor High Throughput Computing\nSystem and the Master-Worker (MW) framework. As an example of this we show in\nthis paper how a radiative transfer application previously coded with MPI is\nsolved using this solution without the need for dedicated machines.",
        "author": [
            "Angel de Vicente",
            "Nayra Rodriguez"
        ],
        "pdfLink": "http://arxiv.org/pdf/cs/0510094v1.pdf",
        "Categories": [
            [
                "cs.DC",
                "astro-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/cs/0510094v1",
        "arXiv ID": "0510094v1"
    },
    {
        "title": "Coded Computing for Secure Boolean Computations",
        "Published: ": "2020-01-23T18:28:08Z",
        "abstract": "The growing size of modern datasets necessitates splitting a large scale\ncomputation into smaller computations and operate in a distributed manner.\nAdversaries in a distributed system deliberately send erroneous data in order\nto affect the computation for their benefit. Boolean functions are the key\ncomponents of many applications, e.g., verification functions in blockchain\nsystems and design of cryptographic algorithms. We consider the problem of\ncomputing a Boolean function in a distributed computing system with particular\nfocus on \\emph{security against Byzantine workers}. Any Boolean function can be\nmodeled as a multivariate polynomial with high degree in general. However, the\nsecurity threshold (i.e., the maximum number of adversarial workers can be\ntolerated such that the correct results can be obtained) provided by the recent\nproposed Lagrange Coded Computing (LCC) can be extremely low if the degree of\nthe polynomial is high. We propose three different schemes called \\emph{coded\nAlgebraic normal form (ANF)}, \\emph{coded Disjunctive normal form (DNF)} and\n\\emph{coded polynomial threshold function (PTF)}. The key idea of the proposed\nschemes is to model it as the concatenation of some low-degree polynomials and\nthreshold functions. In terms of the security threshold, we show that the\nproposed coded ANF and coded DNF are optimal by providing a matching outer\nbound.",
        "author": [
            "Chien-Sheng Yang",
            "A. Salman Avestimehr"
        ],
        "pdfLink": "http://arxiv.org/pdf/2001.08720v2.pdf",
        "Categories": [
            [
                "cs.DC",
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/2001.08720v2",
        "arXiv ID": "2001.08720v2"
    },
    {
        "title": "High-performance Kernel Machines with Implicit Distributed Optimization\n  and Randomization",
        "Published: ": "2014-09-03T02:28:51Z",
        "abstract": "In order to fully utilize \"big data\", it is often required to use \"big\nmodels\". Such models tend to grow with the complexity and size of the training\ndata, and do not make strong parametric assumptions upfront on the nature of\nthe underlying statistical dependencies. Kernel methods fit this need well, as\nthey constitute a versatile and principled statistical methodology for solving\na wide range of non-parametric modelling problems. However, their high\ncomputational costs (in storage and time) pose a significant barrier to their\nwidespread adoption in big data applications.\n  We propose an algorithmic framework and high-performance implementation for\nmassive-scale training of kernel-based statistical models, based on combining\ntwo key technical ingredients: (i) distributed general purpose convex\noptimization, and (ii) the use of randomization to improve the scalability of\nkernel methods. Our approach is based on a block-splitting variant of the\nAlternating Directions Method of Multipliers, carefully reconfigured to handle\nvery large random feature matrices, while exploiting hybrid parallelism\ntypically found in modern clusters of multicore machines. Our implementation\nsupports a variety of statistical learning tasks by enabling several loss\nfunctions, regularization schemes, kernels, and layers of randomized\napproximations for both dense and sparse datasets, in a highly extensible\nframework. We evaluate the ability of our framework to learn models on data\nfrom applications, and provide a comparison against existing sequential and\nparallel libraries.",
        "author": [
            "Vikas Sindhwani",
            "Haim Avron"
        ],
        "pdfLink": "http://arxiv.org/pdf/1409.0940v3.pdf",
        "Categories": [
            [
                "stat.ML",
                "cs.DC",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1409.0940v3",
        "arXiv ID": "1409.0940v3"
    },
    {
        "title": "Machine learning based energy-free structure predictions of molecules\n  (closed and open-shell), transition states, and solids",
        "Published: ": "2021-02-04T18:55:22Z",
        "abstract": "The computational prediction of atomistic structure is a long-standing\nproblem in physics, chemistry, materials, and biology. Within conventional\nforce-field or {\\em ab initio} calculations, structure is determined through\nenergy minimization, which is either approximate or computationally demanding.\nAlas, the accuracy-cost trade-off prohibits the generation of synthetic big\ndata records with meaningful energy based conformational search and structure\nrelaxation output. Exploiting implicit correlations among relaxed structures,\nour kernel ridge regression model, dubbed Graph-To-Structure (G2S), generalizes\nacross chemical compound space, enabling direct predictions of relaxed\nstructures for out-of-sample compounds, and effectively bypassing the energy\noptimization task. After training on constitutional and compositional isomers\n(no conformers) G2S infers atomic coordinates relying solely on stoichiometry\nand bond-network information as input (Our numerical evidence includes closed\nand open shell molecules, transition states, and solids). For all data\nconsidered, G2S learning curves reach mean absolute interatomic distance\nprediction errors of less than 0.2 {\\AA} for less than eight thousand training\nstructures -- on par or better than popular empirical methods. Applicability\ntest of G2S include meaningful structures of molecules for which standard\nmethods require manual intervention, improved initial guesses for subsequent\nconventional {\\em ab initio} based relaxation, and input for structural based\nrepresentations commonly used in quantum machine learning models, (bridging the\ngap between graph and structure based models).",
        "author": [
            "Dominik Lemm",
            "Guido Falk von Rudorff",
            "O. Anatole von Lilienfeld"
        ],
        "pdfLink": "http://arxiv.org/pdf/2102.02806v5.pdf",
        "Categories": [
            [
                "physics.chem-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2102.02806v5",
        "arXiv ID": "2102.02806v5"
    },
    {
        "title": "A half-century of global collaboration in science and the 'Shrinking\n  World'",
        "Published: ": "2022-11-08T18:15:23Z",
        "abstract": "Recent decades have witnessed a dramatic shift in the cross-border\ncollaboration mode of researchers, with countries increasingly cooperating and\ncompeting with one another. It is crucial for leaders in academia and policy to\nunderstand the full extent of international research collaboration, their\ncountry's position within it, and its evolution over time. However, evidence\nfor such world-scale dynamism is still scarce. This paper provides unique\nevidence of how international collaboration clusters have formed and evolved\nover the past 50 years across various scientific publications, using data from\nOpenAlex, a large-scale Open Bibliometrics platform launched in 2022. We first\nexamine how the global presence of top-tier countries has changed in 15 natural\nscience disciplines over time, as measured by publication volumes and\ninternational collaboration rates. Notably, we observe that the US and China\nhave been rapidly moving closer together for decades but began moving apart\nafter 2019. We then perform a hierarchical clustering to analyse and visualise\nthe international collaboration clusters for each discipline and period.\nFinally, we provide quantitative evidence of a `Shrinking World' of research\ncollaboration at a global scale over the past half-century. Our results provide\nvaluable insights into the big picture of past, present and future\ninternational collaboration.",
        "author": [
            "Keisuke Okamura"
        ],
        "pdfLink": "http://arxiv.org/pdf/2211.04429v2.pdf",
        "Categories": [
            [
                "cs.DL",
                "cs.CY",
                "cs.SI",
                "physics.data-an",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2211.04429v2",
        "arXiv ID": "2211.04429v2"
    },
    {
        "title": "AI-enabled exploration of Instagram profiles predicts soft skills and\n  personality traits to empower hiring decisions",
        "Published: ": "2022-12-14T07:35:11Z",
        "abstract": "It does not matter whether it is a job interview with Tech Giants, Wall\nStreet firms, or a small startup; all candidates want to demonstrate their best\nselves or even present themselves better than they really are. Meanwhile,\nrecruiters want to know the candidates' authentic selves and detect soft skills\nthat prove an expert candidate would be a great fit in any company. Recruiters\nworldwide usually struggle to find employees with the highest level of these\nskills. Digital footprints can assist recruiters in this process by providing\ncandidates' unique set of online activities, while social media delivers one of\nthe largest digital footprints to track people. In this study, for the first\ntime, we show that a wide range of behavioral competencies consisting of 16\nin-demand soft skills can be automatically predicted from Instagram profiles\nbased on the following lists and other quantitative features using machine\nlearning algorithms. We also provide predictions on Big Five personality\ntraits. Models were built based on a sample of 400 Iranian volunteer users who\nanswered an online questionnaire and provided their Instagram usernames which\nallowed us to crawl the public profiles. We applied several machine learning\nalgorithms to the uniformed data. Deep learning models mostly outperformed by\ndemonstrating 70% and 69% average Accuracy in two-level and three-level\nclassifications respectively. Creating a large pool of people with the highest\nlevel of soft skills, and making more accurate evaluations of job candidates is\npossible with the application of AI on social media user-generated data.",
        "author": [
            "Mercedeh Harirchian",
            "Fereshteh Amin",
            "Saeed Rouhani",
            "Aref Aligholipour",
            "Vahid Amiri Lord"
        ],
        "pdfLink": "http://arxiv.org/pdf/2212.07069v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.CY",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2212.07069v2",
        "arXiv ID": "2212.07069v2"
    },
    {
        "title": "Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case\n  Study using Latent Dirichlet Allocation Method",
        "Published: ": "2023-01-08T12:33:58Z",
        "abstract": "Topic Modelling (TM) is from the research branches of natural language\nunderstanding (NLU) and natural language processing (NLP) that is to facilitate\ninsightful analysis from large documents and datasets, such as a summarisation\nof main topics and the topic changes. This kind of discovery is getting more\npopular in real-life applications due to its impact on big data analytics. In\nthis study, from the social-media and healthcare domain, we apply popular\nLatent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish\nnewspaper articles about Coronavirus. We describe the corpus we created\nincluding 6515 articles, methods applied, and statistics on topic changes over\napproximately 1 year and two months period of time from 17th January 2020 to\n13th March 2021. We hope this work can be an asset for grounding applications\nof topic modelling and can be inspiring for similar case studies in an era with\npandemics, to support socio-economic impact research as well as clinical and\nhealthcare analytics. Our data and source code are openly available at\nhttps://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation\n(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding;\nBERT-topic",
        "author": [
            "Bernadeta Grici\u016bt\u0117",
            "Lifeng Han",
            "Goran Nenadic"
        ],
        "pdfLink": "http://arxiv.org/pdf/2301.03029v6.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2301.03029v6",
        "arXiv ID": "2301.03029v6"
    },
    {
        "title": "Fault Prognosis of Turbofan Engines: Eventual Failure Prediction and\n  Remaining Useful Life Estimation",
        "Published: ": "2023-03-23T01:19:41Z",
        "abstract": "In the era of industrial big data, prognostics and health management is\nessential to improve the prediction of future failures to minimize inventory,\nmaintenance, and human costs. Used for the 2021 PHM Data Challenge, the new\nCommercial Modular Aero-Propulsion System Simulation dataset from NASA is an\nopen-source benchmark containing simulated turbofan engine units flown under\nrealistic flight conditions. Deep learning approaches implemented previously\nfor this application attempt to predict the remaining useful life of the engine\nunits, but have not utilized labeled failure mode information, impeding\npractical usage and explainability. To address these limitations, a new\nprognostics approach is formulated with a customized loss function to\nsimultaneously predict the current health state, the eventual failing\ncomponent(s), and the remaining useful life. The proposed method incorporates\nprincipal component analysis to orthogonalize statistical time-domain features,\nwhich are inputs into supervised regressors such as random forests, extreme\nrandom forests, XGBoost, and artificial neural networks. The highest performing\nalgorithm, ANN-Flux, achieves AUROC and AUPR scores exceeding 0.95 for each\nclassification. In addition, ANN-Flux reduces the remaining useful life RMSE by\n38% for the same test split of the dataset compared to past work, with\nsignificantly less computational cost.",
        "author": [
            "Joseph Cohen",
            "Xun Huan",
            "Jun Ni"
        ],
        "pdfLink": "http://arxiv.org/pdf/2303.12982v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.SY",
                "eess.SP",
                "eess.SY"
            ]
        ],
        "Link": "http://arxiv.org/abs/2303.12982v1",
        "arXiv ID": "2303.12982v1"
    },
    {
        "title": "Intra- & Extra-Source Exemplar-Based Style Synthesis for Improved Domain\n  Generalization",
        "Published: ": "2023-07-02T19:56:43Z",
        "abstract": "The generalization with respect to domain shifts, as they frequently appear\nin applications such as autonomous driving, is one of the remaining big\nchallenges for deep learning models. Therefore, we propose an exemplar-based\nstyle synthesis pipeline to improve domain generalization in semantic\nsegmentation. Our method is based on a novel masked noise encoder for StyleGAN2\ninversion. The model learns to faithfully reconstruct the image, preserving its\nsemantic layout through noise prediction. Using the proposed masked noise\nencoder to randomize style and content combinations in the training set, i.e.,\nintra-source style augmentation (ISSA) effectively increases the diversity of\ntraining data and reduces spurious correlation. As a result, we achieve up to\n$12.4\\%$ mIoU improvements on driving-scene semantic segmentation under\ndifferent types of data shifts, i.e., changing geographic locations, adverse\nweather conditions, and day to night. ISSA is model-agnostic and\nstraightforwardly applicable with CNNs and Transformers. It is also\ncomplementary to other domain generalization techniques, e.g., it improves the\nrecent state-of-the-art solution RobustNet by $3\\%$ mIoU in Cityscapes to Dark\nZ\\\"urich. In addition, we demonstrate the strong plug-n-play ability of the\nproposed style synthesis pipeline, which is readily usable for extra-source\nexemplars e.g., web-crawled images, without any retraining or fine-tuning.\nMoreover, we study a new use case to indicate neural network's generalization\ncapability by building a stylized proxy validation set. This application has\nsignificant practical sense for selecting models to be deployed in the\nopen-world environment. Our code is available at\n\\url{https://github.com/boschresearch/ISSA}.",
        "author": [
            "Yumeng Li",
            "Dan Zhang",
            "Margret Keuper",
            "Anna Khoreva"
        ],
        "pdfLink": "http://arxiv.org/pdf/2307.00648v1.pdf",
        "Categories": [
            [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/2307.00648v1",
        "arXiv ID": "2307.00648v1"
    },
    {
        "title": "Layerwise Perturbation-Based Adversarial Training for Hard Drive Health\n  Degree Prediction",
        "Published: ": "2018-09-11T22:43:19Z",
        "abstract": "With the development of cloud computing and big data, the reliability of data\nstorage systems becomes increasingly important. Previous researchers have shown\nthat machine learning algorithms based on SMART attributes are effective\nmethods to predict hard drive failures. In this paper, we use SMART attributes\nto predict hard drive health degrees which are helpful for taking different\nfault tolerant actions in advance. Given the highly imbalanced SMART datasets,\nit is a nontrivial work to predict the health degree precisely. The proposed\nmodel would encounter overfitting and biased fitting problems if it is trained\nby the traditional methods. In order to resolve this problem, we propose two\nstrategies to better utilize imbalanced data and improve performance. Firstly,\nwe design a layerwise perturbation-based adversarial training method which can\nadd perturbations to any layers of a neural network to improve the\ngeneralization of the network. Secondly, we extend the training method to the\nsemi-supervised settings. Then, it is possible to utilize unlabeled data that\nhave a potential of failure to further improve the performance of the model.\nOur extensive experiments on two real-world hard drive datasets demonstrate the\nsuperiority of the proposed schemes for both supervised and semi-supervised\nclassification. The model trained by the proposed method can correctly predict\nthe hard drive health status 5 and 15 days in advance. Finally, we verify the\ngenerality of the proposed training method in other similar anomaly detection\ntasks where the dataset is imbalanced. The results argue that the proposed\nmethods are applicable to other domains.",
        "author": [
            "Jianguo Zhang",
            "Ji Wang",
            "Lifang He",
            "Zhao Li",
            "Philip S. Yu"
        ],
        "pdfLink": "http://arxiv.org/pdf/1809.04188v4.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1809.04188v4",
        "arXiv ID": "1809.04188v4"
    },
    {
        "title": "Swap-Free Fat-Water Separation in Dixon MRI using Conditional Generative\n  Adversarial Networks",
        "Published: ": "2021-07-29T16:56:00Z",
        "abstract": "Dixon MRI is widely used for body composition studies. Current processing\nmethods associated with large whole-body volumes are time intensive and prone\nto artifacts during fat-water separation performed on the scanner, making the\ndata difficult to analyse. The most common artifact are fat-water swaps, where\nthe labels are inverted at the voxel level. It is common for researchers to\ndiscard swapped data (generally around 10%), which can be wasteful and lead to\nunintended biases. The UK Biobank is acquiring Dixon MRI for over 100,000\nparticipants, and thousands of swaps will occur. If those go undetected, errors\nwill propagate into processes such as abdominal organ segmentation and dilute\nthe results in population-based analyses. There is a clear need for a fast and\nrobust method to accurately separate fat and water channels. In this work we\npropose such a method based on style transfer using a conditional generative\nadversarial network. We also introduce a new Dixon loss function for the\ngenerator model. Using data from the UK Biobank Dixon MRI, our model is able to\npredict highly accurate fat and water channels that are free from artifacts. We\nshow that the model separates fat and water channels using either single input\n(in-phase) or dual input (in-phase and opposed-phase), with the latter\nproducing improved results. Our proposed method enables faster and more\naccurate downstream analysis of body composition from Dixon MRI in population\nstudies by eliminating the need for visual inspection or discarding data due to\nfat-water swaps.",
        "author": [
            "Nicolas Basty",
            "Marjola Thanaj",
            "Madeleine Cule",
            "Elena P. Sorokin",
            "Yi Liu",
            "Jimmy D. Bell",
            "E. Louise Thomas",
            "Brandon Whitcher"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.14175v1.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.14175v1",
        "arXiv ID": "2107.14175v1"
    },
    {
        "title": "The impact of NFT profile pictures within social network communities",
        "Published: ": "2022-06-13T19:48:43Z",
        "abstract": "This paper presents an analysis of the role of social media, specifically\nTwitter, in the context of non-fungible tokens, better known as NFTs. Such\nemerging technology framing the creation and exchange of digital object,\nstarted years ago with early projects such as \"CryptoPunks\" and since early\n2021, has received an increasing interest by a community of people creating,\nbuying, selling NFT's and by the media reporting to the general public. In this\nwork it is shown how the landscape of one class of projects, specifically those\nused as social media profile pictures, has become mainstream with leading\nprojects such as \"Bored Ape Yacht Club\", \"Cool Cats\" and \"Doodles\". This work\nillustrates how heterogeneous data was collected from the Ethereum blockchain\nand Twitter and then analysed using algorithms and state-of-art metrics related\nto graphs. The initial results show that from a social network perspective, the\ncollections of most popular NFTs can be considered as a single community around\nNFTs. Thus, while each project has its own value and volume of exchange, on a\nsocial level all of them are primarily influenced by the evolution of values\nand trades of \"Bored Ape Yacht Club\" collection.",
        "author": [
            "Simone Casale-Brunet",
            "Mirko Zichichi",
            "Lee Hutchinson",
            "Marco Mattavelli",
            "Stefano Ferretti"
        ],
        "pdfLink": "http://arxiv.org/pdf/2206.06443v2.pdf",
        "Categories": [
            [
                "cs.SI",
                "Game theory, economics, finance, and other social and behavioral\n  sciences"
            ]
        ],
        "Link": "http://arxiv.org/abs/2206.06443v2",
        "arXiv ID": "2206.06443v2"
    },
    {
        "title": "Mobile big data analysis with machine learning",
        "Published: ": "2018-08-02T13:31:23Z",
        "abstract": "This paper investigates to identify the requirement and the development of\nmachine learning-based mobile big data analysis through discussing the insights\nof challenges in the mobile big data (MBD). Furthermore, it reviews the\nstate-of-the-art applications of data analysis in the area of MBD. Firstly, we\nintroduce the development of MBD. Secondly, the frequently adopted methods of\ndata analysis are reviewed. Three typical applications of MBD analysis, namely\nwireless channel modeling, human online and offline behavior analysis, and\nspeech recognition in the internet of vehicles, are introduced respectively.\nFinally, we summarize the main challenges and future development directions of\nmobile big data analysis.",
        "author": [
            "Jiyang Xie",
            "Zeyu Song",
            "Yupeng Li",
            "Zhanyu Ma"
        ],
        "pdfLink": "http://arxiv.org/pdf/1808.00803v2.pdf",
        "Categories": [
            [
                "cs.LG",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1808.00803v2",
        "arXiv ID": "1808.00803v2"
    },
    {
        "title": "Ethernet Packet Processor for SoC Application",
        "Published: ": "2012-07-21T13:47:55Z",
        "abstract": "As the demand for Internet expands significantly in numbers of users,\nservers, IP addresses, switches and routers, the IP based network architecture\nmust evolve and change. The design of domain specific processors that require\nhigh performance, low power and high degree of programmability is the\nbottleneck in many processor based applications. This paper describes the\ndesign of ethernet packet processor for system-on-chip (SoC) which performs all\ncore packet processing functions, including segmentation and reassembly,\npacketization classification, route and queue management which will speedup\nswitching/routing performance. Our design has been configured for use with\nmultiple projects ttargeted to a commercial configurable logic device the\nsystem is designed to support 10/100/1000 links with a speed advantage. VHDL\nhas been used to implement and simulated the required functions in FPGA.",
        "author": [
            "Raja Jitendra Nayaka",
            "R. C. Biradar"
        ],
        "pdfLink": "http://arxiv.org/pdf/1207.5138v1.pdf",
        "Categories": [
            [
                "cs.AR",
                "cs.NI",
                "Airccse Conferences"
            ]
        ],
        "Link": "http://arxiv.org/abs/1207.5138v1",
        "arXiv ID": "1207.5138v1"
    },
    {
        "title": "Sparse Channel Estimation for MIMO-OFDM Amplify-and-Forward Two-Way\n  Relay Networks",
        "Published: ": "2013-02-06T13:23:19Z",
        "abstract": "Accurate channel impulse response (CIR) is required for coherent detection\nand it can also help improve communication quality of service in\nnext-generation wireless communication systems. One of the advanced systems is\nmulti-input multi-output orthogonal frequency-division multiplexing (MIMO-OFDM)\namplify and forward two-way relay networks (AF-TWRN). Linear channel estimation\nmethods, e.g., least square (LS), have been proposed to estimate the CIR.\nHowever, these methods never take advantage of channel sparsity and then cause\nperformance loss. In this paper, we propose a sparse channel estimation method\nto exploit the sparse structure information in the CIR at each end user. Sparse\nchannel estimation problem is formulated as compressed sensing (CS) using\nsparse decomposition theory and the estimation process is implemented by LASSO\nalgorithm. Computer simulation results are given to confirm the superiority of\nproposed method over the LS-based channel estimation method.",
        "author": [
            "Guan Gui",
            "Wei Peng",
            "Fumiyuki Adachi"
        ],
        "pdfLink": "http://arxiv.org/pdf/1302.1358v1.pdf",
        "Categories": [
            [
                "cs.IT",
                "math.IT"
            ]
        ],
        "Link": "http://arxiv.org/abs/1302.1358v1",
        "arXiv ID": "1302.1358v1"
    },
    {
        "title": "Joint Optimization of Hadamard Sensing and Reconstruction in Compressed\n  Sensing Fluorescence Microscopy",
        "Published: ": "2021-05-17T15:42:28Z",
        "abstract": "Compressed sensing fluorescence microscopy (CS-FM) proposes a scheme whereby\nless measurements are collected during sensing and reconstruction is performed\nto recover the image. Much work has gone into optimizing the sensing and\nreconstruction portions separately. We propose a method of jointly optimizing\nboth sensing and reconstruction end-to-end under a total measurement\nconstraint, enabling learning of the optimal sensing scheme concurrently with\nthe parameters of a neural network-based reconstruction network. We train our\nmodel on a rich dataset of confocal, two-photon, and wide-field microscopy\nimages comprising of a variety of biological samples. We show that our method\noutperforms several baseline sensing schemes and a regularized regression\nreconstruction algorithm.",
        "author": [
            "Alan Q. Wang",
            "Aaron K. LaViolette",
            "Leo Moon",
            "Chris Xu",
            "Mert R. Sabuncu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2105.07961v2.pdf",
        "Categories": [
            [
                "eess.IV",
                "cs.CV"
            ]
        ],
        "Link": "http://arxiv.org/abs/2105.07961v2",
        "arXiv ID": "2105.07961v2"
    },
    {
        "title": "Finding Clusters of Similar-minded People on Twitter Regarding the\n  Covid-19 Pandemic",
        "Published: ": "2022-03-06T21:41:35Z",
        "abstract": "Two clustering methods to determine users with similar opinions on the\nCovid-19 pandemic and the related public debate in Germany will be presented in\nthis paper. We believe, they can help gaining an overview over similar-minded\ngroups and could support the prevention of fake-news distribution. The first\nmethod uses a new approach to create a network based on retweet relationships\nbetween users and the most retweeted users, the so-called influencers. The\nsecond method extracts hashtags from users posts to create a \"user feature\nvector\" which is then clustered, using a consensus matrix based on previous\nwork, to identify groups using the same language. With both approaches it was\npossible to identify clusters that seem to fit groups of different public\nopinions in Germany. However, we also found that clusters from one approach can\nnot be associated with clusters from the other due to filtering steps in the\ntwo methods.",
        "author": [
            "Philipp Kappus",
            "Paul Gro\u00df"
        ],
        "pdfLink": "http://arxiv.org/pdf/2203.04764v1.pdf",
        "Categories": [
            [
                "cs.SI"
            ]
        ],
        "Link": "http://arxiv.org/abs/2203.04764v1",
        "arXiv ID": "2203.04764v1"
    },
    {
        "title": "Discovering Social Circles in Ego Networks",
        "Published: ": "2012-10-30T21:53:20Z",
        "abstract": "People's personal social networks are big and cluttered, and currently there\nis no good way to automatically organize them. Social networking sites allow\nusers to manually categorize their friends into social circles (e.g. 'circles'\non Google+, and 'lists' on Facebook and Twitter), however they are laborious to\nconstruct and must be updated whenever a user's network grows. In this paper,\nwe study the novel task of automatically identifying users' social circles. We\npose this task as a multi-membership node clustering problem on a user's\nego-network, a network of connections between her friends. We develop a model\nfor detecting circles that combines network structure as well as user profile\ninformation. For each circle we learn its members and the circle-specific user\nprofile similarity metric. Modeling node membership to multiple circles allows\nus to detect overlapping as well as hierarchically nested circles. Experiments\nshow that our model accurately identifies circles on a diverse set of data from\nFacebook, Google+, and Twitter, for all of which we obtain hand-labeled\nground-truth.",
        "author": [
            "Julian McAuley",
            "Jure Leskovec"
        ],
        "pdfLink": "http://arxiv.org/pdf/1210.8182v3.pdf",
        "Categories": [
            [
                "cs.SI",
                "physics.soc-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1210.8182v3",
        "arXiv ID": "1210.8182v3"
    },
    {
        "title": "Parameters optimization and real-time calibration of\n  Measurement-Device-Independent Quantum Key Distribution Network based on Back\n  Propagation Artificial Neural Network",
        "Published: ": "2018-12-20T07:10:45Z",
        "abstract": "The parameters choosing (such as probabilities of choosing X-basis or\nZ-basis, intensity of signal state and decoy state, etc.) and system\ncalibrating will be more challenging when the number of users of a\nmeasurement-device-independent quantum key distribution(MDI-QKD) network\nbecomes larger. At present, people usually use optimization algorithms to\nsearch the best parameters. This method can find the optimized parameters\naccurately but may cost lots of time and hardware resources. It's a big problem\nin large scale MDI-QKD network. Here, we present a new method, using Back\nPropagation Artificial Neural Network(BPNN) to predict, rather than searching\nthe optimized parameters. Compared with optimization algorithms, our BPNN is\nfaster and more lightweight, it can save system resources. Another big problem\nbrought by large scale MDI-QKD network is system recalibration. BPNN can\nsupport this work in real time, and it only needs to use some discarded data\ngenerated from communication process, rather than require us to add additional\ndevices or scan the system",
        "author": [
            "Feng-Yu Lu",
            "Zhen-Qiang Yin",
            "Chao Wang",
            "Chao-Han Cui",
            "Jun Teng",
            "Shuang Wang",
            "Wei Chen",
            "Wei Huang",
            "Bing-Jie Xu",
            "Guang-Can Guo",
            "Zheng-Fu Han"
        ],
        "pdfLink": "http://arxiv.org/pdf/1812.08388v2.pdf",
        "Categories": [
            [
                "quant-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/1812.08388v2",
        "arXiv ID": "1812.08388v2"
    },
    {
        "title": "MIN: Co-Governing Multi-Identifier Network Architecture and its\n  Prototype on Operator's Network",
        "Published: ": "2019-08-01T14:12:27Z",
        "abstract": "IP protocol is the core of TCP/IP network layer. However, since IP address\nand its Domain Name are allocated and managed by a single agency, there are\nrisks of centralization. The semantic overload of IP address also reduces its\nscalability and mobility, which further hinders the security.\n  This paper proposes a co-governing Multi-Identifier Network (MIN)\narchitecture that constructs a network layer with parallel coexistence of\nmultiple identifiers, including identity, content, geographic information, and\nIP address. On the management plane, we develop an efficient management system\nusing consortium blockchain with voting consensus, so the network can\nsimultaneously manage and support by hundreds or thousands of nodes with high\nthroughput. On the data plane, we propose an algorithm merging hash table and\nprefix tree (HTP) for FIB, which avoids the false-negative error and can\ninter-translate different identifiers with tens of billions of entries.\nFurther, we propose a scheme to transport IP packets using CCN as a tunnel for\nsupporting progressive deployment. We deployed the prototype of MIN to the\nlargest operators' network in Mainland China, Hongkong and Macao, and\ndemonstrated that the network can register identifier under co-governing\nconsensus algorithm, support VoD service very well.",
        "author": [
            "Hui Li",
            "Jiangxing Wu",
            "Xin Yang",
            "Han Wang",
            "Julong Lan",
            "Ke Xu",
            "Yunyong Zhang",
            "Jinwu Wei",
            "Shisheng Chen",
            "Wei Liang",
            "Fusheng Zhu",
            "Yiqin Lu",
            "Wai Ho Mow",
            "Yeung Wai-Ho",
            "Zefeng Zheng",
            "Peng Yi",
            "Xinsheng Ji",
            "Qinrang Liu",
            "Wei Li",
            "Kaiyan Tian",
            "Jiang Zhu",
            "Jiaxing Song",
            "Yijun Liu",
            "Junfeng Ma",
            "Jiawei Hu",
            "Rui Xu",
            "Jiansen Huang",
            "Guohua Wei",
            "Jiuhua Qi",
            "Ting Huang",
            "Kaixuan Xing"
        ],
        "pdfLink": "http://arxiv.org/pdf/1908.00418v1.pdf",
        "Categories": [
            [
                "cs.NI",
                "68M10",
                "C.2.1; C.2.6"
            ]
        ],
        "Link": "http://arxiv.org/abs/1908.00418v1",
        "arXiv ID": "1908.00418v1"
    },
    {
        "title": "Quantum Computers for Weather and Climate Prediction: The Good, the Bad\n  and the Noisy",
        "Published: ": "2022-10-31T16:35:05Z",
        "abstract": "Over the past few years, quantum computers and quantum algorithms have\nattracted considerable interest and attention from numerous scientific\ndisciplines. In this article, we aim to provide a non-technical, yet\ninformative introduction to key aspects of quantum computing. We discuss\nwhether quantum computers one day might become useful tools for numerical\nweather and climate prediction. Using a recently developed quantum algorithm\nfor solving non-linear differential equations, we integrate a simple non-linear\nmodel. In addition to considering the advantages that quantum computers have to\noffer, we shall also discuss the challenges one faces when trying to use\nquantum computers for real-world problems involving ''big data'', such as\nweather prediction.",
        "author": [
            "Felix Tennie",
            "Tim Palmer"
        ],
        "pdfLink": "http://arxiv.org/pdf/2210.17460v1.pdf",
        "Categories": [
            [
                "quant-ph",
                "physics.ao-ph"
            ]
        ],
        "Link": "http://arxiv.org/abs/2210.17460v1",
        "arXiv ID": "2210.17460v1"
    },
    {
        "title": "Machine Learning Enhanced Blockchain Consensus with Transaction\n  Prioritization for Smart Cities",
        "Published: ": "2021-07-20T00:57:30Z",
        "abstract": "In the given technology-driven era, smart cities are the next frontier of\ntechnology, aiming at improving the quality of people's lives. Many research\nworks focus on future smart cities with a holistic approach towards smart city\ndevelopment. In this paper, we introduce such future smart cities that leverage\nblockchain technology in areas like data security, energy and waste management,\ngovernance, transport, supply chain, including emergency events, and\nenvironmental monitoring. Blockchain, being a decentralized immutable ledger,\nhas the potential to promote the development of smart cities by guaranteeing\ntransparency, data security, interoperability, and privacy. Particularly, using\nblockchain in emergency events will provide interoperability between many\nparties involved in the response, will increase timeliness of services, and\nestablish transparency. In that case, if a current fee-based or\nfirst-come-first-serve-based processing is used, emergency events may get\ndelayed in being processed due to competition, and thus, threatening people's\nlives. Thus, there is a need for transaction prioritization based on the\npriority of information and quick creation of blocks (variable interval block\ncreation mechanism). Also, since the leaders ensure transaction prioritization\nwhile generating blocks, leader rotation and proper election procedure become\nimportant for the transaction prioritization process to take place honestly and\nefficiently. In our consensus protocol, we deploy a machine learning (ML)\nalgorithm to achieve efficient leader election and design a novel dynamic block\ncreation algorithm. Also, to ensure honest assessment from the followers on the\nblocks generated by the leaders, a peer-prediction-based verification mechanism\nis proposed. Both security analysis and simulation experiments are carried out\nto demonstrate the robustness and accuracy of our proposed scheme.",
        "author": [
            "S. Valli Sanghami",
            "John J. Lee",
            "Qin Hu"
        ],
        "pdfLink": "http://arxiv.org/pdf/2107.10242v1.pdf",
        "Categories": [
            [
                "cs.CR"
            ]
        ],
        "Link": "http://arxiv.org/abs/2107.10242v1",
        "arXiv ID": "2107.10242v1"
    },
    {
        "title": "Predicting the Computational Cost of Deep Learning Models",
        "Published: ": "2018-11-28T23:36:50Z",
        "abstract": "Deep learning is rapidly becoming a go-to tool for many artificial\nintelligence problems due to its ability to outperform other approaches and\neven humans at many problems. Despite its popularity we are still unable to\naccurately predict the time it will take to train a deep learning network to\nsolve a given problem. This training time can be seen as the product of the\ntraining time per epoch and the number of epochs which need to be performed to\nreach the desired level of accuracy. Some work has been carried out to predict\nthe training time for an epoch -- most have been based around the assumption\nthat the training time is linearly related to the number of floating point\noperations required. However, this relationship is not true and becomes\nexacerbated in cases where other activities start to dominate the execution\ntime. Such as the time to load data from memory or loss of performance due to\nnon-optimal parallel execution. In this work we propose an alternative approach\nin which we train a deep learning network to predict the execution time for\nparts of a deep learning network. Timings for these individual parts can then\nbe combined to provide a prediction for the whole execution time. This has\nadvantages over linear approaches as it can model more complex scenarios. But,\nalso, it has the ability to predict execution times for scenarios unseen in the\ntraining data. Therefore, our approach can be used not only to infer the\nexecution time for a batch, or entire epoch, but it can also support making a\nwell-informed choice for the appropriate hardware and model.",
        "author": [
            "Daniel Justus",
            "John Brennan",
            "Stephen Bonner",
            "Andrew Stephen McGough"
        ],
        "pdfLink": "http://arxiv.org/pdf/1811.11880v1.pdf",
        "Categories": [
            [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1811.11880v1",
        "arXiv ID": "1811.11880v1"
    },
    {
        "title": "Mixed Membership Word Embeddings for Computational Social Science",
        "Published: ": "2017-05-20T23:45:54Z",
        "abstract": "Word embeddings improve the performance of NLP systems by revealing the\nhidden structural relationships between words. Despite their success in many\napplications, word embeddings have seen very little use in computational social\nscience NLP tasks, presumably due to their reliance on big data, and to a lack\nof interpretability. I propose a probabilistic model-based word embedding\nmethod which can recover interpretable embeddings, without big data. The key\ninsight is to leverage mixed membership modeling, in which global\nrepresentations are shared, but individual entities (i.e. dictionary words) are\nfree to use these representations to uniquely differing degrees. I show how to\ntrain the model using a combination of state-of-the-art training techniques for\nword embeddings and topic models. The experimental results show an improvement\nin predictive language modeling of up to 63% in MRR over the skip-gram, and\ndemonstrate that the representations are beneficial for supervised learning. I\nillustrate the interpretability of the models with computational social science\ncase studies on State of the Union addresses and NIPS articles.",
        "author": [
            "James Foulds"
        ],
        "pdfLink": "http://arxiv.org/pdf/1705.07368v3.pdf",
        "Categories": [
            [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        ],
        "Link": "http://arxiv.org/abs/1705.07368v3",
        "arXiv ID": "1705.07368v3"
    },
    {
        "title": "A Fixed-Point of View on Gradient Methods for Big Data",
        "Published: ": "2017-06-29T17:46:50Z",
        "abstract": "Interpreting gradient methods as fixed-point iterations, we provide a\ndetailed analysis of those methods for minimizing convex objective functions.\nDue to their conceptual and algorithmic simplicity, gradient methods are widely\nused in machine learning for massive data sets (big data). In particular,\nstochastic gradient methods are considered the de- facto standard for training\ndeep neural networks. Studying gradient methods within the realm of fixed-point\ntheory provides us with powerful tools to analyze their convergence properties.\nIn particular, gradient methods using inexact or noisy gradients, such as\nstochastic gradient descent, can be studied conveniently using well-known\nresults on inexact fixed-point iterations. Moreover, as we demonstrate in this\npaper, the fixed-point approach allows an elegant derivation of accelerations\nfor basic gradient methods. In particular, we will show how gradient descent\ncan be accelerated by a fixed-point preserving transformation of an operator\nassociated with the objective function.",
        "author": [
            "Alexander Jung"
        ],
        "pdfLink": "http://arxiv.org/pdf/1706.09880v4.pdf",
        "Categories": [
            [
                "stat.ML"
            ]
        ],
        "Link": "http://arxiv.org/abs/1706.09880v4",
        "arXiv ID": "1706.09880v4"
    }
]